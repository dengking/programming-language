{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\u5173\u4e8e\u672c\u5de5\u7a0b programming language\uff08\u7f16\u7a0b\u8bed\u8a00\uff09\u662f\u6211\u4eec\uff08\u8f6f\u4ef6\u5de5\u7a0b\u5e08\uff09\u8d56\u4ee5\u751f\u5b58\u7684\u5de5\u5177\uff0c\u6211\u4eec\u9700\u8981\u597d\u597d\u5730\u5b66\u4e60\u5b83\u3002\u672c\u5de5\u7a0b\u603b\u7ed3programming language\u7684\u4e00\u4e9b\u7406\u8bba\uff0c\u603b\u7ed3\u6211\u6240\u638c\u63e1\u7684programming language\u3002","title":"Home"},{"location":"#_1","text":"programming language\uff08\u7f16\u7a0b\u8bed\u8a00\uff09\u662f\u6211\u4eec\uff08\u8f6f\u4ef6\u5de5\u7a0b\u5e08\uff09\u8d56\u4ee5\u751f\u5b58\u7684\u5de5\u5177\uff0c\u6211\u4eec\u9700\u8981\u597d\u597d\u5730\u5b66\u4e60\u5b83\u3002\u672c\u5de5\u7a0b\u603b\u7ed3programming language\u7684\u4e00\u4e9b\u7406\u8bba\uff0c\u603b\u7ed3\u6211\u6240\u638c\u63e1\u7684programming language\u3002","title":"\u5173\u4e8e\u672c\u5de5\u7a0b"},{"location":"Summary-of-my-programming-language/","text":"Summary of my programming language \u622a\u6b62\u76ee\u524d\u4e3a\u6b62\uff0c\u6211\u5df2\u7ecf\u63a5\u89e6\u4e86\u591a\u79cdprogramming language\uff0c\u73b0\u5728\u975e\u5e38\u6709\u5fc5\u8981\u5bf9\u8fd9\u4e9bprogramming language\u7684\u540c\u4e0e\u5f02\u8fdb\u884c\u603b\u7ed3\u4e86\uff1b \u4e3b\u8981\u4ee5 python \uff0c c \uff0c c++ \u6765\u4f5c\u4e3a\u7814\u7a76\u5bf9\u8c61\u3002 \u5bf9\u5b83\u4eec\u7684\u5bf9\u6bd4\uff0c\u9700\u8981\u4ece\u591a\u4e2a\u89d2\u5ea6\u6765\u8fdb\u884c\u5c55\u5f00\uff0c\u4e3b\u8981\u4ee5\u300aCompilers Principles Techniques and Tools 2 nd .pdf\u300b\u4e3a\u84dd\u672c\uff0c\u7136\u540e\u52a0\u4e0a\u4e00\u4e9b\u6211\u4e4b\u524d\u5728computer science\u4e2d\u6240\u603b\u7ed3\u7684\u5185\u5bb9\uff1b compiler and interpreter \u53c2\u8003\u5185\u5bb9\uff1a \u300aCompilers Principles Techniques and Tools 2 nd .pdf\u300bchapter 1.1 Language Processors \u9996\u5148\u9700\u8981\u51c6\u786e\u5730\u7406\u89e3compiler\u548cinterpreter\uff1b Simply stated, a compiler is a program that can read a program in one language , the source language and translate it into an equivalent program in another language , the target language ; source program | \\|/ {Compiler} | \\|/ target program c \u548c c++ \u4e2d\uff0ccompiler\u7684target language\u662fexecutable machine-language program\uff1b python\u4e2d\uff0ccompiler\u7684target language\u662f bytecode .\uff08\u53c2\u89c1 Is Python interpreted or compiled? Yes. \uff09 \u663e\u7136\uff0c c \u548c c++ \u7ed3\u679c\u7f16\u8bd1\u8fbe\u5230\u7684program\u662f\u53ef\u4ee5\u76f4\u63a5\u6267\u884c\u7684\uff0c\u800cpython\u7ed3\u679c\u7f16\u8bd1\u751f\u6210\u7684program\u5219\u9700\u8981python interpreter\u7684\u89e3\u91ca\u6267\u884c\uff1b Programming Language Basics declaration\uff0cdefinition\uff0cstatement\uff0cexpression declaration\u548cdefinition\u662f\u4e24\u4e2a\u975e\u5e38\u63a5\u8fd1\u4e14\u5bb9\u6613\u6df7\u6dc6\u7684\u6982\u5ff5\uff0c\u5728\u6b64\u4e4b\u524d\u5148\u5fc5\u987b\u628a\u8fd9\u4e24\u4e2a\u641e\u6e05\u695a\uff1b \u5728 c \u548c c++ \u4e2d\uff0c\u6709\u5934\u6587\u4ef6\uff08header file .h \uff09\u548c\u6e90\u4ee3\u7801\u6587\u4ef6\uff08source code file .c \u548c .cpp \uff09\u6587\u4ef6\uff0c\u5728\u8fd9\u4e24\u95e8\u8bed\u8a00\u4e2d\u540c\u65f6\u5305\u542bdeclaration\u548cdefinition\uff0c\u5e76\u4e14\u533a\u5206\u5b83\u4eec\uff1b\u800cpython\u5219\u53ea\u6709 .py \u6587\u4ef6\uff0c\u5e76\u4e14 python lacks declaration \uff0c\u5373python\u4e2d\u53ea\u6709definition\uff1b \u5728 compiler/declaration\uff0cdefinition\uff0cstatement\uff0cexpression \u4e2d\u5bf9\u8fd9\u4e2a\u95ee\u9898\u8fdb\u884c\u4e86\u4e13\u95e8\u7684\u5206\u6790\uff1b resource management \u6b64\u5904\u7684resource\u4e3a\uff1anetwork connection\uff0cfile c++ \u4e2d\u4f7f\u7528RAII\uff0cpython\u4e2d\u4f7f\u7528 with \uff0c\u800c c \u4e2d\uff0c\u5219\u6ca1\u6709\u7279\u522b\u7684\u673a\u5236\uff0c\u6240\u6709\u7684\u4e00\u5207\u90fd\u9700\u8981programmer\u663e\u793a\u5730\u8c03\u7528\u4e0e\u6267\u884c\uff0cc\u4e2d\u7ecf\u5e38\u4f7f\u7528 goto \u3002 \u5bf9\u8d44\u6e90\u7684\u7ba1\u7406\u8bbe\u8ba1\u5230\u4e00\u5bf9\u76f8\u53cd\u7684\u64cd\u4f5c\uff1a new and delete lock and unlock \u4e0d\u540c\u7684\u8bed\u8a00\u6709\u4e0d\u540c\u7684\u652f\u6301\u65b9\u5f0f\uff1a C++ RAII python with \u5728\u5de5\u7a0b Linux-OS \u7684 Linux-OS's-multitasking \u4e2d\u7684process-resource\u7ae0\u8282\u5bf9\u6b64\u8fdb\u884c\u4e86\u63cf\u8ff0\u3002 \u601d\u8003\uff1a\u53ef\u4ee5\u770b\u5230\uff0c\u65e0\u8bbapython\u8fd8\u662fc++\uff0cresource management\u65b9\u6848\u90fd\u662f\u6d89\u53ca\u4e00\u5bf9\u76f8\u53cd\u7684\u64cd\u4f5c\uff0cc++\u7684resource management\u65b9\u6848\u4f7f\u7528\u7684\u57fa\u4e8escope\u7684\uff0c\u800cpython\u7684scope\u975e\u5e38\u7b80\u5355\uff0c\u6240\u4ee5\u5b83\u4f7f\u7528\u7684\u662fmagic function\u7684\u65b9\u5f0f\u3002 magic function\u7684\u4f7f\u7528 c\u4e2d\u538b\u6839\u5c31\u6ca1\u6709magic function\uff0cc compiler\u5728\u7f16\u8bd1source code\u7684\u65f6\u5019\uff0c\u65e0\u9700\u4e3a\u5176\u751f\u6210\u6216\u8005\u9009\u62e9\u6307\u5b9a\u7684\u51fd\u6570\uff1b c++ \u4e2d\u4f7f\u7528\u4e86magic function\uff0c\u6bd4\u5982\u5b83\u652f\u6301\u5404\u79cdconstructor\uff0c\u5176\u5b9econstructor\u5c31\u662f\u6700\u6700\u5178\u578b\u7684magic function\uff1b c++ compiler\u4f1a\u5728\u7ffb\u8bd1\u4ee3\u7801\u7684\u8fc7\u7a0b\u4e2d\uff0c\u6839\u636e\u9700\u6c42\u4e3a\u5728\u7f16\u8bd1\u751f\u6210\u7684\u4ee3\u7801\u52a0\u5165constructor\uff0c\u6bd4\u5982 MyClass a \uff0c\u7f16\u8bd1\u5668\u5728\u7f16\u8bd1\u8fc7\u7a0b\u4e2d\uff0c\u5c31\u4f1a\u52a0\u5165constructor\uff1b\u663e\u7136\uff0c c++ \u4e2d\uff0c\u8fd9\u4e9bmagic function\u7684\u9009\u62e9\u662fstatic\u7684\uff0c\u662f\u5728compile time\u7684\uff1b\u5e76\u4e14c++\u533a\u5206copy\u8bed\u4e49\u548cmove\u8bed\u4e49\uff0c\u7f16\u8bd1\u5668\u80fd\u591f\u6839\u636esource code\u9009\u62e9\u6b63\u786e\u7684constructor\uff1b DefaultConstructible specifies that an object of the type can be default constructed (named requirement) MoveConstructible (C++11) specifies that an object of the type can be constructed from rvalue (named requirement) CopyConstructible specifies that an object of the type can be constructed from lvalue (named requirement) MoveAssignable (C++11) specifies that an object of the type can be assigned from rvalue (named requirement) CopyAssignable specifies that an object of the type can be assigned from lvalue (named requirement) Destructible specifies that an object of the type can be destroyed (named requirement) python\u4e2d\u5219\u5b58\u5728\u7740\u5927\u91cf\u7684magic function\uff0c\u6bd4\u5982\u4e3a\u4e86\u652f\u6301iteration\uff0c\u652f\u6301index\u7b49\uff1bpython\u4f7f\u7528\u7684\u662fname lookup\uff0c\u5bf9magic function\u7684\u9009\u62e9\u4e5f\u662f\u4f7f\u7528\u7684name lookup\uff0c\u5e76\u4e14python\u7684name lookup\u662f\u53d1\u751f\u5728runtime\uff0c\u6240\u4ee5python\u7684magic function\u662f\u53d1\u751f\u5728runtime\u7684\uff1b c++ \u6bd4\u8f83\u590d\u6742\uff0c\u5e76\u4e14\u5b83\u7684\u7c7b\u578b\u9650\u5236\u975e\u5e38\u4e25\u683c\uff0c\u5e76\u4e14\u5b83\u7684\u7c7b\u578b\u9650\u5236\u90fd\u662f\u901a\u8fc7compiler\u6765\u8fdb\u884c\u7684\uff1b\u5b83\u7684standard library\u5bf9\u4e8e\u64cd\u4f5c\u7684**\u7c7b\u578b**\u4f1a\u63d0\u51fa named requirement \uff0c\u5982\u679c\u5bf9\u5e94\u7684\u7c7b\u578b\u4e0d\u6ee1\u8db3standard library\u6240\u8981\u6c42\u7684 named requirement \u7684\u8bdd\uff0c\u5219compiler\u4f1a\u62a5\u9519\uff1b\u5982\u4e0b\u662f\u4e00\u4e9b\u5178\u578b\u7684 named requirement \uff0c\u5176\u5b9e\u5982\u679cprogrammer\u5728\u8fdb\u884cprogram\u7684\u65f6\u5019\uff0c\u5982\u679c\u8981\u60f3\u8ba9\u81ea\u5df1\u5b9a\u4e49\u7684type\u6ee1\u8db3\u5bf9\u5e94\u7684requirement\u7684\u8bdd\uff0c\u5c31\u9700\u8981\u63d0\u4f9b\u5bf9\u5e94\u7684function\uff1b SUMMARY : \u5173\u4e8e c++ \u7684 named requirement \uff0c\u901a\u8fc7\u8fd9\u7bc7\u6587\u7ae0\u5c31\u53ef\u4ee5\u8fdb\u884c\u7406\u89e3\uff1a C++ vector emplace_back calls copy constructor python\u548c c++ \u4e0d\u540c\uff0c\u5b83\u4e5f\u662f\u5f3a\u7c7b\u578b\u7684\uff0c\u4f46\u662fpython\u662fduck type\uff0cpython\u7684\u7c7b\u578b\u9650\u5236\u4e0d\u662f\u901a\u8fc7\u5b83\u7684compiler\u6765\u8fdb\u884c\u7684\uff0c\u5b83\u7684**\u7c7b\u578b\u9650\u5236**\u662f\u901a\u8fc7runtime\u7684name lookup\uff0c\u4e3b\u8981\u5bf9\u8c61\u5b9a\u4e49\u4e86\u5b83\u6240\u671f\u671b\u7684magic function\uff0c\u5219\u5b83\u5c31\u8ba4\u4e3a\u8fd9\u4e2a\u5bf9\u8c61\u6ee1\u8db3\u4e86\u81ea\u5df1\u7684**\u7c7b\u578b\u9650\u5236**\uff1b \u548cpython\u4e0e c++ \u76f8\u6bd4\uff0c c \u5219\u6ca1\u6709\u5982\u6b64\u90fd\u7684\u9650\u5236\uff0c c \u8bed\u8a00\u4e2d\uff0c\u538b\u6839\u5c31\u6ca1\u6709magic method\uff1b type system constant c++ \u548c c \u4e2d\u4f7f\u7528 const (computer programming) \u6765\u4f5c\u4e3a Type qualifier python\u4e2d\u91c7\u53d6\u7684\u662f\u5b8c\u5168\u4e0d\u540c\u7684\u65b9\u5f0f\uff0cpython\u4e2d\u6ca1\u6709 Type qualifier \uff0cpython\u4e2d\uff0ctype\u5c31\u51b3\u5b9a\u4e86\u6570\u636e\u7684const\uff0c\u5e76\u4e14\u5728python\u4e2d\uff0c\u538b\u6839\u5c31\u4e0d\u53ebconst\uff0cpython\u4e2d\u53eb\u505a*mutable*\uff0c\u5728python\u7684Data model \u00b6 \u4e2d\u5bf9\u8fd9\u4e2a\u95ee\u9898\u8fdb\u884c\u4e86\u63cf\u8ff0\uff1bAn object\u2019s mutability is determined by its type;numbers, strings and tuples are immutable, while dictionaries and lists are mutable. THINKING : \u5728c\u4e2d\uff0c\u4f55\u65f6\u5fc5\u987b\u8981\u4f7f\u7528const\uff1f\u5982\u901a\u8fc7 const char * \u6765\u5f15\u7528\u4e00\u4e2a c string Explicit or implicit declaration and inference \u5173\u4e8e\u8fd9\u4e00\u70b9\uff0c c \uff0c c++ \u548cpython\u91c7\u7528\u4e86\u5b8c\u5168\u76f8\u53cd\u7684\u65b9\u5f0f\uff1b C and C++ , require type declarations : the programmer must explicitly associate each variable with a specific type. \u800cpython\u5219\u65e0\u9700type declaration\uff1b Type safety c\u8bed\u8a00\u5373\u975etype safe\u4e5f\u975ememory safe\uff1b Type checking c \u548c c++ \u6240\u91c7\u7528\u7684\u662fstatic check\uff0c\u800cpython\u6240\u91c7\u7528\u7684\u662fdynamic type\uff1b type operation programming language\u9700\u8981\u63d0\u4f9binterface\u6765\u4f9b\u7528\u6237\u5bf9type\u8fdb\u884coperate\uff0c\u4e0b\u9762\u603b\u7ed3\u4e00\u4e0b\u5e38\u89c1\u7684type operation\u3002 Type introspection \u5176\u5b9e\u7b80\u5355\u6765\u8bf4\uff0c \u5c31\u662finstance of\uff0c\u5373object\u786e\u5b9a\u5b83\u7684type\uff0c\u8fd9\u4e5f\u53eb\u505aintrospection\u3002 type conversion and type cast scope \u8fd9\u4e09\u79cdprogramming language\u91c7\u7528\u7684\u90fd\u662fstatic scope\uff0c\u90fd\u662f\u57fa\u4e8eblock scope python display vs c , c++ Initialization c Initialization , c++ Initialization \u5b9e\u73b0\u5bf9variable\u7684initialize\uff1b python lack declaration\uff0c\u4f46\u662fpython\u4e2d\u4e5f\u63d0\u4f9b\u4e86\u7c7b\u4f3c\u7684\u8bed\u6cd5\uff0cpython\u8fd9\u79cd\u53eb\u505a display exception c++ \u548cpython\u90fd\u63d0\u4f9b\u4e86exception\u673a\u5236\uff1b\u7531\u4e8epython\u662f\u7531python interpreter\u89e3\u91ca\u6267\u884c\uff0c\u800c c++ \u7a0b\u5e8f\u662f\u7531OS\u76f4\u63a5\u8fd0\u884c\uff0c\u56e0\u6b64\u4e24\u8005\u7684exception\u548cOS\u4e4b\u95f4\u7684\u5173\u8054\u662f\u4e0d\u540c\u7684\uff1bpython\u4e2d\u7684exception\u4f1a\u5bfc\u81f4python interpreter\u7684\u6267\u884c\u8def\u5f84\u6539\u53d8\uff0c\u57fa\u672c\u4e0a\u4e0d\u4f1a\u6d89\u53ca\u5230OS\uff1b\u800c c++ \u4e2d\u7684exception\uff0c\u5219\u4f1a\u8f6c\u6362\u4e3aOS\u7684signal\uff0c\u6700\u7ec8\u53ef\u80fd\u5bfc\u81f4\u7a0b\u5e8f\u7ec8\u6b62\u8fd0\u884c\uff1b c\u8bed\u8a00\u6ca1\u6709\uff1b python and c++ pMeanRate = tanhx(pMeanRate, 2); \u8fd9\u6bb5\u4ee3\u7801\u5728 c++ \u4e2d\u662f\u975e\u5e38\u597d\u7406\u89e3\u7684\uff1a pMeanRate \u662f\u4e00\u4e2a\u5de6\u503c\uff0c\u6240\u4ee5\u5b83\u65e2\u80fd\u591f\u88abread\uff0c\u4e5f\u80fd\u591f\u88abwrite\uff1b\u4f46\u662f\u5728python\u4e2d\uff0c = \u6240\u8868\u793a\u7684\u662fname bind\uff1b C++17 Structured binding \u548c python Assignment \u521d\u6b21\u63a5\u89e6c++ 17\u5f15\u5165\u7684structured binding\u7279\u6027\uff0c\u6211\u7b2c\u4e00\u60f3\u6cd5\u5c31\u662f\u5b83\u975e\u5e38\u7c7b\u4f3c\u4e8epython\u7684tuple assignment\u3002 C++11 range-for VS python for C++11\u4e2d\u5f15\u5165\u7684range-for\u975e\u5e38\u7c7b\u4f3c\u4e8epython\u4e2d\u7684 for \u3002 c++ iteration vs python iteration python\u901a\u8fc7magic function __next__ \u3001 __iter__ \u6765\u652f\u6301iterator\uff0cc++\u663e\u5f0f\u5b9a\u4e49\u4e86iterator\u7c7b\u3002 reverse iteration c++\u901a\u8fc7 reverse_iterator \uff0cpython\u901a\u8fc7builtin reverse \u6765\u5b9e\u73b0\u3002 \u8bed\u8a00\u7684\u6807\u51c6\u4e0e\u5b9e\u73b0 \u4e00\u79cd\u6807\u51c6\u53ef\u4ee5\u6709\u591a\u79cd\u5b9e\u73b0\u3002 python\u548cc++\u7684\u5b9e\u73b0\u65b9\u5f0f\u662f\u5b8c\u5168\u4e0d\u540c\u7684\uff0cpython\u662f\u89e3\u91ca\u6267\u884c\u7684\uff0c\u800cc++\u662f\u76f4\u63a5\u6267\u884c\u7684\u3002\u8fd9\u5c31\u6ce8\u5b9a\u4e86Python\u7684\u5f88\u591a\u4e8b\u60c5\u662finterpreter\u5b8c\u6210\u7684\uff0c\u800cc++\u7684\u5f88\u591a\u4e8b\u60c5\u662fcompiler\u5b8c\u6210\u7684\u3002\u524d\u8005\u662f\u9759\u6001\u7684\uff0c\u540e\u8005\u662f\u52a8\u6001\u7684\u3002\u53ef\u4ee5\u770b\u5230\uff0cPython\u7684\u6307\u4ee4\u662f\u975e\u5e38\u62bd\u8c61\u7684\u3002python\u4e2d\u7531interpreter\u6765\u9009\u62e9magic function\uff0c\u800cc++\u4e2d\u7531compiler\u6765\u9009\u62e9magic function\u3002 C++ \u7684\u201c\u9759\u201d VS python\u7684\u201c\u52a8\u201d C++\u7684compile\u4fdd\u8bc1\u8fdb\u884c\u4e86\u4e25\u683c\u7684\u68c0\u67e5 python\u5219\u662f\u5b8c\u5168\u52a8\u6001\u7684\uff0c\u5b83\u6709 EAFP \u3001 LBYL \u53c2\u89c1\uff1a Idiomatic Python: EAFP versus LBYL function and -> python\u7684Function definitions \u00b6 \u548cc++\u7684 Function declaration \u4e2d\uff0c\u90fd\u5f15\u5165\u4e86 -> \u7b26\u5408\uff0c\u4e24\u79cd\u8bed\u8a00\u4e2d -> \u7684\u4e00\u4e2a\u5171\u6027\u662f\uff1a -> \u5bf9\u51fd\u6570\u7684\u8fd4\u56de\u7c7b\u578b\u8fdb\u884c\u8bf4\u660e\uff0cc++\u4e2d\u5c06\u6b64\u79f0\u4e3a\u201c Trailing return type\u201d\uff0cpython\u4e2d\u5c06\u6b64\u79f0\u4e3a \u201c\u201creturn\u201d annotation\u201d\u3002 \u4e0e\u6b64\u7c7b\u4f3c\u7684\u662f\uff0cJavaScript\u4e2d\u6709 => \u7b26\u5408\uff0c\u53c2\u89c1\u7ef4\u57fa\u767e\u79d1 JavaScript \u3002 specifier python\u4e2d\u57fa\u672c\u4e0a\u6ca1\u6709\u4ec0\u4e48specifier\uff0c\u4f46\u662f\u5728 c++ \u548c c \u4e2d\u5b58\u5728\u7740\u5927\u91cf\u7684specifier\uff0c\u4e3a\u4ec0\u4e48\u5462\uff1f \u56e0\u4e3ac++\u548cc\u662fsystem language\uff0c\u5b83\u4eec\u9700\u8981\u5bf9process\u8fd0\u884c\u7684\u5e95\u5c42\u7ec6\u8282\u8fdb\u884c\u63cf\u8ff0\u3001\u8fdb\u884c\u63a7\u5236\uff0c\u8fd9\u4e9bspecifier\u5c31\u662f\u51fa\u4e8e\u6b64\u76ee\u7684\u7684\u3002 \u5982\u4e0b\u662f\u5bf9specifier\u7684\u5206\u7c7b\uff1a Access modifiers explicit specifier inline specifier storage class specifiers \u4f7f\u7528specifier\u6765\u5bf9\u67d0\u4e00\u65b9\u9762\u8fdb\u884c\u63cf\u8ff0\u3002 name \u5728cppreference Declarations \u4e2d\u5173\u4e8e\u201cname\u201d\u7684\u63cf\u8ff0 Declarations introduce (or re-introduce) names into the C++ program.","title":"Summary-of-my-programming-language"},{"location":"Summary-of-my-programming-language/#summary-of-my-programming-language","text":"\u622a\u6b62\u76ee\u524d\u4e3a\u6b62\uff0c\u6211\u5df2\u7ecf\u63a5\u89e6\u4e86\u591a\u79cdprogramming language\uff0c\u73b0\u5728\u975e\u5e38\u6709\u5fc5\u8981\u5bf9\u8fd9\u4e9bprogramming language\u7684\u540c\u4e0e\u5f02\u8fdb\u884c\u603b\u7ed3\u4e86\uff1b \u4e3b\u8981\u4ee5 python \uff0c c \uff0c c++ \u6765\u4f5c\u4e3a\u7814\u7a76\u5bf9\u8c61\u3002 \u5bf9\u5b83\u4eec\u7684\u5bf9\u6bd4\uff0c\u9700\u8981\u4ece\u591a\u4e2a\u89d2\u5ea6\u6765\u8fdb\u884c\u5c55\u5f00\uff0c\u4e3b\u8981\u4ee5\u300aCompilers Principles Techniques and Tools 2 nd .pdf\u300b\u4e3a\u84dd\u672c\uff0c\u7136\u540e\u52a0\u4e0a\u4e00\u4e9b\u6211\u4e4b\u524d\u5728computer science\u4e2d\u6240\u603b\u7ed3\u7684\u5185\u5bb9\uff1b","title":"Summary of my programming language"},{"location":"Summary-of-my-programming-language/#compiler-and-interpreter","text":"\u53c2\u8003\u5185\u5bb9\uff1a \u300aCompilers Principles Techniques and Tools 2 nd .pdf\u300bchapter 1.1 Language Processors \u9996\u5148\u9700\u8981\u51c6\u786e\u5730\u7406\u89e3compiler\u548cinterpreter\uff1b Simply stated, a compiler is a program that can read a program in one language , the source language and translate it into an equivalent program in another language , the target language ; source program | \\|/ {Compiler} | \\|/ target program c \u548c c++ \u4e2d\uff0ccompiler\u7684target language\u662fexecutable machine-language program\uff1b python\u4e2d\uff0ccompiler\u7684target language\u662f bytecode .\uff08\u53c2\u89c1 Is Python interpreted or compiled? Yes. \uff09 \u663e\u7136\uff0c c \u548c c++ \u7ed3\u679c\u7f16\u8bd1\u8fbe\u5230\u7684program\u662f\u53ef\u4ee5\u76f4\u63a5\u6267\u884c\u7684\uff0c\u800cpython\u7ed3\u679c\u7f16\u8bd1\u751f\u6210\u7684program\u5219\u9700\u8981python interpreter\u7684\u89e3\u91ca\u6267\u884c\uff1b","title":"compiler and interpreter"},{"location":"Summary-of-my-programming-language/#programming-language-basics","text":"","title":"Programming Language Basics"},{"location":"Summary-of-my-programming-language/#declarationdefinitionstatementexpression","text":"declaration\u548cdefinition\u662f\u4e24\u4e2a\u975e\u5e38\u63a5\u8fd1\u4e14\u5bb9\u6613\u6df7\u6dc6\u7684\u6982\u5ff5\uff0c\u5728\u6b64\u4e4b\u524d\u5148\u5fc5\u987b\u628a\u8fd9\u4e24\u4e2a\u641e\u6e05\u695a\uff1b \u5728 c \u548c c++ \u4e2d\uff0c\u6709\u5934\u6587\u4ef6\uff08header file .h \uff09\u548c\u6e90\u4ee3\u7801\u6587\u4ef6\uff08source code file .c \u548c .cpp \uff09\u6587\u4ef6\uff0c\u5728\u8fd9\u4e24\u95e8\u8bed\u8a00\u4e2d\u540c\u65f6\u5305\u542bdeclaration\u548cdefinition\uff0c\u5e76\u4e14\u533a\u5206\u5b83\u4eec\uff1b\u800cpython\u5219\u53ea\u6709 .py \u6587\u4ef6\uff0c\u5e76\u4e14 python lacks declaration \uff0c\u5373python\u4e2d\u53ea\u6709definition\uff1b \u5728 compiler/declaration\uff0cdefinition\uff0cstatement\uff0cexpression \u4e2d\u5bf9\u8fd9\u4e2a\u95ee\u9898\u8fdb\u884c\u4e86\u4e13\u95e8\u7684\u5206\u6790\uff1b","title":"declaration\uff0cdefinition\uff0cstatement\uff0cexpression"},{"location":"Summary-of-my-programming-language/#resource-management","text":"\u6b64\u5904\u7684resource\u4e3a\uff1anetwork connection\uff0cfile c++ \u4e2d\u4f7f\u7528RAII\uff0cpython\u4e2d\u4f7f\u7528 with \uff0c\u800c c \u4e2d\uff0c\u5219\u6ca1\u6709\u7279\u522b\u7684\u673a\u5236\uff0c\u6240\u6709\u7684\u4e00\u5207\u90fd\u9700\u8981programmer\u663e\u793a\u5730\u8c03\u7528\u4e0e\u6267\u884c\uff0cc\u4e2d\u7ecf\u5e38\u4f7f\u7528 goto \u3002 \u5bf9\u8d44\u6e90\u7684\u7ba1\u7406\u8bbe\u8ba1\u5230\u4e00\u5bf9\u76f8\u53cd\u7684\u64cd\u4f5c\uff1a new and delete lock and unlock \u4e0d\u540c\u7684\u8bed\u8a00\u6709\u4e0d\u540c\u7684\u652f\u6301\u65b9\u5f0f\uff1a C++ RAII python with \u5728\u5de5\u7a0b Linux-OS \u7684 Linux-OS's-multitasking \u4e2d\u7684process-resource\u7ae0\u8282\u5bf9\u6b64\u8fdb\u884c\u4e86\u63cf\u8ff0\u3002 \u601d\u8003\uff1a\u53ef\u4ee5\u770b\u5230\uff0c\u65e0\u8bbapython\u8fd8\u662fc++\uff0cresource management\u65b9\u6848\u90fd\u662f\u6d89\u53ca\u4e00\u5bf9\u76f8\u53cd\u7684\u64cd\u4f5c\uff0cc++\u7684resource management\u65b9\u6848\u4f7f\u7528\u7684\u57fa\u4e8escope\u7684\uff0c\u800cpython\u7684scope\u975e\u5e38\u7b80\u5355\uff0c\u6240\u4ee5\u5b83\u4f7f\u7528\u7684\u662fmagic function\u7684\u65b9\u5f0f\u3002","title":"resource management"},{"location":"Summary-of-my-programming-language/#magic-function","text":"c\u4e2d\u538b\u6839\u5c31\u6ca1\u6709magic function\uff0cc compiler\u5728\u7f16\u8bd1source code\u7684\u65f6\u5019\uff0c\u65e0\u9700\u4e3a\u5176\u751f\u6210\u6216\u8005\u9009\u62e9\u6307\u5b9a\u7684\u51fd\u6570\uff1b c++ \u4e2d\u4f7f\u7528\u4e86magic function\uff0c\u6bd4\u5982\u5b83\u652f\u6301\u5404\u79cdconstructor\uff0c\u5176\u5b9econstructor\u5c31\u662f\u6700\u6700\u5178\u578b\u7684magic function\uff1b c++ compiler\u4f1a\u5728\u7ffb\u8bd1\u4ee3\u7801\u7684\u8fc7\u7a0b\u4e2d\uff0c\u6839\u636e\u9700\u6c42\u4e3a\u5728\u7f16\u8bd1\u751f\u6210\u7684\u4ee3\u7801\u52a0\u5165constructor\uff0c\u6bd4\u5982 MyClass a \uff0c\u7f16\u8bd1\u5668\u5728\u7f16\u8bd1\u8fc7\u7a0b\u4e2d\uff0c\u5c31\u4f1a\u52a0\u5165constructor\uff1b\u663e\u7136\uff0c c++ \u4e2d\uff0c\u8fd9\u4e9bmagic function\u7684\u9009\u62e9\u662fstatic\u7684\uff0c\u662f\u5728compile time\u7684\uff1b\u5e76\u4e14c++\u533a\u5206copy\u8bed\u4e49\u548cmove\u8bed\u4e49\uff0c\u7f16\u8bd1\u5668\u80fd\u591f\u6839\u636esource code\u9009\u62e9\u6b63\u786e\u7684constructor\uff1b DefaultConstructible specifies that an object of the type can be default constructed (named requirement) MoveConstructible (C++11) specifies that an object of the type can be constructed from rvalue (named requirement) CopyConstructible specifies that an object of the type can be constructed from lvalue (named requirement) MoveAssignable (C++11) specifies that an object of the type can be assigned from rvalue (named requirement) CopyAssignable specifies that an object of the type can be assigned from lvalue (named requirement) Destructible specifies that an object of the type can be destroyed (named requirement) python\u4e2d\u5219\u5b58\u5728\u7740\u5927\u91cf\u7684magic function\uff0c\u6bd4\u5982\u4e3a\u4e86\u652f\u6301iteration\uff0c\u652f\u6301index\u7b49\uff1bpython\u4f7f\u7528\u7684\u662fname lookup\uff0c\u5bf9magic function\u7684\u9009\u62e9\u4e5f\u662f\u4f7f\u7528\u7684name lookup\uff0c\u5e76\u4e14python\u7684name lookup\u662f\u53d1\u751f\u5728runtime\uff0c\u6240\u4ee5python\u7684magic function\u662f\u53d1\u751f\u5728runtime\u7684\uff1b c++ \u6bd4\u8f83\u590d\u6742\uff0c\u5e76\u4e14\u5b83\u7684\u7c7b\u578b\u9650\u5236\u975e\u5e38\u4e25\u683c\uff0c\u5e76\u4e14\u5b83\u7684\u7c7b\u578b\u9650\u5236\u90fd\u662f\u901a\u8fc7compiler\u6765\u8fdb\u884c\u7684\uff1b\u5b83\u7684standard library\u5bf9\u4e8e\u64cd\u4f5c\u7684**\u7c7b\u578b**\u4f1a\u63d0\u51fa named requirement \uff0c\u5982\u679c\u5bf9\u5e94\u7684\u7c7b\u578b\u4e0d\u6ee1\u8db3standard library\u6240\u8981\u6c42\u7684 named requirement \u7684\u8bdd\uff0c\u5219compiler\u4f1a\u62a5\u9519\uff1b\u5982\u4e0b\u662f\u4e00\u4e9b\u5178\u578b\u7684 named requirement \uff0c\u5176\u5b9e\u5982\u679cprogrammer\u5728\u8fdb\u884cprogram\u7684\u65f6\u5019\uff0c\u5982\u679c\u8981\u60f3\u8ba9\u81ea\u5df1\u5b9a\u4e49\u7684type\u6ee1\u8db3\u5bf9\u5e94\u7684requirement\u7684\u8bdd\uff0c\u5c31\u9700\u8981\u63d0\u4f9b\u5bf9\u5e94\u7684function\uff1b SUMMARY : \u5173\u4e8e c++ \u7684 named requirement \uff0c\u901a\u8fc7\u8fd9\u7bc7\u6587\u7ae0\u5c31\u53ef\u4ee5\u8fdb\u884c\u7406\u89e3\uff1a C++ vector emplace_back calls copy constructor python\u548c c++ \u4e0d\u540c\uff0c\u5b83\u4e5f\u662f\u5f3a\u7c7b\u578b\u7684\uff0c\u4f46\u662fpython\u662fduck type\uff0cpython\u7684\u7c7b\u578b\u9650\u5236\u4e0d\u662f\u901a\u8fc7\u5b83\u7684compiler\u6765\u8fdb\u884c\u7684\uff0c\u5b83\u7684**\u7c7b\u578b\u9650\u5236**\u662f\u901a\u8fc7runtime\u7684name lookup\uff0c\u4e3b\u8981\u5bf9\u8c61\u5b9a\u4e49\u4e86\u5b83\u6240\u671f\u671b\u7684magic function\uff0c\u5219\u5b83\u5c31\u8ba4\u4e3a\u8fd9\u4e2a\u5bf9\u8c61\u6ee1\u8db3\u4e86\u81ea\u5df1\u7684**\u7c7b\u578b\u9650\u5236**\uff1b \u548cpython\u4e0e c++ \u76f8\u6bd4\uff0c c \u5219\u6ca1\u6709\u5982\u6b64\u90fd\u7684\u9650\u5236\uff0c c \u8bed\u8a00\u4e2d\uff0c\u538b\u6839\u5c31\u6ca1\u6709magic method\uff1b","title":"magic function\u7684\u4f7f\u7528"},{"location":"Summary-of-my-programming-language/#type-system","text":"","title":"type system"},{"location":"Summary-of-my-programming-language/#constant","text":"c++ \u548c c \u4e2d\u4f7f\u7528 const (computer programming) \u6765\u4f5c\u4e3a Type qualifier python\u4e2d\u91c7\u53d6\u7684\u662f\u5b8c\u5168\u4e0d\u540c\u7684\u65b9\u5f0f\uff0cpython\u4e2d\u6ca1\u6709 Type qualifier \uff0cpython\u4e2d\uff0ctype\u5c31\u51b3\u5b9a\u4e86\u6570\u636e\u7684const\uff0c\u5e76\u4e14\u5728python\u4e2d\uff0c\u538b\u6839\u5c31\u4e0d\u53ebconst\uff0cpython\u4e2d\u53eb\u505a*mutable*\uff0c\u5728python\u7684Data model \u00b6 \u4e2d\u5bf9\u8fd9\u4e2a\u95ee\u9898\u8fdb\u884c\u4e86\u63cf\u8ff0\uff1bAn object\u2019s mutability is determined by its type;numbers, strings and tuples are immutable, while dictionaries and lists are mutable. THINKING : \u5728c\u4e2d\uff0c\u4f55\u65f6\u5fc5\u987b\u8981\u4f7f\u7528const\uff1f\u5982\u901a\u8fc7 const char * \u6765\u5f15\u7528\u4e00\u4e2a c string","title":"constant"},{"location":"Summary-of-my-programming-language/#explicit-or-implicit-declaration-and-inference","text":"\u5173\u4e8e\u8fd9\u4e00\u70b9\uff0c c \uff0c c++ \u548cpython\u91c7\u7528\u4e86\u5b8c\u5168\u76f8\u53cd\u7684\u65b9\u5f0f\uff1b C and C++ , require type declarations : the programmer must explicitly associate each variable with a specific type. \u800cpython\u5219\u65e0\u9700type declaration\uff1b","title":"Explicit or implicit declaration and inference"},{"location":"Summary-of-my-programming-language/#type-safety","text":"c\u8bed\u8a00\u5373\u975etype safe\u4e5f\u975ememory safe\uff1b","title":"Type safety"},{"location":"Summary-of-my-programming-language/#type-checking","text":"c \u548c c++ \u6240\u91c7\u7528\u7684\u662fstatic check\uff0c\u800cpython\u6240\u91c7\u7528\u7684\u662fdynamic type\uff1b","title":"Type checking"},{"location":"Summary-of-my-programming-language/#type-operation","text":"programming language\u9700\u8981\u63d0\u4f9binterface\u6765\u4f9b\u7528\u6237\u5bf9type\u8fdb\u884coperate\uff0c\u4e0b\u9762\u603b\u7ed3\u4e00\u4e0b\u5e38\u89c1\u7684type operation\u3002","title":"type operation"},{"location":"Summary-of-my-programming-language/#type-introspection","text":"\u5176\u5b9e\u7b80\u5355\u6765\u8bf4\uff0c \u5c31\u662finstance of\uff0c\u5373object\u786e\u5b9a\u5b83\u7684type\uff0c\u8fd9\u4e5f\u53eb\u505aintrospection\u3002","title":"Type introspection"},{"location":"Summary-of-my-programming-language/#type-conversion-and-type-cast","text":"","title":"type conversion and type cast"},{"location":"Summary-of-my-programming-language/#scope","text":"\u8fd9\u4e09\u79cdprogramming language\u91c7\u7528\u7684\u90fd\u662fstatic scope\uff0c\u90fd\u662f\u57fa\u4e8eblock scope","title":"scope"},{"location":"Summary-of-my-programming-language/#python-display-vs-c-c-initialization","text":"c Initialization , c++ Initialization \u5b9e\u73b0\u5bf9variable\u7684initialize\uff1b python lack declaration\uff0c\u4f46\u662fpython\u4e2d\u4e5f\u63d0\u4f9b\u4e86\u7c7b\u4f3c\u7684\u8bed\u6cd5\uff0cpython\u8fd9\u79cd\u53eb\u505a display","title":"python display vs c, c++ Initialization"},{"location":"Summary-of-my-programming-language/#exception","text":"c++ \u548cpython\u90fd\u63d0\u4f9b\u4e86exception\u673a\u5236\uff1b\u7531\u4e8epython\u662f\u7531python interpreter\u89e3\u91ca\u6267\u884c\uff0c\u800c c++ \u7a0b\u5e8f\u662f\u7531OS\u76f4\u63a5\u8fd0\u884c\uff0c\u56e0\u6b64\u4e24\u8005\u7684exception\u548cOS\u4e4b\u95f4\u7684\u5173\u8054\u662f\u4e0d\u540c\u7684\uff1bpython\u4e2d\u7684exception\u4f1a\u5bfc\u81f4python interpreter\u7684\u6267\u884c\u8def\u5f84\u6539\u53d8\uff0c\u57fa\u672c\u4e0a\u4e0d\u4f1a\u6d89\u53ca\u5230OS\uff1b\u800c c++ \u4e2d\u7684exception\uff0c\u5219\u4f1a\u8f6c\u6362\u4e3aOS\u7684signal\uff0c\u6700\u7ec8\u53ef\u80fd\u5bfc\u81f4\u7a0b\u5e8f\u7ec8\u6b62\u8fd0\u884c\uff1b c\u8bed\u8a00\u6ca1\u6709\uff1b","title":"exception"},{"location":"Summary-of-my-programming-language/#python-and-c","text":"pMeanRate = tanhx(pMeanRate, 2); \u8fd9\u6bb5\u4ee3\u7801\u5728 c++ \u4e2d\u662f\u975e\u5e38\u597d\u7406\u89e3\u7684\uff1a pMeanRate \u662f\u4e00\u4e2a\u5de6\u503c\uff0c\u6240\u4ee5\u5b83\u65e2\u80fd\u591f\u88abread\uff0c\u4e5f\u80fd\u591f\u88abwrite\uff1b\u4f46\u662f\u5728python\u4e2d\uff0c = \u6240\u8868\u793a\u7684\u662fname bind\uff1b","title":"python and c++"},{"location":"Summary-of-my-programming-language/#c17-structured-binding-python-assignment","text":"\u521d\u6b21\u63a5\u89e6c++ 17\u5f15\u5165\u7684structured binding\u7279\u6027\uff0c\u6211\u7b2c\u4e00\u60f3\u6cd5\u5c31\u662f\u5b83\u975e\u5e38\u7c7b\u4f3c\u4e8epython\u7684tuple assignment\u3002","title":"C++17 Structured binding \u548c python Assignment"},{"location":"Summary-of-my-programming-language/#c11-range-for-vs-python-for","text":"C++11\u4e2d\u5f15\u5165\u7684range-for\u975e\u5e38\u7c7b\u4f3c\u4e8epython\u4e2d\u7684 for \u3002","title":"C++11 range-for VS python for"},{"location":"Summary-of-my-programming-language/#c-iteration-vs-python-iteration","text":"python\u901a\u8fc7magic function __next__ \u3001 __iter__ \u6765\u652f\u6301iterator\uff0cc++\u663e\u5f0f\u5b9a\u4e49\u4e86iterator\u7c7b\u3002","title":"c++ iteration vs python iteration"},{"location":"Summary-of-my-programming-language/#reverse-iteration","text":"c++\u901a\u8fc7 reverse_iterator \uff0cpython\u901a\u8fc7builtin reverse \u6765\u5b9e\u73b0\u3002","title":"reverse iteration"},{"location":"Summary-of-my-programming-language/#_1","text":"\u4e00\u79cd\u6807\u51c6\u53ef\u4ee5\u6709\u591a\u79cd\u5b9e\u73b0\u3002 python\u548cc++\u7684\u5b9e\u73b0\u65b9\u5f0f\u662f\u5b8c\u5168\u4e0d\u540c\u7684\uff0cpython\u662f\u89e3\u91ca\u6267\u884c\u7684\uff0c\u800cc++\u662f\u76f4\u63a5\u6267\u884c\u7684\u3002\u8fd9\u5c31\u6ce8\u5b9a\u4e86Python\u7684\u5f88\u591a\u4e8b\u60c5\u662finterpreter\u5b8c\u6210\u7684\uff0c\u800cc++\u7684\u5f88\u591a\u4e8b\u60c5\u662fcompiler\u5b8c\u6210\u7684\u3002\u524d\u8005\u662f\u9759\u6001\u7684\uff0c\u540e\u8005\u662f\u52a8\u6001\u7684\u3002\u53ef\u4ee5\u770b\u5230\uff0cPython\u7684\u6307\u4ee4\u662f\u975e\u5e38\u62bd\u8c61\u7684\u3002python\u4e2d\u7531interpreter\u6765\u9009\u62e9magic function\uff0c\u800cc++\u4e2d\u7531compiler\u6765\u9009\u62e9magic function\u3002","title":"\u8bed\u8a00\u7684\u6807\u51c6\u4e0e\u5b9e\u73b0"},{"location":"Summary-of-my-programming-language/#c-vs-python","text":"C++\u7684compile\u4fdd\u8bc1\u8fdb\u884c\u4e86\u4e25\u683c\u7684\u68c0\u67e5 python\u5219\u662f\u5b8c\u5168\u52a8\u6001\u7684\uff0c\u5b83\u6709 EAFP \u3001 LBYL \u53c2\u89c1\uff1a Idiomatic Python: EAFP versus LBYL","title":"C++ \u7684\u201c\u9759\u201d VS python\u7684\u201c\u52a8\u201d"},{"location":"Summary-of-my-programming-language/#function-and-","text":"python\u7684Function definitions \u00b6 \u548cc++\u7684 Function declaration \u4e2d\uff0c\u90fd\u5f15\u5165\u4e86 -> \u7b26\u5408\uff0c\u4e24\u79cd\u8bed\u8a00\u4e2d -> \u7684\u4e00\u4e2a\u5171\u6027\u662f\uff1a -> \u5bf9\u51fd\u6570\u7684\u8fd4\u56de\u7c7b\u578b\u8fdb\u884c\u8bf4\u660e\uff0cc++\u4e2d\u5c06\u6b64\u79f0\u4e3a\u201c Trailing return type\u201d\uff0cpython\u4e2d\u5c06\u6b64\u79f0\u4e3a \u201c\u201creturn\u201d annotation\u201d\u3002 \u4e0e\u6b64\u7c7b\u4f3c\u7684\u662f\uff0cJavaScript\u4e2d\u6709 => \u7b26\u5408\uff0c\u53c2\u89c1\u7ef4\u57fa\u767e\u79d1 JavaScript \u3002","title":"function and -&gt;"},{"location":"Summary-of-my-programming-language/#specifier","text":"python\u4e2d\u57fa\u672c\u4e0a\u6ca1\u6709\u4ec0\u4e48specifier\uff0c\u4f46\u662f\u5728 c++ \u548c c \u4e2d\u5b58\u5728\u7740\u5927\u91cf\u7684specifier\uff0c\u4e3a\u4ec0\u4e48\u5462\uff1f \u56e0\u4e3ac++\u548cc\u662fsystem language\uff0c\u5b83\u4eec\u9700\u8981\u5bf9process\u8fd0\u884c\u7684\u5e95\u5c42\u7ec6\u8282\u8fdb\u884c\u63cf\u8ff0\u3001\u8fdb\u884c\u63a7\u5236\uff0c\u8fd9\u4e9bspecifier\u5c31\u662f\u51fa\u4e8e\u6b64\u76ee\u7684\u7684\u3002 \u5982\u4e0b\u662f\u5bf9specifier\u7684\u5206\u7c7b\uff1a Access modifiers explicit specifier inline specifier storage class specifiers \u4f7f\u7528specifier\u6765\u5bf9\u67d0\u4e00\u65b9\u9762\u8fdb\u884c\u63cf\u8ff0\u3002","title":"specifier"},{"location":"Summary-of-my-programming-language/#name","text":"\u5728cppreference Declarations \u4e2d\u5173\u4e8e\u201cname\u201d\u7684\u63cf\u8ff0 Declarations introduce (or re-introduce) names into the C++ program.","title":"name"},{"location":"ABI/","text":"\u5173\u4e8e\u672c\u7ae0 \u5728**\u6307\u4ee4\u5c42**\u538b\u6839\u5c31\u6ca1\u6709\u51fd\u6570\u3001\u51fd\u6570\u53c2\u6570\u7b49\u6982\u5ff5\uff0c\u8fd9\u4e9b\u6982\u5ff5\u90fd\u662fhigh level program language\u5efa\u7acb\u8d77\u6765\u7684\uff0c\u5b83\u4eec\u7684\u5b9e\u73b0\u90fd\u662f\u5efa\u7acb\u5728**\u6307\u4ee4\u5c42**\u4e4b\u4e0a\uff0c\u8fde\u63a5\u51fd\u6570\u8c03\u7528\u548c\u6307\u4ee4\u5c42\u7684\u6b63\u662f\u6240\u8c13\u7684calling convention\uff0c\u5b83\u7531compiler\u6765\u5b9e\u73b0\u7684\u3002 \u672c\u7ae0\u6240\u5c06\u63a2\u7d22\u5404\u79cd\u5728high level program language\u4e2d\u5efa\u7acb\u7684\u6982\u5ff5\u662f\u5982\u4f55\u901a\u8fc7\u6307\u4ee4\u6765\u8fdb\u884c\u5b9e\u73b0\u7684\u3002 \u5982\u4f55\u5b9e\u73b0\u63a7\u5236\u6d41 \u6240\u8c13\u7684 Control flow \u5176\u5b9e\u5c31\u662f program counter \u6211\u4eec\u5e38\u5e38\u542c\u5230Control flow\uff0c\u7ef4\u57fa\u767e\u79d1\u7684 Control flow \u5bf9\u5b83\u7684\u603b\u7ed3\u662f\u975e\u5e38\u5168\u9762\u7684\uff0c\u4ecehigh-level programming language\u7ea7\u522b\uff08\u5728high-level programming language\u4e2d\u6709control flow statement\uff0c\u6bd4\u5982return\u3001goto\u7b49\uff09\uff0c\u5230 machine language \u7ea7\u522b\uff08\u8fd9\u662f\u6700\u5e95\u5c42\u4e86\uff1b\u4ee5x86 \u4e3a\u4f8b\uff0c JMP \u6307\u4ee4\uff0c\u66f4\u591a\u53c2\u89c1 X86 Assembly/Control Flow \uff09\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u91cd\u70b9\u5173\u6ce8\u7684\u662f machine language \u7ea7\u522b\uff0c\u6b63\u5982\u5176\u6240\u603b\u7ed3\u7684\uff1a At the level of machine language or assembly language , control flow instructions usually work by altering the program counter . For some central processing units (CPUs), the only control flow instructions available are conditional or unconditional branch instructions, also termed jumps. CPU\u7684 program counter \u9ed8\u8ba4\u884c\u4e3a\u662f\uff1a\u81ea\u52a01\u7684\uff0c\u6240\u4ee5\u7a0b\u5e8f\u9ed8\u8ba4\u662f\u987a\u5e8f\u6267\u884c\u5373\u53ef\uff08\u7f16\u8bd1\u5668\u7f16\u8bd1\u751f\u6210\u7684machine language program\u5176\u5b9e\u662f\u987a\u5e8f\u7684\uff09\uff0c\u901a\u8fc7control flow instruction\uff0c\u53ef\u7528\u6539\u53d8\u8fd9\u79cd\u9ed8\u8ba4\u884c\u4e3a\uff0c\u4ece\u800c\u5b9e\u73b0\u5404\u79cd\u6267\u884cflow\u3002 \u4e00\u4e2a\u4f8b\u5b50\u662f\u5728OS\u4e66\u76844.1. The Role of Interrupt Signals As the name suggests, interrupt signals provide a way to divert the processor to code outside the normal** flow of control**. When an interrupt signal arrives, the CPU must stop what it's currently doing and switch to a new activity; it does this by saving the current value of the program counter (i.e., the content of the eip and cs registers) in the Kernel Mode stack and by placing an address related to the interrupt type into the program counter. \u6b63\u5728\u4e0d\u540c\u7684\u5c42\u6b21\u6765\u770b\u5f85\u672c\u8d28\u4e0a\u76f8\u540c\u7684\u4e8b\u60c5\uff0c\u5728program language\u5c42\uff0c\u6211\u4eec\u628a\u5b83\u53eb\u505aflow of control\uff0c\u5728\u6307\u4ee4\u5c42\uff0c\u6211\u4eec\u5b83\u5176\u5b9e\u662fprogram counter\u3002 \u5982\u4f55\u5b9e\u73b0\u51fd\u6570\u8c03\u7528","title":"Introduction"},{"location":"ABI/#_1","text":"\u5728**\u6307\u4ee4\u5c42**\u538b\u6839\u5c31\u6ca1\u6709\u51fd\u6570\u3001\u51fd\u6570\u53c2\u6570\u7b49\u6982\u5ff5\uff0c\u8fd9\u4e9b\u6982\u5ff5\u90fd\u662fhigh level program language\u5efa\u7acb\u8d77\u6765\u7684\uff0c\u5b83\u4eec\u7684\u5b9e\u73b0\u90fd\u662f\u5efa\u7acb\u5728**\u6307\u4ee4\u5c42**\u4e4b\u4e0a\uff0c\u8fde\u63a5\u51fd\u6570\u8c03\u7528\u548c\u6307\u4ee4\u5c42\u7684\u6b63\u662f\u6240\u8c13\u7684calling convention\uff0c\u5b83\u7531compiler\u6765\u5b9e\u73b0\u7684\u3002 \u672c\u7ae0\u6240\u5c06\u63a2\u7d22\u5404\u79cd\u5728high level program language\u4e2d\u5efa\u7acb\u7684\u6982\u5ff5\u662f\u5982\u4f55\u901a\u8fc7\u6307\u4ee4\u6765\u8fdb\u884c\u5b9e\u73b0\u7684\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"ABI/#_2","text":"","title":"\u5982\u4f55\u5b9e\u73b0\u63a7\u5236\u6d41"},{"location":"ABI/#control-flowprogram-counter","text":"\u6211\u4eec\u5e38\u5e38\u542c\u5230Control flow\uff0c\u7ef4\u57fa\u767e\u79d1\u7684 Control flow \u5bf9\u5b83\u7684\u603b\u7ed3\u662f\u975e\u5e38\u5168\u9762\u7684\uff0c\u4ecehigh-level programming language\u7ea7\u522b\uff08\u5728high-level programming language\u4e2d\u6709control flow statement\uff0c\u6bd4\u5982return\u3001goto\u7b49\uff09\uff0c\u5230 machine language \u7ea7\u522b\uff08\u8fd9\u662f\u6700\u5e95\u5c42\u4e86\uff1b\u4ee5x86 \u4e3a\u4f8b\uff0c JMP \u6307\u4ee4\uff0c\u66f4\u591a\u53c2\u89c1 X86 Assembly/Control Flow \uff09\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u91cd\u70b9\u5173\u6ce8\u7684\u662f machine language \u7ea7\u522b\uff0c\u6b63\u5982\u5176\u6240\u603b\u7ed3\u7684\uff1a At the level of machine language or assembly language , control flow instructions usually work by altering the program counter . For some central processing units (CPUs), the only control flow instructions available are conditional or unconditional branch instructions, also termed jumps. CPU\u7684 program counter \u9ed8\u8ba4\u884c\u4e3a\u662f\uff1a\u81ea\u52a01\u7684\uff0c\u6240\u4ee5\u7a0b\u5e8f\u9ed8\u8ba4\u662f\u987a\u5e8f\u6267\u884c\u5373\u53ef\uff08\u7f16\u8bd1\u5668\u7f16\u8bd1\u751f\u6210\u7684machine language program\u5176\u5b9e\u662f\u987a\u5e8f\u7684\uff09\uff0c\u901a\u8fc7control flow instruction\uff0c\u53ef\u7528\u6539\u53d8\u8fd9\u79cd\u9ed8\u8ba4\u884c\u4e3a\uff0c\u4ece\u800c\u5b9e\u73b0\u5404\u79cd\u6267\u884cflow\u3002 \u4e00\u4e2a\u4f8b\u5b50\u662f\u5728OS\u4e66\u76844.1. The Role of Interrupt Signals As the name suggests, interrupt signals provide a way to divert the processor to code outside the normal** flow of control**. When an interrupt signal arrives, the CPU must stop what it's currently doing and switch to a new activity; it does this by saving the current value of the program counter (i.e., the content of the eip and cs registers) in the Kernel Mode stack and by placing an address related to the interrupt type into the program counter. \u6b63\u5728\u4e0d\u540c\u7684\u5c42\u6b21\u6765\u770b\u5f85\u672c\u8d28\u4e0a\u76f8\u540c\u7684\u4e8b\u60c5\uff0c\u5728program language\u5c42\uff0c\u6211\u4eec\u628a\u5b83\u53eb\u505aflow of control\uff0c\u5728\u6307\u4ee4\u5c42\uff0c\u6211\u4eec\u5b83\u5176\u5b9e\u662fprogram counter\u3002","title":"\u6240\u8c13\u7684Control flow\u5176\u5b9e\u5c31\u662fprogram counter"},{"location":"ABI/#_3","text":"","title":"\u5982\u4f55\u5b9e\u73b0\u51fd\u6570\u8c03\u7528"},{"location":"ABI/Application-binary-interface/","text":"Application binary interface In computer software , an application binary interface ( ABI ) is an interface between two binary program modules ; often, one of these modules is a library or operating system facility, and the other is a program that is being run by a user. An ABI defines how data structures or computational routines are accessed in machine code , which is a low-level, hardware-dependent format; in contrast, an API defines this access in source code , which is a relatively high-level, hardware-independent, often human-readable format. A common aspect of an ABI is the calling convention , which determines how data is provided as input to or read as output from computational routines; examples are the x86 calling conventions . Adhering to an ABI (which may or may not be officially standardized) is usually the job of a compiler , operating system, or library author; however, an application programmer may have to deal with an ABI directly when writing a program in a mix of programming languages, which can be achieved by using foreign function calls . Description ABIs cover details such as: a processor instruction set (with details like register file structure, stack organization, memory access types, ...) the sizes, layouts, and alignments of basic data types that the processor can directly access the calling convention , which controls how functions ' arguments are passed and return values are retrieved; for example, whether all parameters are passed on the stack or some are passed in registers , which registers are used for which function parameters, and whether the first function parameter passed on the stack is pushed first or last onto the stack how an application should make system calls to the operating system and, if the ABI specifies direct system calls rather than procedure calls to system call stubs, the system call numbers and in the case of a complete operating system ABI, the binary format of object files , program libraries and so on. Complete ABIs A complete ABI, such as the Intel Binary Compatibility Standard (iBCS), allows a program from one operating system supporting that ABI to run without modifications on any other such system, provided that necessary shared libraries are present, and similar prerequisites are fulfilled. Other[ which? ] ABIs standardize details such as the C++ name mangling , exception propagation, and calling convention between compilers on the same platform, but do not require cross-platform compatibility. Embedded ABIs An embedded-application binary interface (EABI) specifies standard conventions for file formats , data types, register usage, stack frame organization, and function parameter passing of an embedded software program, for use with an embedded operating system . Compilers that support the EABI create object code that is compatible with code generated by other such compilers, allowing developers to link libraries generated with one compiler with object code generated with another compiler. Developers writing their own assembly language code may also interface with assembly generated by a compliant compiler. EABIs are designed to optimize for performance within the limited resources of an embedded system. Therefore, EABIs omit most abstractions that are made between kernel and user code in complex operating systems. For example, dynamic linking is avoided to allow smaller executables and faster loading, fixed register usage allows more compact stacks and kernel calls, and running the application in privileged mode allows direct access to custom hardware operation without the indirection of calling a device driver. [ 4] The choice of EABI can affect performance.[ 5] [ 6] Widely used EABIs include PowerPC ,[ 4] ARM EABI2[ 7] and MIPS EABI.[ 8] Difference between API and ABI Q: I am new to linux system programming and I came across API and ABI while reading Linux System Programming . Definition of API : An API defines the interfaces by which one piece of software communicates with another at the source level. Definition of ABI : Whereas an API defines a source interface, an ABI defines the low-level binary interface between two or more pieces of software on a particular architecture. It defines how an application interacts with itself, how an application interacts with the kernel , and how an application interacts with libraries . How can a program communicate at a source level ? What is a source level ? Is it related to source code in anyway? Or the source of the library gets included in the main program ? The only difference I know is API is mostly used by programmers and ABI is mostly used by compiler. A: by source level they mean something like include file to expose function definitions \u2013 Anycorn A : API: Application Program Interface This is the set of public types/variables/functions that you expose from your application/library. In C/C++ this is what you expose in the header files that you ship with the application. ABI: Application Binary Interface This is how the compiler builds an application. It defines things (but is not limited to): How parameters are passed to functions (registers/stack). Who cleans parameters from the stack (caller/callee). Where the return value is placed for return. How exceptions propagate.","title":"Application-binary-interface"},{"location":"ABI/Application-binary-interface/#application-binary-interface","text":"In computer software , an application binary interface ( ABI ) is an interface between two binary program modules ; often, one of these modules is a library or operating system facility, and the other is a program that is being run by a user. An ABI defines how data structures or computational routines are accessed in machine code , which is a low-level, hardware-dependent format; in contrast, an API defines this access in source code , which is a relatively high-level, hardware-independent, often human-readable format. A common aspect of an ABI is the calling convention , which determines how data is provided as input to or read as output from computational routines; examples are the x86 calling conventions . Adhering to an ABI (which may or may not be officially standardized) is usually the job of a compiler , operating system, or library author; however, an application programmer may have to deal with an ABI directly when writing a program in a mix of programming languages, which can be achieved by using foreign function calls .","title":"Application binary interface"},{"location":"ABI/Application-binary-interface/#description","text":"ABIs cover details such as: a processor instruction set (with details like register file structure, stack organization, memory access types, ...) the sizes, layouts, and alignments of basic data types that the processor can directly access the calling convention , which controls how functions ' arguments are passed and return values are retrieved; for example, whether all parameters are passed on the stack or some are passed in registers , which registers are used for which function parameters, and whether the first function parameter passed on the stack is pushed first or last onto the stack how an application should make system calls to the operating system and, if the ABI specifies direct system calls rather than procedure calls to system call stubs, the system call numbers and in the case of a complete operating system ABI, the binary format of object files , program libraries and so on.","title":"Description"},{"location":"ABI/Application-binary-interface/#complete-abis","text":"A complete ABI, such as the Intel Binary Compatibility Standard (iBCS), allows a program from one operating system supporting that ABI to run without modifications on any other such system, provided that necessary shared libraries are present, and similar prerequisites are fulfilled. Other[ which? ] ABIs standardize details such as the C++ name mangling , exception propagation, and calling convention between compilers on the same platform, but do not require cross-platform compatibility.","title":"Complete ABIs"},{"location":"ABI/Application-binary-interface/#embedded-abis","text":"An embedded-application binary interface (EABI) specifies standard conventions for file formats , data types, register usage, stack frame organization, and function parameter passing of an embedded software program, for use with an embedded operating system . Compilers that support the EABI create object code that is compatible with code generated by other such compilers, allowing developers to link libraries generated with one compiler with object code generated with another compiler. Developers writing their own assembly language code may also interface with assembly generated by a compliant compiler. EABIs are designed to optimize for performance within the limited resources of an embedded system. Therefore, EABIs omit most abstractions that are made between kernel and user code in complex operating systems. For example, dynamic linking is avoided to allow smaller executables and faster loading, fixed register usage allows more compact stacks and kernel calls, and running the application in privileged mode allows direct access to custom hardware operation without the indirection of calling a device driver. [ 4] The choice of EABI can affect performance.[ 5] [ 6] Widely used EABIs include PowerPC ,[ 4] ARM EABI2[ 7] and MIPS EABI.[ 8]","title":"Embedded ABIs"},{"location":"ABI/Application-binary-interface/#difference-between-api-and-abi","text":"Q: I am new to linux system programming and I came across API and ABI while reading Linux System Programming . Definition of API : An API defines the interfaces by which one piece of software communicates with another at the source level. Definition of ABI : Whereas an API defines a source interface, an ABI defines the low-level binary interface between two or more pieces of software on a particular architecture. It defines how an application interacts with itself, how an application interacts with the kernel , and how an application interacts with libraries . How can a program communicate at a source level ? What is a source level ? Is it related to source code in anyway? Or the source of the library gets included in the main program ? The only difference I know is API is mostly used by programmers and ABI is mostly used by compiler. A: by source level they mean something like include file to expose function definitions \u2013 Anycorn A :","title":"Difference between API and ABI"},{"location":"ABI/Application-binary-interface/#api-application-program-interface","text":"This is the set of public types/variables/functions that you expose from your application/library. In C/C++ this is what you expose in the header files that you ship with the application.","title":"API: Application Program Interface"},{"location":"ABI/Application-binary-interface/#abi-application-binary-interface","text":"This is how the compiler builds an application. It defines things (but is not limited to): How parameters are passed to functions (registers/stack). Who cleans parameters from the stack (caller/callee). Where the return value is placed for return. How exceptions propagate.","title":"ABI: Application Binary Interface"},{"location":"ABI/Alignment/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u4e3b\u8981\u8ba8\u8bbaC\u548cC++\u4e2d\u6d89\u53ca\u7684\u548calignment\u76f8\u5173\u7684\u5185\u5bb9\uff0c\u5173\u4e8ehardware\u5c42\u7ea7\u7684alignment\u76f8\u5173\u7684\u5185\u5bb9\uff0c\u53c2\u89c1\u8fc7\u7a0b Hardware \u7684 Memory-alignment \u7ae0\u8282\u3002","title":"Introduction"},{"location":"ABI/Alignment/#_1","text":"\u672c\u7ae0\u4e3b\u8981\u8ba8\u8bbaC\u548cC++\u4e2d\u6d89\u53ca\u7684\u548calignment\u76f8\u5173\u7684\u5185\u5bb9\uff0c\u5173\u4e8ehardware\u5c42\u7ea7\u7684alignment\u76f8\u5173\u7684\u5185\u5bb9\uff0c\u53c2\u89c1\u8fc7\u7a0b Hardware \u7684 Memory-alignment \u7ae0\u8282\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"ABI/Alignment/Data-alignment/","text":"Data Alignment","title":"[Data Alignment](http://www.songho.ca/misc/alignment/dataalign.html)"},{"location":"ABI/Alignment/Data-alignment/#data-alignment","text":"","title":"Data Alignment"},{"location":"ABI/Alignment/Data-structure-alignment/Data-alignment/","text":"Data Alignment","title":"Data-alignment"},{"location":"ABI/Alignment/Data-structure-alignment/Data-alignment/#data-alignment","text":"","title":"Data Alignment"},{"location":"ABI/Alignment/Data-structure-alignment/Data-structure-alignment/","text":"\u7ef4\u57fa\u767e\u79d1 Data structure alignment Data structure alignment refers to the way data is arranged and accessed in computer memory . It consists of three separate but related issues: data alignment , data structure padding , and packing . The CPU in modern computer hardware performs reads and writes to memory most efficiently when the data is naturally aligned , which generally means that the data address is a multiple of the data size . Data alignment refers to aligning elements according to their natural alignment . To ensure natural alignment, it may be necessary to insert some padding between structure elements or after the last element of a structure. NOTE: \u4ec0\u4e48\u662f**natural alignment**\uff1f Although data structure alignment is a fundamental issue for all modern computers, many computer languages and computer language implementations handle data alignment automatically. Ada ,[ 1] [ 2] PL/I ,[ 3] Pascal ,[ 4] certain C and C++ implementations, D ,[ 5] Rust ,[ 6] C# ,[ 7] and assembly language allow at least partial control of data structure padding, which may be useful in certain special circumstances. Definitions A memory address a is said to be n-byte aligned when a is a multiple of n bytes (where n is a power of 2). In this context a byte is the smallest unit of memory access, i.e. each memory address specifies a different byte. An n -byte aligned address would have a minimum of log2(n) least-significant zeros when expressed in binary . The alternate wording b-bit aligned designates a b/8 byte aligned address (ex. 64-bit aligned is 8 bytes aligned). A memory access is said to be aligned when the data being accessed is n bytes long and the datum address is n -byte aligned. When a memory access is not aligned, it is said to be misaligned . Note that by definition byte memory accesses are always aligned. SUMMARY : \u6ce8\u610fmemory address alignment\u548cmemory access alignment A memory pointer that refers to primitive data that is n bytes long is said to be aligned if it is only allowed to contain addresses that are n -byte aligned, otherwise it is said to be unaligned . A memory pointer that refers to a data aggregate (a data structure or array) is aligned if (and only if) each primitive datum in the aggregate is aligned. SUMMARY : \u5728 c \u4e2d\uff0c\u901a\u8fc7\u7c7b\u4f3c int * p \u6765\u58f0\u660e\u6307\u9488\u6240\u6307\u5411\u7684\u7c7b\u578b\uff0c\u5176\u5b9e\u8fd9\u4e5f\u662f\u5728\u5411compiler\u58f0\u660ealignment requirement\uff1b Note that the definitions above assume that each primitive datum is a power of two bytes long. When this is not the case (as with 80-bit floating-point on x86 ) the context influences the conditions where the datum is considered aligned or not. Data structures can be stored in memory on the stack with a static size known as bounded or on the heap with a dynamic size known as unbounded . Problems A computer accesses memory by a single memory word at a time. As long as the memory word size is at least as large as the largest primitive data type supported by the computer, aligned accesses will always access a single memory word. This may not be true for misaligned data accesses. SUMMARY : largest primitive data type\uff0c\u5728C\u4e2d\u5c31\u662f long \u3002 If the highest and lowest bytes in a datum are not within the same memory word the computer must split the datum access into multiple memory accesses . This requires a lot of complex circuitry to generate the memory accesses and coordinate them. To handle the case where the memory words are in different memory pages the processor must either verify that both pages are present before executing the instruction or be able to handle a TLB miss or a page fault on any memory access during the instruction execution. When a single memory word is accessed the operation is atomic , i.e. the whole memory word is read or written at once and other devices must wait until the read or write operation completes before they can access it. This may not be true for unaligned accesses to multiple memory words, e.g. the first word might be read by one device, both words written by another device and then the second word read by the first device so that the value read is neither the original value nor the updated value. Although such failures are rare, they can be very difficult to identify. SUMMARY : \u8fd9\u4e00\u8282\u6240\u603b\u7ed3\u7684\u662fmisaligned memory\u6240\u5e26\u6765\u7684\u95ee\u9898\uff1b Data structure padding Although the compiler (or interpreter ) normally allocates individual data items on aligned boundaries, data structures often have members with different alignment requirements . To maintain proper alignment the translator normally inserts additional unnamed data members so that each member is properly aligned. In addition, the data structure as a whole may be padded with a final unnamed member. This allows each member of an array of structures to be properly aligned. SUMMARY : \u56e0\u4e3a\u5728 c \u4e2d\uff0c struct \u5f80\u5f80\u662f\u5360\u636e\u7740\u8fde\u7eed\u7684\u5185\u5b58\u7a7a\u95f4\uff0c struct \u4e2d\u7684\u6bcf\u4e2a\u6210\u5458\u53d8\u91cf\u90fd\u6709alignment requirement\uff0c\u6240\u4ee5\u5c31\u5b58\u5728\u8fd9\u6837\u7684\u53ef\u80fd\u6027\uff1a\u4e3a\u4e86\u6ee1\u8db3\u540e\u4e00\u4e2a\u6210\u5458\u53d8\u91cf\u7684alignment requirement\uff0c\u5728\u5b83\u548c\u524d\u4e00\u4e2a\u6210\u5458\u53d8\u91cf\u4e4b\u95f4\u5b58\u5728\u7740\u7c7b\u4f3c\u4e8e\u7a7a\u6d1e\u7684\u7a7a\u95f4\uff0c \u5176\u5b9e\u8fd9\u4e2a\u7a7a\u95f4\u5c31\u662f\u4e0b\u9762\u6240\u8c13\u7684padding\uff1b\u663e\u7136\u6dfb\u52a0padding\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u6ee1\u8db3\u6210\u5458\u53d8\u91cf\u7684alignment requirement\uff1b\u4ece\u4e0b\u9762\u7684\u4ecb\u7ecd\u6765\u770b\uff0cpadding\u4e0d\u4ec5\u4f1a\u53d1\u751f\u5728\u4e24\u4e2a\u6210\u5458\u53d8\u91cf\u4e4b\u95f4\uff0c\u4e5f\u4f1a\u53d1\u751f\u5728 struct \u4e4b\u540e\uff1b Padding is only inserted when a structure member is followed by a member with a larger alignment requirement or at the end of the structure. By changing the ordering of members in a structure, it is possible to change the amount of padding required to maintain alignment. For example, if members are sorted by descending alignment requirements a minimal amount of padding is required. The minimal amount of padding required is always less than the largest alignment in the structure. Computing the maximum amount of padding required is more complicated, but is always less than the sum of the alignment requirements for all members minus twice the sum of the alignment requirements for the least aligned half of the structure members. Although C and C++ do not allow the compiler to reorder structure members to save space, other languages might. It is also possible to tell most C and C++ compilers to \" pack \" the members of a structure to a certain level of alignment , e.g. \" pack(2) \" means align data members larger than a byte to a two-byte boundary so that any padding members are at most one byte long. SUMMARY : \u5173\u4e8epacking\u548cpadding\u4e4b\u95f4\u7684\u5173\u8054\uff0c\u53c2\u8003\u8fd9\u7bc7\u6587\u7ae0\uff1a Structure padding and packing One use for such \"packed\" structures is to conserve memory . For example, a structure containing a single byte and a four-byte integer would require three additional bytes of padding. A large array of such structures would use 37.5% less memory if they are packed, although accessing each structure might take longer. This compromise may be considered a form of space\u2013time tradeoff . Although use of \"packed\" structures is most frequently used to conserve memory space , it may also be used to format a data structure for transmission using a standard protocol. However, in this usage, care must also be taken to ensure that the values of the struct members are stored with the endianness required by the protocol (often network byte order ), which may be different from the endianness used natively by the host machine. Computing padding The following formulas provide the number of padding bytes required to align the start of a data structure (where mod is the modulo operator): padding = ( align - ( offset mod align )) mod align aligned = offset + padding = offset + (( align - ( offset mod align )) mod align ) SUMMARY : \u4e0a\u8ff0\u8ba1\u7b97\u662f\u975e\u5e38\u7b80\u5355\u7684 For example, the padding to add to offset 0x59d for a 4-byte aligned structure is 3. The structure will then start at 0x5a0 , which is a multiple of 4. However, when the alignment of offset is already equal to that of align , the second modulo in (align - (offset mod align)) mod align will return zero, therefore the original value is left unchanged. Since the alignment is by definition a power of two, the modulo operation can be reduced to a bitwise boolean AND operation. The following formulas produce the aligned offset (where & is a bitwise AND and ~ a bitwise NOT ): padding = ( align - ( offset & ( align - 1 ))) & ( align - 1 ) = ( - offset & ( align - 1 )) aligned = ( offset + ( align - 1 )) & ~ ( align - 1 ) = ( offset + ( align - 1 )) & - align Typical alignment of C structs on x86 Data structure members are stored sequentially in memory so that, in the structure below, the member Data1 will always precede Data2 ; and Data2 will always precede Data3 : struct MyData { short Data1 ; short Data2 ; short Data3 ; }; If the type \"short\" is stored in two bytes of memory then each member of the data structure depicted above would be 2-byte aligned. Data1 would be at offset 0, Data2 at offset 2, and Data3 at offset 4. The size of this structure would be 6 bytes. SUMMARY : struct MyData \u7684**alignment requirement**\u662f\u4ec0\u4e48\uff1f The type of each member of the structure usually has a default alignment , meaning that it will, unless otherwise requested by the programmer, be aligned on a pre-determined boundary. The following typical alignments are valid for compilers from Microsoft ( Visual C++ ), Borland / CodeGear ( C++Builder ), Digital Mars (DMC), and GNU ( GCC ) when compiling for 32-bit x86: A char (one byte) will be 1-byte aligned. A short (two bytes) will be 2-byte aligned. An int (four bytes) will be 4-byte aligned. A long (four bytes) will be 4-byte aligned. A float (four bytes) will be 4-byte aligned. A double (eight bytes) will be 8-byte aligned on Windows and 4-byte aligned on Linux (8-byte with -malign-double compile time option). A long long (eight bytes) will be 4-byte aligned. A long double (ten bytes with C++Builder and DMC, eight bytes with Visual C++, twelve bytes with GCC) will be 8-byte aligned with C++Builder, 2-byte aligned with DMC, 8-byte aligned with Visual C++, and 4-byte aligned with GCC. Any pointer (four bytes) will be 4-byte aligned. (e.g.: char* , int* ) The only notable differences in alignment for an LP64 64-bit system when compared to a 32-bit system are: A long (eight bytes) will be 8-byte aligned. A double (eight bytes) will be 8-byte aligned. A long long (eight bytes) will be 8-byte aligned. A long double (eight bytes with Visual C++, sixteen bytes with GCC) will be 8-byte aligned with Visual C++ and 16-byte aligned with GCC. Any pointer (eight bytes) will be 8-byte aligned. Some data types are dependent on the implementation. Here is a structure with members of various types, totaling 8 bytes before compilation: struct MixedData { char Data1 ; short Data2 ; int Data3 ; char Data4 ; }; After compilation the data structure will be supplemented with padding bytes to ensure a proper alignment for each of its members: struct MixedData /* After compilation in 32-bit x86 machine */ { char Data1 ; /* 1 byte */ char Padding1 [ 1 ]; /* 1 byte for the following 'short' to be aligned on a 2 byte boundary assuming that the address where structure begins is an even number */ short Data2 ; /* 2 bytes */ int Data3 ; /* 4 bytes - largest structure member */ char Data4 ; /* 1 byte */ char Padding2 [ 3 ]; /* 3 bytes to make total size of the structure 12 bytes */ }; The compiled size of the structure is now 12 bytes. It is important to note that the last member is padded with the number of bytes required so that the total size of the structure should be a multiple of the largest alignment of any structure member (alignment(int) in this case , which = 4 on linux-32bit/gcc)[ citation needed ]. In this case 3 bytes are added to the last member to pad the structure to the size of a 12 bytes (alignment(int) \u00d7 3). struct FinalPad { float x ; char n [ 1 ]; }; In this example the total size of the structure sizeof (FinalPad) == 8, not 5 (so that the size is a multiple of 4 (alignment of float)). struct FinalPadShort { short s ; char n [ 3 ]; }; In this example the total size of the structure sizeof ( FinalPadShort ) == 6, not 5 (not 8 either) (so that the size is a multiple of 2 (alignment(short) = 2 on linux-32bit/gcc)). It is possible to change the alignment of structures to reduce the memory they require (or to conform to an existing format) by reordering structure members or changing the compiler\u2019s alignment (or \u201cpacking\u201d) of structure members. struct MixedData /* after reordering */ { char Data1 ; char Data4 ; /* reordered */ short Data2 ; int Data3 ; }; The compiled size of the structure now matches the pre-compiled size of 8 bytes . Note that Padding1[1] has been replaced (and thus eliminated) by Data4 and Padding2[3] is no longer necessary as the structure is already aligned to the size of a long word. The alternative method of enforcing the MixedData structure to be aligned to a one byte boundary will cause the pre-processor to discard the pre-determined alignment of the structure members and thus no padding bytes would be inserted. While there is no standard way of defining the alignment of structure members, some compilers use #pragma directives to specify packing inside source files. Here is an example: #pragma pack(push) /* push current alignment to stack */ #pragma pack(1) /* set alignment to 1 byte boundary */ struct MyPackedData { char Data1 ; long Data2 ; char Data3 ; }; #pragma pack(pop) /* restore original alignment from stack */ This structure would have a compiled size of 6 bytes on a 32-bit system. The above directives are available in compilers from Microsoft ,[ 8] Borland , GNU ,[ 9] and many others. Another example: struct MyPackedData { char Data1 ; long Data2 __attribute__ (( packed )); char Data3 ; }; Default packing and #pragma pack On some Microsoft compilers, particularly for the RISC processor, there is an unexpected relationship between project default packing (the /Zp directive) and the #pragma pack directive. The #pragma pack directive can only be used to reduce the packing size of a structure from the project default packing.[ 10] This leads to interoperability problems with library headers which use, for example, #pragma pack(8) , if the project packing is smaller than this. For this reason, setting the project packing to any value other than the default of 8 bytes would break the #pragma pack directives used in library headers and result in binary incompatibilities between structures. This limitation is not present when compiling for x86. Allocating memory aligned to cache lines It would be beneficial to allocate memory aligned to cache lines . If an array is partitioned for more than one thread to operate on, having the sub-array boundaries unaligned to cache lines could lead to performance degradation. Here is an example to allocate memory (double array of size 10) aligned to cache of 64 bytes. #include <stdlib.h> double * foo ( void ) { double * var ; //create array of size 10 int ok ; ok = posix_memalign (( void ** ) & var , 64 , 10 * sizeof ( double )); if ( ok != 0 ) return NULL ; return var ; } Hardware significance of alignment requirements Alignment concerns can affect areas much larger than a C structure when the purpose is the efficient mapping of that area through a hardware address translation mechanism (PCI remapping, operation of a MMU ). For instance, on a 32-bit operating system, a 4 KiB (4096 Bytes) page is not just an arbitrary 4 KiB chunk of data. Instead, it is usually a region of memory that's aligned on a 4 KiB boundary. This is because aligning a page on a page-sized boundary lets the hardware map a virtual address to a physical address by substituting the higher bits in the address, rather than doing complex arithmetic. Example: Assume that we have a TLB mapping of virtual address 0x2CFC7000 to physical address 0x12345000 . (Note that both these addresses are aligned at 4 KiB boundaries.) Accessing data located at virtual address va=0x2CFC7ABC causes a TLB resolution of 0x2CFC7 to 0x12345 to issue a physical access to pa=0x12345ABC . Here, the 20/12-bit split luckily matches the hexadecimal representation split at 5/3 digits. The hardware can implement this translation by simply combining the first 20 bits of the physical address ( 0x12345 ) and the last 12 bits of the virtual address ( 0xABC ). This is also referred to as virtually indexed (ABC) physically tagged (12345). A block of data of size 2^{(n+1)} - 1 2^{(n+1)} - 1 always has one sub-block of size 2^n 2^n aligned on 2^n 2^n bytes. This is how a dynamic allocator that has no knowledge of alignment, can be used to provide aligned buffers, at the price of a factor two in space loss. // Example: get 4096 bytes aligned on a 4096 byte buffer with malloc() // unaligned pointer to large area void * up = malloc (( 1 << 13 ) - 1 ); // well-aligned pointer to 4 KiB void * ap = aligntonext ( up , 12 ); where aligntonext(p, r) works by adding an aligned increment, then clearing the r least significant bits of p . A possible implementation is // Assume `uint32_t p, bits;` for readability #define alignto(p, bits) (((p) >> bits) << bits) #define aligntonext(p, bits) alignto(((p) + (1 << bits) - 1), bits)","title":"Data-structure-alignment"},{"location":"ABI/Alignment/Data-structure-alignment/Data-structure-alignment/#data-structure-alignment","text":"Data structure alignment refers to the way data is arranged and accessed in computer memory . It consists of three separate but related issues: data alignment , data structure padding , and packing . The CPU in modern computer hardware performs reads and writes to memory most efficiently when the data is naturally aligned , which generally means that the data address is a multiple of the data size . Data alignment refers to aligning elements according to their natural alignment . To ensure natural alignment, it may be necessary to insert some padding between structure elements or after the last element of a structure. NOTE: \u4ec0\u4e48\u662f**natural alignment**\uff1f Although data structure alignment is a fundamental issue for all modern computers, many computer languages and computer language implementations handle data alignment automatically. Ada ,[ 1] [ 2] PL/I ,[ 3] Pascal ,[ 4] certain C and C++ implementations, D ,[ 5] Rust ,[ 6] C# ,[ 7] and assembly language allow at least partial control of data structure padding, which may be useful in certain special circumstances.","title":"\u7ef4\u57fa\u767e\u79d1Data structure alignment"},{"location":"ABI/Alignment/Data-structure-alignment/Data-structure-alignment/#definitions","text":"A memory address a is said to be n-byte aligned when a is a multiple of n bytes (where n is a power of 2). In this context a byte is the smallest unit of memory access, i.e. each memory address specifies a different byte. An n -byte aligned address would have a minimum of log2(n) least-significant zeros when expressed in binary . The alternate wording b-bit aligned designates a b/8 byte aligned address (ex. 64-bit aligned is 8 bytes aligned). A memory access is said to be aligned when the data being accessed is n bytes long and the datum address is n -byte aligned. When a memory access is not aligned, it is said to be misaligned . Note that by definition byte memory accesses are always aligned. SUMMARY : \u6ce8\u610fmemory address alignment\u548cmemory access alignment A memory pointer that refers to primitive data that is n bytes long is said to be aligned if it is only allowed to contain addresses that are n -byte aligned, otherwise it is said to be unaligned . A memory pointer that refers to a data aggregate (a data structure or array) is aligned if (and only if) each primitive datum in the aggregate is aligned. SUMMARY : \u5728 c \u4e2d\uff0c\u901a\u8fc7\u7c7b\u4f3c int * p \u6765\u58f0\u660e\u6307\u9488\u6240\u6307\u5411\u7684\u7c7b\u578b\uff0c\u5176\u5b9e\u8fd9\u4e5f\u662f\u5728\u5411compiler\u58f0\u660ealignment requirement\uff1b Note that the definitions above assume that each primitive datum is a power of two bytes long. When this is not the case (as with 80-bit floating-point on x86 ) the context influences the conditions where the datum is considered aligned or not. Data structures can be stored in memory on the stack with a static size known as bounded or on the heap with a dynamic size known as unbounded .","title":"Definitions"},{"location":"ABI/Alignment/Data-structure-alignment/Data-structure-alignment/#problems","text":"A computer accesses memory by a single memory word at a time. As long as the memory word size is at least as large as the largest primitive data type supported by the computer, aligned accesses will always access a single memory word. This may not be true for misaligned data accesses. SUMMARY : largest primitive data type\uff0c\u5728C\u4e2d\u5c31\u662f long \u3002 If the highest and lowest bytes in a datum are not within the same memory word the computer must split the datum access into multiple memory accesses . This requires a lot of complex circuitry to generate the memory accesses and coordinate them. To handle the case where the memory words are in different memory pages the processor must either verify that both pages are present before executing the instruction or be able to handle a TLB miss or a page fault on any memory access during the instruction execution. When a single memory word is accessed the operation is atomic , i.e. the whole memory word is read or written at once and other devices must wait until the read or write operation completes before they can access it. This may not be true for unaligned accesses to multiple memory words, e.g. the first word might be read by one device, both words written by another device and then the second word read by the first device so that the value read is neither the original value nor the updated value. Although such failures are rare, they can be very difficult to identify. SUMMARY : \u8fd9\u4e00\u8282\u6240\u603b\u7ed3\u7684\u662fmisaligned memory\u6240\u5e26\u6765\u7684\u95ee\u9898\uff1b","title":"Problems"},{"location":"ABI/Alignment/Data-structure-alignment/Data-structure-alignment/#data-structure-padding","text":"Although the compiler (or interpreter ) normally allocates individual data items on aligned boundaries, data structures often have members with different alignment requirements . To maintain proper alignment the translator normally inserts additional unnamed data members so that each member is properly aligned. In addition, the data structure as a whole may be padded with a final unnamed member. This allows each member of an array of structures to be properly aligned. SUMMARY : \u56e0\u4e3a\u5728 c \u4e2d\uff0c struct \u5f80\u5f80\u662f\u5360\u636e\u7740\u8fde\u7eed\u7684\u5185\u5b58\u7a7a\u95f4\uff0c struct \u4e2d\u7684\u6bcf\u4e2a\u6210\u5458\u53d8\u91cf\u90fd\u6709alignment requirement\uff0c\u6240\u4ee5\u5c31\u5b58\u5728\u8fd9\u6837\u7684\u53ef\u80fd\u6027\uff1a\u4e3a\u4e86\u6ee1\u8db3\u540e\u4e00\u4e2a\u6210\u5458\u53d8\u91cf\u7684alignment requirement\uff0c\u5728\u5b83\u548c\u524d\u4e00\u4e2a\u6210\u5458\u53d8\u91cf\u4e4b\u95f4\u5b58\u5728\u7740\u7c7b\u4f3c\u4e8e\u7a7a\u6d1e\u7684\u7a7a\u95f4\uff0c \u5176\u5b9e\u8fd9\u4e2a\u7a7a\u95f4\u5c31\u662f\u4e0b\u9762\u6240\u8c13\u7684padding\uff1b\u663e\u7136\u6dfb\u52a0padding\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u6ee1\u8db3\u6210\u5458\u53d8\u91cf\u7684alignment requirement\uff1b\u4ece\u4e0b\u9762\u7684\u4ecb\u7ecd\u6765\u770b\uff0cpadding\u4e0d\u4ec5\u4f1a\u53d1\u751f\u5728\u4e24\u4e2a\u6210\u5458\u53d8\u91cf\u4e4b\u95f4\uff0c\u4e5f\u4f1a\u53d1\u751f\u5728 struct \u4e4b\u540e\uff1b Padding is only inserted when a structure member is followed by a member with a larger alignment requirement or at the end of the structure. By changing the ordering of members in a structure, it is possible to change the amount of padding required to maintain alignment. For example, if members are sorted by descending alignment requirements a minimal amount of padding is required. The minimal amount of padding required is always less than the largest alignment in the structure. Computing the maximum amount of padding required is more complicated, but is always less than the sum of the alignment requirements for all members minus twice the sum of the alignment requirements for the least aligned half of the structure members. Although C and C++ do not allow the compiler to reorder structure members to save space, other languages might. It is also possible to tell most C and C++ compilers to \" pack \" the members of a structure to a certain level of alignment , e.g. \" pack(2) \" means align data members larger than a byte to a two-byte boundary so that any padding members are at most one byte long. SUMMARY : \u5173\u4e8epacking\u548cpadding\u4e4b\u95f4\u7684\u5173\u8054\uff0c\u53c2\u8003\u8fd9\u7bc7\u6587\u7ae0\uff1a Structure padding and packing One use for such \"packed\" structures is to conserve memory . For example, a structure containing a single byte and a four-byte integer would require three additional bytes of padding. A large array of such structures would use 37.5% less memory if they are packed, although accessing each structure might take longer. This compromise may be considered a form of space\u2013time tradeoff . Although use of \"packed\" structures is most frequently used to conserve memory space , it may also be used to format a data structure for transmission using a standard protocol. However, in this usage, care must also be taken to ensure that the values of the struct members are stored with the endianness required by the protocol (often network byte order ), which may be different from the endianness used natively by the host machine.","title":"Data structure padding"},{"location":"ABI/Alignment/Data-structure-alignment/Data-structure-alignment/#computing-padding","text":"The following formulas provide the number of padding bytes required to align the start of a data structure (where mod is the modulo operator): padding = ( align - ( offset mod align )) mod align aligned = offset + padding = offset + (( align - ( offset mod align )) mod align ) SUMMARY : \u4e0a\u8ff0\u8ba1\u7b97\u662f\u975e\u5e38\u7b80\u5355\u7684 For example, the padding to add to offset 0x59d for a 4-byte aligned structure is 3. The structure will then start at 0x5a0 , which is a multiple of 4. However, when the alignment of offset is already equal to that of align , the second modulo in (align - (offset mod align)) mod align will return zero, therefore the original value is left unchanged. Since the alignment is by definition a power of two, the modulo operation can be reduced to a bitwise boolean AND operation. The following formulas produce the aligned offset (where & is a bitwise AND and ~ a bitwise NOT ): padding = ( align - ( offset & ( align - 1 ))) & ( align - 1 ) = ( - offset & ( align - 1 )) aligned = ( offset + ( align - 1 )) & ~ ( align - 1 ) = ( offset + ( align - 1 )) & - align","title":"Computing padding"},{"location":"ABI/Alignment/Data-structure-alignment/Data-structure-alignment/#typical-alignment-of-c-structs-on-x86","text":"Data structure members are stored sequentially in memory so that, in the structure below, the member Data1 will always precede Data2 ; and Data2 will always precede Data3 : struct MyData { short Data1 ; short Data2 ; short Data3 ; }; If the type \"short\" is stored in two bytes of memory then each member of the data structure depicted above would be 2-byte aligned. Data1 would be at offset 0, Data2 at offset 2, and Data3 at offset 4. The size of this structure would be 6 bytes. SUMMARY : struct MyData \u7684**alignment requirement**\u662f\u4ec0\u4e48\uff1f The type of each member of the structure usually has a default alignment , meaning that it will, unless otherwise requested by the programmer, be aligned on a pre-determined boundary. The following typical alignments are valid for compilers from Microsoft ( Visual C++ ), Borland / CodeGear ( C++Builder ), Digital Mars (DMC), and GNU ( GCC ) when compiling for 32-bit x86: A char (one byte) will be 1-byte aligned. A short (two bytes) will be 2-byte aligned. An int (four bytes) will be 4-byte aligned. A long (four bytes) will be 4-byte aligned. A float (four bytes) will be 4-byte aligned. A double (eight bytes) will be 8-byte aligned on Windows and 4-byte aligned on Linux (8-byte with -malign-double compile time option). A long long (eight bytes) will be 4-byte aligned. A long double (ten bytes with C++Builder and DMC, eight bytes with Visual C++, twelve bytes with GCC) will be 8-byte aligned with C++Builder, 2-byte aligned with DMC, 8-byte aligned with Visual C++, and 4-byte aligned with GCC. Any pointer (four bytes) will be 4-byte aligned. (e.g.: char* , int* ) The only notable differences in alignment for an LP64 64-bit system when compared to a 32-bit system are: A long (eight bytes) will be 8-byte aligned. A double (eight bytes) will be 8-byte aligned. A long long (eight bytes) will be 8-byte aligned. A long double (eight bytes with Visual C++, sixteen bytes with GCC) will be 8-byte aligned with Visual C++ and 16-byte aligned with GCC. Any pointer (eight bytes) will be 8-byte aligned. Some data types are dependent on the implementation. Here is a structure with members of various types, totaling 8 bytes before compilation: struct MixedData { char Data1 ; short Data2 ; int Data3 ; char Data4 ; }; After compilation the data structure will be supplemented with padding bytes to ensure a proper alignment for each of its members: struct MixedData /* After compilation in 32-bit x86 machine */ { char Data1 ; /* 1 byte */ char Padding1 [ 1 ]; /* 1 byte for the following 'short' to be aligned on a 2 byte boundary assuming that the address where structure begins is an even number */ short Data2 ; /* 2 bytes */ int Data3 ; /* 4 bytes - largest structure member */ char Data4 ; /* 1 byte */ char Padding2 [ 3 ]; /* 3 bytes to make total size of the structure 12 bytes */ }; The compiled size of the structure is now 12 bytes. It is important to note that the last member is padded with the number of bytes required so that the total size of the structure should be a multiple of the largest alignment of any structure member (alignment(int) in this case , which = 4 on linux-32bit/gcc)[ citation needed ]. In this case 3 bytes are added to the last member to pad the structure to the size of a 12 bytes (alignment(int) \u00d7 3). struct FinalPad { float x ; char n [ 1 ]; }; In this example the total size of the structure sizeof (FinalPad) == 8, not 5 (so that the size is a multiple of 4 (alignment of float)). struct FinalPadShort { short s ; char n [ 3 ]; }; In this example the total size of the structure sizeof ( FinalPadShort ) == 6, not 5 (not 8 either) (so that the size is a multiple of 2 (alignment(short) = 2 on linux-32bit/gcc)). It is possible to change the alignment of structures to reduce the memory they require (or to conform to an existing format) by reordering structure members or changing the compiler\u2019s alignment (or \u201cpacking\u201d) of structure members. struct MixedData /* after reordering */ { char Data1 ; char Data4 ; /* reordered */ short Data2 ; int Data3 ; }; The compiled size of the structure now matches the pre-compiled size of 8 bytes . Note that Padding1[1] has been replaced (and thus eliminated) by Data4 and Padding2[3] is no longer necessary as the structure is already aligned to the size of a long word. The alternative method of enforcing the MixedData structure to be aligned to a one byte boundary will cause the pre-processor to discard the pre-determined alignment of the structure members and thus no padding bytes would be inserted. While there is no standard way of defining the alignment of structure members, some compilers use #pragma directives to specify packing inside source files. Here is an example: #pragma pack(push) /* push current alignment to stack */ #pragma pack(1) /* set alignment to 1 byte boundary */ struct MyPackedData { char Data1 ; long Data2 ; char Data3 ; }; #pragma pack(pop) /* restore original alignment from stack */ This structure would have a compiled size of 6 bytes on a 32-bit system. The above directives are available in compilers from Microsoft ,[ 8] Borland , GNU ,[ 9] and many others. Another example: struct MyPackedData { char Data1 ; long Data2 __attribute__ (( packed )); char Data3 ; };","title":"Typical alignment of C structs on x86"},{"location":"ABI/Alignment/Data-structure-alignment/Data-structure-alignment/#default-packing-and-pragma-pack","text":"On some Microsoft compilers, particularly for the RISC processor, there is an unexpected relationship between project default packing (the /Zp directive) and the #pragma pack directive. The #pragma pack directive can only be used to reduce the packing size of a structure from the project default packing.[ 10] This leads to interoperability problems with library headers which use, for example, #pragma pack(8) , if the project packing is smaller than this. For this reason, setting the project packing to any value other than the default of 8 bytes would break the #pragma pack directives used in library headers and result in binary incompatibilities between structures. This limitation is not present when compiling for x86.","title":"Default packing and #pragma pack"},{"location":"ABI/Alignment/Data-structure-alignment/Data-structure-alignment/#allocating-memory-aligned-to-cache-lines","text":"It would be beneficial to allocate memory aligned to cache lines . If an array is partitioned for more than one thread to operate on, having the sub-array boundaries unaligned to cache lines could lead to performance degradation. Here is an example to allocate memory (double array of size 10) aligned to cache of 64 bytes. #include <stdlib.h> double * foo ( void ) { double * var ; //create array of size 10 int ok ; ok = posix_memalign (( void ** ) & var , 64 , 10 * sizeof ( double )); if ( ok != 0 ) return NULL ; return var ; }","title":"Allocating memory aligned to cache lines"},{"location":"ABI/Alignment/Data-structure-alignment/Data-structure-alignment/#hardware-significance-of-alignment-requirements","text":"Alignment concerns can affect areas much larger than a C structure when the purpose is the efficient mapping of that area through a hardware address translation mechanism (PCI remapping, operation of a MMU ). For instance, on a 32-bit operating system, a 4 KiB (4096 Bytes) page is not just an arbitrary 4 KiB chunk of data. Instead, it is usually a region of memory that's aligned on a 4 KiB boundary. This is because aligning a page on a page-sized boundary lets the hardware map a virtual address to a physical address by substituting the higher bits in the address, rather than doing complex arithmetic. Example: Assume that we have a TLB mapping of virtual address 0x2CFC7000 to physical address 0x12345000 . (Note that both these addresses are aligned at 4 KiB boundaries.) Accessing data located at virtual address va=0x2CFC7ABC causes a TLB resolution of 0x2CFC7 to 0x12345 to issue a physical access to pa=0x12345ABC . Here, the 20/12-bit split luckily matches the hexadecimal representation split at 5/3 digits. The hardware can implement this translation by simply combining the first 20 bits of the physical address ( 0x12345 ) and the last 12 bits of the virtual address ( 0xABC ). This is also referred to as virtually indexed (ABC) physically tagged (12345). A block of data of size 2^{(n+1)} - 1 2^{(n+1)} - 1 always has one sub-block of size 2^n 2^n aligned on 2^n 2^n bytes. This is how a dynamic allocator that has no knowledge of alignment, can be used to provide aligned buffers, at the price of a factor two in space loss. // Example: get 4096 bytes aligned on a 4096 byte buffer with malloc() // unaligned pointer to large area void * up = malloc (( 1 << 13 ) - 1 ); // well-aligned pointer to 4 KiB void * ap = aligntonext ( up , 12 ); where aligntonext(p, r) works by adding an aligned increment, then clearing the r least significant bits of p . A possible implementation is // Assume `uint32_t p, bits;` for readability #define alignto(p, bits) (((p) >> bits) << bits) #define aligntonext(p, bits) alignto(((p) + (1 << bits) - 1), bits)","title":"Hardware significance of alignment requirements"},{"location":"ABI/Alignment/Data-structure-alignment/The-Lost-Art-of-Structure-Packing/","text":"The Lost Art of Structure Packing 1. Who should read this This page is about a technique for reducing the memory footprint of programs in compiled languages with C-like structures - manually repacking these declarations for reduced size. To read it, you will require basic knowledge of the C programming language. You need to know this technique if you intend to write code for memory-constrained embedded systems, or operating-system kernels. It is useful if you are working with application data sets so large that your programs routinely hit memory limits. It is good to know in any application where you really, really care about optimizing your use of memory bandwidth and minimizing cache-line misses. SUMMARY : \u5728 Data structure alignment \u4e2d\u4e5f\u63d0\u53ca\u4e86 cache-line \u3002 Finally, knowing this technique is a gateway to other esoteric C topics. You are not an advanced C programmer until you have grasped these rules. You are not a master of C until you could have written this document yourself and can criticize it intelligently. This document originated with \"C\" in the title, but many of the techniques discussed here also apply to the Go language - and should generalize to any compiled language with C-like structures. There is a note discussing Go and Rust towards the end. 2. Why I wrote it This webpage exists because in late 2013 I found myself heavily applying an optimization technique that I had learned more than two decades previously and not used much since. SUMMARY : \u8fd9\u4e2a\u7f51\u9875\u7684\u5b58\u5728\u662f\u56e0\u4e3a\u57282013\u5e74\u672b\u6211\u53d1\u73b0\u81ea\u5df1\u5927\u91cf\u5e94\u7528\u4e86\u4e00\u79cd\u4f18\u5316\u6280\u672f\uff0c\u8fd9\u79cd\u6280\u672f\u662f\u6211\u5728\u4e8c\u5341\u591a\u5e74\u524d\u5b66\u5230\u7684\u5e76\u4e14\u4ece\u90a3\u65f6\u8d77\u5c31\u6ca1\u7528\u8fc7\u591a\u5c11\u3002 I needed to reduce the memory footprint of a program that used thousands - sometimes hundreds of thousands - of C struct instances. The program was cvs-fast-export and the problem was that it was dying with out-of-memory errors on large repositories. SUMMARY : out-of-memory\u7684\u610f\u601d\u662f\u5185\u5b58\u4e0d\u8db3\uff0c\u53c2\u89c1 Out of memory \u3002 There are ways to reduce memory usage significantly in situations like this, by rearranging the order of structure members in careful ways. This can lead to dramatic gains - in my case I was able to cut the working-set size by around 40%, enabling the program to handle much larger repositories without dying. But as I worked, and thought about what I was doing, it began to dawn on me that the technique I was using has been more than half forgotten in these latter days. A little web research confirmed that programmers don\u2019t seem to talk about it much any more, at least not where a search engine can see them. A couple of Wikipedia entries touch the topic, but I found nobody who covered it comprehensively. There are actually reasons for this that aren\u2019t stupid. CS courses (rightly) steer people away from micro-optimization towards finding better algorithms. The plunging price of machine resources has made squeezing memory usage less necessary. And the way hackers used to learn how to do it back in the day was by bumping their noses on strange hardware architectures - a less common experience now. But the technique still has value in important situations, and will as long as memory is finite. This document is intended to save programmers from having to rediscover the technique, so they can concentrate effort on more important things. SUMMARY : \u5b9e\u9645\u4e0a\u6709\u4e9b\u539f\u56e0\u5e76\u4e0d\u662f\u611a\u8822\u7684\u3002 CS\u8bfe\u7a0b\uff08\u6b63\u786e\u5730\uff09\u5f15\u5bfc\u4eba\u4eec\u8fdc\u79bb\u5fae\u89c2\u4f18\u5316\uff0c\u5bfb\u627e\u66f4\u597d\u7684\u7b97\u6cd5\u3002 \u673a\u5668\u8d44\u6e90\u7684\u4ef7\u683c\u66b4\u8dcc\u4f7f\u5f97\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u7684\u5fc5\u8981\u6027\u964d\u4f4e\u3002 \u9ed1\u5ba2\u8fc7\u53bb\u5e38\u5e38\u5b66\u4e60\u5982\u4f55\u505a\u5230\u8fd9\u4e00\u70b9\u7684\u65b9\u5f0f\u662f\u5728\u5947\u602a\u7684\u786c\u4ef6\u67b6\u6784\u4e0a\u55e4\u4e4b\u4ee5\u9f3b - \u73b0\u5728\u8fd9\u79cd\u4e0d\u592a\u5e38\u89c1\u7684\u4f53\u9a8c\u3002 \u4f46\u662f\u8fd9\u79cd\u6280\u672f\u5728\u91cd\u8981\u60c5\u51b5\u4e0b\u4ecd\u7136\u5177\u6709\u4ef7\u503c\uff0c\u5e76\u4e14\u53ea\u8981\u5b58\u50a8\u5668\u662f\u6709\u9650\u7684\u3002 \u672c\u6587\u6863\u65e8\u5728\u5e2e\u52a9\u7a0b\u5e8f\u5458\u4e0d\u5fc5\u91cd\u65b0\u53d1\u73b0\u8be5\u6280\u672f\uff0c\u56e0\u6b64\u4ed6\u4eec\u53ef\u4ee5\u5c06\u7cbe\u529b\u96c6\u4e2d\u5728\u66f4\u91cd\u8981\u7684\u4e8b\u60c5\u4e0a\u3002 3. Alignment requirements The first thing to understand is that, on modern processors, the way your compiler lays out basic datatypes in memory is constrained in order to make memory accesses faster. Our examples are in C, but any compiled language generates code under the same constraints. Storage for the basic C datatypes on an x86 or ARM processor doesn\u2019t normally start at arbitrary byte addresses in memory. Rather, each type except char has an alignment requirement ; chars can start on any byte address, but 2-byte shorts must start on an even address, 4-byte ints or floats must start on an address divisible by 4, and 8-byte longs or doubles must start on an address divisible by 8. Signed or unsigned makes no difference. The jargon(\u884c\u8bdd) for this is that basic C types on x86 and ARM are self-aligned . Pointers, whether 32-bit (4-byte) or 64-bit (8-byte) are self-aligned too. SUMMARY : \u4e0d\u540c\u7c7b\u578b\u7684align requirement\u5176\u5b9e\u5c31\u7b49\u4e8e sizeof Self-alignment makes access faster because it facilitates generating single-instruction fetches and puts of the typed data. Without alignment constraints, on the other hand, the code might end up having to do two or more accesses spanning\uff08\u8de8\u8d8a\uff09 machine-word boundaries . Characters are a special case; they\u2019re equally expensive from anywhere they live inside a single machine word . That\u2019s why they don\u2019t have a preferred alignment. SUMMARY : \u6700\u540e\u4e00\u6bb5\u8bdd\u7684\u610f\u601d\u662f\uff1a\u5bf9\u4e8e char \u7c7b\u578b\u7684\u6570\u636e\uff0c\u5b83\u4eec\u5e76\u6ca1\u6709preferred alignment\uff0c\u56e0\u4e3a\u65e0\u8bba\u5b83\u4eec\u4f4d\u4e8e\u4f55\u5904\uff0c\u88abaccess\u7684\u65f6\u5019\u6240\u9700\u7684\u8017\u8d39\u662f\u76f8\u540c\u7684\uff1b SUMMARY : \u5728\u8fd9\u7bc7\u6587\u7ae0\u4e2d\uff0c\u63cf\u8ff0\u4e86CPU \u8fdb\u884cmemory access\u7684\u65b9\u5f0f\uff1a Data alignment: Straighten up and fly right \uff0c\u4e0b\u9762\u8fd9\u4e2a\u56fe\u7247\u662f\u53d6\u81ea\u8fd9\u7bc7\u6587\u7ae0\uff1a Figure 2. How processors see memory I said \"on modern processors\" because on some older ones forcing your C program to violate alignment rules (say, by casting an odd\uff08\u5947\u6570\uff09 address into an int pointer and trying to use it) didn\u2019t just slow your code down, it caused an illegal instruction fault . This was the behavior, for example, on Sun SPARC chips. In fact, with sufficient determination and the right (e18) hardware flag set on the processor, you can still trigger this on x86 . THINKING : \u5728\u4ec0\u4e48\u60c5\u51b5\u4e0b\uff0c\u4f1a\u51fa\u73b0violate alignment rules\uff1f \u4e0b\u9762\u8fd9\u7bc7\u6587\u7ae0\u4e2d\u6240\u5217\u51fa\u7684\u662f\u4e00\u79cd\u60c5\u51b5 Should I worry about the alignment during pointer casting? \u8fd9\u7bc7\u6587\u7ae0\u4e2d\u6240\u4ecb\u7ecd\u7684\u548c\u4e0b\u9762\u94fe\u63a5\u4e2d\u7684\u60c5\u51b5\u975e\u5e38\u7c7b\u4f3c SUMMARY : \u5173\u4e8eillegal instruction fault\u5728 Unaligned accesses in C/C++: what, why and solutions to do it properly \u4e2d\u4ecb\u7ecd\u4e86\u3002 Also, self-alignment is not the only possible rule. Historically, some processors (especially those lacking barrel shifters ) have had more restrictive ones. If you do embedded systems, you might trip over one of these lurking in the underbrush. Be aware this is possible. From when it was first written at the beginning of 2014 until late 2016, this section ended with the last paragraph. During that period I\u2019ve learned something rather reassuring\uff08\u4f7f\u653e\u5fc3\uff09 from working with the source code for the reference implementation of NTP. It does packet analysis by reading packets off the wire directly into memory that the rest of the code sees as a struct , relying on the assumption of minimal self-aligned padding . SUMMARY : NTP\u53c2\u89c1 Network Time Protocol \u3002 The interesting news is that NTP has apparently being getting away with this for *decades* across a very wide span of hardware, operating systems, and compilers, including not just Unixes but under Windows variants as well. This suggests that platforms with padding rules other than self-alignment are either nonexistent or confined to such specialized niches that they\u2019re never either NTP servers or clients. 4. Padding Now we\u2019ll look at a simple example of variable layout in memory. Consider the following series of variable declarations in the top level of a C module: char * p ; char c ; int x ; If you didn\u2019t know anything about data alignment , you might assume that these three variables would occupy a continuous span of bytes in memory. That is, on a 32-bit machine 4 bytes of pointer would be immediately followed by 1 byte of char and that immediately followed by 4 bytes of int. And a 64-bit machine would be different only in that the pointer would be 8 bytes. In fact, the hidden assumption that the allocated order of static variables is their source order is not necessarily valid ; the C standards don\u2019t mandate it. I\u2019m going to ignore this detail because (a) that hidden assumption is usually correct anyway, and (b) the actual purpose of talking about padding and packing outside structures is to prepare you for what happens inside them. SUMMARY : \u5bf9\u4e8eC standard\u5e76\u6ca1\u6709\u5f3a\u5236\u8981\u6c42\u7684\u6807\u5fd7\u6211\u4eec\u662f\u4e0d\u80fd\u591f\u4f9d\u8d56\u5b83\u7684\uff0c \u6bd4\u5982\u8fd9\u91cc\u6240\u8ff0\u7684\uff1athe allocated order of static variables is their source order\uff1b\u56e0\u4e3a\u6211\u4eec\u7684source code\u5176\u5b9e\u5e76\u4e0d\u603b\u662f\u7b26\u5408\u7f16\u8bd1\u5668\u6240\u8ba4\u4e3a\u7684\u6700\u4f18\u539f\u5219\u7684\uff0c\u6bd4\u5982\u8bf4\u4e0a\u9762\u7684\u4ee3\u7801\uff0c\u663e\u7136\u5b83\u4f1a\u9020\u62103 bytes gap\u3002\u5176\u5b9e\u7f16\u8bd1\u5668\u662f\u5b8c\u5168\u53ef\u4ee5\u8fdb\u884c\u4f18\u5316\u6765\u5c06\u8fd93 byte\u7ed9\u53bb\u9664\u7684\uff1b Here\u2019s what actually happens (on an x86 or ARM or anything else with self-aligned types). The storage for p starts on a self-aligned 4- or 8-byte boundary depending on the machine word size. This is pointer alignment - the strictest possible. SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u5176\u5b9e\u662f\u6bd4\u8f83\u6a21\u7cca\u7684\uff0c\u6309\u7167\u524d\u9762\u7684\u63a8\u7406\uff1aalignment \u7b49\u4e8e sizeof \uff0c\u90a3\u4e48 pointer alignment \u5c31\u7b49\u4e8e\u5b83\u7684 sizeof \uff1b\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\u8bf4\uff0c pointer alignment \u53d6\u51b3\u4e8emachine word size\uff0c\u90a3\u8fd9\u8bf4\u660e pointer alignement \u548cmachine word size\u4e4b\u95f4\u662f\u5b58\u5728\u7740\u975e\u5e38\u5927\u7684\u5173\u8054\u7684\uff0c\u90a3\u5230\u5e95\u662f\u4ec0\u4e48\u5173\u8054\u5462\uff1f\u662f pointer alignment \u7b49\u4e8emachine word size\u5417\uff1f\u8fd9\u5f15\u53d1\u4e86\u6211\u7684\u601d\u8003\uff1a What is the size of a pointer? \u6309\u7167\u6211\u4e4b\u524d\u7684\u60f3\u6cd5\uff1a\u6307\u9488\u7684\u5927\u5c0f\u5fc5\u987b\u80fd\u591f\u4fdd\u8bc1\u5b83\u80fd\u591f\u8bbf\u95ee\u5230\u8fd9\u4e2a\u5185\u5b58\u7a7a\u95f4\uff0c\u8fd9\u8bf4\u660e\u6307\u9488\u7c7b\u578b\u7684\u957f\u5ea6\u548c\u5185\u5b58\u7a7a\u95f4\u7684\u5927\u5c0f\u662f\u5b58\u5728\u7740\u5173\u8054\u7684\uff1b \u8fd9\u7bc7\u6587\u7ae0\u4e5f\u6bd4\u8f83\u597d\uff1a C\u8bed\u8a00\u6307\u9488\u7684\u957f\u5ea6\u548c\u7c7b\u578b The storage for c follows immediately. But the 4-byte alignment requirement of x forces a gap in the layout; it comes out as though there were a fourth intervening variable, like this: char * p ; /* 4 or 8 bytes */ char c ; /* 1 byte */ char pad [ 3 ]; /* 3 bytes */ int x ; /* 4 bytes */ The pad[3] character array represents the fact that there are three bytes of waste space in the structure. The old-school term for this was \"slop\". The value of the padding bits is undefined ; in particular it is not guaranteed that they will be zeroed. Compare what happens if x is a 2-byte short: char * p ; char c ; short x ; In that case, the actual layout will be this: char * p ; /* 4 or 8 bytes */ char c ; /* 1 byte */ char pad [ 1 ]; /* 1 byte */ short x ; /* 2 bytes */ On the other hand, if x is a long on a 64-bit machine char * p ; char c ; long x ; we end up with this: char * p ; /* 8 bytes */ char c ; /* 1 byte char pad[7]; /* 7 bytes */ long x ; /* 8 bytes */ If you have been following carefully, you are probably now wondering about the case where the shorter variable declaration comes first: char c ; char * p ; int x ; If the actual memory layout were written like this char c ; char pad1 [ M ]; char * p ; char pad2 [ N ]; int x ; what can we say about M and N ? First, in this case N will be zero. The address of x , coming right after p , is guaranteed to be pointer-aligned , which is never less strict than int-aligned . SUMMARY : \u56e0\u4e3a\u8fd9\u4e9balign\u7684\u503c\u90fd\u662f2\u7684\u5e42\uff0c\u6240\u4ee5\u5b83\u4eec\u4e4b\u95f4\u5b58\u5728\u7740\u500d\u6570\u7684\u5173\u7cfb\uff1b The value of M is less predictable. If the compiler happened to map c to the last byte of a machine word, the next byte (the first of p ) would be the first byte of the next one and properly pointer-aligned . M would be zero. It is more likely that c will be mapped to the first byte of a machine word. In that case M will be whatever padding is needed to ensure that p has pointer alignment - 3 on a 32-bit machine, 7 on a 64-bit machine. Intermediate cases are possible. M can be anything from 0 to 7 (0 to 3 on 32-bit) because a char can start on any byte boundary in a machine word. If you wanted to make those variables take up less space, you could get that effect by swapping x with c in the original sequence. char * p ; /* 8 bytes */ long x ; /* 8 bytes */ char c ; /* 1 byte Usually, for the small number of scalar variables in your C programs, bumming out the few bytes you can get by changing the order of declaration won\u2019t save you enough to be significant. The technique becomes more interesting when applied to nonscalar variables - especially struct s. Before we get to those, let\u2019s dispose of arrays of scalars. On a platform with self-aligned types, arrays of char / short / int / long /pointer have no internal padding; each member is automatically self-aligned at the end of the next one. All these rules and examples map over to Go with only syntactic changes. In the next section we will see that the same is *not* necessarily true of structure arrays. 5. Structure alignment and padding In general, a struct instance will have the alignment of its widest scalar member . Compilers do this as the easiest way to ensure that all the members are self-aligned for fast access. Also, in C (and Go, and Rust) the address of a struct is the same as the address of its first member - there is no leading padding . Beware: in C++ , classes that look like struct s may break this rule! (Whether they do or not depends on how base classes and virtual member functions are implemented, and varies by compiler.) (When you\u2019re in doubt about this sort of thing, ANSI C provides an offsetof() macro which can be used to read out structure member offsets.) Consider this struct : struct foo1 { char * p ; char c ; long x ; }; Assuming a 64-bit machine, any instance of struct foo1 will have 8-byte alignment. The memory layout of one of these looks unsurprising, like this: struct foo1 { char * p ; /* 8 bytes */ char c ; /* 1 byte char pad[7]; /* 7 bytes */ long x ; /* 8 bytes */ }; It\u2019s laid out exactly as though variables of these types has been separately declared. But if we put c first, that\u2019s no longer true. struct foo2 { char c ; /* 1 byte */ char pad [ 7 ]; /* 7 bytes */ char * p ; /* 8 bytes */ long x ; /* 8 bytes */ }; If the members were separate variables, c could start at any byte boundary and the size of pad might vary. Because struct foo2 has the pointer alignment of its widest member, that\u2019s no longer possible. Now c has to be pointer-aligned , and following padding of 7 bytes is locked in. SUMMARY : \u8fd9\u6bb5\u8bdd\u7ed9\u51fa\u4e86\u4e0a\u8ff0\u4e24\u79cd\u65b9\u5f0f\u4e4b\u95f4\u7684\u5dee\u5f02\u6240\u5728\uff1b Now let\u2019s talk about trailing padding on structures. To explain this, I need to introduce a basic concept which I\u2019ll call the stride address of a structure. It is the first address following the structure data that has the same alignment as the structure . The general rule of trailing structure padding is this: the compiler will behave as though the structure has trailing padding out to its stride address . This rule controls what sizeof() will return. Consider this example on a 64-bit x86 or ARM machine: struct foo3 { char * p ; /* 8 bytes */ char c ; /* 1 byte */ }; struct foo3 singleton ; struct foo3 quad [ 4 ]; You might think that sizeof(struct foo3) should be 9, but it\u2019s actually 16. The stride address is that of (&p)[2] . Thus, in the quad array, each member has 7 bytes of trailing padding, because the first member of each following struct wants to be self-aligned on an 8-byte boundary. The memory layout is as though the structure had been declared like this: struct foo3 { char * p ; /* 8 bytes */ char c ; /* 1 byte */ char pad [ 7 ]; }; For contrast, consider the following example: struct foo4 { short s ; /* 2 bytes */ char c ; /* 1 byte */ }; Because s only needs to be 2-byte aligned, the stride address is just one byte after c , and struct foo4 as a whole only needs one byte of trailing padding . It will be laid out like this: struct foo4 { short s ; /* 2 bytes */ char c ; /* 1 byte */ char pad [ 1 ]; }; and sizeof(struct foo4) will return 4. Here\u2019s a last important detail: If your structure has structure members, the inner structs want to have the alignment of longest scalar too. Suppose you write this: struct foo5 { char c ; struct foo5_inner { char * p ; short x ; } inner ; }; The char *p member in the inner struct forces the outer struct to be pointer-aligned as well as the inner. Actual layout will be like this on a 64-bit machine: struct foo5 { char c ; /* 1 byte*/ char pad1 [ 7 ]; /* 7 bytes */ struct foo5_inner { char * p ; /* 8 bytes */ short x ; /* 2 bytes */ char pad2 [ 6 ]; /* 6 bytes */ } inner ; }; This structure gives us a hint of the savings that might be possible from repacking structures. Of 24 bytes, 13 of them are padding. That\u2019s more than 50% waste space! 6. Bitfields Now let\u2019s consider C bitfields. What they give you the ability to do is declare structure fields of smaller than character width, down to 1 bit, like this: struct foo6 { short s ; char c ; int flip : 1 ; int nybble : 4 ; int septet : 7 ; }; The thing to know about bitfields is that they are implemented with word- and byte-level mask and rotate instructions operating on machine words, and cannot cross word boundaries. C99 guarentees that bit-fields will be packed as tightly as possible, provided they don\u2019t cross storage unit boundaries (6.7.2.1 #10 ). This restriction is relaxed in C11 (6.7.2.1p11) and C++14 ([class.bit]p1); these revisions do not actually require struct foo9 to be 64 bits instead of 32; a bit-field can span multiple allocation units instead of starting a new one. It\u2019s up to the implementation to decide; GCC leaves it up to the ABI, which for x64 does prevent them from sharing an allocation unit. Assuming we\u2019re on a 32-bit machine, the C99 rules imply that the layout may look like this: struct foo6 { short s ; /* 2 bytes */ char c ; /* 1 byte */ int flip : 1 ; /* total 1 bit */ int nybble : 4 ; /* total 5 bits */ int pad1 : 3 ; /* pad to an 8-bit boundary */ int septet : 7 ; /* 7 bits */ int pad2 : 25 ; /* pad to 32 bits */ }; But this isn\u2019t the only possibility, because the C standard does not specify that bits are allocated low-to-high. So the layout could look like this: struct foo6 { short s ; /* 2 bytes */ char c ; /* 1 byte */ int pad1 : 3 ; /* pad to an 8-bit boundary */ int flip : 1 ; /* total 1 bit */ int nybble : 4 ; /* total 5 bits */ int pad2 : 25 ; /* pad to 32 bits */ int septet : 7 ; /* 7 bits */ }; That is, the padding could precede rather than following the payload bits. Note also that, as with normal structure padding, the padding bits are not guaranteed to be zero; C99 mentions this. Note that the base type of a bit field is interpreted for signedness but not necessarily for size. It is up to implementors whether \"short flip:1\" or \"long flip:1\" are supported, and whether those base types change the size of the storage unit the field is packed into. Proceed with caution and check with -Wpadded if you have it available (e.g. under clang). Compilers on exotic hardware might interpret the C99 rules in surprising ways; older compilers might not quite follow them. The restriction that bitfields cannot cross machine word boundaries means that, while the first two of the following structures pack into one and two 32-bit words as you\u2019d expect, the third ( struct foo9 ) takes up *three* 32-bit words in C99, in the last of which only one bit is used. struct foo7 { int bigfield : 31 ; /* 32-bit word 1 begins */ int littlefield : 1 ; }; struct foo8 { int bigfield1 : 31 ; /* 32-bit word 1 begins /* int littlefield1:1; int bigfield2:31; /* 32-bit word 2 begins */ int littlefield2 : 1 ; }; struct foo9 { int bigfield1 : 31 ; /* 32-bit word 1 begins */ int bigfield2 : 31 ; /* 32-bit word 2 begins */ int littlefield1 : 1 ; int littlefield2 : 1 ; /* 32-bit word 3 begins */ }; Again, C11 and C++14 may pack foo9 tighter, but it would perhaps be unwise to count on this. On the other hand, struct foo8 would fit into a single 64-bit word if the machine has those. 7. Structure reordering Now that you know how and why compilers insert padding in and after your structures we\u2019ll examine what you can do to squeeze out the slop. This is the art of structure packing. The first thing to notice is that slop only happens in two places. One is where storage bound to a larger data type (with stricter alignment requirements) follows storage bound to a smaller one. The other is where a struct naturally ends before its stride address, requiring padding so the next one will be properly aligned. The simplest way to eliminate slop is to reorder the structure members by decreasing alignment. That is: make all the pointer-aligned subfields come first, because on a 64-bit machine they will be 8 bytes. Then the 4-byte ints; then the 2-byte shorts; then the character fields. So, for example, consider this simple linked-list structure: struct foo10 { char c ; struct foo10 * p ; short x ; }; With the implied slop made explicit, here it is: struct foo10 { char c ; /* 1 byte */ char pad1 [ 7 ]; /* 7 bytes */ struct foo10 * p ; /* 8 bytes */ short x ; /* 2 bytes */ char pad2 [ 6 ]; /* 6 bytes */ }; That\u2019s 24 bytes. If we reorder by size, we get this: struct foo11 { struct foo11 * p ; short x ; char c ; }; Considering self-alignment, we see that none of the data fields need padding. This is because the stride address for a (longer) field with stricter alignment is always a validly-aligned start address for a (shorter) field with less strict requirements. All the repacked struct actually requires is trailing padding: struct foo11 { struct foo11 * p ; /* 8 bytes */ short x ; /* 2 bytes */ char c ; /* 1 byte */ char pad [ 5 ]; /* 5 bytes */ }; Our repack transformation drops the size from 24 to 16 bytes. This might not seem like a lot, but suppose you have a linked list of 200K of these? The savings add up fast - especially on memory-constrained embedded systems or in the core part of an OS kernel that has to stay resident. Note that reordering is not guaranteed to produce savings. Applying this technique to an earlier example, struct foo5 , we get this: struct foo12 { struct foo5 { char * p ; /* 8 bytes */ short x ; /* 2 bytes */ } inner ; char c ; /* 1 byte*/ }; With padding written out, this is struct foo12 { struct foo5 { char * p ; /* 8 bytes */ short x ; /* 2 bytes */ char pad [ 6 ]; /* 6 bytes */ } inner ; char c ; /* 1 byte*/ char pad [ 7 ]; /* 7 bytes */ }; It\u2019s still 24 bytes because c cannot back into the inner struct\u2019s trailing padding. To collect that gain you would need to redesign your data structures. Curiously, strictly ordering your structure fields by increasing size also works to mimimize padding. You can minimize padding with any order in which (a) all fields of any one size are in a continuous span (completely eliminating padding between them), and (b) the gaps between those spans are such that the sizes on either side have as few doubling steps of difference from each other as possible. Usually this means no padding at all on one side. Even more general minimal-padding orders are possible. Example: struct foo13 { int32_t i ; int32_t i2 ; char octet [ 8 ]; int32_t i3 ; int32_t i4 ; int64_t l ; int32_t i5 ; int32_t i6 ; }; This struct has zero padding under self-alignment rules. Working out why is a useful exercise to develop your understanding. Since shipping the first version of this guide I have been asked why, if reordering for minimal slop is so simple, C compilers don\u2019t do it automatically. The answer: C is a language originally designed for writing operating systems and other code close to the hardware. Automatic reordering would interfere with a systems programmer\u2019s ability to lay out structures that exactly match the byte and bit-level layout of memory-mapped device control blocks. Go hews to the C philosophy and does not reorder fields. Rust makes the opposite choice; by default, its compiler may reorder structure fields. 8. Awkward scalar cases Using enumerated types instead of #defines is a good idea, if only because symbolic debuggers have those symbols available and can show them rather than raw integers. But, while enums are guaranteed to be compatible with an integral type, the C standard does not specify which underlying integral type is to be used for them. Be aware when repacking your structs that while enumerated-type variables are usually ints, this is compiler-dependent; they could be shorts, longs, or even chars by default. Your compiler may have a pragma or command-line option to force the size. The long double type is a similar trouble spot. Some C platforms implement this in 80 bits, some in 128, and some of the 80-bit platforms pad it to 96 or 128 bits. In both cases it\u2019s best to use sizeof() to check the storage size. Finally, under x86 Linux doubles are sometimes an exception to the self-alignment rule; an 8-byte double may require only 4-byte alignment within a struct even though standalone doubles variables have 8-byte self-alignment. This depends on compiler and options. 9. Readability and cache locality While reordering by size is the simplest way to eliminate slop, it\u2019s not necessarily the right thing. There are two more issues: readability and cache locality. Programs are not just communications to a computer, they are communications to other human beings. Code readability is important even (or especially!) when the audience of the communication is only your future self. A clumsy, mechanical reordering of your structure can harm readability. When possible, it is better to reorder fields so they remain in coherent groups with semantically related pieces of data kept close together. Ideally, the design of your structure should communicate the design of your program. When your program frequently accesses a structure, or parts of a structure, it is helpful for performance if the accesses tend to fit within a cache line - the memory block fetched by your processor when it is told to get any single address within the block. On 64-bit x86 a cache line is 64 bytes beginning on a self-aligned address; on other platforms it is often 32 bytes. The things you should do to preserve readability - grouping related and co-accessed data in adjacent fields - also improve cache-line locality. These are both reasons to reorder intelligently, with awareness of your code\u2019s data-access patterns. If your code does concurrent access to a structure from multiple threads, there\u2019s a third issue: cache line bouncing. To minimize expensive bus traffic, you should arrange your data so that reads come from one cache line and writes go to another in your tighter loops. And yes, this sometimes contradicts the previous guidance about grouping related data in the same cache-line-sized block. Multithreading is hard. Cache-line bouncing and other multithread optimization issues are very advanced topics which deserve an entire tutorial of their own. The best I can do here is make you aware that these issues exist. 10. Other packing techniques Reordering works best when combined with other techniques for slimming your structures. If you have several boolean flags in a struct, for example, consider reducing them to 1-bit bitfields and packing them into a place in the structure that would otherwise be slop. You\u2019ll take a small access-time penalty for this - but if it squeezes the working set enough smaller, that penalty will be swamped by your gains from avoided cache misses. More generally, look for ways to shorten data field sizes. In cvs-fast-export, for example, one squeeze I applied was to use the knowledge that RCS and CVS repositories didn\u2019t exist before 1982. I dropped a 64-bit Unix time_t (zero date at the beginning of 1970) for a 32-bit time offset from 1982-01-01T00:00:00; this will cover dates to 2118. (Note: if you pull a trick like this, do a bounds check whenever you set the field to prevent nasty bugs!) Each such field shortening not only decreases the explicit size of your structure, it may remove slop and/or create additional opportunities for gains from field reordering. Virtuous cascades of such effects are not very hard to trigger. The riskiest form of packing is to use unions. If you know that certain fields in your structure are never used in combination with certain other fields, consider using a union to make them share storage. But be extra careful and verify your work with regression testing, because if your lifetime analysis is even slightly wrong you will get bugs ranging from crashes to (much worse) subtle data corruption. 11. Overriding alignment rules Sometimes you can coerce your compiler into not using the processor\u2019s normal alignment rules by using a pragma, usually #pragma pack . GCC and clang have an attribute**packed you can attach to individual structure declarations; GCC has an -fpack-struct option for entire compilations. Do not do this casually, as it forces the generation of more expensive and slower code. Usually you can save as much memory, or almost as much, with the techniques I describe here. The only good reason for #pragma pack is if you have to exactly match your C data layout to some kind of bit-level hardware or protocol requirement, like a memory-mapped hardware port, and violating normal alignment is required for that to work. If you\u2019re in that situation, and you don\u2019t already know everything else I\u2019m writing about here, you\u2019re in deep trouble and I wish you luck. 12. Tools The clang compiler has a -Wpadded option that causes it to generate messages about alignment holes and padding. Some versions also have an undocumented -fdump-record-layouts option that yields more information . If you\u2019re using C11, you can deploy static_assert to check your assumptions about type and structure sizes. Example: #include <assert.h> struct foo4 { short s; /* 2 bytes */ char c; /* 1 byte */ }; static_assert(sizeof(struct foo4) == 4, \u201cCheck your assumptions\"); I have not used it myself, but several respondents speak well of a program called pahole . This tool cooperates with a compiler to produce reports on your structures that describe padding, alignment, and cache line boundaries. This was at one time a standalone C program, but that is now unmaintained; s script with the name pahole now ships with gdb and that is what you should use. I\u2019ve received a report that a proprietary code auditing tool called \"PVS Studio\" can detect structure-packing opportunities. 13. Proof and exceptional cases You can download sourcecode for a little program that demonstrates the assertions about scalar and structure sizes made above. It is packtest.c . If you look through enough strange combinations of compilers, options, and unusual hardware, you will find exceptions to some of the rules I have described. They get more common as you go back in time to older processor designs. The next level beyond knowing these rules is knowing how and when to expect that they will be broken. In the years when I learned them (the early 1980s) we spoke of people who didn\u2019t get this as victims of \"all-the-world\u2019s-a-VAX syndrome\". Remember that not all the world is a PC. 14. Go and Rust The Go language is in many respects similar to C. It has structures and arrays, though not bitfields or unions. Go compilers have the same optimization and alignment issues as C compilers. One important difference is that the Go specification *requires* structure fields to be self-aligned. As in C, array elements are padded up to the following stride address. Therefore, if you know the implications of self-aligment in C, you can apply them directly to calculating sizes and offsets in Go and to space-optimizing Go structures. The obvious correspondence mostly works. I say \"mostly\" because Go has one odd quirk. Since Go 1.5, a zero-length field at the end of a struct (that is, a zero-length array or empty struct) is sized and aligned as though it is one byte. The reasons for this are discussed in an essay Padding is Hard by one of the Go developers. Rust follows C-like field alignment rules if a structure is annotated with \"repr(C)\". Otherwise (by default) all bets are off: padding rules are (deliberately) unspecified and the compiler may even reorder structure members. It is probably best to let the Rust compiler do space optimization rather than forcing it. 15. Supporting this work If you were educated or entertained by this document, please sign up for my Patreon feed . The time needed to write and maintain documents like this one is not free, and while I enjoying giving them to the world my bills won\u2019t pay themselves. Even a few dollars a month - from enough of you - helps a lot. 16. Related Reading This section exists to collect pointers to essays which I judge to be good companions to this one. A Guide to Undefined Behavior in C and C++ Time, Clock, and Calendar Programming In C Things Every Hacker Once Knew","title":"The-Lost-Art-of-Structure-Packing"},{"location":"ABI/Alignment/Data-structure-alignment/The-Lost-Art-of-Structure-Packing/#the-lost-art-of-structure-packing","text":"","title":"The Lost Art of Structure Packing"},{"location":"ABI/Alignment/Data-structure-alignment/The-Lost-Art-of-Structure-Packing/#1-who-should-read-this","text":"This page is about a technique for reducing the memory footprint of programs in compiled languages with C-like structures - manually repacking these declarations for reduced size. To read it, you will require basic knowledge of the C programming language. You need to know this technique if you intend to write code for memory-constrained embedded systems, or operating-system kernels. It is useful if you are working with application data sets so large that your programs routinely hit memory limits. It is good to know in any application where you really, really care about optimizing your use of memory bandwidth and minimizing cache-line misses. SUMMARY : \u5728 Data structure alignment \u4e2d\u4e5f\u63d0\u53ca\u4e86 cache-line \u3002 Finally, knowing this technique is a gateway to other esoteric C topics. You are not an advanced C programmer until you have grasped these rules. You are not a master of C until you could have written this document yourself and can criticize it intelligently. This document originated with \"C\" in the title, but many of the techniques discussed here also apply to the Go language - and should generalize to any compiled language with C-like structures. There is a note discussing Go and Rust towards the end.","title":"1. Who should read this"},{"location":"ABI/Alignment/Data-structure-alignment/The-Lost-Art-of-Structure-Packing/#2-why-i-wrote-it","text":"This webpage exists because in late 2013 I found myself heavily applying an optimization technique that I had learned more than two decades previously and not used much since. SUMMARY : \u8fd9\u4e2a\u7f51\u9875\u7684\u5b58\u5728\u662f\u56e0\u4e3a\u57282013\u5e74\u672b\u6211\u53d1\u73b0\u81ea\u5df1\u5927\u91cf\u5e94\u7528\u4e86\u4e00\u79cd\u4f18\u5316\u6280\u672f\uff0c\u8fd9\u79cd\u6280\u672f\u662f\u6211\u5728\u4e8c\u5341\u591a\u5e74\u524d\u5b66\u5230\u7684\u5e76\u4e14\u4ece\u90a3\u65f6\u8d77\u5c31\u6ca1\u7528\u8fc7\u591a\u5c11\u3002 I needed to reduce the memory footprint of a program that used thousands - sometimes hundreds of thousands - of C struct instances. The program was cvs-fast-export and the problem was that it was dying with out-of-memory errors on large repositories. SUMMARY : out-of-memory\u7684\u610f\u601d\u662f\u5185\u5b58\u4e0d\u8db3\uff0c\u53c2\u89c1 Out of memory \u3002 There are ways to reduce memory usage significantly in situations like this, by rearranging the order of structure members in careful ways. This can lead to dramatic gains - in my case I was able to cut the working-set size by around 40%, enabling the program to handle much larger repositories without dying. But as I worked, and thought about what I was doing, it began to dawn on me that the technique I was using has been more than half forgotten in these latter days. A little web research confirmed that programmers don\u2019t seem to talk about it much any more, at least not where a search engine can see them. A couple of Wikipedia entries touch the topic, but I found nobody who covered it comprehensively. There are actually reasons for this that aren\u2019t stupid. CS courses (rightly) steer people away from micro-optimization towards finding better algorithms. The plunging price of machine resources has made squeezing memory usage less necessary. And the way hackers used to learn how to do it back in the day was by bumping their noses on strange hardware architectures - a less common experience now. But the technique still has value in important situations, and will as long as memory is finite. This document is intended to save programmers from having to rediscover the technique, so they can concentrate effort on more important things. SUMMARY : \u5b9e\u9645\u4e0a\u6709\u4e9b\u539f\u56e0\u5e76\u4e0d\u662f\u611a\u8822\u7684\u3002 CS\u8bfe\u7a0b\uff08\u6b63\u786e\u5730\uff09\u5f15\u5bfc\u4eba\u4eec\u8fdc\u79bb\u5fae\u89c2\u4f18\u5316\uff0c\u5bfb\u627e\u66f4\u597d\u7684\u7b97\u6cd5\u3002 \u673a\u5668\u8d44\u6e90\u7684\u4ef7\u683c\u66b4\u8dcc\u4f7f\u5f97\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u7684\u5fc5\u8981\u6027\u964d\u4f4e\u3002 \u9ed1\u5ba2\u8fc7\u53bb\u5e38\u5e38\u5b66\u4e60\u5982\u4f55\u505a\u5230\u8fd9\u4e00\u70b9\u7684\u65b9\u5f0f\u662f\u5728\u5947\u602a\u7684\u786c\u4ef6\u67b6\u6784\u4e0a\u55e4\u4e4b\u4ee5\u9f3b - \u73b0\u5728\u8fd9\u79cd\u4e0d\u592a\u5e38\u89c1\u7684\u4f53\u9a8c\u3002 \u4f46\u662f\u8fd9\u79cd\u6280\u672f\u5728\u91cd\u8981\u60c5\u51b5\u4e0b\u4ecd\u7136\u5177\u6709\u4ef7\u503c\uff0c\u5e76\u4e14\u53ea\u8981\u5b58\u50a8\u5668\u662f\u6709\u9650\u7684\u3002 \u672c\u6587\u6863\u65e8\u5728\u5e2e\u52a9\u7a0b\u5e8f\u5458\u4e0d\u5fc5\u91cd\u65b0\u53d1\u73b0\u8be5\u6280\u672f\uff0c\u56e0\u6b64\u4ed6\u4eec\u53ef\u4ee5\u5c06\u7cbe\u529b\u96c6\u4e2d\u5728\u66f4\u91cd\u8981\u7684\u4e8b\u60c5\u4e0a\u3002","title":"2. Why I wrote it"},{"location":"ABI/Alignment/Data-structure-alignment/The-Lost-Art-of-Structure-Packing/#3-alignment-requirements","text":"The first thing to understand is that, on modern processors, the way your compiler lays out basic datatypes in memory is constrained in order to make memory accesses faster. Our examples are in C, but any compiled language generates code under the same constraints. Storage for the basic C datatypes on an x86 or ARM processor doesn\u2019t normally start at arbitrary byte addresses in memory. Rather, each type except char has an alignment requirement ; chars can start on any byte address, but 2-byte shorts must start on an even address, 4-byte ints or floats must start on an address divisible by 4, and 8-byte longs or doubles must start on an address divisible by 8. Signed or unsigned makes no difference. The jargon(\u884c\u8bdd) for this is that basic C types on x86 and ARM are self-aligned . Pointers, whether 32-bit (4-byte) or 64-bit (8-byte) are self-aligned too. SUMMARY : \u4e0d\u540c\u7c7b\u578b\u7684align requirement\u5176\u5b9e\u5c31\u7b49\u4e8e sizeof Self-alignment makes access faster because it facilitates generating single-instruction fetches and puts of the typed data. Without alignment constraints, on the other hand, the code might end up having to do two or more accesses spanning\uff08\u8de8\u8d8a\uff09 machine-word boundaries . Characters are a special case; they\u2019re equally expensive from anywhere they live inside a single machine word . That\u2019s why they don\u2019t have a preferred alignment. SUMMARY : \u6700\u540e\u4e00\u6bb5\u8bdd\u7684\u610f\u601d\u662f\uff1a\u5bf9\u4e8e char \u7c7b\u578b\u7684\u6570\u636e\uff0c\u5b83\u4eec\u5e76\u6ca1\u6709preferred alignment\uff0c\u56e0\u4e3a\u65e0\u8bba\u5b83\u4eec\u4f4d\u4e8e\u4f55\u5904\uff0c\u88abaccess\u7684\u65f6\u5019\u6240\u9700\u7684\u8017\u8d39\u662f\u76f8\u540c\u7684\uff1b SUMMARY : \u5728\u8fd9\u7bc7\u6587\u7ae0\u4e2d\uff0c\u63cf\u8ff0\u4e86CPU \u8fdb\u884cmemory access\u7684\u65b9\u5f0f\uff1a Data alignment: Straighten up and fly right \uff0c\u4e0b\u9762\u8fd9\u4e2a\u56fe\u7247\u662f\u53d6\u81ea\u8fd9\u7bc7\u6587\u7ae0\uff1a Figure 2. How processors see memory I said \"on modern processors\" because on some older ones forcing your C program to violate alignment rules (say, by casting an odd\uff08\u5947\u6570\uff09 address into an int pointer and trying to use it) didn\u2019t just slow your code down, it caused an illegal instruction fault . This was the behavior, for example, on Sun SPARC chips. In fact, with sufficient determination and the right (e18) hardware flag set on the processor, you can still trigger this on x86 . THINKING : \u5728\u4ec0\u4e48\u60c5\u51b5\u4e0b\uff0c\u4f1a\u51fa\u73b0violate alignment rules\uff1f \u4e0b\u9762\u8fd9\u7bc7\u6587\u7ae0\u4e2d\u6240\u5217\u51fa\u7684\u662f\u4e00\u79cd\u60c5\u51b5 Should I worry about the alignment during pointer casting? \u8fd9\u7bc7\u6587\u7ae0\u4e2d\u6240\u4ecb\u7ecd\u7684\u548c\u4e0b\u9762\u94fe\u63a5\u4e2d\u7684\u60c5\u51b5\u975e\u5e38\u7c7b\u4f3c SUMMARY : \u5173\u4e8eillegal instruction fault\u5728 Unaligned accesses in C/C++: what, why and solutions to do it properly \u4e2d\u4ecb\u7ecd\u4e86\u3002 Also, self-alignment is not the only possible rule. Historically, some processors (especially those lacking barrel shifters ) have had more restrictive ones. If you do embedded systems, you might trip over one of these lurking in the underbrush. Be aware this is possible. From when it was first written at the beginning of 2014 until late 2016, this section ended with the last paragraph. During that period I\u2019ve learned something rather reassuring\uff08\u4f7f\u653e\u5fc3\uff09 from working with the source code for the reference implementation of NTP. It does packet analysis by reading packets off the wire directly into memory that the rest of the code sees as a struct , relying on the assumption of minimal self-aligned padding . SUMMARY : NTP\u53c2\u89c1 Network Time Protocol \u3002 The interesting news is that NTP has apparently being getting away with this for *decades* across a very wide span of hardware, operating systems, and compilers, including not just Unixes but under Windows variants as well. This suggests that platforms with padding rules other than self-alignment are either nonexistent or confined to such specialized niches that they\u2019re never either NTP servers or clients.","title":"3. Alignment requirements"},{"location":"ABI/Alignment/Data-structure-alignment/The-Lost-Art-of-Structure-Packing/#4-padding","text":"Now we\u2019ll look at a simple example of variable layout in memory. Consider the following series of variable declarations in the top level of a C module: char * p ; char c ; int x ; If you didn\u2019t know anything about data alignment , you might assume that these three variables would occupy a continuous span of bytes in memory. That is, on a 32-bit machine 4 bytes of pointer would be immediately followed by 1 byte of char and that immediately followed by 4 bytes of int. And a 64-bit machine would be different only in that the pointer would be 8 bytes. In fact, the hidden assumption that the allocated order of static variables is their source order is not necessarily valid ; the C standards don\u2019t mandate it. I\u2019m going to ignore this detail because (a) that hidden assumption is usually correct anyway, and (b) the actual purpose of talking about padding and packing outside structures is to prepare you for what happens inside them. SUMMARY : \u5bf9\u4e8eC standard\u5e76\u6ca1\u6709\u5f3a\u5236\u8981\u6c42\u7684\u6807\u5fd7\u6211\u4eec\u662f\u4e0d\u80fd\u591f\u4f9d\u8d56\u5b83\u7684\uff0c \u6bd4\u5982\u8fd9\u91cc\u6240\u8ff0\u7684\uff1athe allocated order of static variables is their source order\uff1b\u56e0\u4e3a\u6211\u4eec\u7684source code\u5176\u5b9e\u5e76\u4e0d\u603b\u662f\u7b26\u5408\u7f16\u8bd1\u5668\u6240\u8ba4\u4e3a\u7684\u6700\u4f18\u539f\u5219\u7684\uff0c\u6bd4\u5982\u8bf4\u4e0a\u9762\u7684\u4ee3\u7801\uff0c\u663e\u7136\u5b83\u4f1a\u9020\u62103 bytes gap\u3002\u5176\u5b9e\u7f16\u8bd1\u5668\u662f\u5b8c\u5168\u53ef\u4ee5\u8fdb\u884c\u4f18\u5316\u6765\u5c06\u8fd93 byte\u7ed9\u53bb\u9664\u7684\uff1b Here\u2019s what actually happens (on an x86 or ARM or anything else with self-aligned types). The storage for p starts on a self-aligned 4- or 8-byte boundary depending on the machine word size. This is pointer alignment - the strictest possible. SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u5176\u5b9e\u662f\u6bd4\u8f83\u6a21\u7cca\u7684\uff0c\u6309\u7167\u524d\u9762\u7684\u63a8\u7406\uff1aalignment \u7b49\u4e8e sizeof \uff0c\u90a3\u4e48 pointer alignment \u5c31\u7b49\u4e8e\u5b83\u7684 sizeof \uff1b\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\u8bf4\uff0c pointer alignment \u53d6\u51b3\u4e8emachine word size\uff0c\u90a3\u8fd9\u8bf4\u660e pointer alignement \u548cmachine word size\u4e4b\u95f4\u662f\u5b58\u5728\u7740\u975e\u5e38\u5927\u7684\u5173\u8054\u7684\uff0c\u90a3\u5230\u5e95\u662f\u4ec0\u4e48\u5173\u8054\u5462\uff1f\u662f pointer alignment \u7b49\u4e8emachine word size\u5417\uff1f\u8fd9\u5f15\u53d1\u4e86\u6211\u7684\u601d\u8003\uff1a What is the size of a pointer? \u6309\u7167\u6211\u4e4b\u524d\u7684\u60f3\u6cd5\uff1a\u6307\u9488\u7684\u5927\u5c0f\u5fc5\u987b\u80fd\u591f\u4fdd\u8bc1\u5b83\u80fd\u591f\u8bbf\u95ee\u5230\u8fd9\u4e2a\u5185\u5b58\u7a7a\u95f4\uff0c\u8fd9\u8bf4\u660e\u6307\u9488\u7c7b\u578b\u7684\u957f\u5ea6\u548c\u5185\u5b58\u7a7a\u95f4\u7684\u5927\u5c0f\u662f\u5b58\u5728\u7740\u5173\u8054\u7684\uff1b \u8fd9\u7bc7\u6587\u7ae0\u4e5f\u6bd4\u8f83\u597d\uff1a C\u8bed\u8a00\u6307\u9488\u7684\u957f\u5ea6\u548c\u7c7b\u578b The storage for c follows immediately. But the 4-byte alignment requirement of x forces a gap in the layout; it comes out as though there were a fourth intervening variable, like this: char * p ; /* 4 or 8 bytes */ char c ; /* 1 byte */ char pad [ 3 ]; /* 3 bytes */ int x ; /* 4 bytes */ The pad[3] character array represents the fact that there are three bytes of waste space in the structure. The old-school term for this was \"slop\". The value of the padding bits is undefined ; in particular it is not guaranteed that they will be zeroed. Compare what happens if x is a 2-byte short: char * p ; char c ; short x ; In that case, the actual layout will be this: char * p ; /* 4 or 8 bytes */ char c ; /* 1 byte */ char pad [ 1 ]; /* 1 byte */ short x ; /* 2 bytes */ On the other hand, if x is a long on a 64-bit machine char * p ; char c ; long x ; we end up with this: char * p ; /* 8 bytes */ char c ; /* 1 byte char pad[7]; /* 7 bytes */ long x ; /* 8 bytes */ If you have been following carefully, you are probably now wondering about the case where the shorter variable declaration comes first: char c ; char * p ; int x ; If the actual memory layout were written like this char c ; char pad1 [ M ]; char * p ; char pad2 [ N ]; int x ; what can we say about M and N ? First, in this case N will be zero. The address of x , coming right after p , is guaranteed to be pointer-aligned , which is never less strict than int-aligned . SUMMARY : \u56e0\u4e3a\u8fd9\u4e9balign\u7684\u503c\u90fd\u662f2\u7684\u5e42\uff0c\u6240\u4ee5\u5b83\u4eec\u4e4b\u95f4\u5b58\u5728\u7740\u500d\u6570\u7684\u5173\u7cfb\uff1b The value of M is less predictable. If the compiler happened to map c to the last byte of a machine word, the next byte (the first of p ) would be the first byte of the next one and properly pointer-aligned . M would be zero. It is more likely that c will be mapped to the first byte of a machine word. In that case M will be whatever padding is needed to ensure that p has pointer alignment - 3 on a 32-bit machine, 7 on a 64-bit machine. Intermediate cases are possible. M can be anything from 0 to 7 (0 to 3 on 32-bit) because a char can start on any byte boundary in a machine word. If you wanted to make those variables take up less space, you could get that effect by swapping x with c in the original sequence. char * p ; /* 8 bytes */ long x ; /* 8 bytes */ char c ; /* 1 byte Usually, for the small number of scalar variables in your C programs, bumming out the few bytes you can get by changing the order of declaration won\u2019t save you enough to be significant. The technique becomes more interesting when applied to nonscalar variables - especially struct s. Before we get to those, let\u2019s dispose of arrays of scalars. On a platform with self-aligned types, arrays of char / short / int / long /pointer have no internal padding; each member is automatically self-aligned at the end of the next one. All these rules and examples map over to Go with only syntactic changes. In the next section we will see that the same is *not* necessarily true of structure arrays.","title":"4. Padding"},{"location":"ABI/Alignment/Data-structure-alignment/The-Lost-Art-of-Structure-Packing/#5-structure-alignment-and-padding","text":"In general, a struct instance will have the alignment of its widest scalar member . Compilers do this as the easiest way to ensure that all the members are self-aligned for fast access. Also, in C (and Go, and Rust) the address of a struct is the same as the address of its first member - there is no leading padding . Beware: in C++ , classes that look like struct s may break this rule! (Whether they do or not depends on how base classes and virtual member functions are implemented, and varies by compiler.) (When you\u2019re in doubt about this sort of thing, ANSI C provides an offsetof() macro which can be used to read out structure member offsets.) Consider this struct : struct foo1 { char * p ; char c ; long x ; }; Assuming a 64-bit machine, any instance of struct foo1 will have 8-byte alignment. The memory layout of one of these looks unsurprising, like this: struct foo1 { char * p ; /* 8 bytes */ char c ; /* 1 byte char pad[7]; /* 7 bytes */ long x ; /* 8 bytes */ }; It\u2019s laid out exactly as though variables of these types has been separately declared. But if we put c first, that\u2019s no longer true. struct foo2 { char c ; /* 1 byte */ char pad [ 7 ]; /* 7 bytes */ char * p ; /* 8 bytes */ long x ; /* 8 bytes */ }; If the members were separate variables, c could start at any byte boundary and the size of pad might vary. Because struct foo2 has the pointer alignment of its widest member, that\u2019s no longer possible. Now c has to be pointer-aligned , and following padding of 7 bytes is locked in. SUMMARY : \u8fd9\u6bb5\u8bdd\u7ed9\u51fa\u4e86\u4e0a\u8ff0\u4e24\u79cd\u65b9\u5f0f\u4e4b\u95f4\u7684\u5dee\u5f02\u6240\u5728\uff1b Now let\u2019s talk about trailing padding on structures. To explain this, I need to introduce a basic concept which I\u2019ll call the stride address of a structure. It is the first address following the structure data that has the same alignment as the structure . The general rule of trailing structure padding is this: the compiler will behave as though the structure has trailing padding out to its stride address . This rule controls what sizeof() will return. Consider this example on a 64-bit x86 or ARM machine: struct foo3 { char * p ; /* 8 bytes */ char c ; /* 1 byte */ }; struct foo3 singleton ; struct foo3 quad [ 4 ]; You might think that sizeof(struct foo3) should be 9, but it\u2019s actually 16. The stride address is that of (&p)[2] . Thus, in the quad array, each member has 7 bytes of trailing padding, because the first member of each following struct wants to be self-aligned on an 8-byte boundary. The memory layout is as though the structure had been declared like this: struct foo3 { char * p ; /* 8 bytes */ char c ; /* 1 byte */ char pad [ 7 ]; }; For contrast, consider the following example: struct foo4 { short s ; /* 2 bytes */ char c ; /* 1 byte */ }; Because s only needs to be 2-byte aligned, the stride address is just one byte after c , and struct foo4 as a whole only needs one byte of trailing padding . It will be laid out like this: struct foo4 { short s ; /* 2 bytes */ char c ; /* 1 byte */ char pad [ 1 ]; }; and sizeof(struct foo4) will return 4. Here\u2019s a last important detail: If your structure has structure members, the inner structs want to have the alignment of longest scalar too. Suppose you write this: struct foo5 { char c ; struct foo5_inner { char * p ; short x ; } inner ; }; The char *p member in the inner struct forces the outer struct to be pointer-aligned as well as the inner. Actual layout will be like this on a 64-bit machine: struct foo5 { char c ; /* 1 byte*/ char pad1 [ 7 ]; /* 7 bytes */ struct foo5_inner { char * p ; /* 8 bytes */ short x ; /* 2 bytes */ char pad2 [ 6 ]; /* 6 bytes */ } inner ; }; This structure gives us a hint of the savings that might be possible from repacking structures. Of 24 bytes, 13 of them are padding. That\u2019s more than 50% waste space!","title":"5. Structure alignment and padding"},{"location":"ABI/Alignment/Data-structure-alignment/The-Lost-Art-of-Structure-Packing/#6-bitfields","text":"Now let\u2019s consider C bitfields. What they give you the ability to do is declare structure fields of smaller than character width, down to 1 bit, like this: struct foo6 { short s ; char c ; int flip : 1 ; int nybble : 4 ; int septet : 7 ; }; The thing to know about bitfields is that they are implemented with word- and byte-level mask and rotate instructions operating on machine words, and cannot cross word boundaries. C99 guarentees that bit-fields will be packed as tightly as possible, provided they don\u2019t cross storage unit boundaries (6.7.2.1 #10 ). This restriction is relaxed in C11 (6.7.2.1p11) and C++14 ([class.bit]p1); these revisions do not actually require struct foo9 to be 64 bits instead of 32; a bit-field can span multiple allocation units instead of starting a new one. It\u2019s up to the implementation to decide; GCC leaves it up to the ABI, which for x64 does prevent them from sharing an allocation unit. Assuming we\u2019re on a 32-bit machine, the C99 rules imply that the layout may look like this: struct foo6 { short s ; /* 2 bytes */ char c ; /* 1 byte */ int flip : 1 ; /* total 1 bit */ int nybble : 4 ; /* total 5 bits */ int pad1 : 3 ; /* pad to an 8-bit boundary */ int septet : 7 ; /* 7 bits */ int pad2 : 25 ; /* pad to 32 bits */ }; But this isn\u2019t the only possibility, because the C standard does not specify that bits are allocated low-to-high. So the layout could look like this: struct foo6 { short s ; /* 2 bytes */ char c ; /* 1 byte */ int pad1 : 3 ; /* pad to an 8-bit boundary */ int flip : 1 ; /* total 1 bit */ int nybble : 4 ; /* total 5 bits */ int pad2 : 25 ; /* pad to 32 bits */ int septet : 7 ; /* 7 bits */ }; That is, the padding could precede rather than following the payload bits. Note also that, as with normal structure padding, the padding bits are not guaranteed to be zero; C99 mentions this. Note that the base type of a bit field is interpreted for signedness but not necessarily for size. It is up to implementors whether \"short flip:1\" or \"long flip:1\" are supported, and whether those base types change the size of the storage unit the field is packed into. Proceed with caution and check with -Wpadded if you have it available (e.g. under clang). Compilers on exotic hardware might interpret the C99 rules in surprising ways; older compilers might not quite follow them. The restriction that bitfields cannot cross machine word boundaries means that, while the first two of the following structures pack into one and two 32-bit words as you\u2019d expect, the third ( struct foo9 ) takes up *three* 32-bit words in C99, in the last of which only one bit is used. struct foo7 { int bigfield : 31 ; /* 32-bit word 1 begins */ int littlefield : 1 ; }; struct foo8 { int bigfield1 : 31 ; /* 32-bit word 1 begins /* int littlefield1:1; int bigfield2:31; /* 32-bit word 2 begins */ int littlefield2 : 1 ; }; struct foo9 { int bigfield1 : 31 ; /* 32-bit word 1 begins */ int bigfield2 : 31 ; /* 32-bit word 2 begins */ int littlefield1 : 1 ; int littlefield2 : 1 ; /* 32-bit word 3 begins */ }; Again, C11 and C++14 may pack foo9 tighter, but it would perhaps be unwise to count on this. On the other hand, struct foo8 would fit into a single 64-bit word if the machine has those.","title":"6. Bitfields"},{"location":"ABI/Alignment/Data-structure-alignment/The-Lost-Art-of-Structure-Packing/#7-structure-reordering","text":"Now that you know how and why compilers insert padding in and after your structures we\u2019ll examine what you can do to squeeze out the slop. This is the art of structure packing. The first thing to notice is that slop only happens in two places. One is where storage bound to a larger data type (with stricter alignment requirements) follows storage bound to a smaller one. The other is where a struct naturally ends before its stride address, requiring padding so the next one will be properly aligned. The simplest way to eliminate slop is to reorder the structure members by decreasing alignment. That is: make all the pointer-aligned subfields come first, because on a 64-bit machine they will be 8 bytes. Then the 4-byte ints; then the 2-byte shorts; then the character fields. So, for example, consider this simple linked-list structure: struct foo10 { char c ; struct foo10 * p ; short x ; }; With the implied slop made explicit, here it is: struct foo10 { char c ; /* 1 byte */ char pad1 [ 7 ]; /* 7 bytes */ struct foo10 * p ; /* 8 bytes */ short x ; /* 2 bytes */ char pad2 [ 6 ]; /* 6 bytes */ }; That\u2019s 24 bytes. If we reorder by size, we get this: struct foo11 { struct foo11 * p ; short x ; char c ; }; Considering self-alignment, we see that none of the data fields need padding. This is because the stride address for a (longer) field with stricter alignment is always a validly-aligned start address for a (shorter) field with less strict requirements. All the repacked struct actually requires is trailing padding: struct foo11 { struct foo11 * p ; /* 8 bytes */ short x ; /* 2 bytes */ char c ; /* 1 byte */ char pad [ 5 ]; /* 5 bytes */ }; Our repack transformation drops the size from 24 to 16 bytes. This might not seem like a lot, but suppose you have a linked list of 200K of these? The savings add up fast - especially on memory-constrained embedded systems or in the core part of an OS kernel that has to stay resident. Note that reordering is not guaranteed to produce savings. Applying this technique to an earlier example, struct foo5 , we get this: struct foo12 { struct foo5 { char * p ; /* 8 bytes */ short x ; /* 2 bytes */ } inner ; char c ; /* 1 byte*/ }; With padding written out, this is struct foo12 { struct foo5 { char * p ; /* 8 bytes */ short x ; /* 2 bytes */ char pad [ 6 ]; /* 6 bytes */ } inner ; char c ; /* 1 byte*/ char pad [ 7 ]; /* 7 bytes */ }; It\u2019s still 24 bytes because c cannot back into the inner struct\u2019s trailing padding. To collect that gain you would need to redesign your data structures. Curiously, strictly ordering your structure fields by increasing size also works to mimimize padding. You can minimize padding with any order in which (a) all fields of any one size are in a continuous span (completely eliminating padding between them), and (b) the gaps between those spans are such that the sizes on either side have as few doubling steps of difference from each other as possible. Usually this means no padding at all on one side. Even more general minimal-padding orders are possible. Example: struct foo13 { int32_t i ; int32_t i2 ; char octet [ 8 ]; int32_t i3 ; int32_t i4 ; int64_t l ; int32_t i5 ; int32_t i6 ; }; This struct has zero padding under self-alignment rules. Working out why is a useful exercise to develop your understanding. Since shipping the first version of this guide I have been asked why, if reordering for minimal slop is so simple, C compilers don\u2019t do it automatically. The answer: C is a language originally designed for writing operating systems and other code close to the hardware. Automatic reordering would interfere with a systems programmer\u2019s ability to lay out structures that exactly match the byte and bit-level layout of memory-mapped device control blocks. Go hews to the C philosophy and does not reorder fields. Rust makes the opposite choice; by default, its compiler may reorder structure fields.","title":"7. Structure reordering"},{"location":"ABI/Alignment/Data-structure-alignment/The-Lost-Art-of-Structure-Packing/#8-awkward-scalar-cases","text":"Using enumerated types instead of #defines is a good idea, if only because symbolic debuggers have those symbols available and can show them rather than raw integers. But, while enums are guaranteed to be compatible with an integral type, the C standard does not specify which underlying integral type is to be used for them. Be aware when repacking your structs that while enumerated-type variables are usually ints, this is compiler-dependent; they could be shorts, longs, or even chars by default. Your compiler may have a pragma or command-line option to force the size. The long double type is a similar trouble spot. Some C platforms implement this in 80 bits, some in 128, and some of the 80-bit platforms pad it to 96 or 128 bits. In both cases it\u2019s best to use sizeof() to check the storage size. Finally, under x86 Linux doubles are sometimes an exception to the self-alignment rule; an 8-byte double may require only 4-byte alignment within a struct even though standalone doubles variables have 8-byte self-alignment. This depends on compiler and options.","title":"8. Awkward scalar cases"},{"location":"ABI/Alignment/Data-structure-alignment/The-Lost-Art-of-Structure-Packing/#9-readability-and-cache-locality","text":"While reordering by size is the simplest way to eliminate slop, it\u2019s not necessarily the right thing. There are two more issues: readability and cache locality. Programs are not just communications to a computer, they are communications to other human beings. Code readability is important even (or especially!) when the audience of the communication is only your future self. A clumsy, mechanical reordering of your structure can harm readability. When possible, it is better to reorder fields so they remain in coherent groups with semantically related pieces of data kept close together. Ideally, the design of your structure should communicate the design of your program. When your program frequently accesses a structure, or parts of a structure, it is helpful for performance if the accesses tend to fit within a cache line - the memory block fetched by your processor when it is told to get any single address within the block. On 64-bit x86 a cache line is 64 bytes beginning on a self-aligned address; on other platforms it is often 32 bytes. The things you should do to preserve readability - grouping related and co-accessed data in adjacent fields - also improve cache-line locality. These are both reasons to reorder intelligently, with awareness of your code\u2019s data-access patterns. If your code does concurrent access to a structure from multiple threads, there\u2019s a third issue: cache line bouncing. To minimize expensive bus traffic, you should arrange your data so that reads come from one cache line and writes go to another in your tighter loops. And yes, this sometimes contradicts the previous guidance about grouping related data in the same cache-line-sized block. Multithreading is hard. Cache-line bouncing and other multithread optimization issues are very advanced topics which deserve an entire tutorial of their own. The best I can do here is make you aware that these issues exist.","title":"9. Readability and cache locality"},{"location":"ABI/Alignment/Data-structure-alignment/The-Lost-Art-of-Structure-Packing/#10-other-packing-techniques","text":"Reordering works best when combined with other techniques for slimming your structures. If you have several boolean flags in a struct, for example, consider reducing them to 1-bit bitfields and packing them into a place in the structure that would otherwise be slop. You\u2019ll take a small access-time penalty for this - but if it squeezes the working set enough smaller, that penalty will be swamped by your gains from avoided cache misses. More generally, look for ways to shorten data field sizes. In cvs-fast-export, for example, one squeeze I applied was to use the knowledge that RCS and CVS repositories didn\u2019t exist before 1982. I dropped a 64-bit Unix time_t (zero date at the beginning of 1970) for a 32-bit time offset from 1982-01-01T00:00:00; this will cover dates to 2118. (Note: if you pull a trick like this, do a bounds check whenever you set the field to prevent nasty bugs!) Each such field shortening not only decreases the explicit size of your structure, it may remove slop and/or create additional opportunities for gains from field reordering. Virtuous cascades of such effects are not very hard to trigger. The riskiest form of packing is to use unions. If you know that certain fields in your structure are never used in combination with certain other fields, consider using a union to make them share storage. But be extra careful and verify your work with regression testing, because if your lifetime analysis is even slightly wrong you will get bugs ranging from crashes to (much worse) subtle data corruption.","title":"10. Other packing techniques"},{"location":"ABI/Alignment/Data-structure-alignment/The-Lost-Art-of-Structure-Packing/#11-overriding-alignment-rules","text":"Sometimes you can coerce your compiler into not using the processor\u2019s normal alignment rules by using a pragma, usually #pragma pack . GCC and clang have an attribute**packed you can attach to individual structure declarations; GCC has an -fpack-struct option for entire compilations. Do not do this casually, as it forces the generation of more expensive and slower code. Usually you can save as much memory, or almost as much, with the techniques I describe here. The only good reason for #pragma pack is if you have to exactly match your C data layout to some kind of bit-level hardware or protocol requirement, like a memory-mapped hardware port, and violating normal alignment is required for that to work. If you\u2019re in that situation, and you don\u2019t already know everything else I\u2019m writing about here, you\u2019re in deep trouble and I wish you luck.","title":"11. Overriding alignment rules"},{"location":"ABI/Alignment/Data-structure-alignment/The-Lost-Art-of-Structure-Packing/#12-tools","text":"The clang compiler has a -Wpadded option that causes it to generate messages about alignment holes and padding. Some versions also have an undocumented -fdump-record-layouts option that yields more information . If you\u2019re using C11, you can deploy static_assert to check your assumptions about type and structure sizes. Example: #include <assert.h> struct foo4 { short s; /* 2 bytes */ char c; /* 1 byte */ }; static_assert(sizeof(struct foo4) == 4, \u201cCheck your assumptions\"); I have not used it myself, but several respondents speak well of a program called pahole . This tool cooperates with a compiler to produce reports on your structures that describe padding, alignment, and cache line boundaries. This was at one time a standalone C program, but that is now unmaintained; s script with the name pahole now ships with gdb and that is what you should use. I\u2019ve received a report that a proprietary code auditing tool called \"PVS Studio\" can detect structure-packing opportunities.","title":"12. Tools"},{"location":"ABI/Alignment/Data-structure-alignment/The-Lost-Art-of-Structure-Packing/#13-proof-and-exceptional-cases","text":"You can download sourcecode for a little program that demonstrates the assertions about scalar and structure sizes made above. It is packtest.c . If you look through enough strange combinations of compilers, options, and unusual hardware, you will find exceptions to some of the rules I have described. They get more common as you go back in time to older processor designs. The next level beyond knowing these rules is knowing how and when to expect that they will be broken. In the years when I learned them (the early 1980s) we spoke of people who didn\u2019t get this as victims of \"all-the-world\u2019s-a-VAX syndrome\". Remember that not all the world is a PC.","title":"13. Proof and exceptional cases"},{"location":"ABI/Alignment/Data-structure-alignment/The-Lost-Art-of-Structure-Packing/#14-go-and-rust","text":"The Go language is in many respects similar to C. It has structures and arrays, though not bitfields or unions. Go compilers have the same optimization and alignment issues as C compilers. One important difference is that the Go specification *requires* structure fields to be self-aligned. As in C, array elements are padded up to the following stride address. Therefore, if you know the implications of self-aligment in C, you can apply them directly to calculating sizes and offsets in Go and to space-optimizing Go structures. The obvious correspondence mostly works. I say \"mostly\" because Go has one odd quirk. Since Go 1.5, a zero-length field at the end of a struct (that is, a zero-length array or empty struct) is sized and aligned as though it is one byte. The reasons for this are discussed in an essay Padding is Hard by one of the Go developers. Rust follows C-like field alignment rules if a structure is annotated with \"repr(C)\". Otherwise (by default) all bets are off: padding rules are (deliberately) unspecified and the compiler may even reorder structure members. It is probably best to let the Rust compiler do space optimization rather than forcing it.","title":"14. Go and Rust"},{"location":"ABI/Alignment/Data-structure-alignment/The-Lost-Art-of-Structure-Packing/#15-supporting-this-work","text":"If you were educated or entertained by this document, please sign up for my Patreon feed . The time needed to write and maintain documents like this one is not free, and while I enjoying giving them to the world my bills won\u2019t pay themselves. Even a few dollars a month - from enough of you - helps a lot.","title":"15. Supporting this work"},{"location":"ABI/Alignment/Data-structure-alignment/The-Lost-Art-of-Structure-Packing/#16-related-reading","text":"This section exists to collect pointers to essays which I judge to be good companions to this one. A Guide to Undefined Behavior in C and C++ Time, Clock, and Calendar Programming In C Things Every Hacker Once Knew","title":"16. Related Reading"},{"location":"ABI/Book-x86-Disassembly/","text":"\u5173\u4e8e\u672c\u4e66 x86 calling conventions","title":"Introduction"},{"location":"ABI/Book-x86-Disassembly/#_1","text":"x86 calling conventions","title":"\u5173\u4e8e\u672c\u4e66"},{"location":"ABI/Call-convention/Calling-Conventions-Demystified/","text":"Calling Conventions Demystified Introduction C calling convention (__cdecl) Standard calling convention (__stdcall) Fast calling convention (__fastcall) Thiscall Conclusion Calling Conventions Demystified Introduction During the long, hard, but yet beautiful process of learning C++ programming for Windows, you have probably been curious about the strange specifiers that sometime appear in front of function declarations, like __cdecl , __stdcall , __fastcall , WINAPI , etc. After looking through MSDN, or some other reference, you probably found out that these specifiers specify the calling conventions for functions. In this article, I will try to explain different calling conventions used by Visual C++ (and probably other Windows C/C++ compilers). I emphasize that above mentioned specifiers are Microsoft-specific, and that you should not use them if you want to write portable code. So, what are the calling conventions? When a function is called, the arguments are typically passed to it, and the return value is retrieved. A calling convention describes how the arguments are passed and values returned by functions. It also specifies how the function names are decorated. Is it really necessary to understand the calling conventions to write good C/C++ programs? Not at all. However, it may be helpful with debugging. Also, it is necessary for linking C/C++ with assembly code. To understand this article, you will need to have some very basic knowledge of assembly programming. No matter which calling convention is used, the following things will happen: All arguments are widened to 4 bytes (on Win32, of course), and put into appropriate memory locations. These locations are typically on the stack, but may also be in registers; this is specified by calling conventions . Program execution jumps to the address of the called function . Inside the function, registers ESI , EDI , EBX , and EBP are saved on the stack. The part of code that performs these operations is called function prolog (\u51fd\u6570\u5f00\u573a) and usually is generated by the compiler. The function-specific code is executed, and the return value is placed into the EAX register. Registers ESI, EDI, EBX, and EBP are restored from the stack. The piece of code that does this is called function epilog (\u51fd\u6570\u6536\u573a), and as with the function prolog, in most cases the compiler generates it. Arguments are removed from the stack. This operation is called stack cleanup and may be performed either inside the called function or by the caller, depending on the calling convention used. As an example for the calling conventions (except for this ), we are going to use a simple function: Hide Copy Code int sumExample ( int a , int b ) { return a + b ; } The call to this function will look like this: Hide Copy Code int c = sum ( 2 , 3 ); For __cdecl , __stdcall , and __fastcall calling conventions, I compiled the example code as C (not C++). The function name decorations , mentioned later in the article, apply to the C decoration schema. C++ name decorations are beyond the scope of this article. C calling convention ( __cdecl ) This convention is the default for C/C++ programs (compiler option /Gd). If a project is set to use some other calling convention, we can still declare a function to use __cdecl : Hide Copy Code int __cdecl sumExample (int a, int b); The main characteristics of __cdecl calling convention are: Arguments are passed from right to left, and placed on the stack. Stack cleanup is performed by the caller. Function name is decorated by prefixing it with an underscore character '_' . Now, take a look at an example of a __cdecl call: Hide Copy Code ; // push arguments to the stack, from right to left push 3 push 2 ; // call the function call _sumExample ; // cleanup the stack by adding the size of the arguments to ESP register add esp,8 ; // copy the return value from EAX to a local variable (int c) mov dword ptr [c],eax The called function is shown below: Hide Copy Code ; // function prolog push ebp mov ebp,esp sub esp,0C0h push ebx push esi push edi lea edi,[ebp-0C0h] mov ecx,30h mov eax,0CCCCCCCCh rep stos dword ptr [edi] ; // return a + b; mov eax,dword ptr [a] add eax,dword ptr [b] ; // function epilog pop edi pop esi pop ebx mov esp,ebp pop ebp ret Standard calling convention ( __stdcall ) This convention is usually used to call Win32 API functions. In fact, WINAPI is nothing but another name for __stdcall : Hide Copy Code #define WINAPI __stdcall We can explicitly declare a function to use the __stdcall convention: Hide Copy Code int __stdcall sumExample ( int a , int b ); Also, we can use the compiler option /Gz to specify __stdcall for all functions not explicitly declared with some other calling convention. The main characteristics of __stdcall calling convention are: Arguments are passed from right to left, and placed on the stack. Stack cleanup is performed by the called function. Function name is decorated by prepending an underscore character and appending a '@' character and the number of bytes of stack space required. The example follows: Hide Copy Code ; // push arguments to the stack, from right to left push 3 push 2 ; // call the function call _sumExample@8 ; // copy the return value from EAX to a local variable (int c) mov dword ptr [c],eax The function code is shown below: Hide Copy Code ; // function prolog goes here (the same code as in the __cdecl example) ; // return a + b; mov eax,dword ptr [a] add eax,dword ptr [b] ; // function epilog goes here (the same code as in the __cdecl example) ; // cleanup the stack and return ret 8 Because the stack is cleaned by the called function, the __stdcall calling convention creates smaller executables than __cdecl , in which the code for stack cleanup must be generated for each function call. On the other hand, functions with the variable number of arguments (like printf() ) must use __cdecl , because only the caller knows the number of arguments in each function call; therefore only the caller can perform the stack cleanup. Fast calling convention (__fastcall) Fast calling convention indicates that the arguments should be placed in registers, rather than on the stack, whenever possible. This reduces the cost of a function call, because operations with registers are faster than with the stack. We can explicitly declare a function to use the __fastcall convention as shown: Hide Copy Code int __fastcall sumExample ( int a , int b ); We can also use the compiler option /Gr to specify __fastcall for all functions not explicitly declared with some other calling convention. The main characteristics of __fastcall calling convention are: The first two function arguments that require 32 bits or less are placed into registers ECX and EDX. The rest of them are pushed on the stack from right to left. Arguments are popped from the stack by the called function. Function name is decorated by by prepending a '@' character and appending a '@' and the number of bytes (decimal) of space required by the arguments. Note: Microsoft have reserved the right to change the registers for passing the arguments in future compiler versions. Here goes an example: Hide Copy Code ; // put the arguments in the registers EDX and ECX mov edx,3 mov ecx,2 ; // call the function call @fastcallSum@8 ; // copy the return value from EAX to a local variable (int c) mov dword ptr [c],eax Function code: Hide Copy Code ; // function prolog push ebp mov ebp,esp sub esp,0D8h push ebx push esi push edi push ecx lea edi,[ebp-0D8h] mov ecx,36h mov eax,0CCCCCCCCh rep stos dword ptr [edi] pop ecx mov dword ptr [ebp-14h],edx mov dword ptr [ebp-8],ecx ; // return a + b; mov eax,dword ptr [a] add eax,dword ptr [b] ;// function epilog pop edi pop esi pop ebx mov esp,ebp pop ebp ret How fast is this calling convention, comparing to __cdecl and __stdcall ? Find out for yourselves. Set the compiler option /Gr , and compare the execution time. I didn't find __fastcall to be any faster than other calling conventons, but you may come to different conclusions. Thiscall Thiscall is the default calling convention for calling member functions of C++ classes (except for those with a variable number of arguments). The main characteristics of thiscall calling convention are: Arguments are passed from right to left, and placed on the stack. this is placed in ECX . Stack cleanup is performed by the called function. The example for this calling convention had to be a little different. First, the code is compiled as C++, and not C. Second, we have a struct with a member function, instead of a global function. Hide Copy Code struct CSum { int sum ( int a , int b ) { return a + b ;} }; The assembly code for the function call looks like this: Hide Copy Code push 3 push 2 lea ecx ,[ sumObj ] call ? sum @ CSum @@ QAEHHH @ Z ; CSum :: sum mov dword ptr [ s4 ], eax The function itself is given below: Hide Copy Code push ebp mov ebp , esp sub esp , 0 CCh push ebx push esi push edi push ecx lea edi ,[ ebp - 0 CCh ] mov ecx , 33 h mov eax , 0 CCCCCCCCh rep stos dword ptr [ edi ] pop ecx mov dword ptr [ ebp - 8 ], ecx mov eax , dword ptr [ a ] add eax , dword ptr [ b ] pop edi pop esi pop ebx mov esp , ebp pop ebp ret 8 Now, what happens if we have a member function with a variable number of arguments? In that case, __cdecl is used, and this is pushed onto the stack last. Conclusion To cut a long story short, we'll outline the main differences between the calling conventions: __cdecl is the default calling convention for C and C++ programs. The advantage of this calling convetion is that it allows functions with a variable number of arguments to be used. The disadvantage is that it creates larger executables. __stdcall is used to call Win32 API functions. It does not allow functions to have a variable number of arguments. __fastcall attempts to put arguments in registers, rather than on the stack, thus making function calls faster. Thiscall calling convention is the default calling convention used by C++ member functions that do not use variable arguments. In most cases, this is all you'll ever need to know about the calling conventions.","title":"Calling-Conventions-Demystified"},{"location":"ABI/Call-convention/Calling-Conventions-Demystified/#calling-conventions-demystified","text":"","title":"Calling Conventions Demystified"},{"location":"ABI/Call-convention/Calling-Conventions-Demystified/#introduction","text":"During the long, hard, but yet beautiful process of learning C++ programming for Windows, you have probably been curious about the strange specifiers that sometime appear in front of function declarations, like __cdecl , __stdcall , __fastcall , WINAPI , etc. After looking through MSDN, or some other reference, you probably found out that these specifiers specify the calling conventions for functions. In this article, I will try to explain different calling conventions used by Visual C++ (and probably other Windows C/C++ compilers). I emphasize that above mentioned specifiers are Microsoft-specific, and that you should not use them if you want to write portable code. So, what are the calling conventions? When a function is called, the arguments are typically passed to it, and the return value is retrieved. A calling convention describes how the arguments are passed and values returned by functions. It also specifies how the function names are decorated. Is it really necessary to understand the calling conventions to write good C/C++ programs? Not at all. However, it may be helpful with debugging. Also, it is necessary for linking C/C++ with assembly code. To understand this article, you will need to have some very basic knowledge of assembly programming. No matter which calling convention is used, the following things will happen: All arguments are widened to 4 bytes (on Win32, of course), and put into appropriate memory locations. These locations are typically on the stack, but may also be in registers; this is specified by calling conventions . Program execution jumps to the address of the called function . Inside the function, registers ESI , EDI , EBX , and EBP are saved on the stack. The part of code that performs these operations is called function prolog (\u51fd\u6570\u5f00\u573a) and usually is generated by the compiler. The function-specific code is executed, and the return value is placed into the EAX register. Registers ESI, EDI, EBX, and EBP are restored from the stack. The piece of code that does this is called function epilog (\u51fd\u6570\u6536\u573a), and as with the function prolog, in most cases the compiler generates it. Arguments are removed from the stack. This operation is called stack cleanup and may be performed either inside the called function or by the caller, depending on the calling convention used. As an example for the calling conventions (except for this ), we are going to use a simple function: Hide Copy Code int sumExample ( int a , int b ) { return a + b ; } The call to this function will look like this: Hide Copy Code int c = sum ( 2 , 3 ); For __cdecl , __stdcall , and __fastcall calling conventions, I compiled the example code as C (not C++). The function name decorations , mentioned later in the article, apply to the C decoration schema. C++ name decorations are beyond the scope of this article.","title":"Introduction"},{"location":"ABI/Call-convention/Calling-Conventions-Demystified/#c-calling-convention-__cdecl","text":"This convention is the default for C/C++ programs (compiler option /Gd). If a project is set to use some other calling convention, we can still declare a function to use __cdecl : Hide Copy Code int __cdecl sumExample (int a, int b); The main characteristics of __cdecl calling convention are: Arguments are passed from right to left, and placed on the stack. Stack cleanup is performed by the caller. Function name is decorated by prefixing it with an underscore character '_' . Now, take a look at an example of a __cdecl call: Hide Copy Code ; // push arguments to the stack, from right to left push 3 push 2 ; // call the function call _sumExample ; // cleanup the stack by adding the size of the arguments to ESP register add esp,8 ; // copy the return value from EAX to a local variable (int c) mov dword ptr [c],eax The called function is shown below: Hide Copy Code ; // function prolog push ebp mov ebp,esp sub esp,0C0h push ebx push esi push edi lea edi,[ebp-0C0h] mov ecx,30h mov eax,0CCCCCCCCh rep stos dword ptr [edi] ; // return a + b; mov eax,dword ptr [a] add eax,dword ptr [b] ; // function epilog pop edi pop esi pop ebx mov esp,ebp pop ebp ret","title":"C calling convention (__cdecl)"},{"location":"ABI/Call-convention/Calling-Conventions-Demystified/#standard-calling-convention-__stdcall","text":"This convention is usually used to call Win32 API functions. In fact, WINAPI is nothing but another name for __stdcall : Hide Copy Code #define WINAPI __stdcall We can explicitly declare a function to use the __stdcall convention: Hide Copy Code int __stdcall sumExample ( int a , int b ); Also, we can use the compiler option /Gz to specify __stdcall for all functions not explicitly declared with some other calling convention. The main characteristics of __stdcall calling convention are: Arguments are passed from right to left, and placed on the stack. Stack cleanup is performed by the called function. Function name is decorated by prepending an underscore character and appending a '@' character and the number of bytes of stack space required. The example follows: Hide Copy Code ; // push arguments to the stack, from right to left push 3 push 2 ; // call the function call _sumExample@8 ; // copy the return value from EAX to a local variable (int c) mov dword ptr [c],eax The function code is shown below: Hide Copy Code ; // function prolog goes here (the same code as in the __cdecl example) ; // return a + b; mov eax,dword ptr [a] add eax,dword ptr [b] ; // function epilog goes here (the same code as in the __cdecl example) ; // cleanup the stack and return ret 8 Because the stack is cleaned by the called function, the __stdcall calling convention creates smaller executables than __cdecl , in which the code for stack cleanup must be generated for each function call. On the other hand, functions with the variable number of arguments (like printf() ) must use __cdecl , because only the caller knows the number of arguments in each function call; therefore only the caller can perform the stack cleanup.","title":"Standard calling convention (__stdcall)"},{"location":"ABI/Call-convention/Calling-Conventions-Demystified/#fast-calling-convention-__fastcall","text":"Fast calling convention indicates that the arguments should be placed in registers, rather than on the stack, whenever possible. This reduces the cost of a function call, because operations with registers are faster than with the stack. We can explicitly declare a function to use the __fastcall convention as shown: Hide Copy Code int __fastcall sumExample ( int a , int b ); We can also use the compiler option /Gr to specify __fastcall for all functions not explicitly declared with some other calling convention. The main characteristics of __fastcall calling convention are: The first two function arguments that require 32 bits or less are placed into registers ECX and EDX. The rest of them are pushed on the stack from right to left. Arguments are popped from the stack by the called function. Function name is decorated by by prepending a '@' character and appending a '@' and the number of bytes (decimal) of space required by the arguments. Note: Microsoft have reserved the right to change the registers for passing the arguments in future compiler versions. Here goes an example: Hide Copy Code ; // put the arguments in the registers EDX and ECX mov edx,3 mov ecx,2 ; // call the function call @fastcallSum@8 ; // copy the return value from EAX to a local variable (int c) mov dword ptr [c],eax Function code: Hide Copy Code ; // function prolog push ebp mov ebp,esp sub esp,0D8h push ebx push esi push edi push ecx lea edi,[ebp-0D8h] mov ecx,36h mov eax,0CCCCCCCCh rep stos dword ptr [edi] pop ecx mov dword ptr [ebp-14h],edx mov dword ptr [ebp-8],ecx ; // return a + b; mov eax,dword ptr [a] add eax,dword ptr [b] ;// function epilog pop edi pop esi pop ebx mov esp,ebp pop ebp ret How fast is this calling convention, comparing to __cdecl and __stdcall ? Find out for yourselves. Set the compiler option /Gr , and compare the execution time. I didn't find __fastcall to be any faster than other calling conventons, but you may come to different conclusions.","title":"Fast calling convention (__fastcall)"},{"location":"ABI/Call-convention/Calling-Conventions-Demystified/#thiscall","text":"Thiscall is the default calling convention for calling member functions of C++ classes (except for those with a variable number of arguments). The main characteristics of thiscall calling convention are: Arguments are passed from right to left, and placed on the stack. this is placed in ECX . Stack cleanup is performed by the called function. The example for this calling convention had to be a little different. First, the code is compiled as C++, and not C. Second, we have a struct with a member function, instead of a global function. Hide Copy Code struct CSum { int sum ( int a , int b ) { return a + b ;} }; The assembly code for the function call looks like this: Hide Copy Code push 3 push 2 lea ecx ,[ sumObj ] call ? sum @ CSum @@ QAEHHH @ Z ; CSum :: sum mov dword ptr [ s4 ], eax The function itself is given below: Hide Copy Code push ebp mov ebp , esp sub esp , 0 CCh push ebx push esi push edi push ecx lea edi ,[ ebp - 0 CCh ] mov ecx , 33 h mov eax , 0 CCCCCCCCh rep stos dword ptr [ edi ] pop ecx mov dword ptr [ ebp - 8 ], ecx mov eax , dword ptr [ a ] add eax , dword ptr [ b ] pop edi pop esi pop ebx mov esp , ebp pop ebp ret 8 Now, what happens if we have a member function with a variable number of arguments? In that case, __cdecl is used, and this is pushed onto the stack last.","title":"Thiscall"},{"location":"ABI/Call-convention/Calling-Conventions-Demystified/#conclusion","text":"To cut a long story short, we'll outline the main differences between the calling conventions: __cdecl is the default calling convention for C and C++ programs. The advantage of this calling convetion is that it allows functions with a variable number of arguments to be used. The disadvantage is that it creates larger executables. __stdcall is used to call Win32 API functions. It does not allow functions to have a variable number of arguments. __fastcall attempts to put arguments in registers, rather than on the stack, thus making function calls faster. Thiscall calling convention is the default calling convention used by C++ member functions that do not use variable arguments. In most cases, this is all you'll ever need to know about the calling conventions.","title":"Conclusion"},{"location":"ABI/Call-convention/Calling-convention/","text":"Calling convention In computer science , a calling convention is an implementation-level (low-level) scheme for how subroutines receive parameters from their caller and how they return a result. Differences in various implementations include where parameters, return values , return addresses and scope links are placed, and how the tasks of preparing for a function call and restoring the environment afterward are divided between the caller and the callee(\u4ee5\u53ca\u5982\u4f55\u5728\u8c03\u7528\u8005\u548c\u88ab\u8c03\u7528\u8005\u4e4b\u95f4\u5212\u5206\u51c6\u5907\u51fd\u6570\u8c03\u7528\u548c\u6062\u590d\u73af\u5883\u7684\u4efb\u52a1). Calling conventions may be related to a particular programming language's evaluation strategy but most often are not considered part of it (or vice versa), as the evaluation strategy is usually defined on a higher abstraction level and seen as a part of the language rather than as a low-level implementation detail of a particular language's compiler . Variations Calling conventions may differ in: Where parameters, return values and return addresses are placed (in registers , on the call stack , a mix of both, or in other memory structures) The order in which actual arguments for formal parameters are passed (or the parts of a large or complex argument) How a (possibly long or complex) return value is delivered from the callee back to the caller (on the stack, in a register, or within the heap) How the task of setting up for and cleaning up after a function call is divided between the caller and the callee Whether and how metadata describing the arguments is passed Where the previous value of the frame pointer is stored, which is used to restore the frame pointer when the routine ends (in the stack frame, or in some register) Where any static scope links for the routine's non-local data access are placed (typically at one or more positions in the stack frame, but sometimes in a general register, or, for some architectures, in special-purpose registers) How local variables are allocated can sometimes also be part of the calling convention (when the caller allocates for the callee) In some cases, differences also include the following: Conventions on which registers may be directly used by the callee, without being preserved (otherwise regarded as an ABI detail) Which registers are considered to be volatile and, if volatile, need not be restored by the callee (often regarded as an ABI detail) Compiler variation Although some [ which? ] languages actually may specify this partially in the programming language specification (or in some pivotal implementation), different implementations of such languages (i.e. different compilers ) may typically still use various calling conventions , often selectable. Reasons for this are performance, frequent adaptation to the conventions of other popular languages (with or without technical reasons), and restrictions or conventions imposed by various \"platforms\" (combinations of CPU architectures and operating systems ). Architecture variation CPU architectures always have more than one possible calling convention[ why? ]. With many general-purpose registers and other features, the potential number of calling conventions is large, although some[ which? ] architectures are formally specified to use only one calling convention, supplied by the architect. x86 (32-bit) Main article: x86 calling conventions The x86 architecture is used with many different calling conventions. Due to the small number of architectural registers, the x86 calling conventions mostly pass arguments on the stack, while the return value (or a pointer to it) is passed in a register. Some conventions use registers for the first few parameters, which may improve performance for short and simple leaf-routines very frequently invoked (i.e. routines that do not call other routines and do not have to be reentrant ). Example call: push EAX ; pass some register result push byte[EBP+20] ; pass some memory variable (FASM/TASM syntax) push 3 ; pass some constant call calc ; the returned result is now in EAX Typical callee structure: ( some or all (except ret) of the instructions below may be optimized away in simple procedures ) calc: push EBP ; save old frame pointer mov EBP,ESP ; get new frame pointer sub ESP,localsize ; reserve place for locals . . ; perform calculations, leave result in EAX . mov ESP,EBP ; free space for locals pop EBP ; restore old frame pointer ret paramsize ; free parameter space and return ARM (A32) The standard 32-bit ARM calling convention allocates the 15 general-purpose registers as: r14 is the link register. (The BL instruction, used in a subroutine call, stores the return address in this register). r13 is the stack pointer. (The Push/Pop instructions in \"Thumb\" operating mode use this register only). r12 is the Intra-Procedure-call scratch register. r4 to r11: used to hold local variables. r0 to r3: used to hold argument values passed to a subroutine, and also hold results returned from a subroutine. The 16 th register, r15, is the program counter. If the type of value returned is too large to fit in r0 to r3, or whose size cannot be determined statically at compile time, then the caller must allocate space for that value at run time, and pass a pointer to that space in r0. Subroutines must preserve the contents of r4 to r11 and the stack pointer. (Perhaps by saving them to the stack in the function prologue, then using them as scratch space, then restoring them from the stack in the function epilogue). In particular, subroutines that call other subroutines must save the return address in the link register r14 to the stack before calling those other subroutines. However, such subroutines do not need to return that value to r14\u2014they merely need to load that value into r15, the program counter, to return. The ARM calling convention mandates using a full-descending stack.[ 1] This calling convention causes a \"typical\" ARM subroutine to In the prologue, push r4 to r11 to the stack, and push the return address in r14, to the stack. (This can be done with a single STM instruction). copy any passed arguments (in r0 to r3) to the local scratch registers (r4 to r11). allocate other local variables to the remaining local scratch registers (r4 to r11). do calculations and call other subroutines as necessary using BL, assuming r0 to r3, r12 and r14 will not be preserved. put the result in r0 In the epilogue, pull r4 to r11 from the stack, and pull the return address to the program counter r15. (This can be done with a single LDM instruction). See also Calling Conventions","title":"Calling-convention"},{"location":"ABI/Call-convention/Calling-convention/#calling-convention","text":"In computer science , a calling convention is an implementation-level (low-level) scheme for how subroutines receive parameters from their caller and how they return a result. Differences in various implementations include where parameters, return values , return addresses and scope links are placed, and how the tasks of preparing for a function call and restoring the environment afterward are divided between the caller and the callee(\u4ee5\u53ca\u5982\u4f55\u5728\u8c03\u7528\u8005\u548c\u88ab\u8c03\u7528\u8005\u4e4b\u95f4\u5212\u5206\u51c6\u5907\u51fd\u6570\u8c03\u7528\u548c\u6062\u590d\u73af\u5883\u7684\u4efb\u52a1). Calling conventions may be related to a particular programming language's evaluation strategy but most often are not considered part of it (or vice versa), as the evaluation strategy is usually defined on a higher abstraction level and seen as a part of the language rather than as a low-level implementation detail of a particular language's compiler .","title":"Calling convention"},{"location":"ABI/Call-convention/Calling-convention/#variations","text":"Calling conventions may differ in: Where parameters, return values and return addresses are placed (in registers , on the call stack , a mix of both, or in other memory structures) The order in which actual arguments for formal parameters are passed (or the parts of a large or complex argument) How a (possibly long or complex) return value is delivered from the callee back to the caller (on the stack, in a register, or within the heap) How the task of setting up for and cleaning up after a function call is divided between the caller and the callee Whether and how metadata describing the arguments is passed Where the previous value of the frame pointer is stored, which is used to restore the frame pointer when the routine ends (in the stack frame, or in some register) Where any static scope links for the routine's non-local data access are placed (typically at one or more positions in the stack frame, but sometimes in a general register, or, for some architectures, in special-purpose registers) How local variables are allocated can sometimes also be part of the calling convention (when the caller allocates for the callee) In some cases, differences also include the following: Conventions on which registers may be directly used by the callee, without being preserved (otherwise regarded as an ABI detail) Which registers are considered to be volatile and, if volatile, need not be restored by the callee (often regarded as an ABI detail)","title":"Variations"},{"location":"ABI/Call-convention/Calling-convention/#compiler-variation","text":"Although some [ which? ] languages actually may specify this partially in the programming language specification (or in some pivotal implementation), different implementations of such languages (i.e. different compilers ) may typically still use various calling conventions , often selectable. Reasons for this are performance, frequent adaptation to the conventions of other popular languages (with or without technical reasons), and restrictions or conventions imposed by various \"platforms\" (combinations of CPU architectures and operating systems ).","title":"Compiler variation"},{"location":"ABI/Call-convention/Calling-convention/#architecture-variation","text":"CPU architectures always have more than one possible calling convention[ why? ]. With many general-purpose registers and other features, the potential number of calling conventions is large, although some[ which? ] architectures are formally specified to use only one calling convention, supplied by the architect.","title":"Architecture variation"},{"location":"ABI/Call-convention/Calling-convention/#x86-32-bit","text":"Main article: x86 calling conventions The x86 architecture is used with many different calling conventions. Due to the small number of architectural registers, the x86 calling conventions mostly pass arguments on the stack, while the return value (or a pointer to it) is passed in a register. Some conventions use registers for the first few parameters, which may improve performance for short and simple leaf-routines very frequently invoked (i.e. routines that do not call other routines and do not have to be reentrant ). Example call: push EAX ; pass some register result push byte[EBP+20] ; pass some memory variable (FASM/TASM syntax) push 3 ; pass some constant call calc ; the returned result is now in EAX Typical callee structure: ( some or all (except ret) of the instructions below may be optimized away in simple procedures ) calc: push EBP ; save old frame pointer mov EBP,ESP ; get new frame pointer sub ESP,localsize ; reserve place for locals . . ; perform calculations, leave result in EAX . mov ESP,EBP ; free space for locals pop EBP ; restore old frame pointer ret paramsize ; free parameter space and return","title":"x86 (32-bit)"},{"location":"ABI/Call-convention/Calling-convention/#arm-a32","text":"The standard 32-bit ARM calling convention allocates the 15 general-purpose registers as: r14 is the link register. (The BL instruction, used in a subroutine call, stores the return address in this register). r13 is the stack pointer. (The Push/Pop instructions in \"Thumb\" operating mode use this register only). r12 is the Intra-Procedure-call scratch register. r4 to r11: used to hold local variables. r0 to r3: used to hold argument values passed to a subroutine, and also hold results returned from a subroutine. The 16 th register, r15, is the program counter. If the type of value returned is too large to fit in r0 to r3, or whose size cannot be determined statically at compile time, then the caller must allocate space for that value at run time, and pass a pointer to that space in r0. Subroutines must preserve the contents of r4 to r11 and the stack pointer. (Perhaps by saving them to the stack in the function prologue, then using them as scratch space, then restoring them from the stack in the function epilogue). In particular, subroutines that call other subroutines must save the return address in the link register r14 to the stack before calling those other subroutines. However, such subroutines do not need to return that value to r14\u2014they merely need to load that value into r15, the program counter, to return. The ARM calling convention mandates using a full-descending stack.[ 1] This calling convention causes a \"typical\" ARM subroutine to In the prologue, push r4 to r11 to the stack, and push the return address in r14, to the stack. (This can be done with a single STM instruction). copy any passed arguments (in r0 to r3) to the local scratch registers (r4 to r11). allocate other local variables to the remaining local scratch registers (r4 to r11). do calculations and call other subroutines as necessary using BL, assuming r0 to r3, r12 and r14 will not be preserved. put the result in r0 In the epilogue, pull r4 to r11 from the stack, and pull the return address to the program counter r15. (This can be done with a single LDM instruction).","title":"ARM (A32)"},{"location":"ABI/Call-convention/Calling-convention/#see-also","text":"","title":"See also"},{"location":"ABI/Call-convention/Calling-convention/#calling-conventions","text":"","title":"Calling Conventions"},{"location":"ABI/Call-convention/Prologue-and-epilogue/","text":"What is this assembly function prologue / epilogue code doing with rbp / rsp / leave? About x86","title":"[What is this assembly function prologue / epilogue code doing with rbp / rsp / leave?](https://stackoverflow.com/questions/14296088/what-is-this-assembly-function-prologue-epilogue-code-doing-with-rbp-rsp-l)"},{"location":"ABI/Call-convention/Prologue-and-epilogue/#what-is-this-assembly-function-prologue-epilogue-code-doing-with-rbp-rsp-leave","text":"","title":"What is this assembly function prologue / epilogue code doing with rbp / rsp / leave?"},{"location":"ABI/Call-convention/Prologue-and-epilogue/#about-x86","text":"","title":"About x86"},{"location":"ABI/Call-convention/Reading-list/","text":"\u5173\u4e8e\u51fd\u6570\u8c03\u7528\uff0c\u4e0b\u9762\u5185\u5bb9\u662f\u9700\u8981\u8fdb\u884c\u8865\u5145\u7684\uff1a Entry point Function prologue Housekeeping (computing) Subroutine","title":"Reading list"},{"location":"ABI/Call-convention/X86-calling-conventions/","text":"","title":"X86 calling conventions"},{"location":"ABI/Library/Library(computing)/","text":"Library (computing) Illustration of an application which uses libvorbisfile to play an Ogg Vorbis file In computer science , a library is a collection of non-volatile resources used by computer programs , often for software development . These may include configuration data, documentation, help data, message templates, pre-written code and subroutines , classes , values or type specifications. In IBM's OS/360 and its successors they are referred to as partitioned data sets . A library is also a collection of implementations of behavior, written in terms of a language, that has a well-defined interface by which the behavior is invoked. For instance, people who want to write a higher level program can use a library to make system calls instead of implementing those system calls over and over again. In addition, the behavior is provided for reuse by multiple independent programs. A program invokes the library-provided behavior via a mechanism of the language. For example, in a simple imperative language such as C, the behavior in a library is invoked by using C's normal function-call. What distinguishes the call as being to a library function, versus being to another function in the same program, is the way that the code is organized in the system. Library code is organized in such a way that it can be used by multiple programs that have no connection to each other, while code that is part of a program is organized to be used only within that one program. This distinction can gain a hierarchical notion when a program grows large, such as a multi-million-line program. In that case, there may be internal libraries that are reused by independent sub-portions of the large program. The distinguishing feature is that a library is organized for the purposes of being reused by independent programs or sub-programs, and the user only needs to know the interface and not the internal details of the library. The value of a library lies in the reuse of the behavior. When a program invokes a library, it gains the behavior implemented inside that library without having to implement that behavior itself. Libraries encourage the sharing of code in a modular fashion, and ease the distribution of the code. The behavior implemented by a library can be connected to the invoking program at different program lifecycle phases . If the code of the library is accessed during the build of the invoking program, then the library is called a static library .[ 1] An alternative is to build the executable of the invoking program and distribute that, independently of the library implementation. The library behavior is connected after the executable has been invoked to be executed, either as part of the process of starting the execution, or in the middle of execution. In this case the library is called a dynamic library (loaded at run time ). A dynamic library can be loaded and linked when preparing a program for execution, by the linker . Alternatively, in the middle of execution, an application may explicitly request that a module be loaded . Most compiled languages have a standard library although programmers can also create their own custom libraries. Most modern software systems provide libraries that implement the majority of the system services. Such libraries have commoditized the services which a modern application requires. As such, most code used by modern applications is provided in these system libraries. Linking Main articles: Link time and Linker (computing) Libraries are important in the program linking or binding process, which resolves references known as links or symbols to library modules. The linking process is usually automatically done by a linker or binder program that searches a set of libraries and other modules in a given order. Usually it is not considered an error if a link target can be found multiple times in a given set of libraries. Linking may be done when an executable file is created, or whenever the program is used at run time . The references being resolved may be addresses(\u5730\u5740) for jumps and other routine calls. They may be in the main program, or in one module depending upon another. They are resolved into fixed or relocatable addresses (from a common base) by allocating runtime memory for the memory segments of each module referenced. Some programming languages may use a feature called smart linking whereby the linker is aware of or integrated with the compiler, such that the linker knows how external references are used, and code in a library that is never actually used , even though internally referenced, can be discarded from the compiled application. For example, a program that only uses integers for arithmetic, or does no arithmetic operations at all, can exclude floating-point library routines. This smart-linking feature can lead to smaller application file sizes and reduced memory usage. Relocation Main article: Relocation (computer science) Some references in a program or library module are stored in a relative or symbolic form which cannot be resolved until all code and libraries are assigned final static addresses . Relocation is the process of adjusting these references, and is done either by the linker or the loader . In general, relocation cannot be done to individual libraries themselves because the addresses in memory may vary depending on the program using them and other libraries they are combined with. Position-independent code avoids references to absolute addresses and therefore does not require relocation. See also Program Library HOWTO https://stackoverflow.com/questions/480764/linux-error-while-loading-shared-libraries-cannot-open-shared-object-file-no-s","title":"Library(computing)"},{"location":"ABI/Library/Library(computing)/#library-computing","text":"Illustration of an application which uses libvorbisfile to play an Ogg Vorbis file In computer science , a library is a collection of non-volatile resources used by computer programs , often for software development . These may include configuration data, documentation, help data, message templates, pre-written code and subroutines , classes , values or type specifications. In IBM's OS/360 and its successors they are referred to as partitioned data sets . A library is also a collection of implementations of behavior, written in terms of a language, that has a well-defined interface by which the behavior is invoked. For instance, people who want to write a higher level program can use a library to make system calls instead of implementing those system calls over and over again. In addition, the behavior is provided for reuse by multiple independent programs. A program invokes the library-provided behavior via a mechanism of the language. For example, in a simple imperative language such as C, the behavior in a library is invoked by using C's normal function-call. What distinguishes the call as being to a library function, versus being to another function in the same program, is the way that the code is organized in the system. Library code is organized in such a way that it can be used by multiple programs that have no connection to each other, while code that is part of a program is organized to be used only within that one program. This distinction can gain a hierarchical notion when a program grows large, such as a multi-million-line program. In that case, there may be internal libraries that are reused by independent sub-portions of the large program. The distinguishing feature is that a library is organized for the purposes of being reused by independent programs or sub-programs, and the user only needs to know the interface and not the internal details of the library. The value of a library lies in the reuse of the behavior. When a program invokes a library, it gains the behavior implemented inside that library without having to implement that behavior itself. Libraries encourage the sharing of code in a modular fashion, and ease the distribution of the code. The behavior implemented by a library can be connected to the invoking program at different program lifecycle phases . If the code of the library is accessed during the build of the invoking program, then the library is called a static library .[ 1] An alternative is to build the executable of the invoking program and distribute that, independently of the library implementation. The library behavior is connected after the executable has been invoked to be executed, either as part of the process of starting the execution, or in the middle of execution. In this case the library is called a dynamic library (loaded at run time ). A dynamic library can be loaded and linked when preparing a program for execution, by the linker . Alternatively, in the middle of execution, an application may explicitly request that a module be loaded . Most compiled languages have a standard library although programmers can also create their own custom libraries. Most modern software systems provide libraries that implement the majority of the system services. Such libraries have commoditized the services which a modern application requires. As such, most code used by modern applications is provided in these system libraries.","title":"Library (computing)"},{"location":"ABI/Library/Library(computing)/#linking","text":"Main articles: Link time and Linker (computing) Libraries are important in the program linking or binding process, which resolves references known as links or symbols to library modules. The linking process is usually automatically done by a linker or binder program that searches a set of libraries and other modules in a given order. Usually it is not considered an error if a link target can be found multiple times in a given set of libraries. Linking may be done when an executable file is created, or whenever the program is used at run time . The references being resolved may be addresses(\u5730\u5740) for jumps and other routine calls. They may be in the main program, or in one module depending upon another. They are resolved into fixed or relocatable addresses (from a common base) by allocating runtime memory for the memory segments of each module referenced. Some programming languages may use a feature called smart linking whereby the linker is aware of or integrated with the compiler, such that the linker knows how external references are used, and code in a library that is never actually used , even though internally referenced, can be discarded from the compiled application. For example, a program that only uses integers for arithmetic, or does no arithmetic operations at all, can exclude floating-point library routines. This smart-linking feature can lead to smaller application file sizes and reduced memory usage.","title":"Linking"},{"location":"ABI/Library/Library(computing)/#relocation","text":"Main article: Relocation (computer science) Some references in a program or library module are stored in a relative or symbolic form which cannot be resolved until all code and libraries are assigned final static addresses . Relocation is the process of adjusting these references, and is done either by the linker or the loader . In general, relocation cannot be done to individual libraries themselves because the addresses in memory may vary depending on the program using them and other libraries they are combined with. Position-independent code avoids references to absolute addresses and therefore does not require relocation.","title":"Relocation"},{"location":"ABI/Library/Library(computing)/#see-also","text":"Program Library HOWTO https://stackoverflow.com/questions/480764/linux-error-while-loading-shared-libraries-cannot-open-shared-object-file-no-s","title":"See also"},{"location":"ABI/Library/Position-independent-code/Position-Independent-Code(PIC)-in-shared-libraries/","text":"Position Independent Code (PIC) in shared libraries Some problems of load-time relocation PIC - introduction Key insight #1 - offset between text and data sections Key insight #2 - making an IP-relative offset work on x86 The Global Offset Table (GOT) PIC with data references through GOT - an example Function calls in PIC The lazy binding optimization The Procedure Linkage Table (PLT) PIC with function calls through PLT and GOT - an example Controlling if and when the resolution is done by the loader The costs of PIC Conclusion Position Independent Code (PIC) in shared libraries I've described the need for special handling of shared libraries while loading them into the process's address space in a previous article . Briefly, when the linker creates a shared library, it doesn't know in advance where it might be loaded. This creates a problem for the data and code references within the library, which should be somehow made to point to the correct memory locations. There are two main approaches to solve this problem in Linux ELF shared libraries: Load-time relocation Position independent code (PIC) Load-time relocation was already covered . Here, I want to explain the second approach - PIC. I originally planned to focus on both x86 and x64 (a.k.a. x86-64) in this article, but as it grew longer and longer I decided it won't be practical. So, it will explain only how PIC works on x86, picking this older architecture specifically because (unlike x64) it wasn't designed with PIC in mind, so implementing PIC on it is a bit trickier. A future (hopefully much shorter) article will build upon the foundation of this one to explain how PIC is implemented on x64. Some problems of load-time relocation As we've seen in the previous article, load-time relocation is a fairly straightforward method, and it works. PIC, however, is much more popular nowadays, and is usually the recommended method of building shared libraries. Why is this so? Load-time relocation has a couple of problems: it takes time to perform, and it makes the text section of the library non-shareable. First, the performance problem. If a shared library was linked with load-time relocation entries, it will take some time to actually perform these relocations when the application is loaded. You may think that the cost shouldn't be too large - after all, the loader doesn't have to scan through the whole text section - it should only look at the relocation entries. But if a complex piece of software loads multiple large shared libraries at start-up, and each shared library must first have its load-time relocations applied, these costs can build up and result in a noticeable delay in the start-up time of the application. Second, the non-shareable text section problem, which is somewhat more serious. One of the main points of having shared libraries in the first place, is saving RAM. Some common shared libraries are used by multiple applications. If the text section (where the code is) of the shared library can only be loaded into memory once (and then mapped into the virtual memories of many processes), considerable amounts of RAM can be saved. But this is not possible with load-time relocation, since when using this technique the text section has to be modified at load-time to apply the relocations. Therefore, for each application that loaded this shared library, it will have to be wholly placed in RAM again [ 1] . Different applications won't be able to really share it. Moreover, having a writable text section (it must be kept writable, to allow the dynamic loader to perform the relocations) poses a security risk, making it easier to exploit the application. As we'll see in this article, PIC mostly mitigates these problems. PIC - introduction The idea behind PIC is simple - add an additional level of indirection to all global data and function references in the code. By cleverly utilizing some artifacts of the linking and loading processes, it's possible to make the text section of the shared library truly position independent , in the sense that it can be easily mapped into different memory addresses without needing to change one bit. In the next few sections I will explain in detail how this feat is achieved. Key insight #1 - offset between text and data sections One of the key insights on which PIC relies is the offset between the text and data sections, known to the linker at link-time . When the linker combines several object files together, it collects their sections (for example, all text sections get unified into a single large text section). Therefore, the linker knows both about the sizes of the sections and about their relative locations. For example, the text section may be immediately followed by the data section, so the offset from any given instruction in the text section to the beginning of the data section is just the size of the text section minus the offset of the instruction from the beginning of the text section - and both these quantities are known to the linker. In the diagram above, the code section was loaded into some address (unknown at link-time) 0xXXXX0000 (the X-es literally mean \"don't care\"), and the data section right after it at offset 0xXXXXF000. Then, if some instruction at offset 0x80 in the code section wants to reference stuff in the data section, the linker knows the relative offset (0xEF80 in this case) and can encode it in the instruction. Note that it wouldn't matter if another section was placed between the code and data sections, or if the data section preceded the code section. Since the linker knows the sizes of all sections and decides where to place them, the insight holds. Key insight #2 - making an IP-relative offset work on x86 The above is only useful if we can actually put the relative offset to work. But data references (i.e. in the mov instruction) on x86 require absolute addresses. So, what can we do? If we have a relative address and need an absolute address, what's missing is the value of the instruction pointer (since, by definition, the relative address is relative to the instruction's location). There's no instruction to obtain the value of the instruction pointer on x86, but we can use a simple trick to get it. Here's some assembly pseudo-code that demonstrates it: call TMPLABEL TMPLABEL: pop ebx What happens here is: The CPU executes call TMPLABEL , which causes it to save the address of the next instruction (the pop ebx ) on stack and jump to the label. Since the instruction at the label is pop ebx , it gets executed next. It pops a value from the stack into ebx . But this value is the address of the instruction itself, so ebx now effectively contains the value of the instruction pointer. The Global Offset Table (GOT) With this at hand, we can finally get to the implementation of position-independent data addressing on x86. It is accomplished by means of a \"global offset table\", or in short GOT. A GOT is simply a table of addresses, residing in the data section. Suppose some instruction in the code section wants to refer to a variable. Instead of referring to it directly by absolute address (which would require a relocation), it refers to an entry in the GOT. Since the GOT is in a known place in the data section, this reference is relative and known to the linker. The GOT entry, in turn, will contain the absolute address of the variable: In pseudo-assembly, we replace an absolute addressing instruction: ; Place the value of the variable in edx mov edx, [ADDR_OF_VAR] With displacement addressing from a register, along with an extra indirection: ; 1. Somehow get the address of the GOT into ebx lea ebx, ADDR_OF_GOT ; 2. Suppose ADDR_OF_VAR is stored at offset 0x10 ; in the GOT. Then this will place ADDR_OF_VAR ; into edx. mov edx, DWORD PTR [ebx + 0x10] ; 3. Finally, access the variable and place its ; value into edx. mov edx, DWORD PTR [edx] So, we've gotten rid of a relocation in the code section by redirecting variable references through the GOT. But we've also created a relocation in the data section. Why? Because the GOT still has to contain the absolute address of the variable for the scheme described above to work. So what have we gained? A lot, it turns out. A relocation in the data section is much less problematic than one in the code section, for two reasons (which directly address the two main problems of load-time relocation of code described in the beginning of the article): Relocations in the code section are required per variable reference , while in the GOT we only need to relocate once per variable . There are likely much more references to variables than variables, so this is more efficient. The data section is writable and not shared between processes anyway, so adding relocations to it does no harm. Moving relocations from the code section, however, allows to make it read-only and share it between processes. PIC with data references through GOT - an example I will now show a complete example that demonstrates the mechanics of PIC: int myglob = 42; int ml_func(int a, int b) { return myglob + a + b; } This chunk of code will be compiled into a shared library (using the -fpic and -shared flags as appropriate) named libmlpic_dataonly.so . Let's take a look at its disassembly, focusing on the ml_func function: 0000043c <ml_func>: 43c: 55 push ebp 43d: 89 e5 mov ebp,esp 43f: e8 16 00 00 00 call 45a <__i686.get_pc_thunk.cx> 444: 81 c1 b0 1b 00 00 add ecx,0x1bb0 44a: 8b 81 f0 ff ff ff mov eax,DWORD PTR [ecx-0x10] 450: 8b 00 mov eax,DWORD PTR [eax] 452: 03 45 08 add eax,DWORD PTR [ebp+0x8] 455: 03 45 0c add eax,DWORD PTR [ebp+0xc] 458: 5d pop ebp 459: c3 ret 0000045a <__i686.get_pc_thunk.cx>: 45a: 8b 0c 24 mov ecx,DWORD PTR [esp] 45d: c3 ret I'm going to refer to instructions by their addresses (the left-most number in the disassembly). This address is the offset from the load address of the shared library. At 43f , the address of the next instruction is placed into ecx , by means of the technique described in the \"key insight #2 \" section above. At 444 , a known constant offset from the instruction to the place where the GOT is located is added to ecx . So ecx now serves as a base pointer to GOT. At 44a , a value is taken from [ecx - 0x10] , which is a GOT entry, and placed into eax . This is the address of myglob . At 450 the indirection is done, and the value of myglob is placed into eax . Later the parameters a and b are added to myglob and the value is returned (by keeping it in eax ). We can also query the shared library with readelf -S to see where the GOT section was placed: Section Headers: [Nr] Name Type Addr Off Size ES Flg Lk Inf Al <snip> [19] .got PROGBITS 00001fe4 000fe4 000010 04 WA 0 0 4 [20] .got.plt PROGBITS 00001ff4 000ff4 000014 04 WA 0 0 4 <snip> Let's do some math to check the computation done by the compiler to find myglob . As I mentioned above, the call to __i686.get_pc_thunk.cx places the address of the next instruction into ecx . That address is 0x444 [ 2] . The next instruction then adds 0x1bb0 to it, and the result in ecx is going to be 0x1ff4 . Finally, to actually obtain the GOT entry holding the address of myglob , displacement addressing is used - [ecx - 0x10] , so the entry is at 0x1fe4 , which is the first entry in the GOT according to the section header. Why there's another section whose name starts with .got will be explained later in the article [ 3] . Note that the compiler chooses to point ecx to after the GOT and then use negative offsets to obtain entries. This is fine, as long as the math works out. And so far it does. There's something we're still missing, however. How does the address of myglob actually get into the GOT slot at 0x1fe4 ? Recall that I mentioned a relocation, so let's find it: > readelf -r libmlpic_dataonly.so Relocation section '.rel.dyn' at offset 0x2dc contains 5 entries: Offset Info Type Sym.Value Sym. Name 00002008 00000008 R_386_RELATIVE 00001fe4 00000406 R_386_GLOB_DAT 0000200c myglob <snip> Note the relocation section for myglob , pointing to address 0x1fe4 , as expected. The relocation is of type R_386_GLOB_DAT , which simply tells the dynamic loader - \"put the actual value of the symbol (i.e. its address) into that offset\". So everything works out nicely. All that's left is to check how it actually looks when the library is loaded. We can do this by writing a simple \"driver\" executable that links to libmlpic_dataonly.so and calls ml_func , and then running it through GDB. > gdb driver [...] skipping output (gdb) set environment LD_LIBRARY_PATH=. (gdb) break ml_func [...] (gdb) run Starting program: [...]pic_tests/driver Breakpoint 1, ml_func (a=1, b=1) at ml_reloc_dataonly.c:5 5 return myglob + a + b; (gdb) set disassembly-flavor intel (gdb) disas ml_func Dump of assembler code for function ml_func: 0x0013143c <+0>: push ebp 0x0013143d <+1>: mov ebp,esp 0x0013143f <+3>: call 0x13145a <__i686.get_pc_thunk.cx> 0x00131444 <+8>: add ecx,0x1bb0 => 0x0013144a <+14>: mov eax,DWORD PTR [ecx-0x10] 0x00131450 <+20>: mov eax,DWORD PTR [eax] 0x00131452 <+22>: add eax,DWORD PTR [ebp+0x8] 0x00131455 <+25>: add eax,DWORD PTR [ebp+0xc] 0x00131458 <+28>: pop ebp 0x00131459 <+29>: ret End of assembler dump. (gdb) i registers eax 0x1 1 ecx 0x132ff4 1257460 [...] skipping output The debugger has entered ml_func , and stopped at IP 0x0013144a [ 4] . We see that ecx holds the value 0x132ff4 (which is the address of the instruction plus 0x1bb0 , as explained before). Note that at this point, at runtime, these are absolute addresses - the shared library has already been loaded into the address space of the process. So, the GOT entry for myglob is at [ecx - 0x10] . Let's check what's there: (gdb) x 0x132fe4 0x132fe4: 0x0013300c So, we'd expect 0x0013300c to be the address of myglob . Let's verify: (gdb) p &myglob $1 = (int *) 0x13300c Indeed, it is! Function calls in PIC Alright, so this is how data addressing works in position independent code. But what about function calls? Theoretically, the exact same approach could work for function calls as well. Instead of call actually containing the address of the function to call, let it contain the address of a known GOT entry, and fill in that entry during loading. But this is not how function calls work in PIC. What actually happens is a bit more complicated. Before I explain how it's done, a few words about the motivation for such a mechanism. The lazy binding optimization When a shared library refers to some function, the real address of that function is not known until load time. Resolving this address is called binding , and it's something the dynamic loader does when it loads the shared library into the process's memory space. This binding process is non-trivial, since the loader has to actually look up the function symbol in special tables [ 5] . So, resolving each function takes time. Not a lot of time, but it adds up since the amount of functions in libraries is typically much larger than the amount of global variables. Moreover, most of these resolutions are done in vain, because in a typical run of a program only a fraction of functions actually get called (think about various functions handling error and special conditions, which typically don't get called at all). So, to speed up this process, a clever lazy binding scheme was devised. \"Lazy\" is a generic name for a family of optimizations in computer programming, where work is delayed until the last moment when it's actually needed, with the intention of avoiding doing this work if its results are never required during a specific run of a program. Good examples of laziness are copy-on-write and lazy evaluation . This lazy binding scheme is attained by adding yet another level of indirection - the PLT. The Procedure Linkage Table (PLT) The PLT is part of the executable text section, consisting of a set of entries (one for each external function the shared library calls). Each PLT entry is a short chunk of executable code. Instead of calling the function directly, the code calls an entry in the PLT, which then takes care to call the actual function. This arrangement is sometimes called a \" trampoline \". Each PLT entry also has a corresponding entry in the GOT which contains the actual offset to the function, but only when the dynamic loader resolves it. I know this is confusing, but hopefully it will be come clearer once I explain the details in the next few paragraphs and diagrams. As the previous section mentioned, PLTs allow lazy resolution of functions. When the shared library is first loaded, the function calls have not been resolved yet: Explanation: In the code, a function func is called. The compiler translates it to a call to func@plt , which is some N-th entry in the PLT. The PLT consists of a special first entry, followed by a bunch of identically structured entries, one for each function needing resolution. Each PLT entry but the first consists of these parts: A jump to a location which is specified in a corresponding GOT entry Preparation of arguments for a \"resolver\" routine Call to the resolver routine, which resides in the first entry of the PLT The first PLT entry is a call to a resolver routine, which is located in the dynamic loader itself [ 6] . This routine resolves the actual address of the function. More on its action a bit later. Before the function's actual address has been resolved, the Nth GOT entry just points to after the jump. This is why this arrow in the diagram is colored differently - it's not an actual jump, just a pointer. What happens when func is called for the first time is this: PLT[n] is called and jumps to the address pointed to in GOT[n] . This address points into PLT[n] itself, to the preparation of arguments for the resolver. The resolver is then called. The resolver performs resolution of the actual address of func , places its actual address into GOT[n] and calls func . After the first call, the diagram looks a bit differently: Note that GOT[n] now points to the actual func [ 7] instead of back into the PLT. So, when func is called again: PLT[n] is called and jumps to the address pointed to in GOT[n] . GOT[n] points to func , so this just transfers control to func . In other words, now func is being actually called, without going through the resolver, at the cost of one additional jump. That's all there is to it, really. This mechanism allows lazy resolution of functions, and no resolution at all for functions that aren't actually called. It also leaves the code/text section of the library completely position independent, since the only place where an absolute address is used is the GOT, which resides in the data section and will be relocated by the dynamic loader. Even the PLT itself is PIC, so it can live in the read-only text section. I didn't get into much details regarding the resolver, but it's really not important for our purpose here. The resolver is simply a chunk of low-level code in the loader that does symbol resolution. The arguments prepared for it in each PLT entry, along with a suitable relocation entry, help it know about the symbol that needs resolution and about the GOT entry to update. PIC with function calls through PLT and GOT - an example Once again, to fortify the hard-learned theory with a practical demonstration, here's a complete example showing function call resolution using the mechanism described above. I'll be moving forward a bit faster this time. Here's the code for the shared library: int myglob = 42; int ml_util_func(int a) { return a + 1; } int ml_func(int a, int b) { int c = b + ml_util_func(a); myglob += c; return b + myglob; } This code will be compiled into libmlpic.so , and the focus is going to be on the call to ml_util_func from ml_func . Let's first disassemble ml_func : 00000477 <ml_func>: 477: 55 push ebp 478: 89 e5 mov ebp,esp 47a: 53 push ebx 47b: 83 ec 24 sub esp,0x24 47e: e8 e4 ff ff ff call 467 <__i686.get_pc_thunk.bx> 483: 81 c3 71 1b 00 00 add ebx,0x1b71 489: 8b 45 08 mov eax,DWORD PTR [ebp+0x8] 48c: 89 04 24 mov DWORD PTR [esp],eax 48f: e8 0c ff ff ff call 3a0 <ml_util_func@plt> <... snip more code> The interesting part is the call to ml_util_func@plt . Note also that the address of GOT is in ebx . Here's what ml_util_func@plt looks like (it's in an executable section called .plt ): 000003a0 <ml_util_func@plt>: 3a0: ff a3 14 00 00 00 jmp DWORD PTR [ebx+0x14] 3a6: 68 10 00 00 00 push 0x10 3ab: e9 c0 ff ff ff jmp 370 <_init+0x30> Recall that each PLT entry consists of three parts: A jump to an address specified in GOT (this is the jump to [ebx+0x14] ) Preparation of arguments for the resolver Call to the resolver The resolver (PLT entry 0) resides at address 0x370 , but it's of no interest to us here. What's more interesting is to see what the GOT contains. For that, we first have to do some math. The \"get IP\" trick in ml_func was done on address 0x483 , to which 0x1b71 is added. So the base of the GOT is at 0x1ff4 . We can take a peek at the GOT contents with readelf [ 8] : > readelf -x .got.plt libmlpic.so Hex dump of section '.got.plt': 0x00001ff4 241f0000 00000000 00000000 86030000 $............... 0x00002004 96030000 a6030000 ........ The GOT entry ml_util_func@plt looks at is at offset +0x14 , or 0x2008 . From above, the word at that location is 0x3a6 , which is the address of the push instruction in ml_util_func@plt . To help the dynamic loader do its job, a relocation entry is also added and specifies which place in the GOT to relocate for ml_util_func : > readelf -r libmlpic.so [...] snip output Relocation section '.rel.plt' at offset 0x328 contains 3 entries: Offset Info Type Sym.Value Sym. Name 00002000 00000107 R_386_JUMP_SLOT 00000000 __cxa_finalize 00002004 00000207 R_386_JUMP_SLOT 00000000 __gmon_start__ 00002008 00000707 R_386_JUMP_SLOT 0000046c ml_util_func The last line means that the dynamic loader should place the value (address) of symbol ml_util_func into 0x2008 (which, recall, is the GOT entry for this function). It would be interesting to see this GOT entry modification actually happen after the first call. Let's once again use GDB for the inspection. > gdb driver [...] skipping output (gdb) set environment LD_LIBRARY_PATH=. (gdb) break ml_func Breakpoint 1 at 0x80483c0 (gdb) run Starting program: /pic_tests/driver Breakpoint 1, ml_func (a=1, b=1) at ml_main.c:10 10 int c = b + ml_util_func(a); (gdb) We're now before the first call to ml_util_func . Recall that GOT is pointed to by ebx in this code. Let's see what's in it: (gdb) i registers ebx ebx 0x132ff4 And the offset to the entry we need is at [ebx+0x14] : (gdb) x/w 0x133008 0x133008: 0x001313a6 Yep, the 0x3a6 ending, looks right. Now, let's step until after the call to ml_util_func and check again: (gdb) step ml_util_func (a=1) at ml_main.c:5 5 return a + 1; (gdb) x/w 0x133008 0x133008: 0x0013146c The value at 0x133008 was changed. Hence, 0x0013146c should be the real address of ml_util_func , placed in there by the dynamic loader: (gdb) p &ml_util_func $1 = (int (*)(int)) 0x13146c <ml_util_func> Just as expected. Controlling if and when the resolution is done by the loader This would be a good place to mention that the process of lazy symbol resolution performed by the dynamic loader can be configured with some environment variables (and corresponding flags to ld when linking the shared library). This is sometimes useful for special performance requirements or debugging. The LD_BIND_NOW env var, when defined, tells the dynamic loader to always perform the resolution for all symbols at start-up time, and not lazily. You can easily verify this in action by setting this env var and re-running the previous sample with GDB. You'll see that the GOT entry for ml_util_func contains its real address even before the first call to the function. Conversely, the LD_BIND_NOT env var tells the dynamic loader not to update the GOT entry at all. Each call to an external function will then go through the dynamic loader and be resolved anew. The dynamic loader is configurable by other flags as well. I encourage you to go over man ld.so - it contains some interesting information. The costs of PIC This article started by stating the problems of load-time relocation and how the PIC approach fixes them. But PIC is also not without problems. One immediately apparent cost is the extra indirection required for all external references to data and code in PIC. That's an extra memory load for each reference to a global variable, and for each call to a function. How problematic this is in practice depends on the compiler, the CPU architecture and the particular application. Another, less apparent cost, is the increased register usage required to implement PIC. In order to avoid locating the GOT too frequently, it makes sense for the compiler to generate code that keeps its address in a register (usually ebx ). But that ties down a whole register just for the sake of GOT. While not a big problem for RISC architectures that tend to have a lot of general purposes registers, it presents a performance problem for architectures like x86, which has a small amount of registers. PIC means having one general purpose register less, which adds up indirect costs since now more memory references have to be made. Conclusion This article explained what position independent code is, and how it helps create shared libraries with shareable read-only text sections. There are some tradeoffs when choosing between PIC and its alternative (load-time relocation), and the eventual outcome really depends on a lot of factors, like the CPU architecture on which the program is going to run. That said, PIC is becoming more and more popular. Some non-Intel architectures like SPARC64 force PIC-only code for shared libraries, and many others (for example, ARM) include IP-relative addressing modes to make PIC more efficient. Both are true for the successor of x86, the x64 architecture. I will discuss PIC on x64 in a future article. The focus of this article, however, has not been on performance considerations or architectural decisions. My aim was to explain, given that PIC is used, how it works . If the explanation wasn't clear enough - please let me know in the comments and I will try to provide more information. [ 1] Unless all applications load this library into the exact same virtual memory address. But this usually isn't done on Linux. [ 2] 0x444 (and all other addresses mentioned in this computation) is relative to the load address of the shared library, which is unknown until an executable actually loads it at runtime. Note how it doesn't matter in the code since it only juggles relative addresses. [ 3] The astute reader may wonder why .got is a separate section at all. Didn't I just show in the diagrams that it's located in the data section? In practice, it is. I don't want to get into the distinction between ELF sections and segments here, since that would take use too far away from the point. But briefly, any number of \"data\" sections can be defined for a library and mapped into a read-write segment. This doesn't really matter, as long as the ELF file is organized correctly. Separating the data segment into different logical sections provides modularity and makes the linker's job easier. [ 4] Note that gdb skipped the part where ecx is assigned. That's because it's kind-of considered to be part of the function's prolog (the real reason is in the way gcc structures its debug info, of course). Several references to global data and functions are made inside a function, and a register pointing to GOT can serve all of them. [ 5] Shared library ELF objects actually come with special hash table sections for this purpose. [ 6] The dynamic loader on Linux is just another shared library which gets loaded into the address space of all running processes. [ 7] I placed func in a separate code section, although in theory this could be the same one where the call to func is made (i.e. in the same shared library). The \"extra credit\" section of this article has information about why a call to an external function in the same shared library needs PIC (or relocation) as well. [ 8] Recall that in the data reference example I promised to explain why there are apparently two GOT sections in the object: .got and .got.plt . Now it should become obvious that this is just to conveniently split the GOT entries required for global data from GOT entries required for the PLT. This is also why when the GOT offset is computed in functions, it points to .got.plt , which comes right after .got . This way, negative offsets lead us to .got , while positive offsets lead us to .got.plt . While convenient, such an arrangement is by no means compulsory. Both parts could be placed into a single .got section.","title":"Position-Independent-Code(PIC)-in-shared-libraries"},{"location":"ABI/Library/Position-independent-code/Position-Independent-Code(PIC)-in-shared-libraries/#position-independent-code-pic-in-shared-libraries","text":"I've described the need for special handling of shared libraries while loading them into the process's address space in a previous article . Briefly, when the linker creates a shared library, it doesn't know in advance where it might be loaded. This creates a problem for the data and code references within the library, which should be somehow made to point to the correct memory locations. There are two main approaches to solve this problem in Linux ELF shared libraries: Load-time relocation Position independent code (PIC) Load-time relocation was already covered . Here, I want to explain the second approach - PIC. I originally planned to focus on both x86 and x64 (a.k.a. x86-64) in this article, but as it grew longer and longer I decided it won't be practical. So, it will explain only how PIC works on x86, picking this older architecture specifically because (unlike x64) it wasn't designed with PIC in mind, so implementing PIC on it is a bit trickier. A future (hopefully much shorter) article will build upon the foundation of this one to explain how PIC is implemented on x64.","title":"Position Independent Code (PIC) in shared libraries"},{"location":"ABI/Library/Position-independent-code/Position-Independent-Code(PIC)-in-shared-libraries/#some-problems-of-load-time-relocation","text":"As we've seen in the previous article, load-time relocation is a fairly straightforward method, and it works. PIC, however, is much more popular nowadays, and is usually the recommended method of building shared libraries. Why is this so? Load-time relocation has a couple of problems: it takes time to perform, and it makes the text section of the library non-shareable. First, the performance problem. If a shared library was linked with load-time relocation entries, it will take some time to actually perform these relocations when the application is loaded. You may think that the cost shouldn't be too large - after all, the loader doesn't have to scan through the whole text section - it should only look at the relocation entries. But if a complex piece of software loads multiple large shared libraries at start-up, and each shared library must first have its load-time relocations applied, these costs can build up and result in a noticeable delay in the start-up time of the application. Second, the non-shareable text section problem, which is somewhat more serious. One of the main points of having shared libraries in the first place, is saving RAM. Some common shared libraries are used by multiple applications. If the text section (where the code is) of the shared library can only be loaded into memory once (and then mapped into the virtual memories of many processes), considerable amounts of RAM can be saved. But this is not possible with load-time relocation, since when using this technique the text section has to be modified at load-time to apply the relocations. Therefore, for each application that loaded this shared library, it will have to be wholly placed in RAM again [ 1] . Different applications won't be able to really share it. Moreover, having a writable text section (it must be kept writable, to allow the dynamic loader to perform the relocations) poses a security risk, making it easier to exploit the application. As we'll see in this article, PIC mostly mitigates these problems.","title":"Some problems of load-time relocation"},{"location":"ABI/Library/Position-independent-code/Position-Independent-Code(PIC)-in-shared-libraries/#pic-introduction","text":"The idea behind PIC is simple - add an additional level of indirection to all global data and function references in the code. By cleverly utilizing some artifacts of the linking and loading processes, it's possible to make the text section of the shared library truly position independent , in the sense that it can be easily mapped into different memory addresses without needing to change one bit. In the next few sections I will explain in detail how this feat is achieved.","title":"PIC - introduction"},{"location":"ABI/Library/Position-independent-code/Position-Independent-Code(PIC)-in-shared-libraries/#key-insight-1-offset-between-text-and-data-sections","text":"One of the key insights on which PIC relies is the offset between the text and data sections, known to the linker at link-time . When the linker combines several object files together, it collects their sections (for example, all text sections get unified into a single large text section). Therefore, the linker knows both about the sizes of the sections and about their relative locations. For example, the text section may be immediately followed by the data section, so the offset from any given instruction in the text section to the beginning of the data section is just the size of the text section minus the offset of the instruction from the beginning of the text section - and both these quantities are known to the linker. In the diagram above, the code section was loaded into some address (unknown at link-time) 0xXXXX0000 (the X-es literally mean \"don't care\"), and the data section right after it at offset 0xXXXXF000. Then, if some instruction at offset 0x80 in the code section wants to reference stuff in the data section, the linker knows the relative offset (0xEF80 in this case) and can encode it in the instruction. Note that it wouldn't matter if another section was placed between the code and data sections, or if the data section preceded the code section. Since the linker knows the sizes of all sections and decides where to place them, the insight holds.","title":"Key insight #1 - offset between text and data sections"},{"location":"ABI/Library/Position-independent-code/Position-Independent-Code(PIC)-in-shared-libraries/#key-insight-2-making-an-ip-relative-offset-work-on-x86","text":"The above is only useful if we can actually put the relative offset to work. But data references (i.e. in the mov instruction) on x86 require absolute addresses. So, what can we do? If we have a relative address and need an absolute address, what's missing is the value of the instruction pointer (since, by definition, the relative address is relative to the instruction's location). There's no instruction to obtain the value of the instruction pointer on x86, but we can use a simple trick to get it. Here's some assembly pseudo-code that demonstrates it: call TMPLABEL TMPLABEL: pop ebx What happens here is: The CPU executes call TMPLABEL , which causes it to save the address of the next instruction (the pop ebx ) on stack and jump to the label. Since the instruction at the label is pop ebx , it gets executed next. It pops a value from the stack into ebx . But this value is the address of the instruction itself, so ebx now effectively contains the value of the instruction pointer.","title":"Key insight #2 - making an IP-relative offset work on x86"},{"location":"ABI/Library/Position-independent-code/Position-Independent-Code(PIC)-in-shared-libraries/#the-global-offset-table-got","text":"With this at hand, we can finally get to the implementation of position-independent data addressing on x86. It is accomplished by means of a \"global offset table\", or in short GOT. A GOT is simply a table of addresses, residing in the data section. Suppose some instruction in the code section wants to refer to a variable. Instead of referring to it directly by absolute address (which would require a relocation), it refers to an entry in the GOT. Since the GOT is in a known place in the data section, this reference is relative and known to the linker. The GOT entry, in turn, will contain the absolute address of the variable: In pseudo-assembly, we replace an absolute addressing instruction: ; Place the value of the variable in edx mov edx, [ADDR_OF_VAR] With displacement addressing from a register, along with an extra indirection: ; 1. Somehow get the address of the GOT into ebx lea ebx, ADDR_OF_GOT ; 2. Suppose ADDR_OF_VAR is stored at offset 0x10 ; in the GOT. Then this will place ADDR_OF_VAR ; into edx. mov edx, DWORD PTR [ebx + 0x10] ; 3. Finally, access the variable and place its ; value into edx. mov edx, DWORD PTR [edx] So, we've gotten rid of a relocation in the code section by redirecting variable references through the GOT. But we've also created a relocation in the data section. Why? Because the GOT still has to contain the absolute address of the variable for the scheme described above to work. So what have we gained? A lot, it turns out. A relocation in the data section is much less problematic than one in the code section, for two reasons (which directly address the two main problems of load-time relocation of code described in the beginning of the article): Relocations in the code section are required per variable reference , while in the GOT we only need to relocate once per variable . There are likely much more references to variables than variables, so this is more efficient. The data section is writable and not shared between processes anyway, so adding relocations to it does no harm. Moving relocations from the code section, however, allows to make it read-only and share it between processes.","title":"The Global Offset Table (GOT)"},{"location":"ABI/Library/Position-independent-code/Position-Independent-Code(PIC)-in-shared-libraries/#pic-with-data-references-through-got-an-example","text":"I will now show a complete example that demonstrates the mechanics of PIC: int myglob = 42; int ml_func(int a, int b) { return myglob + a + b; } This chunk of code will be compiled into a shared library (using the -fpic and -shared flags as appropriate) named libmlpic_dataonly.so . Let's take a look at its disassembly, focusing on the ml_func function: 0000043c <ml_func>: 43c: 55 push ebp 43d: 89 e5 mov ebp,esp 43f: e8 16 00 00 00 call 45a <__i686.get_pc_thunk.cx> 444: 81 c1 b0 1b 00 00 add ecx,0x1bb0 44a: 8b 81 f0 ff ff ff mov eax,DWORD PTR [ecx-0x10] 450: 8b 00 mov eax,DWORD PTR [eax] 452: 03 45 08 add eax,DWORD PTR [ebp+0x8] 455: 03 45 0c add eax,DWORD PTR [ebp+0xc] 458: 5d pop ebp 459: c3 ret 0000045a <__i686.get_pc_thunk.cx>: 45a: 8b 0c 24 mov ecx,DWORD PTR [esp] 45d: c3 ret I'm going to refer to instructions by their addresses (the left-most number in the disassembly). This address is the offset from the load address of the shared library. At 43f , the address of the next instruction is placed into ecx , by means of the technique described in the \"key insight #2 \" section above. At 444 , a known constant offset from the instruction to the place where the GOT is located is added to ecx . So ecx now serves as a base pointer to GOT. At 44a , a value is taken from [ecx - 0x10] , which is a GOT entry, and placed into eax . This is the address of myglob . At 450 the indirection is done, and the value of myglob is placed into eax . Later the parameters a and b are added to myglob and the value is returned (by keeping it in eax ). We can also query the shared library with readelf -S to see where the GOT section was placed: Section Headers: [Nr] Name Type Addr Off Size ES Flg Lk Inf Al <snip> [19] .got PROGBITS 00001fe4 000fe4 000010 04 WA 0 0 4 [20] .got.plt PROGBITS 00001ff4 000ff4 000014 04 WA 0 0 4 <snip> Let's do some math to check the computation done by the compiler to find myglob . As I mentioned above, the call to __i686.get_pc_thunk.cx places the address of the next instruction into ecx . That address is 0x444 [ 2] . The next instruction then adds 0x1bb0 to it, and the result in ecx is going to be 0x1ff4 . Finally, to actually obtain the GOT entry holding the address of myglob , displacement addressing is used - [ecx - 0x10] , so the entry is at 0x1fe4 , which is the first entry in the GOT according to the section header. Why there's another section whose name starts with .got will be explained later in the article [ 3] . Note that the compiler chooses to point ecx to after the GOT and then use negative offsets to obtain entries. This is fine, as long as the math works out. And so far it does. There's something we're still missing, however. How does the address of myglob actually get into the GOT slot at 0x1fe4 ? Recall that I mentioned a relocation, so let's find it: > readelf -r libmlpic_dataonly.so Relocation section '.rel.dyn' at offset 0x2dc contains 5 entries: Offset Info Type Sym.Value Sym. Name 00002008 00000008 R_386_RELATIVE 00001fe4 00000406 R_386_GLOB_DAT 0000200c myglob <snip> Note the relocation section for myglob , pointing to address 0x1fe4 , as expected. The relocation is of type R_386_GLOB_DAT , which simply tells the dynamic loader - \"put the actual value of the symbol (i.e. its address) into that offset\". So everything works out nicely. All that's left is to check how it actually looks when the library is loaded. We can do this by writing a simple \"driver\" executable that links to libmlpic_dataonly.so and calls ml_func , and then running it through GDB. > gdb driver [...] skipping output (gdb) set environment LD_LIBRARY_PATH=. (gdb) break ml_func [...] (gdb) run Starting program: [...]pic_tests/driver Breakpoint 1, ml_func (a=1, b=1) at ml_reloc_dataonly.c:5 5 return myglob + a + b; (gdb) set disassembly-flavor intel (gdb) disas ml_func Dump of assembler code for function ml_func: 0x0013143c <+0>: push ebp 0x0013143d <+1>: mov ebp,esp 0x0013143f <+3>: call 0x13145a <__i686.get_pc_thunk.cx> 0x00131444 <+8>: add ecx,0x1bb0 => 0x0013144a <+14>: mov eax,DWORD PTR [ecx-0x10] 0x00131450 <+20>: mov eax,DWORD PTR [eax] 0x00131452 <+22>: add eax,DWORD PTR [ebp+0x8] 0x00131455 <+25>: add eax,DWORD PTR [ebp+0xc] 0x00131458 <+28>: pop ebp 0x00131459 <+29>: ret End of assembler dump. (gdb) i registers eax 0x1 1 ecx 0x132ff4 1257460 [...] skipping output The debugger has entered ml_func , and stopped at IP 0x0013144a [ 4] . We see that ecx holds the value 0x132ff4 (which is the address of the instruction plus 0x1bb0 , as explained before). Note that at this point, at runtime, these are absolute addresses - the shared library has already been loaded into the address space of the process. So, the GOT entry for myglob is at [ecx - 0x10] . Let's check what's there: (gdb) x 0x132fe4 0x132fe4: 0x0013300c So, we'd expect 0x0013300c to be the address of myglob . Let's verify: (gdb) p &myglob $1 = (int *) 0x13300c Indeed, it is!","title":"PIC with data references through GOT - an example"},{"location":"ABI/Library/Position-independent-code/Position-Independent-Code(PIC)-in-shared-libraries/#function-calls-in-pic","text":"Alright, so this is how data addressing works in position independent code. But what about function calls? Theoretically, the exact same approach could work for function calls as well. Instead of call actually containing the address of the function to call, let it contain the address of a known GOT entry, and fill in that entry during loading. But this is not how function calls work in PIC. What actually happens is a bit more complicated. Before I explain how it's done, a few words about the motivation for such a mechanism.","title":"Function calls in PIC"},{"location":"ABI/Library/Position-independent-code/Position-Independent-Code(PIC)-in-shared-libraries/#the-lazy-binding-optimization","text":"When a shared library refers to some function, the real address of that function is not known until load time. Resolving this address is called binding , and it's something the dynamic loader does when it loads the shared library into the process's memory space. This binding process is non-trivial, since the loader has to actually look up the function symbol in special tables [ 5] . So, resolving each function takes time. Not a lot of time, but it adds up since the amount of functions in libraries is typically much larger than the amount of global variables. Moreover, most of these resolutions are done in vain, because in a typical run of a program only a fraction of functions actually get called (think about various functions handling error and special conditions, which typically don't get called at all). So, to speed up this process, a clever lazy binding scheme was devised. \"Lazy\" is a generic name for a family of optimizations in computer programming, where work is delayed until the last moment when it's actually needed, with the intention of avoiding doing this work if its results are never required during a specific run of a program. Good examples of laziness are copy-on-write and lazy evaluation . This lazy binding scheme is attained by adding yet another level of indirection - the PLT.","title":"The lazy binding optimization"},{"location":"ABI/Library/Position-independent-code/Position-Independent-Code(PIC)-in-shared-libraries/#the-procedure-linkage-table-plt","text":"The PLT is part of the executable text section, consisting of a set of entries (one for each external function the shared library calls). Each PLT entry is a short chunk of executable code. Instead of calling the function directly, the code calls an entry in the PLT, which then takes care to call the actual function. This arrangement is sometimes called a \" trampoline \". Each PLT entry also has a corresponding entry in the GOT which contains the actual offset to the function, but only when the dynamic loader resolves it. I know this is confusing, but hopefully it will be come clearer once I explain the details in the next few paragraphs and diagrams. As the previous section mentioned, PLTs allow lazy resolution of functions. When the shared library is first loaded, the function calls have not been resolved yet: Explanation: In the code, a function func is called. The compiler translates it to a call to func@plt , which is some N-th entry in the PLT. The PLT consists of a special first entry, followed by a bunch of identically structured entries, one for each function needing resolution. Each PLT entry but the first consists of these parts: A jump to a location which is specified in a corresponding GOT entry Preparation of arguments for a \"resolver\" routine Call to the resolver routine, which resides in the first entry of the PLT The first PLT entry is a call to a resolver routine, which is located in the dynamic loader itself [ 6] . This routine resolves the actual address of the function. More on its action a bit later. Before the function's actual address has been resolved, the Nth GOT entry just points to after the jump. This is why this arrow in the diagram is colored differently - it's not an actual jump, just a pointer. What happens when func is called for the first time is this: PLT[n] is called and jumps to the address pointed to in GOT[n] . This address points into PLT[n] itself, to the preparation of arguments for the resolver. The resolver is then called. The resolver performs resolution of the actual address of func , places its actual address into GOT[n] and calls func . After the first call, the diagram looks a bit differently: Note that GOT[n] now points to the actual func [ 7] instead of back into the PLT. So, when func is called again: PLT[n] is called and jumps to the address pointed to in GOT[n] . GOT[n] points to func , so this just transfers control to func . In other words, now func is being actually called, without going through the resolver, at the cost of one additional jump. That's all there is to it, really. This mechanism allows lazy resolution of functions, and no resolution at all for functions that aren't actually called. It also leaves the code/text section of the library completely position independent, since the only place where an absolute address is used is the GOT, which resides in the data section and will be relocated by the dynamic loader. Even the PLT itself is PIC, so it can live in the read-only text section. I didn't get into much details regarding the resolver, but it's really not important for our purpose here. The resolver is simply a chunk of low-level code in the loader that does symbol resolution. The arguments prepared for it in each PLT entry, along with a suitable relocation entry, help it know about the symbol that needs resolution and about the GOT entry to update.","title":"The Procedure Linkage Table (PLT)"},{"location":"ABI/Library/Position-independent-code/Position-Independent-Code(PIC)-in-shared-libraries/#pic-with-function-calls-through-plt-and-got-an-example","text":"Once again, to fortify the hard-learned theory with a practical demonstration, here's a complete example showing function call resolution using the mechanism described above. I'll be moving forward a bit faster this time. Here's the code for the shared library: int myglob = 42; int ml_util_func(int a) { return a + 1; } int ml_func(int a, int b) { int c = b + ml_util_func(a); myglob += c; return b + myglob; } This code will be compiled into libmlpic.so , and the focus is going to be on the call to ml_util_func from ml_func . Let's first disassemble ml_func : 00000477 <ml_func>: 477: 55 push ebp 478: 89 e5 mov ebp,esp 47a: 53 push ebx 47b: 83 ec 24 sub esp,0x24 47e: e8 e4 ff ff ff call 467 <__i686.get_pc_thunk.bx> 483: 81 c3 71 1b 00 00 add ebx,0x1b71 489: 8b 45 08 mov eax,DWORD PTR [ebp+0x8] 48c: 89 04 24 mov DWORD PTR [esp],eax 48f: e8 0c ff ff ff call 3a0 <ml_util_func@plt> <... snip more code> The interesting part is the call to ml_util_func@plt . Note also that the address of GOT is in ebx . Here's what ml_util_func@plt looks like (it's in an executable section called .plt ): 000003a0 <ml_util_func@plt>: 3a0: ff a3 14 00 00 00 jmp DWORD PTR [ebx+0x14] 3a6: 68 10 00 00 00 push 0x10 3ab: e9 c0 ff ff ff jmp 370 <_init+0x30> Recall that each PLT entry consists of three parts: A jump to an address specified in GOT (this is the jump to [ebx+0x14] ) Preparation of arguments for the resolver Call to the resolver The resolver (PLT entry 0) resides at address 0x370 , but it's of no interest to us here. What's more interesting is to see what the GOT contains. For that, we first have to do some math. The \"get IP\" trick in ml_func was done on address 0x483 , to which 0x1b71 is added. So the base of the GOT is at 0x1ff4 . We can take a peek at the GOT contents with readelf [ 8] : > readelf -x .got.plt libmlpic.so Hex dump of section '.got.plt': 0x00001ff4 241f0000 00000000 00000000 86030000 $............... 0x00002004 96030000 a6030000 ........ The GOT entry ml_util_func@plt looks at is at offset +0x14 , or 0x2008 . From above, the word at that location is 0x3a6 , which is the address of the push instruction in ml_util_func@plt . To help the dynamic loader do its job, a relocation entry is also added and specifies which place in the GOT to relocate for ml_util_func : > readelf -r libmlpic.so [...] snip output Relocation section '.rel.plt' at offset 0x328 contains 3 entries: Offset Info Type Sym.Value Sym. Name 00002000 00000107 R_386_JUMP_SLOT 00000000 __cxa_finalize 00002004 00000207 R_386_JUMP_SLOT 00000000 __gmon_start__ 00002008 00000707 R_386_JUMP_SLOT 0000046c ml_util_func The last line means that the dynamic loader should place the value (address) of symbol ml_util_func into 0x2008 (which, recall, is the GOT entry for this function). It would be interesting to see this GOT entry modification actually happen after the first call. Let's once again use GDB for the inspection. > gdb driver [...] skipping output (gdb) set environment LD_LIBRARY_PATH=. (gdb) break ml_func Breakpoint 1 at 0x80483c0 (gdb) run Starting program: /pic_tests/driver Breakpoint 1, ml_func (a=1, b=1) at ml_main.c:10 10 int c = b + ml_util_func(a); (gdb) We're now before the first call to ml_util_func . Recall that GOT is pointed to by ebx in this code. Let's see what's in it: (gdb) i registers ebx ebx 0x132ff4 And the offset to the entry we need is at [ebx+0x14] : (gdb) x/w 0x133008 0x133008: 0x001313a6 Yep, the 0x3a6 ending, looks right. Now, let's step until after the call to ml_util_func and check again: (gdb) step ml_util_func (a=1) at ml_main.c:5 5 return a + 1; (gdb) x/w 0x133008 0x133008: 0x0013146c The value at 0x133008 was changed. Hence, 0x0013146c should be the real address of ml_util_func , placed in there by the dynamic loader: (gdb) p &ml_util_func $1 = (int (*)(int)) 0x13146c <ml_util_func> Just as expected.","title":"PIC with function calls through PLT and GOT - an example"},{"location":"ABI/Library/Position-independent-code/Position-Independent-Code(PIC)-in-shared-libraries/#controlling-if-and-when-the-resolution-is-done-by-the-loader","text":"This would be a good place to mention that the process of lazy symbol resolution performed by the dynamic loader can be configured with some environment variables (and corresponding flags to ld when linking the shared library). This is sometimes useful for special performance requirements or debugging. The LD_BIND_NOW env var, when defined, tells the dynamic loader to always perform the resolution for all symbols at start-up time, and not lazily. You can easily verify this in action by setting this env var and re-running the previous sample with GDB. You'll see that the GOT entry for ml_util_func contains its real address even before the first call to the function. Conversely, the LD_BIND_NOT env var tells the dynamic loader not to update the GOT entry at all. Each call to an external function will then go through the dynamic loader and be resolved anew. The dynamic loader is configurable by other flags as well. I encourage you to go over man ld.so - it contains some interesting information.","title":"Controlling if and when the resolution is done by the loader"},{"location":"ABI/Library/Position-independent-code/Position-Independent-Code(PIC)-in-shared-libraries/#the-costs-of-pic","text":"This article started by stating the problems of load-time relocation and how the PIC approach fixes them. But PIC is also not without problems. One immediately apparent cost is the extra indirection required for all external references to data and code in PIC. That's an extra memory load for each reference to a global variable, and for each call to a function. How problematic this is in practice depends on the compiler, the CPU architecture and the particular application. Another, less apparent cost, is the increased register usage required to implement PIC. In order to avoid locating the GOT too frequently, it makes sense for the compiler to generate code that keeps its address in a register (usually ebx ). But that ties down a whole register just for the sake of GOT. While not a big problem for RISC architectures that tend to have a lot of general purposes registers, it presents a performance problem for architectures like x86, which has a small amount of registers. PIC means having one general purpose register less, which adds up indirect costs since now more memory references have to be made.","title":"The costs of PIC"},{"location":"ABI/Library/Position-independent-code/Position-Independent-Code(PIC)-in-shared-libraries/#conclusion","text":"This article explained what position independent code is, and how it helps create shared libraries with shareable read-only text sections. There are some tradeoffs when choosing between PIC and its alternative (load-time relocation), and the eventual outcome really depends on a lot of factors, like the CPU architecture on which the program is going to run. That said, PIC is becoming more and more popular. Some non-Intel architectures like SPARC64 force PIC-only code for shared libraries, and many others (for example, ARM) include IP-relative addressing modes to make PIC more efficient. Both are true for the successor of x86, the x64 architecture. I will discuss PIC on x64 in a future article. The focus of this article, however, has not been on performance considerations or architectural decisions. My aim was to explain, given that PIC is used, how it works . If the explanation wasn't clear enough - please let me know in the comments and I will try to provide more information. [ 1] Unless all applications load this library into the exact same virtual memory address. But this usually isn't done on Linux. [ 2] 0x444 (and all other addresses mentioned in this computation) is relative to the load address of the shared library, which is unknown until an executable actually loads it at runtime. Note how it doesn't matter in the code since it only juggles relative addresses. [ 3] The astute reader may wonder why .got is a separate section at all. Didn't I just show in the diagrams that it's located in the data section? In practice, it is. I don't want to get into the distinction between ELF sections and segments here, since that would take use too far away from the point. But briefly, any number of \"data\" sections can be defined for a library and mapped into a read-write segment. This doesn't really matter, as long as the ELF file is organized correctly. Separating the data segment into different logical sections provides modularity and makes the linker's job easier. [ 4] Note that gdb skipped the part where ecx is assigned. That's because it's kind-of considered to be part of the function's prolog (the real reason is in the way gcc structures its debug info, of course). Several references to global data and functions are made inside a function, and a register pointing to GOT can serve all of them. [ 5] Shared library ELF objects actually come with special hash table sections for this purpose. [ 6] The dynamic loader on Linux is just another shared library which gets loaded into the address space of all running processes. [ 7] I placed func in a separate code section, although in theory this could be the same one where the call to func is made (i.e. in the same shared library). The \"extra credit\" section of this article has information about why a call to an external function in the same shared library needs PIC (or relocation) as well. [ 8] Recall that in the data reference example I promised to explain why there are apparently two GOT sections in the object: .got and .got.plt . Now it should become obvious that this is just to conveniently split the GOT entries required for global data from GOT entries required for the PLT. This is also why when the GOT offset is computed in functions, it points to .got.plt , which comes right after .got . This way, negative offsets lead us to .got , while positive offsets lead us to .got.plt . While convenient, such an arrangement is by no means compulsory. Both parts could be placed into a single .got section.","title":"Conclusion"},{"location":"ABI/Library/Position-independent-code/Position-independent-code/","text":"Position-independent code In computing , position-independent code [ 1] ( PIC [ 1] ) or position-independent executable ( PIE ) is a body of machine code that, being placed somewhere in the primary memory , executes properly regardless of its absolute address (\u65e0\u8bba\u5176\u7edd\u5bf9\u5730\u5740\u5982\u4f55\uff0c\u5b83\u90fd\u88ab\u653e\u7f6e\u5728\u4e3b\u5b58\u50a8\u5668\u4e2d\u7684\u67d0\u4e2a\u4f4d\u7f6e). PIC is commonly used for shared libraries , so that the same library code can be loaded in a location in each program address space where it will not overlap any other uses of memory (for example, other shared libraries). PIC was also used on older computer systems lacking an MMU ,[ 2] so that the operating system could keep applications away from each other even within the single address space of an MMU-less system. Position-independent code can be executed at any memory address without modification. This differs from absolute code ,[ 1] which must be loaded at a specific location to function correctly,[ 1] and load-time locatable (LTL) code,[ 1] in which a linker or program loader modifies a program before execution so it can be run only from a particular memory location.[ 1] Generating position-independent code is often the default behavior for compilers , but they may place restrictions on the use of some language features, such as disallowing use of absolute addresses (position-independent code has to use relative addressing ). Instructions that refer directly to specific memory addresses sometimes execute faster, and replacing them with equivalent relative-addressing instructions may result in slightly slower execution, although modern processors make the difference practically negligible.[ 3]","title":"Position-independent-code"},{"location":"ABI/Library/Position-independent-code/Position-independent-code/#position-independent-code","text":"In computing , position-independent code [ 1] ( PIC [ 1] ) or position-independent executable ( PIE ) is a body of machine code that, being placed somewhere in the primary memory , executes properly regardless of its absolute address (\u65e0\u8bba\u5176\u7edd\u5bf9\u5730\u5740\u5982\u4f55\uff0c\u5b83\u90fd\u88ab\u653e\u7f6e\u5728\u4e3b\u5b58\u50a8\u5668\u4e2d\u7684\u67d0\u4e2a\u4f4d\u7f6e). PIC is commonly used for shared libraries , so that the same library code can be loaded in a location in each program address space where it will not overlap any other uses of memory (for example, other shared libraries). PIC was also used on older computer systems lacking an MMU ,[ 2] so that the operating system could keep applications away from each other even within the single address space of an MMU-less system. Position-independent code can be executed at any memory address without modification. This differs from absolute code ,[ 1] which must be loaded at a specific location to function correctly,[ 1] and load-time locatable (LTL) code,[ 1] in which a linker or program loader modifies a program before execution so it can be run only from a particular memory location.[ 1] Generating position-independent code is often the default behavior for compilers , but they may place restrictions on the use of some language features, such as disallowing use of absolute addresses (position-independent code has to use relative addressing ). Instructions that refer directly to specific memory addresses sometimes execute faster, and replacing them with equivalent relative-addressing instructions may result in slightly slower execution, although modern processors make the difference practically negligible.[ 3]","title":"Position-independent code"},{"location":"ABI/Library/Relocation/Relocation(computing)/","text":"Relocation (computing) Segmentation Relocation table Unix-like systems Relocation procedure Example G53OPS - Operating Systems Relocation and Protection What does 'relocation' mean? Relocation (computing) Relocation is the process of assigning load addresses for position-dependent code and data of a program and adjusting the code and data to reflect the assigned addresses .[ 1] [ 2] Prior to the advent of multiprocess systems, and still in many embedded systems the addresses for objects were absolute starting at a known location, often zero. Since multiprocessing systems dynamically link and switch between programs it became necessary to be able to relocate objects using position-independent code . A linker usually performs relocation in conjunction with symbol resolution , the process of searching files and libraries to replace symbolic references or names of libraries with actual usable addresses in memory before running a program. Relocation is typically done by the linker at link time , but it can also be done at load time by a relocating loader , or at run time by the running program itself. Some architectures avoid relocation entirely by deferring address assignment to run time; this is known as zero address arithmetic .[ which? ] THINKING : \u7f16\u8bd1\u751f\u6210\u7684executable\uff0c\u5b83\u4eec\u4e5f\u662f\u6709\u5730\u5740\u7a7a\u95f4\u7684 Segmentation Object files are segmented into various memory segment types. Example segments include code segment(.text) , initialized data segment(.data) , uninitialized data segment(.bss ), or others.[ clarification needed ] Relocation table The relocation table is a list of pointers created by the translator (a compiler or assembler ) and stored in the object or executable file. Each entry in the table, or \"fixup\", is a pointer to an absolute address in the object code that must be changed when the loader relocates the program so that it will refer to the correct location. Fixups are designed to support relocation of the program as a complete unit. In some cases, each fixup in the table is itself relative to a base address of zero, so the fixups themselves must be changed as the loader moves through the table.[ 3] In some architectures a fixup that crosses certain boundaries (such as a segment boundary) or that is not aligned on a word boundary is illegal and flagged as an error by the linker.[ 4] SUMMARY : \u663e\u7136\uff0c\u6bcf\u4e2aexecutable\u90fd\u5305\u542b\u4e00\u4e2arelocation table\u3002 Unix-like systems The Executable and Linkable Format (ELF) executable format and shared library format used by most Unix-like systems allows several types of relocation to be defined.[ 5] Relocation procedure The linker reads segment information and relocation tables in the object files and performs relocation by: merging all segments of common type into a single segment of that type assigning unique run time addresses to each section and each symbol, giving all code (functions) and data (global variables) unique run time addresses referring to the relocation table to modify[ why? ] symbols so that they point to the correct[ clarification needed ] run time addresses. Example The following example uses Donald Knuth 's MIX architecture and MIXAL assembly language. The principles are the same for any architecture, though the details will change. (A) Program SUBR is compiled to produce object file (B), shown as both machine code and assembler. The compiler may start the compiled code at an arbitrary location, often location zero as shown. Location 13 contains the machine code for the jump instruction to statement ST in location 5. (C) If SUBR is later linked with other code it may be stored at a location other than zero. In this example the linker places it at location 120. The address in the jump instruction, which is now at location 133, must be relocated to point to the new location of the code for statement ST , now 125. [1 61 shown in the instruction is the MIX machine code representation of 125]. (D) When the program is loaded into memory to run it may be loaded at some location other than the one assigned by the linker. This example shows SUBR now at location 300. The address in the jump instruction, now at 313, needs to be relocated again so that it points to the updated location of ST , 305. [4 49 is the MIX machine representation of 305]. G53OPS - Operating Systems Relocation and Protection As soon as we introduce multiprogramming we have two problems that we need to address. Relocation : When a program is run it does not know in advance what location it will be loaded at. Therefore, the program cannot simply generate static addresses (e.g. from jump instructions). Instead, they must be made relative to where the program has been loaded. SUMMARY : \u5728\u7f16\u8bd1\u9636\u6bb5\uff0c\u7f16\u8bd1\u5668\u662f\u65e0\u6cd5\u5f97\u77e5\u5176\u751f\u6210\u7684executable\u5728\u8fd0\u884c\u65f6\u7684location\u7684\uff0c\u56e0\u6b64\u7f16\u8bd1\u5668\u751f\u6210\u7684executable\u4e0d\u80fd\u591f\u4f7f\u7528static address\uff0c\u5b83\u53ea\u80fd\u591f\u4f7f\u7528relative address\uff1b\u7f16\u8bd1\u5668\u5b9e\u73b0relative address\u7684\u65b9\u5f0f\u662f\u4f7f\u7528symbol\u3002\u8fd9\u662f\u4f7f\u7528relocation\u7684\u539f\u56e0\u3002 Protection : Once you can have two programs in memory at the same time there is a danger that one program can write to the address space of another program. This is obviously dangerous and should be avoided. In order to cater(\u8fce\u5408) for relocation we could make the loader modify all the relevant addresses as the binary file is loaded. The OS/360 worked in this way but the scheme suffers from the following problems \u00b7 The program cannot be moved, after it has been loaded without going through the same process. \u00b7 Using this scheme does not help the protection problem as the program can still generate illegal addresses (maybe by using absolute addressing). \u00b7 The program needs to have some sort of map that tells the loader which addresses need to be modified. SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4ecb\u7ecd\u7684\u5185\u5bb9\u6307\u51fa\u4e86\u662f\u7531**loader**\u6765\u6267\u884crelocation\uff0c\u4ee5\u53ca\u6267\u884c\u7684\u65f6\u673a\u3002\u5b83\u8fd8\u6d89\u53ca\u5230\u4e86relocation\u7684\u4e00\u4e9b\u5b9e\u73b0\u65b9\u6cd5\uff0c\u5982\u5f15\u5165relocation table\u3002 A solution, which solves both the relocation and protection problem is to equip(\u914d\u5907) the machine with two registers called the base and limit registers. The base register stores the start address of the partition and the limit register holds the length of the partition. Any address that is generated by the program has the base register added to it. In addition, all addresses are checked to ensure they are within the range of the partition. An additional benefit of this scheme is that if a program is moved within memory, only its base register needs to be amended. This is obviously a lot quicker than having to modify every address reference within the program. The IBM PC uses a scheme similar to this, although it does not have a limit register. What does 'relocation' mean?","title":"Relocation(computing)"},{"location":"ABI/Library/Relocation/Relocation(computing)/#relocation-computing","text":"Relocation is the process of assigning load addresses for position-dependent code and data of a program and adjusting the code and data to reflect the assigned addresses .[ 1] [ 2] Prior to the advent of multiprocess systems, and still in many embedded systems the addresses for objects were absolute starting at a known location, often zero. Since multiprocessing systems dynamically link and switch between programs it became necessary to be able to relocate objects using position-independent code . A linker usually performs relocation in conjunction with symbol resolution , the process of searching files and libraries to replace symbolic references or names of libraries with actual usable addresses in memory before running a program. Relocation is typically done by the linker at link time , but it can also be done at load time by a relocating loader , or at run time by the running program itself. Some architectures avoid relocation entirely by deferring address assignment to run time; this is known as zero address arithmetic .[ which? ] THINKING : \u7f16\u8bd1\u751f\u6210\u7684executable\uff0c\u5b83\u4eec\u4e5f\u662f\u6709\u5730\u5740\u7a7a\u95f4\u7684","title":"Relocation (computing)"},{"location":"ABI/Library/Relocation/Relocation(computing)/#segmentation","text":"Object files are segmented into various memory segment types. Example segments include code segment(.text) , initialized data segment(.data) , uninitialized data segment(.bss ), or others.[ clarification needed ]","title":"Segmentation"},{"location":"ABI/Library/Relocation/Relocation(computing)/#relocation-table","text":"The relocation table is a list of pointers created by the translator (a compiler or assembler ) and stored in the object or executable file. Each entry in the table, or \"fixup\", is a pointer to an absolute address in the object code that must be changed when the loader relocates the program so that it will refer to the correct location. Fixups are designed to support relocation of the program as a complete unit. In some cases, each fixup in the table is itself relative to a base address of zero, so the fixups themselves must be changed as the loader moves through the table.[ 3] In some architectures a fixup that crosses certain boundaries (such as a segment boundary) or that is not aligned on a word boundary is illegal and flagged as an error by the linker.[ 4] SUMMARY : \u663e\u7136\uff0c\u6bcf\u4e2aexecutable\u90fd\u5305\u542b\u4e00\u4e2arelocation table\u3002","title":"Relocation table"},{"location":"ABI/Library/Relocation/Relocation(computing)/#unix-like-systems","text":"The Executable and Linkable Format (ELF) executable format and shared library format used by most Unix-like systems allows several types of relocation to be defined.[ 5]","title":"Unix-like systems"},{"location":"ABI/Library/Relocation/Relocation(computing)/#relocation-procedure","text":"The linker reads segment information and relocation tables in the object files and performs relocation by: merging all segments of common type into a single segment of that type assigning unique run time addresses to each section and each symbol, giving all code (functions) and data (global variables) unique run time addresses referring to the relocation table to modify[ why? ] symbols so that they point to the correct[ clarification needed ] run time addresses.","title":"Relocation procedure"},{"location":"ABI/Library/Relocation/Relocation(computing)/#example","text":"The following example uses Donald Knuth 's MIX architecture and MIXAL assembly language. The principles are the same for any architecture, though the details will change. (A) Program SUBR is compiled to produce object file (B), shown as both machine code and assembler. The compiler may start the compiled code at an arbitrary location, often location zero as shown. Location 13 contains the machine code for the jump instruction to statement ST in location 5. (C) If SUBR is later linked with other code it may be stored at a location other than zero. In this example the linker places it at location 120. The address in the jump instruction, which is now at location 133, must be relocated to point to the new location of the code for statement ST , now 125. [1 61 shown in the instruction is the MIX machine code representation of 125]. (D) When the program is loaded into memory to run it may be loaded at some location other than the one assigned by the linker. This example shows SUBR now at location 300. The address in the jump instruction, now at 313, needs to be relocated again so that it points to the updated location of ST , 305. [4 49 is the MIX machine representation of 305].","title":"Example"},{"location":"ABI/Library/Relocation/Relocation(computing)/#g53ops-operating-systems","text":"","title":"G53OPS - Operating Systems"},{"location":"ABI/Library/Relocation/Relocation(computing)/#relocation-and-protection","text":"As soon as we introduce multiprogramming we have two problems that we need to address. Relocation : When a program is run it does not know in advance what location it will be loaded at. Therefore, the program cannot simply generate static addresses (e.g. from jump instructions). Instead, they must be made relative to where the program has been loaded. SUMMARY : \u5728\u7f16\u8bd1\u9636\u6bb5\uff0c\u7f16\u8bd1\u5668\u662f\u65e0\u6cd5\u5f97\u77e5\u5176\u751f\u6210\u7684executable\u5728\u8fd0\u884c\u65f6\u7684location\u7684\uff0c\u56e0\u6b64\u7f16\u8bd1\u5668\u751f\u6210\u7684executable\u4e0d\u80fd\u591f\u4f7f\u7528static address\uff0c\u5b83\u53ea\u80fd\u591f\u4f7f\u7528relative address\uff1b\u7f16\u8bd1\u5668\u5b9e\u73b0relative address\u7684\u65b9\u5f0f\u662f\u4f7f\u7528symbol\u3002\u8fd9\u662f\u4f7f\u7528relocation\u7684\u539f\u56e0\u3002 Protection : Once you can have two programs in memory at the same time there is a danger that one program can write to the address space of another program. This is obviously dangerous and should be avoided. In order to cater(\u8fce\u5408) for relocation we could make the loader modify all the relevant addresses as the binary file is loaded. The OS/360 worked in this way but the scheme suffers from the following problems \u00b7 The program cannot be moved, after it has been loaded without going through the same process. \u00b7 Using this scheme does not help the protection problem as the program can still generate illegal addresses (maybe by using absolute addressing). \u00b7 The program needs to have some sort of map that tells the loader which addresses need to be modified. SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4ecb\u7ecd\u7684\u5185\u5bb9\u6307\u51fa\u4e86\u662f\u7531**loader**\u6765\u6267\u884crelocation\uff0c\u4ee5\u53ca\u6267\u884c\u7684\u65f6\u673a\u3002\u5b83\u8fd8\u6d89\u53ca\u5230\u4e86relocation\u7684\u4e00\u4e9b\u5b9e\u73b0\u65b9\u6cd5\uff0c\u5982\u5f15\u5165relocation table\u3002 A solution, which solves both the relocation and protection problem is to equip(\u914d\u5907) the machine with two registers called the base and limit registers. The base register stores the start address of the partition and the limit register holds the length of the partition. Any address that is generated by the program has the base register added to it. In addition, all addresses are checked to ensure they are within the range of the partition. An additional benefit of this scheme is that if a program is moved within memory, only its base register needs to be amended. This is obviously a lot quicker than having to modify every address reference within the program. The IBM PC uses a scheme similar to this, although it does not have a limit register.","title":"Relocation and Protection"},{"location":"ABI/Library/Relocation/Relocation(computing)/#what-does-relocation-mean","text":"","title":"What does 'relocation' mean?"},{"location":"ABI/Name-mangling/Name-mangling/","text":"Name mangling Examples C C++ Simple example[edit] Complex example[edit] How different compilers mangle the same functions[edit] Handling of C symbols when linking from C++ Standardised name mangling in C++ Real-world effects of C++ name mangling Demangle via c++filt Demangle via builtin GCC ABI Python Name mangling In compiler construction, name mangling (also called name decoration ) is a technique used to solve various problems caused by the need to resolve unique names for programming entities in many modern programming languages . It provides a way of encoding additional information in the name of a function , structure , class or another datatype in order to pass more semantic information from the compilers to linkers . SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u63cf\u8ff0\u4e86\u4f7f\u7528name mangling\u7684\u610f\u56fe The need arises where the language allows different entities to be named with the same identifier as long as they occupy a different namespace (where a namespace is typically defined by a module, class, or explicit namespace directive) or have different signatures (such as function overloading ). Any object code produced by compilers is usually linked with other pieces of object code (produced by the same or another compiler) by a type of program called a linker . The linker needs a great deal of information on each program entity. For example, to correctly link a function it needs its name, the number of arguments and their types, and so on. Examples C Although name mangling is not generally required or used by languages that do not support function overloading (such as C and classic Pascal), they use it in some cases to provide additional information about a function. For example, compilers targeted at Microsoft Windows platforms support a variety of calling conventions , which determine the manner in which parameters are sent to subroutines and results returned. Because the different calling conventions are not compatible with one another, compilers mangle symbols with codes detailing which convention should be used to call the specific routine. SUMMARY : encode calling convention in the name The mangling scheme was established by Microsoft, and has been informally followed by other compilers including Digital Mars, Borland, and GNU GCC, when compiling code for the Windows platforms. The scheme even applies to other languages, such as Pascal , D , Delphi , Fortran , and C# . This allows subroutines written in those languages to call, or be called by, existing Windows libraries using a calling convention different from their default. When compiling the following C examples: int _cdecl f ( int x ) { return 0 ; } int _stdcall g ( int y ) { return 0 ; } int _fastcall h ( int z ) { return 0 ; } 32 bit compilers emit, respectively: _f _g @ 4 @ h @ 4 In the stdcall and fastcall mangling schemes, the function is encoded as _**name**@**X** and @**name**@**X** respectively, where X is the number of bytes, in decimal, of the argument(s) in the parameter list (including those passed in registers, for fastcall). In the case of cdecl , the function name is merely prefixed by an underscore. The 64-bit convention on Windows (Microsoft C) has no leading underscore. This difference may in some rare cases lead to unresolved externals when porting such code to 64 bits. For example, Fortran code can use 'alias' to link against a C method by name as follows: SUBROUTINE f () !DEC$ ATTRIBUTES C, ALIAS:'_f' :: f END SUBROUTINE This will compile and link fine under 32 bits, but generate an unresolved external '_f' under 64 bits. One workaround for this is not to use 'alias' at all (in which the method names typically need to be capitalized in C and Fortran). Another is to use the BIND option: SUBROUTINE f () BIND ( C , NAME = \"f\" ) END SUBROUTINE C++ C++ compilers are the most widespread users of name mangling . The first C++ compilers were implemented as translators to C source code, which would then be compiled by a C compiler to object code; because of this, symbol names had to conform to C identifier rules. Even later, with the emergence of compilers which produced machine code or assembly directly, the system's linker generally did not support C++ symbols, and mangling was still required. The C++ language does not define a standard decoration scheme, so each compiler uses its own. C++ also has complex language features, such as classes , templates , namespaces , and operator overloading , that alter the meaning of specific symbols based on context or usage. Meta-data about these features can be disambiguated(\u6d88\u9664) by mangling (decorating) the name of a symbol . Because the name-mangling systems for such features are not standardized across compilers, few linkers can link object code that was produced by different compilers. Simple example[ edit ] A single C++ translation unit might define two functions named f() : int f ( void ) { return 1 ; } int f ( int ) { return 0 ; } void g ( void ) { int i = f (), j = f ( 0 ); } These are distinct functions, with no relation to each other apart from the name. The C++ compiler therefore will encode the type information in the symbol name, the result being something resembling: int __f_v ( void ) { return 1 ; } int __f_i ( int ) { return 0 ; } void __g_v ( void ) { int i = __f_v (), j = __f_i ( 0 ); } Even though its name is unique, g() is still mangled: name mangling applies to all symbols. Complex example[ edit ] The mangled symbols in this example, in the comments below the respective identifier name, are those produced by the GNU GCC 3.x compilers: namespace wikipedia { class article { public : std :: string format ( void ); /* = _ZN9wikipedia7article6formatEv */ bool print_to ( std :: ostream & ); /* = _ZN9wikipedia7article8print_toERSo */ class wikilink { public : wikilink ( std :: string const & name ); /* = _ZN9wikipedia7article8wikilinkC1ERKSs */ }; }; } All mangled symbols begin with _Z (note that an identifier beginning with an underscore followed by a capital is a reserved identifier in C, so conflict with user identifiers is avoided); for nested names (including both namespaces and classes), this is followed by N , then a series of pairs (the length being the length of the next identifier), and finally E . For example, wikipedia::article::format becomes _ZN9Wikipedia7article6formatE For functions, this is then followed by the type information; as format() is a void function, this is simply v ; hence: _ZN9Wikipedia7article6formatEv For print_to , the standard type std::ostream (which is a typedef for std::basic_ostream<char, std::char_traits<char> > ) is used, which has the special alias So ; a reference to this type is therefore RSo , with the complete name for the function being: _ZN9Wikipedia7article8print_toERSo How different compilers mangle the same functions[ edit ] There isn't a standard scheme by which even trivial C++ identifiers are mangled, and consequently different compilers (or even different versions of the same compiler, or the same compiler on different platforms) mangle public symbols in radically different (and thus totally incompatible) ways. Consider how different C++ compilers mangle the same functions: Compiler void h(int) void h(int, char) void h(void) Intel C++ 8.0 for Linux _Z1hi _Z1hic _Z1hv HP aC++ A.05.55 IA-64 IAR EWARM C++ 5.4 ARM GCC 3. x and higher Clang 1. x and higher[ 1] IAR EWARM C++ 7.4 ARM _Z<number>hi _Z<number>hic _Z<number>hv GCC 2.9*x* h__Fi h__Fic h__Fv HP aC++ A.03.45 PA-RISC Microsoft Visual C++ v6-v10 ( mangling details ) ?h@@YAXH@Z ?h@@YAXHD@Z ?h@@YAXXZ Digital Mars C++ Borland C++ v3.1 @h$qi @h$qizc @h$qv OpenVMS C++ V6.5 (ARM mode) H__XI H__XIC H__XV OpenVMS C++ V6.5 (ANSI mode) CXX$__7H__FIC26CDH77 CXX$__7H__FV2CB06E8 OpenVMS C++ X7.1 IA-64 CXX$_Z1HI2DSQ26A CXX$_Z1HIC2NP3LI4 CXX$_Z1HV0BCA19V SunPro CC __1cBh6Fi_v_ __1cBh6Fic_v_ __1cBh6F_v_ Tru64 C++ V6.5 (ARM mode) h__Xi h__Xic h__Xv Tru64 C++ V6.5 (ANSI mode) __7h__Fi __7h__Fic __7h__Fv Watcom C++ 10.6 W?h$n(i)v W?h$n(ia)v W?h$n()v Notes: The Compaq C++ compiler on OpenVMS VAX and Alpha (but not IA-64) and Tru64 has two name mangling schemes. The original, pre-standard scheme is known as ARM model, and is based on the name mangling described in the C++ Annotated Reference Manual (ARM). With the advent of new features in standard C++, particularly templates , the ARM scheme became more and more unsuitable \u2014 it could not encode certain function types, or produced identical mangled names for different functions. It was therefore replaced by the newer \"ANSI\" model, which supported all ANSI template features, but was not backwards compatible. On IA-64, a standard Application Binary Interface (ABI) exists (see external links ), which defines (among other things) a standard name-mangling scheme, and which is used by all the IA-64 compilers. GNU GCC 3. x , in addition, has adopted the name mangling scheme defined in this standard for use on other, non-Intel platforms. The Visual Studio and Windows SDK include the program undname which prints the C-style function prototype for a given mangled name. On Microsoft Windows, the Intel compiler[ 2] and Clang [ 3] uses the Visual C++ name mangling for compatibility. For the IAR EWARM C++ 7.4 ARM compiler the best way to determine the name of a function is to compile with the assembler output turned on and to look at the output in the \".s\" file thus generated. Handling of C symbols when linking from C++ The job of the common C++ idiom: #ifdef __cplusplus extern \"C\" { #endif /* ... */ #ifdef __cplusplus } #endif is to ensure that the symbols within are \"unmangled\" \u2013 that the compiler emits(\u521b\u9020\uff0c\u751f\u4ea7\u51fa) a binary file with their names undecorated, as a C compiler would do. As C language definitions are unmangled, the C++ compiler needs to avoid mangling references to these identifiers. For example, the standard strings library, <string.h> usually contains something resembling: #ifdef __cplusplus extern \"C\" { #endif void * memset ( void * , int , size_t ); char * strcat ( char * , const char * ); int strcmp ( const char * , const char * ); char * strcpy ( char * , const char * ); #ifdef __cplusplus } #endif Thus, code such as: if ( strcmp ( argv [ 1 ], \"-x\" ) == 0 ) strcpy ( a , argv [ 2 ]); else memset ( a , 0 , sizeof ( a )); uses the correct, unmangled strcmp and memset . If the extern had not been used, the (SunPro) C++ compiler would produce code equivalent to: if ( __1cGstrcmp6Fpkc1_i_ ( argv [ 1 ], \"-x\" ) == 0 ) __1cGstrcpy6Fpcpkc_0_ ( a , argv [ 2 ]); else __1cGmemset6FpviI_0_ ( a , 0 , sizeof ( a )); Since those symbols do not exist in the C runtime library ( e.g. libc ), link errors would result. Standardised name mangling in C++ Though it would seem that standardised name mangling in the C++ language would lead to greater interoperability between compiler implementations, such a standardization by itself would not suffice to guarantee C++ compiler interoperability and it might even create a false impression that interoperability is possible and safe when it isn't. Name mangling is only one of several application binary interface (ABI) details that need to be decided and observed by a C++ implementation. Other ABI aspects like exception handling , virtual table layout, structure and stack frame padding , etc. also cause differing C++ implementations to be incompatible. Further, requiring a particular form of mangling would cause issues for systems where implementation limits (e.g., length of symbols) dictate a particular mangling scheme. A standardised requirement for name mangling would also prevent an implementation where mangling was not required at all \u2014 for example, a linker which understood the C++ language. The C++ standard therefore does not attempt to standardise name mangling. On the contrary, the Annotated C++ Reference Manual (also known as ARM , ISBN 0-201-51459-1 , section 7.2.1c) actively encourages the use of different mangling schemes to prevent linking when other aspects of the ABI, such as exception handling and virtual table layout, are incompatible. Nevertheless, as detailed in the section above, on some platforms[ 4] the full C++ ABI has been standardized, including name mangling. Real-world effects of C++ name mangling Because C++ symbols are routinely exported from DLL and shared object files, the name mangling scheme is not merely a compiler-internal matter. Different compilers (or different versions of the same compiler, in many cases) produce such binaries under different name decoration schemes, meaning that symbols are frequently unresolved if the compilers used to create the library and the program using it employed different schemes. For example, if a system with multiple C++ compilers installed (e.g., GNU GCC and the OS vendor's compiler) wished to install the Boost C++ Libraries , it would have to be compiled multiple times (once for GCC and once for the vendor compiler). It is good for safety purposes that compilers producing incompatible object codes (codes based on different ABIs, regarding e.g., classes and exceptions) use different name mangling schemes. This guarantees that these incompatibilities are detected at the linking phase, not when executing the software (which could lead to obscure(\u6a21\u7cca\u7684\uff0c\u9690\u6666\u7684) bugs and serious stability issues). For this reason name decoration is an important aspect of any C++-related ABI . Demangle via c++filt $ c++filt _ZNK3MapI10StringName3RefI8GDScriptE10ComparatorIS0_E16DefaultAllocatorE3hasERKS0_ Map<StringName, Ref<GDScript>, Comparator<StringName>, DefaultAllocator>::has ( StringName const & ) const Demangle via builtin GCC ABI #include <stdio.h> #include <stdlib.h> #include <cxxabi.h> int main () { const char * mangled_name = \"_ZNK3MapI10StringName3RefI8GDScriptE10ComparatorIS0_E16DefaultAllocatorE3hasERKS0_\" ; char * demangled_name ; int status = - 1 ; demangled_name = abi :: __cxa_demangle ( mangled_name , NULL , NULL , & status ); printf ( \"Demangled: %s \\n \" , demangled_name ); free ( demangled_name ); return 0 ; } Output: Demangled: Map<StringName, Ref<GDScript>, Comparator<StringName>, DefaultAllocator>::has(StringName const&) const Python In Python , mangling is used for \"private\" class members which are designated as such by giving them a name with two leading underscores and no more than one trailing underscore. For example, __thing will be mangled, as will ___thing and __thing_ , but __thing__ and __thing___ will not. Python's runtime does not restrict access to such members, the mangling only prevents name collisions if a derived class defines a member with the same name. On encountering name mangled attributes, Python transforms these names by prepending a single underscore and the name of the enclosing class, for example: >>> class Test ( object ): ... def __mangled_name ( self ): ... pass ... def normal_name ( self ): ... pass >>> t = Test () >>> [ attr for attr in dir ( t ) if 'name' in attr ] [ '_Test__mangled_name' , 'normal_name' ]","title":"Name-mangling"},{"location":"ABI/Name-mangling/Name-mangling/#name-mangling","text":"In compiler construction, name mangling (also called name decoration ) is a technique used to solve various problems caused by the need to resolve unique names for programming entities in many modern programming languages . It provides a way of encoding additional information in the name of a function , structure , class or another datatype in order to pass more semantic information from the compilers to linkers . SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u63cf\u8ff0\u4e86\u4f7f\u7528name mangling\u7684\u610f\u56fe The need arises where the language allows different entities to be named with the same identifier as long as they occupy a different namespace (where a namespace is typically defined by a module, class, or explicit namespace directive) or have different signatures (such as function overloading ). Any object code produced by compilers is usually linked with other pieces of object code (produced by the same or another compiler) by a type of program called a linker . The linker needs a great deal of information on each program entity. For example, to correctly link a function it needs its name, the number of arguments and their types, and so on.","title":"Name mangling"},{"location":"ABI/Name-mangling/Name-mangling/#examples","text":"","title":"Examples"},{"location":"ABI/Name-mangling/Name-mangling/#c","text":"Although name mangling is not generally required or used by languages that do not support function overloading (such as C and classic Pascal), they use it in some cases to provide additional information about a function. For example, compilers targeted at Microsoft Windows platforms support a variety of calling conventions , which determine the manner in which parameters are sent to subroutines and results returned. Because the different calling conventions are not compatible with one another, compilers mangle symbols with codes detailing which convention should be used to call the specific routine. SUMMARY : encode calling convention in the name The mangling scheme was established by Microsoft, and has been informally followed by other compilers including Digital Mars, Borland, and GNU GCC, when compiling code for the Windows platforms. The scheme even applies to other languages, such as Pascal , D , Delphi , Fortran , and C# . This allows subroutines written in those languages to call, or be called by, existing Windows libraries using a calling convention different from their default. When compiling the following C examples: int _cdecl f ( int x ) { return 0 ; } int _stdcall g ( int y ) { return 0 ; } int _fastcall h ( int z ) { return 0 ; } 32 bit compilers emit, respectively: _f _g @ 4 @ h @ 4 In the stdcall and fastcall mangling schemes, the function is encoded as _**name**@**X** and @**name**@**X** respectively, where X is the number of bytes, in decimal, of the argument(s) in the parameter list (including those passed in registers, for fastcall). In the case of cdecl , the function name is merely prefixed by an underscore. The 64-bit convention on Windows (Microsoft C) has no leading underscore. This difference may in some rare cases lead to unresolved externals when porting such code to 64 bits. For example, Fortran code can use 'alias' to link against a C method by name as follows: SUBROUTINE f () !DEC$ ATTRIBUTES C, ALIAS:'_f' :: f END SUBROUTINE This will compile and link fine under 32 bits, but generate an unresolved external '_f' under 64 bits. One workaround for this is not to use 'alias' at all (in which the method names typically need to be capitalized in C and Fortran). Another is to use the BIND option: SUBROUTINE f () BIND ( C , NAME = \"f\" ) END SUBROUTINE","title":"C"},{"location":"ABI/Name-mangling/Name-mangling/#c_1","text":"C++ compilers are the most widespread users of name mangling . The first C++ compilers were implemented as translators to C source code, which would then be compiled by a C compiler to object code; because of this, symbol names had to conform to C identifier rules. Even later, with the emergence of compilers which produced machine code or assembly directly, the system's linker generally did not support C++ symbols, and mangling was still required. The C++ language does not define a standard decoration scheme, so each compiler uses its own. C++ also has complex language features, such as classes , templates , namespaces , and operator overloading , that alter the meaning of specific symbols based on context or usage. Meta-data about these features can be disambiguated(\u6d88\u9664) by mangling (decorating) the name of a symbol . Because the name-mangling systems for such features are not standardized across compilers, few linkers can link object code that was produced by different compilers.","title":"C++"},{"location":"ABI/Name-mangling/Name-mangling/#simple-exampleedit","text":"A single C++ translation unit might define two functions named f() : int f ( void ) { return 1 ; } int f ( int ) { return 0 ; } void g ( void ) { int i = f (), j = f ( 0 ); } These are distinct functions, with no relation to each other apart from the name. The C++ compiler therefore will encode the type information in the symbol name, the result being something resembling: int __f_v ( void ) { return 1 ; } int __f_i ( int ) { return 0 ; } void __g_v ( void ) { int i = __f_v (), j = __f_i ( 0 ); } Even though its name is unique, g() is still mangled: name mangling applies to all symbols.","title":"Simple example[edit]"},{"location":"ABI/Name-mangling/Name-mangling/#complex-exampleedit","text":"The mangled symbols in this example, in the comments below the respective identifier name, are those produced by the GNU GCC 3.x compilers: namespace wikipedia { class article { public : std :: string format ( void ); /* = _ZN9wikipedia7article6formatEv */ bool print_to ( std :: ostream & ); /* = _ZN9wikipedia7article8print_toERSo */ class wikilink { public : wikilink ( std :: string const & name ); /* = _ZN9wikipedia7article8wikilinkC1ERKSs */ }; }; } All mangled symbols begin with _Z (note that an identifier beginning with an underscore followed by a capital is a reserved identifier in C, so conflict with user identifiers is avoided); for nested names (including both namespaces and classes), this is followed by N , then a series of pairs (the length being the length of the next identifier), and finally E . For example, wikipedia::article::format becomes _ZN9Wikipedia7article6formatE For functions, this is then followed by the type information; as format() is a void function, this is simply v ; hence: _ZN9Wikipedia7article6formatEv For print_to , the standard type std::ostream (which is a typedef for std::basic_ostream<char, std::char_traits<char> > ) is used, which has the special alias So ; a reference to this type is therefore RSo , with the complete name for the function being: _ZN9Wikipedia7article8print_toERSo","title":"Complex example[edit]"},{"location":"ABI/Name-mangling/Name-mangling/#how-different-compilers-mangle-the-same-functionsedit","text":"There isn't a standard scheme by which even trivial C++ identifiers are mangled, and consequently different compilers (or even different versions of the same compiler, or the same compiler on different platforms) mangle public symbols in radically different (and thus totally incompatible) ways. Consider how different C++ compilers mangle the same functions: Compiler void h(int) void h(int, char) void h(void) Intel C++ 8.0 for Linux _Z1hi _Z1hic _Z1hv HP aC++ A.05.55 IA-64 IAR EWARM C++ 5.4 ARM GCC 3. x and higher Clang 1. x and higher[ 1] IAR EWARM C++ 7.4 ARM _Z<number>hi _Z<number>hic _Z<number>hv GCC 2.9*x* h__Fi h__Fic h__Fv HP aC++ A.03.45 PA-RISC Microsoft Visual C++ v6-v10 ( mangling details ) ?h@@YAXH@Z ?h@@YAXHD@Z ?h@@YAXXZ Digital Mars C++ Borland C++ v3.1 @h$qi @h$qizc @h$qv OpenVMS C++ V6.5 (ARM mode) H__XI H__XIC H__XV OpenVMS C++ V6.5 (ANSI mode) CXX$__7H__FIC26CDH77 CXX$__7H__FV2CB06E8 OpenVMS C++ X7.1 IA-64 CXX$_Z1HI2DSQ26A CXX$_Z1HIC2NP3LI4 CXX$_Z1HV0BCA19V SunPro CC __1cBh6Fi_v_ __1cBh6Fic_v_ __1cBh6F_v_ Tru64 C++ V6.5 (ARM mode) h__Xi h__Xic h__Xv Tru64 C++ V6.5 (ANSI mode) __7h__Fi __7h__Fic __7h__Fv Watcom C++ 10.6 W?h$n(i)v W?h$n(ia)v W?h$n()v Notes: The Compaq C++ compiler on OpenVMS VAX and Alpha (but not IA-64) and Tru64 has two name mangling schemes. The original, pre-standard scheme is known as ARM model, and is based on the name mangling described in the C++ Annotated Reference Manual (ARM). With the advent of new features in standard C++, particularly templates , the ARM scheme became more and more unsuitable \u2014 it could not encode certain function types, or produced identical mangled names for different functions. It was therefore replaced by the newer \"ANSI\" model, which supported all ANSI template features, but was not backwards compatible. On IA-64, a standard Application Binary Interface (ABI) exists (see external links ), which defines (among other things) a standard name-mangling scheme, and which is used by all the IA-64 compilers. GNU GCC 3. x , in addition, has adopted the name mangling scheme defined in this standard for use on other, non-Intel platforms. The Visual Studio and Windows SDK include the program undname which prints the C-style function prototype for a given mangled name. On Microsoft Windows, the Intel compiler[ 2] and Clang [ 3] uses the Visual C++ name mangling for compatibility. For the IAR EWARM C++ 7.4 ARM compiler the best way to determine the name of a function is to compile with the assembler output turned on and to look at the output in the \".s\" file thus generated.","title":"How different compilers mangle the same functions[edit]"},{"location":"ABI/Name-mangling/Name-mangling/#handling-of-c-symbols-when-linking-from-c","text":"The job of the common C++ idiom: #ifdef __cplusplus extern \"C\" { #endif /* ... */ #ifdef __cplusplus } #endif is to ensure that the symbols within are \"unmangled\" \u2013 that the compiler emits(\u521b\u9020\uff0c\u751f\u4ea7\u51fa) a binary file with their names undecorated, as a C compiler would do. As C language definitions are unmangled, the C++ compiler needs to avoid mangling references to these identifiers. For example, the standard strings library, <string.h> usually contains something resembling: #ifdef __cplusplus extern \"C\" { #endif void * memset ( void * , int , size_t ); char * strcat ( char * , const char * ); int strcmp ( const char * , const char * ); char * strcpy ( char * , const char * ); #ifdef __cplusplus } #endif Thus, code such as: if ( strcmp ( argv [ 1 ], \"-x\" ) == 0 ) strcpy ( a , argv [ 2 ]); else memset ( a , 0 , sizeof ( a )); uses the correct, unmangled strcmp and memset . If the extern had not been used, the (SunPro) C++ compiler would produce code equivalent to: if ( __1cGstrcmp6Fpkc1_i_ ( argv [ 1 ], \"-x\" ) == 0 ) __1cGstrcpy6Fpcpkc_0_ ( a , argv [ 2 ]); else __1cGmemset6FpviI_0_ ( a , 0 , sizeof ( a )); Since those symbols do not exist in the C runtime library ( e.g. libc ), link errors would result.","title":"Handling of C symbols when linking from C++"},{"location":"ABI/Name-mangling/Name-mangling/#standardised-name-mangling-in-c","text":"Though it would seem that standardised name mangling in the C++ language would lead to greater interoperability between compiler implementations, such a standardization by itself would not suffice to guarantee C++ compiler interoperability and it might even create a false impression that interoperability is possible and safe when it isn't. Name mangling is only one of several application binary interface (ABI) details that need to be decided and observed by a C++ implementation. Other ABI aspects like exception handling , virtual table layout, structure and stack frame padding , etc. also cause differing C++ implementations to be incompatible. Further, requiring a particular form of mangling would cause issues for systems where implementation limits (e.g., length of symbols) dictate a particular mangling scheme. A standardised requirement for name mangling would also prevent an implementation where mangling was not required at all \u2014 for example, a linker which understood the C++ language. The C++ standard therefore does not attempt to standardise name mangling. On the contrary, the Annotated C++ Reference Manual (also known as ARM , ISBN 0-201-51459-1 , section 7.2.1c) actively encourages the use of different mangling schemes to prevent linking when other aspects of the ABI, such as exception handling and virtual table layout, are incompatible. Nevertheless, as detailed in the section above, on some platforms[ 4] the full C++ ABI has been standardized, including name mangling.","title":"Standardised name mangling in C++"},{"location":"ABI/Name-mangling/Name-mangling/#real-world-effects-of-c-name-mangling","text":"Because C++ symbols are routinely exported from DLL and shared object files, the name mangling scheme is not merely a compiler-internal matter. Different compilers (or different versions of the same compiler, in many cases) produce such binaries under different name decoration schemes, meaning that symbols are frequently unresolved if the compilers used to create the library and the program using it employed different schemes. For example, if a system with multiple C++ compilers installed (e.g., GNU GCC and the OS vendor's compiler) wished to install the Boost C++ Libraries , it would have to be compiled multiple times (once for GCC and once for the vendor compiler). It is good for safety purposes that compilers producing incompatible object codes (codes based on different ABIs, regarding e.g., classes and exceptions) use different name mangling schemes. This guarantees that these incompatibilities are detected at the linking phase, not when executing the software (which could lead to obscure(\u6a21\u7cca\u7684\uff0c\u9690\u6666\u7684) bugs and serious stability issues). For this reason name decoration is an important aspect of any C++-related ABI .","title":"Real-world effects of C++ name mangling"},{"location":"ABI/Name-mangling/Name-mangling/#demangle-via-cfilt","text":"$ c++filt _ZNK3MapI10StringName3RefI8GDScriptE10ComparatorIS0_E16DefaultAllocatorE3hasERKS0_ Map<StringName, Ref<GDScript>, Comparator<StringName>, DefaultAllocator>::has ( StringName const & ) const","title":"Demangle via c++filt"},{"location":"ABI/Name-mangling/Name-mangling/#demangle-via-builtin-gcc-abi","text":"#include <stdio.h> #include <stdlib.h> #include <cxxabi.h> int main () { const char * mangled_name = \"_ZNK3MapI10StringName3RefI8GDScriptE10ComparatorIS0_E16DefaultAllocatorE3hasERKS0_\" ; char * demangled_name ; int status = - 1 ; demangled_name = abi :: __cxa_demangle ( mangled_name , NULL , NULL , & status ); printf ( \"Demangled: %s \\n \" , demangled_name ); free ( demangled_name ); return 0 ; } Output: Demangled: Map<StringName, Ref<GDScript>, Comparator<StringName>, DefaultAllocator>::has(StringName const&) const","title":"Demangle via builtin GCC ABI"},{"location":"ABI/Name-mangling/Name-mangling/#python","text":"In Python , mangling is used for \"private\" class members which are designated as such by giving them a name with two leading underscores and no more than one trailing underscore. For example, __thing will be mangled, as will ___thing and __thing_ , but __thing__ and __thing___ will not. Python's runtime does not restrict access to such members, the mangling only prevents name collisions if a derived class defines a member with the same name. On encountering name mangled attributes, Python transforms these names by prepending a single underscore and the name of the enclosing class, for example: >>> class Test ( object ): ... def __mangled_name ( self ): ... pass ... def normal_name ( self ): ... pass >>> t = Test () >>> [ attr for attr in dir ( t ) if 'name' in attr ] [ '_Test__mangled_name' , 'normal_name' ]","title":"Python"},{"location":"C/Book/","text":"","title":"Book"},{"location":"C/C/","text":"C cppreference C reference \u7ef4\u57fa\u767e\u79d1 C (programming_language)","title":"C"},{"location":"C/C/#c","text":"","title":"C"},{"location":"C/C/#cppreference-c-reference","text":"","title":"cppreference C reference"},{"location":"C/C/#c-programming_language","text":"","title":"\u7ef4\u57fa\u767e\u79d1 C (programming_language)"},{"location":"C/What-is-new-in-C/","text":"What is new in C cppreference History of C","title":"What-is-new-in-C"},{"location":"C/What-is-new-in-C/#what-is-new-in-c","text":"","title":"What is new in C"},{"location":"C/What-is-new-in-C/#cppreference-history-of-c","text":"","title":"cppreference History of C"},{"location":"C/Guide/","text":"\u5173\u4e8e\u672c\u7ae0","title":"Introduction"},{"location":"C/Guide/#_1","text":"","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"C/Idiom/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u6587\u603b\u7ed3C\u7684idiom\uff0c\u4e3b\u8981\u53c2\u8003\uff1a https://wiki.c2.com/?CeeIdioms https://stackoverflow.com/questions/1975878/c-idioms-and-little-known-facts","title":"Introduction"},{"location":"C/Idiom/#_1","text":"\u672c\u6587\u603b\u7ed3C\u7684idiom\uff0c\u4e3b\u8981\u53c2\u8003\uff1a https://wiki.c2.com/?CeeIdioms https://stackoverflow.com/questions/1975878/c-idioms-and-little-known-facts","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"C/Language-reference/Array/","text":"","title":"Introduction"},{"location":"C/Language-reference/Basic-concept/Data-model/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u63cf\u8ff0c\u7684data model\uff0c\u4e3b\u8981\u53c2\u8003\u7684\u5185\u5bb9\u6709\uff1a cppreference Objects and alignment","title":"Introduction"},{"location":"C/Language-reference/Basic-concept/Data-model/#_1","text":"\u672c\u7ae0\u63cf\u8ff0c\u7684data model\uff0c\u4e3b\u8981\u53c2\u8003\u7684\u5185\u5bb9\u6709\uff1a cppreference Objects and alignment","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"C/Language-reference/Basic-concept/Data-model/Objects-and-alignment/","text":"Objects and alignment Object representation Effective type Strict aliasing Alignment Objects and alignment C programs create , destroy , access , and manipulate objects. SUMMARY : \u5728 Basic concepts \u4e2d\u6709\u8fd9\u6837\u7684\u4e00\u6bb5\u8bdd\uff1a Declarations and expressions create, destroy, access, and manipulate objects . SUMMARY : \u5230\u5e95\u54ea\u4e9b\u662fobject\u5462\uff1f\u6bd4\u5982**variable**\u662fobject\uff08\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u6765\u770b\uff0cidentifier\u66f4\u52a0\u504f\u5411\u4e8e\u662f\u4e00\u4e2acompile time\u6982\u5ff5\uff0c\u800cvariable\u5219\u662f\u4e00\u4e2arun time\u6982\u5ff5\uff09\uff0carray\u662fobject\uff0c malloc \u51fa\u6765\u7684\u662fobject\uff0c\u6b63\u5982\u4e0b\u9762\u8fd9\u6bb5\u8bdd\u4e2d\u6240\u63cf\u8ff0\u7684\uff1a An object, in C, is region of data storage in the execution environment, the contents of which can represent values (a value is the meaning of the contents of an object, when interpreted as having a specific type ). SUMMARY : \u5728 Memory model \u4e2d\u5bf9data storage\u7684\u89e3\u91ca\u4e3a\uff1aThe data storage (memory) available to a C program is one or more contiguous sequences of bytes . \u5176\u5b9e\u6240\u8c13\u7684 data storage \u5c31\u662fmemory\uff1b SUMMARY : object\u662fruntime\u6982\u5ff5\uff0c\u800cidentifier\u662fcompiler\u6982\u5ff5\uff1b objects \u662fruntime \u6982\u5ff5\uff0c\u56e0\u6b64\u4e0eobject\u76f8\u5173\u7684\u6982\u5ff5\u90fd\u662fruntime\u6982\u5ff5\uff1b\u5b83\u662fc \u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u5bf9c\u7a0b\u5e8f\u8fd0\u884c\u65f6\u7684\u63cf\u8ff0\uff1b Every object has size (can be determined with sizeof ) alignment requirement (can be determined by alignof ) (since C11) SUMMARY : \u5728c\u4e2dalignment requirement\u662f\u7531type\u51b3\u5b9a\u7684\uff1b storage duration (automatic, static, allocated, thread-local) SUMMARY : storage duration \u662f\u4e00\u4e2aruntime \u6982\u5ff5\uff0c\u663e\u7136\uff0c storage duration \u548c lifetime\u5bc6\u5207\u76f8\u5173\uff1b lifetime (equal to storage duration or temporary) SUMMARY : lifetime\u5373\u751f\u547d\u5468\u671f\uff0c\u663e\u7136\u8fd9\u662f\u4e00\u4e2a\u52a8\u6001\u7684\u6982\u5ff5\uff0c\u662fc\u8bbe\u8ba1\u8005\u521b\u8d70\u51fa\u6765\u7528\u4ee5\u63cf\u8ff0object\u7684 effective type (see below) value (which may be indeterminate) optionally, an identifier that denotes this object Objects are created by declarations , allocation functions , string literals , compound literals , and by non-lvalue expressions that return structures or unions with array members . SUMMARY : \u5728c\u4e2d\uff0cfunction\u4e0d\u662fobject\uff0c\u663e\u7136function\u6ca1\u6709storage duration\uff0c\u5e76\u4e14function\u6ca1\u6709size\uff0c\u6ca1\u6709alignment\uff1b\u5728 Type \u7684Type groups\u7ae0\u8282\u4e2d\u63d0\u53ca\uff1aobject types: all types that aren't function types\uff1b\u663e\u7136\u6211\u4eec\u662f\u65e0\u6cd5 malloc \u4e00\u4e2afunction\u7684\uff0c\u800c\u5176\u4ed6\u7684\u90fd\u662f\u53ef\u4ee5 malloc \u51fa\u6765\u7684\uff1bfunction\u662f\u7531compiler\u7f16\u8bd1\u751f\u6210\u7684\uff0c\u5e76\u4e14\u6211\u4eec\u5728\u8fdb\u884cprogram\u7684\u65f6\u5019\uff0c\u6240\u7f16\u5199\u7684\u5927\u591a\u6570\u90fd\u662ffunction\uff0c\u5982 main() \u7b49\uff0c\u5982\u679c\u5141\u8bb8\u7528\u6237\u6765\u4fee\u6539function\uff0c\u6216\u8005\u5220\u9664function\uff0c\u5219\u663e\u7136\u4e00\u5207\u90fd\u4f1a\u4e71\u4e86\u5957\uff1b 20190708 : objects \u662fruntime \u6982\u5ff5\uff0c\u800cfunction\uff0c\u5219\u5e76\u4e0d\u662fruntime\u7684\uff1b SUMMARY : \u67e5\u770b lifetime \u7ae0\u8282\u53ef\u77e5\uff0cObjects are created by declarations \u548cObjects are created by allocation functions \u4e24\u8005\u7684lifetime\u89c4\u5219\u662f\u4e0d\u540c\u7684\uff1b\u67e5\u770b\u4e0b\u9762\u7684 Effective type \u7ae0\u8282\u53ef\u77e5\uff0c\u8fd9\u4e24\u79cd\u5bf9\u8c61\u7684effective type\u7684\u89c4\u5219\u4e5f\u662f\u4e0d\u540c\u7684\uff1b Object representation Except for bit fields , objects are composed of contiguous sequences of one or more bytes, each consisting of CHAR_BIT bits, and can be copied with memcpy into an object of type unsigned char[n] , where n is the size of the object. The contents of the resulting array are known as object representation . SUMMARY : \u5728 Memory model \u4e2d\u4e5f\u63d0\u53ca\u4e86\u4e0a\u9762\u8fd9\u4e00\u6bb5\u4e2d\u7684\u89c2\u70b9\uff1bc\u4e2d\u4f7f\u7528 unsigned char[n] \u6765\u8868\u793aobject\uff0c\u5728\u5176\u4ed6\u66f4\u52a0\u9ad8\u7ea7\u7684\u8bed\u8a00\u4e2d\u4e5f\u90fd\u63d0\u4f9b\u4e86\u7c7b\u4f3c\u7684\u529f\u80fd\uff0c\u5982\uff1apython\u7684Binary Sequence Types \u2014 bytes , bytearray , memoryview \u00b6 SUMMARY : \u8fd9\u7bc7\u6587\u7ae0\u4e5f\u63cf\u8ff0\u4e86\u7c7b\u4f3c\u7684\u95ee\u9898 Data alignment: Straighten up and fly right SUMMARY : \u4e0a\u9762\u8fd9\u4e00\u6bb5\u4e2d\u7684 n \u662f\u5426\u7b49\u4e8e sizeof \u5462\uff1f If two objects have the same object representation , they compare equal (except if they are floating-point NaN s). The opposite is not true: two objects that compare equal may have different object representations because not every bit of the object representation needs to participate in the value . Such bits may be used for padding to satisfy alignment requirement, for parity checks, to indicate trap representations, etc. SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u63d0\u53ca\u4e86object representation\u548cvalue\u4e4b\u95f4\u7684\u5173\u7cfb\uff1b SUMMARY : \u5173\u4e8epadding to satisfy alignment requirement\uff0c\u53c2\u89c1 Data structure alignment SUMMARY : \u5173\u4e8eparity checks, \u53c2\u89c1 Parity bit SUMMARY : \u5173\u4e8etrap representation\uff0c\u53c2\u89c1 trap representation If an object representation does not represent any value of the object type , it is known as trap representation . Accessing a trap representation in any way other than reading it through an lvalue expression of character type is undefined behavior . The value of a structure or union is never a trap representation even if any particular member is one. SUMMARY : \u5173\u4e8e**the object type**\uff0c\u5728 Type \u7684Type groups\u7ae0\u8282\u4e2d\u6709\u7ed9\u51fa\u5176\u5b9a\u4e49\uff1b For the objects of type char , signed char , and unsigned char , every bit of the object representation is required to participate in the value representation and each possible bit pattern represents a distinct value (no padding, trap bits, or multiple representations allowed). When objects of integer types ( short , int , long , long long ) occupy multiple bytes, the use of those bytes is implementation-defined, but the two dominant implementations are big-endian (POWER, Sparc, Itanium) and little-endian (x86, x86_64): a big-endian platform stores the most significant byte at the lowest address of the region of storage occupied by the integer, a little-endian platform stores the least significant byte at the lowest address. See Endianness for detail. See also example below. Although most implementations do not allow trap representations, padding bits, or multiple representations for integer types, there are exceptions; for example a value of an integer type on Itanium may be a trap representation . Effective type Every object has an effective type , which determines which lvalue accesses are valid and which violate the strict aliasing rules . If the object was created by a declaration , the declared type of that object is the object's effective type . If the object was created by an allocation function (including realloc ), it has no declared type . Such object acquires an effective type as follows: The first write to that object through an lvalue that has a type other than character type, at which time the type of that lvalue becomes this object's effective type for that write and all subsequent reads. memcpy or memmove copy another object into that object, at which time the effective type of the source object (if it had one) becomes the effective type of this object for that write and all subsequent reads. Any other access to the object with no declared type, the effective type is the type of the lvalue used for the access. SUMMARY : \u770b\u5230\u4e86effective type\uff0c\u6211\u60f3\u5230\u4e86\u5728Unix\u4e2d\u7684effective user ID\uff1b SUMMARY : c++ \u4e2d\u5e76\u6ca1\u6709effective type\u7684\u6982\u5ff5\uff1b\u5176\u5b9e\u4e3b\u8981\u539f\u56e0\u5728\u4e8ec++\u4e2d\u4f7f\u7528\u4e86 new \uff0c\u800cc\u4e2d\u5219\u662f malloc \uff0c\u663e\u7136\u8fd9\u662f c++ \u5728type safety\u4e0a\u7684\u4e00\u4e9b\u6539\u5584\uff0c\u8fd9\u4e00\u70b9\u5728 Type safety \u4e2d\u6709\u89e3\u91ca\uff1b Strict aliasing Given an object with effective type T1 , using an lvalue expression (typically, dereferencing a pointer) of a different type T2 is undefined behavior , unless: T2 and T1 are compatible types . T2 is cvr-qualified version of a type that is compatible with T1 . SUMMARY : \u8981\u60f3\u7406\u89e3 cvr-qualified \uff0c\u5c31\u9700\u8981\u9996\u5148\u77e5\u9053 Type qualifier \uff1b T2 is a signed or unsigned version of a type that is compatible with T1 . T2 is an aggregate type or union type type that includes one of the aforementioned types among its members (including, recursively, a member of a subaggregate or contained union). T2 is a character type (char, signed char, or unsigned char). int i = 7 ; char * pc = ( char * )( & i ); if ( pc [ 0 ] == '\\x7' ) // aliasing through char is ok puts ( \"This system is little-endian\" ); else puts ( \"This system is big-endian\" ); float * pf = ( float * )( & i ); float d = * pf ; // UB: float lvalue *p cannot be used to access int These rules control whether a function that receives two pointers must re-read one after writing through another: // int* and double* cannot alias void f1 ( int * pi , double * pd , double d ) { // the read from *pi can be done only once, before the loop for ( int i = 0 ; i < * pi ; i ++ ) * pd ++ = d ; } SUMMARY : \u5982\u679c pi \u548c pd \u76f8\u4e92alias\uff0c\u5219\u5b83\u4eec\u6307\u5411\u540c\u4e00memory\uff0c\u5728\u4ee3\u7801\u4e2d\uff0c *pd++ = d write\u4e86\u8fd9\u4e2amemory\uff0c for (int i = 0; i < *pi; i++) \u6bcf\u6b21\u90fdre-read\uff1b struct S { int a , b ; }; // int* and struct S* may alias because S is an aggregate type with a member of type int void f2 ( int * pi , struct S * ps , struct S s ) { // read from *pi must take place after every write through *ps for ( int i = 0 ; i < * pi ; i ++ ) * ps ++ = s ; } SUMMARY : \u4e0a\u9762\u7684\u8fd9\u4e9b\u4ee3\u7801\u662ffunction that receives two pointers \u51fd\u6570\u7684\u5178\u8303\uff1b Note that restrict qualifier can be used to indicate that two pointers do not alias even if the rules above permit them to be. Note that type-punning may also be performed through the inactive member of a union . Alignment Every complete object type has a property called alignment requirement , which is an integer value of type size_t representing the number of bytes between successive addresses at which objects of this type can be allocated. The valid alignment values are non-negative integral powers of two . The alignment requirement of a type can be queried with alignof . (since C11) In order to satisfy alignment requirements of all members of a struct, padding may be inserted after some of its members. #include <stdio.h> #include <stdalign.h> // objects of struct S can be allocated at any address // because both S.a and S.b can be allocated at any address struct S { char a ; // size: 1, alignment: 1 char b ; // size: 1, alignment: 1 }; // size: 2, alignment: 1 // objects of struct X must be allocated at 4-byte boundaries // because X.n must be allocated at 4-byte boundaries // because int's alignment requirement is (usually) 4 struct X { int n ; // size: 4, alignment: 4 char c ; // size: 1, alignment: 1 // three bytes padding }; // size: 8, alignment: 4 int main ( void ) { printf ( \"sizeof(struct S) = %zu \\n \" , sizeof ( struct S )); printf ( \"alignof(struct S) = %zu \\n \" , alignof ( struct S )); printf ( \"sizeof(struct X) = %zu \\n \" , sizeof ( struct X )); printf ( \"alignof(struct X) = %zu \\n \" , alignof ( struct X )); } Possible output: sizeof ( struct S ) = 2 alignof ( struct S ) = 1 sizeof ( struct X ) = 8 alignof ( struct X ) = 4 Each object type imposes its alignment requirement on every object of that type. The strictest (largest) fundamental alignment of any type is the alignment of max_align_t . The weakest (smallest) alignment is the alignment of the types char , signed char , and unsigned char , and equals 1. If an object's alignment is made stricter (larger) than max_align_t using alignas , it has extended alignment requirement . A struct or union type whose member has extended alignment is an over-aligned type . It is implementation-defined if over-aligned types are supported, and their support may be different in each kind of storage duration .","title":"Objects-and-alignment"},{"location":"C/Language-reference/Basic-concept/Data-model/Objects-and-alignment/#objects-and-alignment","text":"C programs create , destroy , access , and manipulate objects. SUMMARY : \u5728 Basic concepts \u4e2d\u6709\u8fd9\u6837\u7684\u4e00\u6bb5\u8bdd\uff1a Declarations and expressions create, destroy, access, and manipulate objects . SUMMARY : \u5230\u5e95\u54ea\u4e9b\u662fobject\u5462\uff1f\u6bd4\u5982**variable**\u662fobject\uff08\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u6765\u770b\uff0cidentifier\u66f4\u52a0\u504f\u5411\u4e8e\u662f\u4e00\u4e2acompile time\u6982\u5ff5\uff0c\u800cvariable\u5219\u662f\u4e00\u4e2arun time\u6982\u5ff5\uff09\uff0carray\u662fobject\uff0c malloc \u51fa\u6765\u7684\u662fobject\uff0c\u6b63\u5982\u4e0b\u9762\u8fd9\u6bb5\u8bdd\u4e2d\u6240\u63cf\u8ff0\u7684\uff1a An object, in C, is region of data storage in the execution environment, the contents of which can represent values (a value is the meaning of the contents of an object, when interpreted as having a specific type ). SUMMARY : \u5728 Memory model \u4e2d\u5bf9data storage\u7684\u89e3\u91ca\u4e3a\uff1aThe data storage (memory) available to a C program is one or more contiguous sequences of bytes . \u5176\u5b9e\u6240\u8c13\u7684 data storage \u5c31\u662fmemory\uff1b SUMMARY : object\u662fruntime\u6982\u5ff5\uff0c\u800cidentifier\u662fcompiler\u6982\u5ff5\uff1b objects \u662fruntime \u6982\u5ff5\uff0c\u56e0\u6b64\u4e0eobject\u76f8\u5173\u7684\u6982\u5ff5\u90fd\u662fruntime\u6982\u5ff5\uff1b\u5b83\u662fc \u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u5bf9c\u7a0b\u5e8f\u8fd0\u884c\u65f6\u7684\u63cf\u8ff0\uff1b Every object has size (can be determined with sizeof ) alignment requirement (can be determined by alignof ) (since C11) SUMMARY : \u5728c\u4e2dalignment requirement\u662f\u7531type\u51b3\u5b9a\u7684\uff1b storage duration (automatic, static, allocated, thread-local) SUMMARY : storage duration \u662f\u4e00\u4e2aruntime \u6982\u5ff5\uff0c\u663e\u7136\uff0c storage duration \u548c lifetime\u5bc6\u5207\u76f8\u5173\uff1b lifetime (equal to storage duration or temporary) SUMMARY : lifetime\u5373\u751f\u547d\u5468\u671f\uff0c\u663e\u7136\u8fd9\u662f\u4e00\u4e2a\u52a8\u6001\u7684\u6982\u5ff5\uff0c\u662fc\u8bbe\u8ba1\u8005\u521b\u8d70\u51fa\u6765\u7528\u4ee5\u63cf\u8ff0object\u7684 effective type (see below) value (which may be indeterminate) optionally, an identifier that denotes this object Objects are created by declarations , allocation functions , string literals , compound literals , and by non-lvalue expressions that return structures or unions with array members . SUMMARY : \u5728c\u4e2d\uff0cfunction\u4e0d\u662fobject\uff0c\u663e\u7136function\u6ca1\u6709storage duration\uff0c\u5e76\u4e14function\u6ca1\u6709size\uff0c\u6ca1\u6709alignment\uff1b\u5728 Type \u7684Type groups\u7ae0\u8282\u4e2d\u63d0\u53ca\uff1aobject types: all types that aren't function types\uff1b\u663e\u7136\u6211\u4eec\u662f\u65e0\u6cd5 malloc \u4e00\u4e2afunction\u7684\uff0c\u800c\u5176\u4ed6\u7684\u90fd\u662f\u53ef\u4ee5 malloc \u51fa\u6765\u7684\uff1bfunction\u662f\u7531compiler\u7f16\u8bd1\u751f\u6210\u7684\uff0c\u5e76\u4e14\u6211\u4eec\u5728\u8fdb\u884cprogram\u7684\u65f6\u5019\uff0c\u6240\u7f16\u5199\u7684\u5927\u591a\u6570\u90fd\u662ffunction\uff0c\u5982 main() \u7b49\uff0c\u5982\u679c\u5141\u8bb8\u7528\u6237\u6765\u4fee\u6539function\uff0c\u6216\u8005\u5220\u9664function\uff0c\u5219\u663e\u7136\u4e00\u5207\u90fd\u4f1a\u4e71\u4e86\u5957\uff1b 20190708 : objects \u662fruntime \u6982\u5ff5\uff0c\u800cfunction\uff0c\u5219\u5e76\u4e0d\u662fruntime\u7684\uff1b SUMMARY : \u67e5\u770b lifetime \u7ae0\u8282\u53ef\u77e5\uff0cObjects are created by declarations \u548cObjects are created by allocation functions \u4e24\u8005\u7684lifetime\u89c4\u5219\u662f\u4e0d\u540c\u7684\uff1b\u67e5\u770b\u4e0b\u9762\u7684 Effective type \u7ae0\u8282\u53ef\u77e5\uff0c\u8fd9\u4e24\u79cd\u5bf9\u8c61\u7684effective type\u7684\u89c4\u5219\u4e5f\u662f\u4e0d\u540c\u7684\uff1b","title":"Objects and alignment"},{"location":"C/Language-reference/Basic-concept/Data-model/Objects-and-alignment/#object-representation","text":"Except for bit fields , objects are composed of contiguous sequences of one or more bytes, each consisting of CHAR_BIT bits, and can be copied with memcpy into an object of type unsigned char[n] , where n is the size of the object. The contents of the resulting array are known as object representation . SUMMARY : \u5728 Memory model \u4e2d\u4e5f\u63d0\u53ca\u4e86\u4e0a\u9762\u8fd9\u4e00\u6bb5\u4e2d\u7684\u89c2\u70b9\uff1bc\u4e2d\u4f7f\u7528 unsigned char[n] \u6765\u8868\u793aobject\uff0c\u5728\u5176\u4ed6\u66f4\u52a0\u9ad8\u7ea7\u7684\u8bed\u8a00\u4e2d\u4e5f\u90fd\u63d0\u4f9b\u4e86\u7c7b\u4f3c\u7684\u529f\u80fd\uff0c\u5982\uff1apython\u7684Binary Sequence Types \u2014 bytes , bytearray , memoryview \u00b6 SUMMARY : \u8fd9\u7bc7\u6587\u7ae0\u4e5f\u63cf\u8ff0\u4e86\u7c7b\u4f3c\u7684\u95ee\u9898 Data alignment: Straighten up and fly right SUMMARY : \u4e0a\u9762\u8fd9\u4e00\u6bb5\u4e2d\u7684 n \u662f\u5426\u7b49\u4e8e sizeof \u5462\uff1f If two objects have the same object representation , they compare equal (except if they are floating-point NaN s). The opposite is not true: two objects that compare equal may have different object representations because not every bit of the object representation needs to participate in the value . Such bits may be used for padding to satisfy alignment requirement, for parity checks, to indicate trap representations, etc. SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u63d0\u53ca\u4e86object representation\u548cvalue\u4e4b\u95f4\u7684\u5173\u7cfb\uff1b SUMMARY : \u5173\u4e8epadding to satisfy alignment requirement\uff0c\u53c2\u89c1 Data structure alignment SUMMARY : \u5173\u4e8eparity checks, \u53c2\u89c1 Parity bit SUMMARY : \u5173\u4e8etrap representation\uff0c\u53c2\u89c1 trap representation If an object representation does not represent any value of the object type , it is known as trap representation . Accessing a trap representation in any way other than reading it through an lvalue expression of character type is undefined behavior . The value of a structure or union is never a trap representation even if any particular member is one. SUMMARY : \u5173\u4e8e**the object type**\uff0c\u5728 Type \u7684Type groups\u7ae0\u8282\u4e2d\u6709\u7ed9\u51fa\u5176\u5b9a\u4e49\uff1b For the objects of type char , signed char , and unsigned char , every bit of the object representation is required to participate in the value representation and each possible bit pattern represents a distinct value (no padding, trap bits, or multiple representations allowed). When objects of integer types ( short , int , long , long long ) occupy multiple bytes, the use of those bytes is implementation-defined, but the two dominant implementations are big-endian (POWER, Sparc, Itanium) and little-endian (x86, x86_64): a big-endian platform stores the most significant byte at the lowest address of the region of storage occupied by the integer, a little-endian platform stores the least significant byte at the lowest address. See Endianness for detail. See also example below. Although most implementations do not allow trap representations, padding bits, or multiple representations for integer types, there are exceptions; for example a value of an integer type on Itanium may be a trap representation .","title":"Object representation"},{"location":"C/Language-reference/Basic-concept/Data-model/Objects-and-alignment/#effective-type","text":"Every object has an effective type , which determines which lvalue accesses are valid and which violate the strict aliasing rules . If the object was created by a declaration , the declared type of that object is the object's effective type . If the object was created by an allocation function (including realloc ), it has no declared type . Such object acquires an effective type as follows: The first write to that object through an lvalue that has a type other than character type, at which time the type of that lvalue becomes this object's effective type for that write and all subsequent reads. memcpy or memmove copy another object into that object, at which time the effective type of the source object (if it had one) becomes the effective type of this object for that write and all subsequent reads. Any other access to the object with no declared type, the effective type is the type of the lvalue used for the access. SUMMARY : \u770b\u5230\u4e86effective type\uff0c\u6211\u60f3\u5230\u4e86\u5728Unix\u4e2d\u7684effective user ID\uff1b SUMMARY : c++ \u4e2d\u5e76\u6ca1\u6709effective type\u7684\u6982\u5ff5\uff1b\u5176\u5b9e\u4e3b\u8981\u539f\u56e0\u5728\u4e8ec++\u4e2d\u4f7f\u7528\u4e86 new \uff0c\u800cc\u4e2d\u5219\u662f malloc \uff0c\u663e\u7136\u8fd9\u662f c++ \u5728type safety\u4e0a\u7684\u4e00\u4e9b\u6539\u5584\uff0c\u8fd9\u4e00\u70b9\u5728 Type safety \u4e2d\u6709\u89e3\u91ca\uff1b","title":"Effective type"},{"location":"C/Language-reference/Basic-concept/Data-model/Objects-and-alignment/#strict-aliasing","text":"Given an object with effective type T1 , using an lvalue expression (typically, dereferencing a pointer) of a different type T2 is undefined behavior , unless: T2 and T1 are compatible types . T2 is cvr-qualified version of a type that is compatible with T1 . SUMMARY : \u8981\u60f3\u7406\u89e3 cvr-qualified \uff0c\u5c31\u9700\u8981\u9996\u5148\u77e5\u9053 Type qualifier \uff1b T2 is a signed or unsigned version of a type that is compatible with T1 . T2 is an aggregate type or union type type that includes one of the aforementioned types among its members (including, recursively, a member of a subaggregate or contained union). T2 is a character type (char, signed char, or unsigned char). int i = 7 ; char * pc = ( char * )( & i ); if ( pc [ 0 ] == '\\x7' ) // aliasing through char is ok puts ( \"This system is little-endian\" ); else puts ( \"This system is big-endian\" ); float * pf = ( float * )( & i ); float d = * pf ; // UB: float lvalue *p cannot be used to access int These rules control whether a function that receives two pointers must re-read one after writing through another: // int* and double* cannot alias void f1 ( int * pi , double * pd , double d ) { // the read from *pi can be done only once, before the loop for ( int i = 0 ; i < * pi ; i ++ ) * pd ++ = d ; } SUMMARY : \u5982\u679c pi \u548c pd \u76f8\u4e92alias\uff0c\u5219\u5b83\u4eec\u6307\u5411\u540c\u4e00memory\uff0c\u5728\u4ee3\u7801\u4e2d\uff0c *pd++ = d write\u4e86\u8fd9\u4e2amemory\uff0c for (int i = 0; i < *pi; i++) \u6bcf\u6b21\u90fdre-read\uff1b struct S { int a , b ; }; // int* and struct S* may alias because S is an aggregate type with a member of type int void f2 ( int * pi , struct S * ps , struct S s ) { // read from *pi must take place after every write through *ps for ( int i = 0 ; i < * pi ; i ++ ) * ps ++ = s ; } SUMMARY : \u4e0a\u9762\u7684\u8fd9\u4e9b\u4ee3\u7801\u662ffunction that receives two pointers \u51fd\u6570\u7684\u5178\u8303\uff1b Note that restrict qualifier can be used to indicate that two pointers do not alias even if the rules above permit them to be. Note that type-punning may also be performed through the inactive member of a union .","title":"Strict aliasing"},{"location":"C/Language-reference/Basic-concept/Data-model/Objects-and-alignment/#alignment","text":"Every complete object type has a property called alignment requirement , which is an integer value of type size_t representing the number of bytes between successive addresses at which objects of this type can be allocated. The valid alignment values are non-negative integral powers of two . The alignment requirement of a type can be queried with alignof . (since C11) In order to satisfy alignment requirements of all members of a struct, padding may be inserted after some of its members. #include <stdio.h> #include <stdalign.h> // objects of struct S can be allocated at any address // because both S.a and S.b can be allocated at any address struct S { char a ; // size: 1, alignment: 1 char b ; // size: 1, alignment: 1 }; // size: 2, alignment: 1 // objects of struct X must be allocated at 4-byte boundaries // because X.n must be allocated at 4-byte boundaries // because int's alignment requirement is (usually) 4 struct X { int n ; // size: 4, alignment: 4 char c ; // size: 1, alignment: 1 // three bytes padding }; // size: 8, alignment: 4 int main ( void ) { printf ( \"sizeof(struct S) = %zu \\n \" , sizeof ( struct S )); printf ( \"alignof(struct S) = %zu \\n \" , alignof ( struct S )); printf ( \"sizeof(struct X) = %zu \\n \" , sizeof ( struct X )); printf ( \"alignof(struct X) = %zu \\n \" , alignof ( struct X )); } Possible output: sizeof ( struct S ) = 2 alignof ( struct S ) = 1 sizeof ( struct X ) = 8 alignof ( struct X ) = 4 Each object type imposes its alignment requirement on every object of that type. The strictest (largest) fundamental alignment of any type is the alignment of max_align_t . The weakest (smallest) alignment is the alignment of the types char , signed char , and unsigned char , and equals 1. If an object's alignment is made stricter (larger) than max_align_t using alignas , it has extended alignment requirement . A struct or union type whose member has extended alignment is an over-aligned type . It is implementation-defined if over-aligned types are supported, and their support may be different in each kind of storage duration .","title":"Alignment"},{"location":"C/Library/A-list-of-open-source-C-libraries/","text":"A list of open source C libraries cppreference A list of open source C libraries","title":"A-list-of-open-source-C-libraries"},{"location":"C/Library/A-list-of-open-source-C-libraries/#a-list-of-open-source-c-libraries","text":"","title":"A list of open source C libraries"},{"location":"C/Library/A-list-of-open-source-C-libraries/#cppreference-a-list-of-open-source-c-libraries","text":"","title":"cppreference A list of open source C libraries"},{"location":"C/Library/Event-driven-programming/Software-libevent/libevent/","text":"libevent \u2013 an event notification library The libevent API provides a mechanism to execute a callback function when a specific event occurs on a file descriptor or after a timeout has been reached. Furthermore, libevent also support callbacks due to signals or regular timeouts . libevent is meant to replace the event loop found in event driven network servers . An application just needs to call event_dispatch() and then add or remove events dynamically without having to change the event loop . SUMMARY :For event driven network servers , please refer to this article . Currently, libevent supports /dev/poll , kqueue(2) , event ports , POSIX select(2) , Windows select() , poll(2) , and epoll(4) . The internal event mechanism is completely independent of the exposed event API, and a simple update of libevent can provide new functionality without having to redesign the applications. As a result, libevent allows for portable application development and provides the most scalable event notification mechanism available on an operating system. SUMMARY :obviously,the implementation of libevent is very good,which conforms to the idea of interface-oriented programming. Libevent can also be used for multi-threaded applications, either by isolating each event_base so that only a single thread accesses it, or by locked access to a single shared event_base. libevent should compile on Linux, *BSD, Mac OS X, Solaris, Windows, and more. Libevent additionally provides a sophisticated framework for buffered network IO, with support for sockets, filters, rate-limiting, SSL , zero-copy file transmission, and IOCP . Libevent includes support for several useful protocols, including DNS , HTTP, and a minimal RPC framework. More information about event notification mechanisms for network servers can be found on Dan Kegel's \" The C10K problem \" web page.","title":"libevent"},{"location":"C/Library/Event-driven-programming/Software-libevent/libevent/#libevent-an-event-notification-library","text":"The libevent API provides a mechanism to execute a callback function when a specific event occurs on a file descriptor or after a timeout has been reached. Furthermore, libevent also support callbacks due to signals or regular timeouts . libevent is meant to replace the event loop found in event driven network servers . An application just needs to call event_dispatch() and then add or remove events dynamically without having to change the event loop . SUMMARY :For event driven network servers , please refer to this article . Currently, libevent supports /dev/poll , kqueue(2) , event ports , POSIX select(2) , Windows select() , poll(2) , and epoll(4) . The internal event mechanism is completely independent of the exposed event API, and a simple update of libevent can provide new functionality without having to redesign the applications. As a result, libevent allows for portable application development and provides the most scalable event notification mechanism available on an operating system. SUMMARY :obviously,the implementation of libevent is very good,which conforms to the idea of interface-oriented programming. Libevent can also be used for multi-threaded applications, either by isolating each event_base so that only a single thread accesses it, or by locked access to a single shared event_base. libevent should compile on Linux, *BSD, Mac OS X, Solaris, Windows, and more. Libevent additionally provides a sophisticated framework for buffered network IO, with support for sockets, filters, rate-limiting, SSL , zero-copy file transmission, and IOCP . Libevent includes support for several useful protocols, including DNS , HTTP, and a minimal RPC framework. More information about event notification mechanisms for network servers can be found on Dan Kegel's \" The C10K problem \" web page.","title":"libevent \u2013 an event notification library"},{"location":"C/Library/Event-driven-programming/Software-libuv/libuv/","text":"Welcome to the libuv documentation \u00b6 Overview \u00b6 libuv is a multi-platform support library with a focus on asynchronous I/O. It was primarily developed for use by Node.js , but it\u2019s also used by Luvit , Julia , pyuv , and others . Features \u00b6 Full-featured event loop backed by epoll, kqueue, IOCP, event ports. SUMMARY:I have seen the event loop in many places, including libevent , celery Asynchronous TCP and UDP sockets Asynchronous DNS resolution Asynchronous file and file system operations File system events ANSI escape code controlled TTY IPC with socket sharing, using Unix domain sockets or named pipes (Windows) Child processes Thread pool Signal handling High resolution clock Threading and synchronization primitives","title":"libuv"},{"location":"C/Library/Event-driven-programming/Software-libuv/libuv/#welcome-to-the-libuv-documentation","text":"","title":"Welcome to the libuv documentation\u00b6"},{"location":"C/Library/Event-driven-programming/Software-libuv/libuv/#overview","text":"libuv is a multi-platform support library with a focus on asynchronous I/O. It was primarily developed for use by Node.js , but it\u2019s also used by Luvit , Julia , pyuv , and others .","title":"Overview\u00b6"},{"location":"C/Library/Event-driven-programming/Software-libuv/libuv/#features","text":"Full-featured event loop backed by epoll, kqueue, IOCP, event ports. SUMMARY:I have seen the event loop in many places, including libevent , celery Asynchronous TCP and UDP sockets Asynchronous DNS resolution Asynchronous file and file system operations File system events ANSI escape code controlled TTY IPC with socket sharing, using Unix domain sockets or named pipes (Windows) Child processes Thread pool Signal handling High resolution clock Threading and synchronization primitives","title":"Features\u00b6"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/Design-overview/","text":"Design overview \u00b6 libuv is cross-platform support library which was originally written for NodeJS . It\u2019s designed around the event-driven asynchronous I/O model . The library provides much more than a simple abstraction over different I/O polling mechanisms : \u2018handles\u2019 and \u2018streams\u2019 provide a high level abstraction for sockets and other entities; cross-platform file I/O and threading functionality is also provided, amongst other things. Here is a diagram illustrating the different parts that compose libuv and what subsystem they relate to: Handles and requests \u00b6 libuv provides users with 2 abstractions to work with, in combination with the event loop : handles and requests . SUMMARY :refer to this article to know more about event loop Handles represent long-lived objects capable of performing certain operations while active. Some examples: A prepare handle gets its callback called once every loop iteration when active. A TCP server handle that gets its connection callback called every time there is a new connection. Requests represent (typically) short-lived operations. These operations can be performed over a handle: write requests are used to write data on a handle; or standalone: getaddrinfo requests don\u2019t need a handle they run directly on the loop. The I/O loop The I/O (or event) loop is the central part of libuv . It establishes the content for all I/O operations, and it\u2019s meant to be tied to a single thread . One can run multiple event loops as long as each runs in a different thread . The libuv event loop (or any other API involving the loop or handles, for that matter) is not thread-safe except where stated otherwise(\u9664\u975e\u53e6\u6709\u8bf4\u660e\uff0c\u5426\u5219libuv\u4e8b\u4ef6\u5faa\u73af\uff08\u6216\u6d89\u53ca\u5faa\u73af\u6216\u53e5\u67c4\u7684\u4efb\u4f55\u5176\u4ed6API\uff09\u90fd\u4e0d\u662f\u7ebf\u7a0b\u5b89\u5168\u7684). The event loop follows the rather usual single threaded asynchronous I/O approach : all (network) I/O is performed on non-blocking sockets which are polled using the best mechanism available on the given platform: epoll on Linux, kqueue on OSX and other BSDs, event ports on SunOS and IOCP on Windows. As part of a loop iteration the loop will block waiting for I/O activity on sockets which have been added to the poller and callbacks will be fired indicating socket conditions (readable, writable hangup) so handles can read, write or perform the desired I/O operation. In order to better understand how the event loop operates, the following diagram illustrates all stages of a loop iteration: The loop concept of \u2018now\u2019 is updated. The event loop caches the current time at the start of the event loop tick in order to reduce the number of time-related system calls. If the loop is alive an iteration is started, otherwise the loop will exit immediately. So, when is a loop considered to be alive ? If a loop has active and ref\u2019d handles, active requests or closing handles it\u2019s considered to be alive . SUMMARY :ref\u2019d \u53c2\u8003\u7684\uff08referenced\uff09 Due timers are run. All active timers scheduled for a time before the loop\u2019s concept of now get their callbacks called. SUMMARY :due timer \u53ef\u4ee5\u7406\u89e3\u4e3a\u201c\u5230\u671f\u8ba1\u6570\u5668\u201d\uff1b\u7b2c\u4e8c\u53e5\u8bdd\u7684\u4e3b\u5e72\u662f\uff1aAll active timers get their callbacks called. Pending callbacks are called. All I/O callbacks are called right after polling for I/O, for the most part. There are cases, however, in which calling such a callback is deferred for the next loop iteration. If the previous iteration deferred any I/O callback it will be run at this point. Idle handle callbacks are called. Despite the unfortunate name, idle handles are run on every loop iteration, if they are active. Prepare handle callbacks are called. Prepare handles get their callbacks called right before the loop will block for I/O. Poll timeout is calculated. Before blocking for I/O the loop calculates for how long it should block. These are the rules when calculating the timeout: If the loop was run with the UV_RUN_NOWAIT flag, the timeout is 0. If the loop is going to be stopped ( uv_stop() was called), the timeout is 0. If there are no active handles or requests, the timeout is 0. If there are any idle handles active, the timeout is 0. If there are any handles pending to be closed, the timeout is 0. If none of the above cases matches, the timeout of the closest timer is taken, or if there are no active timers, infinity. The loop blocks for I/O. At this point the loop will block for I/O for the duration calculated in the previous step. All I/O related handles that were monitoring a given file descriptor for a read or write operation get their callbacks called at this point. Check handle callbacks are called. Check handles get their callbacks called right after the loop has blocked for I/O. Check handles are essentially the counterpart of prepare handles. Close callbacks are called. If a handle was closed by calling uv_close() it will get the close callback called. Special case in case the loop was run with UV_RUN_ONCE , as it implies forward progress. It\u2019s possible that no I/O callbacks were fired after blocking for I/O, but some time has passed so there might be timers which are due, those timers get their callbacks called. Iteration ends. If the loop was run with UV_RUN_NOWAIT or UV_RUN_ONCE modes the iteration ends and uv_run() will return. If the loop was run with UV_RUN_DEFAULT it will continue from the start if it\u2019s still alive , otherwise it will also end. Important libuv uses a thread pool to make asynchronous file I/O operations possible, but network I/O is **always**performed in a single thread, each loop\u2019s thread. Note While the polling mechanism is different, libuv makes the execution model consistent across Unix systems and Windows. File I/O Unlike network I/O, there are no platform-specific file I/O primitives libuv could rely on, so the current approach is to run blocking file I/O operations in a thread pool. For a thorough explanation of the cross-platform file I/O landscape, checkout this post . libuv currently uses a global thread pool on which all loops can queue work. 3 types of operations are currently run on this pool: File system operations DNS functions (getaddrinfo and getnameinfo) User specified code via uv_queue_work() Warning See the Thread pool work scheduling section for more details, but keep in mind the thread pool size is quite limited.","title":"Design-overview"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/Design-overview/#design-overview","text":"libuv is cross-platform support library which was originally written for NodeJS . It\u2019s designed around the event-driven asynchronous I/O model . The library provides much more than a simple abstraction over different I/O polling mechanisms : \u2018handles\u2019 and \u2018streams\u2019 provide a high level abstraction for sockets and other entities; cross-platform file I/O and threading functionality is also provided, amongst other things. Here is a diagram illustrating the different parts that compose libuv and what subsystem they relate to:","title":"Design overview\u00b6"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/Design-overview/#handles-and-requests","text":"libuv provides users with 2 abstractions to work with, in combination with the event loop : handles and requests . SUMMARY :refer to this article to know more about event loop Handles represent long-lived objects capable of performing certain operations while active. Some examples: A prepare handle gets its callback called once every loop iteration when active. A TCP server handle that gets its connection callback called every time there is a new connection. Requests represent (typically) short-lived operations. These operations can be performed over a handle: write requests are used to write data on a handle; or standalone: getaddrinfo requests don\u2019t need a handle they run directly on the loop.","title":"Handles and requests\u00b6"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/Design-overview/#the-io-loop","text":"The I/O (or event) loop is the central part of libuv . It establishes the content for all I/O operations, and it\u2019s meant to be tied to a single thread . One can run multiple event loops as long as each runs in a different thread . The libuv event loop (or any other API involving the loop or handles, for that matter) is not thread-safe except where stated otherwise(\u9664\u975e\u53e6\u6709\u8bf4\u660e\uff0c\u5426\u5219libuv\u4e8b\u4ef6\u5faa\u73af\uff08\u6216\u6d89\u53ca\u5faa\u73af\u6216\u53e5\u67c4\u7684\u4efb\u4f55\u5176\u4ed6API\uff09\u90fd\u4e0d\u662f\u7ebf\u7a0b\u5b89\u5168\u7684). The event loop follows the rather usual single threaded asynchronous I/O approach : all (network) I/O is performed on non-blocking sockets which are polled using the best mechanism available on the given platform: epoll on Linux, kqueue on OSX and other BSDs, event ports on SunOS and IOCP on Windows. As part of a loop iteration the loop will block waiting for I/O activity on sockets which have been added to the poller and callbacks will be fired indicating socket conditions (readable, writable hangup) so handles can read, write or perform the desired I/O operation. In order to better understand how the event loop operates, the following diagram illustrates all stages of a loop iteration: The loop concept of \u2018now\u2019 is updated. The event loop caches the current time at the start of the event loop tick in order to reduce the number of time-related system calls. If the loop is alive an iteration is started, otherwise the loop will exit immediately. So, when is a loop considered to be alive ? If a loop has active and ref\u2019d handles, active requests or closing handles it\u2019s considered to be alive . SUMMARY :ref\u2019d \u53c2\u8003\u7684\uff08referenced\uff09 Due timers are run. All active timers scheduled for a time before the loop\u2019s concept of now get their callbacks called. SUMMARY :due timer \u53ef\u4ee5\u7406\u89e3\u4e3a\u201c\u5230\u671f\u8ba1\u6570\u5668\u201d\uff1b\u7b2c\u4e8c\u53e5\u8bdd\u7684\u4e3b\u5e72\u662f\uff1aAll active timers get their callbacks called. Pending callbacks are called. All I/O callbacks are called right after polling for I/O, for the most part. There are cases, however, in which calling such a callback is deferred for the next loop iteration. If the previous iteration deferred any I/O callback it will be run at this point. Idle handle callbacks are called. Despite the unfortunate name, idle handles are run on every loop iteration, if they are active. Prepare handle callbacks are called. Prepare handles get their callbacks called right before the loop will block for I/O. Poll timeout is calculated. Before blocking for I/O the loop calculates for how long it should block. These are the rules when calculating the timeout: If the loop was run with the UV_RUN_NOWAIT flag, the timeout is 0. If the loop is going to be stopped ( uv_stop() was called), the timeout is 0. If there are no active handles or requests, the timeout is 0. If there are any idle handles active, the timeout is 0. If there are any handles pending to be closed, the timeout is 0. If none of the above cases matches, the timeout of the closest timer is taken, or if there are no active timers, infinity. The loop blocks for I/O. At this point the loop will block for I/O for the duration calculated in the previous step. All I/O related handles that were monitoring a given file descriptor for a read or write operation get their callbacks called at this point. Check handle callbacks are called. Check handles get their callbacks called right after the loop has blocked for I/O. Check handles are essentially the counterpart of prepare handles. Close callbacks are called. If a handle was closed by calling uv_close() it will get the close callback called. Special case in case the loop was run with UV_RUN_ONCE , as it implies forward progress. It\u2019s possible that no I/O callbacks were fired after blocking for I/O, but some time has passed so there might be timers which are due, those timers get their callbacks called. Iteration ends. If the loop was run with UV_RUN_NOWAIT or UV_RUN_ONCE modes the iteration ends and uv_run() will return. If the loop was run with UV_RUN_DEFAULT it will continue from the start if it\u2019s still alive , otherwise it will also end. Important libuv uses a thread pool to make asynchronous file I/O operations possible, but network I/O is **always**performed in a single thread, each loop\u2019s thread. Note While the polling mechanism is different, libuv makes the execution model consistent across Unix systems and Windows.","title":"The I/O loop"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/Design-overview/#file-io","text":"Unlike network I/O, there are no platform-specific file I/O primitives libuv could rely on, so the current approach is to run blocking file I/O operations in a thread pool. For a thorough explanation of the cross-platform file I/O landscape, checkout this post . libuv currently uses a global thread pool on which all loops can queue work. 3 types of operations are currently run on this pool: File system operations DNS functions (getaddrinfo and getnameinfo) User specified code via uv_queue_work() Warning See the Thread pool work scheduling section for more details, but keep in mind the thread pool size is quite limited.","title":"File I/O"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/User-guide/Basics-of-libuv/","text":"Basics of libuv \u00b6 libuv enforces an asynchronous , event-driven style of programming. Its core job is to provide an event loop and callback based notifications of I/O and other activities. libuv offers core utilities like timers, non-blocking networking support, asynchronous file system access, child processes and more. Event loops \u00b6 In event-driven programming, an application expresses interest in certain events and respond to them when they occur. The responsibility of gathering events from the operating system or monitoring other sources of events is handled by libuv , and the user can register callbacks to be invoked when an event occurs. The event-loop usually keeps running forever . In pseudocode: while there are still events to process: e = get the next event if there is a callback associated with e: call the callback Some examples of events are: File is ready for writing A socket has data ready to be read A timer has timed out This event loop is encapsulated by uv_run() \u2013 the end-all(\u7ec8\u7ed3) function when using libuv . SUMMARY :\u8fd9\u53e5\u8bdd\u7684\u610f\u601d\u5c31\u662f\u8bf4\u51fd\u6570 uv_run() \u4ee3\u8868\u7684\u5c31\u662f**event loop**\u3002\u6211\u9700\u8981\u7406\u89e3libuv\u7684programming paradigm\uff0c\u5b83\u4e3a\u4e86\u4fbf\u4e8e\u7528\u6237\u4f7f\u7528\uff0c\u63d0\u4f9b\u4e86\u975e\u5e38\u9ad8\u7ea7\u7684API\uff0c\u8fd9\u4e9bAPI\u671f\u521d\u770b\u8d77\u6765\u662f\u975e\u5e38\u62bd\u8c61\u7684\uff0c\u96be\u4ee5\u7406\u89e3\u7684\uff0c\u4f46\u662f\u4e00\u65e6\u638c\u63e1\u4e86libuv\u7684programming paradigm\u5c31\u975e\u5e38\u597d\u7406\u89e3\u4e86\u3002 The most common activity of systems programs is to deal with input and output, rather than a lot of number-crunching. The problem with using conventional input/output functions ( read , fprintf , etc.) is that they are blocking . The actual write to a hard disk or reading from a network, takes a disproportionately long time compared to the speed of the processor. The functions don\u2019t return until the task is done, so that your program is doing nothing. For programs which require high performance this is a major roadblock as other activities and other I/O operations are kept waiting. SUMMARY : Asynchronous I/O also compare I/O and the processing of data. One of the standard solutions is to use threads. Each blocking I/O operation is started in a separate thread (or in a thread pool). When the blocking function gets invoked in the thread, the processor can schedule another thread to run, which actually needs the CPU. THINKING :I vaguely remember where I saw a similar description, but now I can't remember it. 20190107\uff1a\u662f\u5728APUE\u7684blocking IO\u7ae0\u8282\u4e2d\u3002 The approach followed by libuv uses another style, which is the asynchronous, non-blocking style. Most modern operating systems provide event notification subsystems . For example, a normal read call on a socket would block until the sender actually sent something. Instead, the application can request the operating system to watch the socket and put an event notification in the queue. The application can inspect the events at its convenience (perhaps doing some number crunching before to use the processor to the maximum) and grab the data. It is asynchronous because the application expressed interest at one point, then used the data at another point (in time and space). It is non-blocking because the application process was free to do other tasks. This fits in well with libuv \u2019s event-loop approach, since the operating system events can be treated as just another libuv event. The non-blocking ensures that other events can continue to be handled as fast as they come in [ 1] . Note How the I/O is run in the background is not of our concern, but due to the way our computer hardware works, with the thread as the basic unit of the processor\uff08processor\u4ee5thread\u4f5c\u4e3abasic unit\uff09, libuv and OSes will usually run background/worker threads and/or polling to perform tasks in a non-blocking manner. Bert Belder, one of the libuv core developers has a small video explaining the architecture of libuv and its background. If you have no prior experience with either libuv or libev , it is a quick, useful watch. libuv \u2019s event loop is explained in more detail in the documentation . Hello World \u00b6 With the basics out of the way, lets write our first libuv program. It does nothing, except start a loop which will exit immediately. helloworld/main.c #include <stdio.h> #include <stdlib.h> #include <uv.h> int main () { uv_loop_t * loop = malloc ( sizeof ( uv_loop_t )); uv_loop_init ( loop ); printf ( \"Now quitting. \\n \" ); uv_run ( loop , UV_RUN_DEFAULT ); uv_loop_close ( loop ); free ( loop ); return 0 ; } This program quits immediately because it has no events to process. A libuv event loop has to be told to watch out for events using the various API functions. SUMMARY \uff1a\u5728\u8fd0\u884clibuv\u7684event loop\u7684\u65f6\u5019\uff0c\u9700\u8981\u544a\u77e5event loop\u53bbwatch out\u4ec0\u4e48event\uff1b Starting with libuv v1.0, users should allocate the memory for the loops before initializing it with uv_loop_init(uv_loop_t *) . This allows you to plug in custom memory management . Remember to de-initialize the loop using uv_loop_close(uv_loop_t *) and then delete the storage. The examples never close loops since the program quits after the loop ends and the system will reclaim memory. Production grade projects\uff08\u751f\u4ea7\u7ea7\u522b\u7684\u9879\u76ee\uff09, especially long running systems programs, should take care to release correctly. Default loop \u00b6 A default loop is provided by libuv and can be accessed using uv_default_loop() . You should use this loop if you only want a single loop. Note:node.js uses the default loop as its main loop . If you are writing bindings you should be aware of this. Error handling \u00b6 Initialization functions or synchronous functions which may fail return a negative number on error. Async functions that may fail will pass a status parameter to their callbacks. The error messages are defined as UV_E* constants . You can use the uv_strerror(int) and uv_err_name(int) functions to get a const char * describing the error or the error name respectively. I/O read callbacks (such as for files and sockets) are passed a parameter nread . If nread is less than 0, there was an error (UV_EOF is the end of file error, which you may want to handle differently). Handles and Requests \u00b6 libuv works by the user expressing interest in particular events . This is usually done by creating a handle to an I/O device, timer or process. Handles are opaque structs named as uv_TYPE_t where type signifies\uff08\u8868\u793a\uff09 what the handle is used for. SUMMARY :\u4f7f\u7528handle\u6765\u8bbe\u7f6e\u5bf9\u67d0\u4e2aevent\u7684interest\u3002 handle**\u7684\u7c7b\u578b\u8868\u793a\u6b64handle\u7684\u7528\u9014\uff0c\u5176\u5b9e\u4e5f\u5c31\u5bf9\u5e94\u4e86\u5176\u6240\u5173\u6ce8\u7684event\u3002\u8fd9\u4e5f\u5c31\u662flibuv\u7684**watcher \u3002 libuv watchers UV_REQ_TYPE_PRIVATE UV_REQ_TYPE_MAX } uv_req_type ; /* Handle types. */ typedef struct uv_loop_s uv_loop_t ; typedef struct uv_handle_s uv_handle_t ; typedef struct uv_stream_s uv_stream_t ; typedef struct uv_tcp_s uv_tcp_t ; typedef struct uv_udp_s uv_udp_t ; typedef struct uv_pipe_s uv_pipe_t ; typedef struct uv_tty_s uv_tty_t ; typedef struct uv_poll_s uv_poll_t ; typedef struct uv_timer_s uv_timer_t ; typedef struct uv_prepare_s uv_prepare_t ; typedef struct uv_check_s uv_check_t ; typedef struct uv_idle_s uv_idle_t ; typedef struct uv_async_s uv_async_t ; typedef struct uv_process_s uv_process_t ; typedef struct uv_fs_event_s uv_fs_event_t ; typedef struct uv_fs_poll_s uv_fs_poll_t ; typedef struct uv_signal_s uv_signal_t ; /* Request types. */ typedef struct uv_req_s uv_req_t ; typedef struct uv_getaddrinfo_s uv_getaddrinfo_t ; typedef struct uv_getnameinfo_s uv_getnameinfo_t ; typedef struct uv_shutdown_s uv_shutdown_t ; typedef struct uv_write_s uv_write_t ; typedef struct uv_connect_s uv_connect_t ; typedef struct uv_udp_send_s uv_udp_send_t ; typedef struct uv_fs_s uv_fs_t ; typedef struct uv_work_s uv_work_t ; Handles represent long-lived objects. Async operations on such handles are identified using requests . A request is short-lived (usually used across only one callback\u3002\u8bd1\u6587\uff1a request**\u7684\u4f5c\u7528\u57df\u53ea\u5728\u4e00\u4e2a**callback**\u4e4b\u95f4) and usually indicates one I/O operation on a **handle \uff08 request**\u901a\u5e38\u8868\u793a\u5728\u4e00\u4e2a**handle**\u4e0a\u7684\u4e00\u4e2aI/0\u64cd\u4f5c\uff09. **Requests are used to preserve\uff08\u7ef4\u62a4\uff09 context between the initiation\uff08\u542f\u52a8\uff09 and the callback of individual actions. For example, an UDP socket is represented by a uv_udp_t , while individual writes to the socket use a uv_udp_send_t structure that is passed to the callback after the write is done. SUMMARY :request\u8868\u793a\u5f53handle\u6240watch\u7684event\u53d1\u751f\u7684\u65f6\u5019\uff0c\u8981\u6267\u884c\u7684asynchronous operation\uff0c\u8fd9\u4e9b\u64cd\u4f5c\u901a\u5e38\u662fI/O\u64cd\u4f5c\uff1b Handles are setup by a corresponding: uv_TYPE_init ( uv_loop_t * , uv_TYPE_t * ) function. Callbacks are functions which are called by libuv whenever an event the watcher is interested in has taken place. Application specific logic will usually be implemented in the callback . For example, an IO watcher\u2019s callback will receive the data read from a file, a timer callback will be triggered on timeout and so on. Idling \u00b6 Here is an example of using an idle handle . The callback is called once on every turn of the event loop . A use case for idle handles is discussed in Utilities . Let us use an idle watcher to look at the watcher life cycle and see how uv_run() will now block because a watcher is present. The idle watcher is stopped when the count is reached and uv_run() exits since no event watchers are active. Storing context \u00b6 In callback based programming style you\u2019ll often want to pass some \u2018context\u2019 \u2013 application specific information \u2013 between the call site and the callback . All handles and requests have a void* data member which you can set to the context and cast back in the callback. This is a common pattern used throughout the C library ecosystem. In addition uv_loop_t also has a similar data member.","title":"Basics-of-libuv"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/User-guide/Basics-of-libuv/#basics-of-libuv","text":"libuv enforces an asynchronous , event-driven style of programming. Its core job is to provide an event loop and callback based notifications of I/O and other activities. libuv offers core utilities like timers, non-blocking networking support, asynchronous file system access, child processes and more.","title":"Basics of libuv\u00b6"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/User-guide/Basics-of-libuv/#event-loops","text":"In event-driven programming, an application expresses interest in certain events and respond to them when they occur. The responsibility of gathering events from the operating system or monitoring other sources of events is handled by libuv , and the user can register callbacks to be invoked when an event occurs. The event-loop usually keeps running forever . In pseudocode: while there are still events to process: e = get the next event if there is a callback associated with e: call the callback Some examples of events are: File is ready for writing A socket has data ready to be read A timer has timed out This event loop is encapsulated by uv_run() \u2013 the end-all(\u7ec8\u7ed3) function when using libuv . SUMMARY :\u8fd9\u53e5\u8bdd\u7684\u610f\u601d\u5c31\u662f\u8bf4\u51fd\u6570 uv_run() \u4ee3\u8868\u7684\u5c31\u662f**event loop**\u3002\u6211\u9700\u8981\u7406\u89e3libuv\u7684programming paradigm\uff0c\u5b83\u4e3a\u4e86\u4fbf\u4e8e\u7528\u6237\u4f7f\u7528\uff0c\u63d0\u4f9b\u4e86\u975e\u5e38\u9ad8\u7ea7\u7684API\uff0c\u8fd9\u4e9bAPI\u671f\u521d\u770b\u8d77\u6765\u662f\u975e\u5e38\u62bd\u8c61\u7684\uff0c\u96be\u4ee5\u7406\u89e3\u7684\uff0c\u4f46\u662f\u4e00\u65e6\u638c\u63e1\u4e86libuv\u7684programming paradigm\u5c31\u975e\u5e38\u597d\u7406\u89e3\u4e86\u3002 The most common activity of systems programs is to deal with input and output, rather than a lot of number-crunching. The problem with using conventional input/output functions ( read , fprintf , etc.) is that they are blocking . The actual write to a hard disk or reading from a network, takes a disproportionately long time compared to the speed of the processor. The functions don\u2019t return until the task is done, so that your program is doing nothing. For programs which require high performance this is a major roadblock as other activities and other I/O operations are kept waiting. SUMMARY : Asynchronous I/O also compare I/O and the processing of data. One of the standard solutions is to use threads. Each blocking I/O operation is started in a separate thread (or in a thread pool). When the blocking function gets invoked in the thread, the processor can schedule another thread to run, which actually needs the CPU. THINKING :I vaguely remember where I saw a similar description, but now I can't remember it. 20190107\uff1a\u662f\u5728APUE\u7684blocking IO\u7ae0\u8282\u4e2d\u3002 The approach followed by libuv uses another style, which is the asynchronous, non-blocking style. Most modern operating systems provide event notification subsystems . For example, a normal read call on a socket would block until the sender actually sent something. Instead, the application can request the operating system to watch the socket and put an event notification in the queue. The application can inspect the events at its convenience (perhaps doing some number crunching before to use the processor to the maximum) and grab the data. It is asynchronous because the application expressed interest at one point, then used the data at another point (in time and space). It is non-blocking because the application process was free to do other tasks. This fits in well with libuv \u2019s event-loop approach, since the operating system events can be treated as just another libuv event. The non-blocking ensures that other events can continue to be handled as fast as they come in [ 1] . Note How the I/O is run in the background is not of our concern, but due to the way our computer hardware works, with the thread as the basic unit of the processor\uff08processor\u4ee5thread\u4f5c\u4e3abasic unit\uff09, libuv and OSes will usually run background/worker threads and/or polling to perform tasks in a non-blocking manner. Bert Belder, one of the libuv core developers has a small video explaining the architecture of libuv and its background. If you have no prior experience with either libuv or libev , it is a quick, useful watch. libuv \u2019s event loop is explained in more detail in the documentation .","title":"Event loops\u00b6"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/User-guide/Basics-of-libuv/#hello-world","text":"With the basics out of the way, lets write our first libuv program. It does nothing, except start a loop which will exit immediately. helloworld/main.c #include <stdio.h> #include <stdlib.h> #include <uv.h> int main () { uv_loop_t * loop = malloc ( sizeof ( uv_loop_t )); uv_loop_init ( loop ); printf ( \"Now quitting. \\n \" ); uv_run ( loop , UV_RUN_DEFAULT ); uv_loop_close ( loop ); free ( loop ); return 0 ; } This program quits immediately because it has no events to process. A libuv event loop has to be told to watch out for events using the various API functions. SUMMARY \uff1a\u5728\u8fd0\u884clibuv\u7684event loop\u7684\u65f6\u5019\uff0c\u9700\u8981\u544a\u77e5event loop\u53bbwatch out\u4ec0\u4e48event\uff1b Starting with libuv v1.0, users should allocate the memory for the loops before initializing it with uv_loop_init(uv_loop_t *) . This allows you to plug in custom memory management . Remember to de-initialize the loop using uv_loop_close(uv_loop_t *) and then delete the storage. The examples never close loops since the program quits after the loop ends and the system will reclaim memory. Production grade projects\uff08\u751f\u4ea7\u7ea7\u522b\u7684\u9879\u76ee\uff09, especially long running systems programs, should take care to release correctly.","title":"Hello World\u00b6"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/User-guide/Basics-of-libuv/#default-loop","text":"A default loop is provided by libuv and can be accessed using uv_default_loop() . You should use this loop if you only want a single loop. Note:node.js uses the default loop as its main loop . If you are writing bindings you should be aware of this.","title":"Default loop\u00b6"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/User-guide/Basics-of-libuv/#error-handling","text":"Initialization functions or synchronous functions which may fail return a negative number on error. Async functions that may fail will pass a status parameter to their callbacks. The error messages are defined as UV_E* constants . You can use the uv_strerror(int) and uv_err_name(int) functions to get a const char * describing the error or the error name respectively. I/O read callbacks (such as for files and sockets) are passed a parameter nread . If nread is less than 0, there was an error (UV_EOF is the end of file error, which you may want to handle differently).","title":"Error handling\u00b6"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/User-guide/Basics-of-libuv/#handles-and-requests","text":"libuv works by the user expressing interest in particular events . This is usually done by creating a handle to an I/O device, timer or process. Handles are opaque structs named as uv_TYPE_t where type signifies\uff08\u8868\u793a\uff09 what the handle is used for. SUMMARY :\u4f7f\u7528handle\u6765\u8bbe\u7f6e\u5bf9\u67d0\u4e2aevent\u7684interest\u3002 handle**\u7684\u7c7b\u578b\u8868\u793a\u6b64handle\u7684\u7528\u9014\uff0c\u5176\u5b9e\u4e5f\u5c31\u5bf9\u5e94\u4e86\u5176\u6240\u5173\u6ce8\u7684event\u3002\u8fd9\u4e5f\u5c31\u662flibuv\u7684**watcher \u3002 libuv watchers UV_REQ_TYPE_PRIVATE UV_REQ_TYPE_MAX } uv_req_type ; /* Handle types. */ typedef struct uv_loop_s uv_loop_t ; typedef struct uv_handle_s uv_handle_t ; typedef struct uv_stream_s uv_stream_t ; typedef struct uv_tcp_s uv_tcp_t ; typedef struct uv_udp_s uv_udp_t ; typedef struct uv_pipe_s uv_pipe_t ; typedef struct uv_tty_s uv_tty_t ; typedef struct uv_poll_s uv_poll_t ; typedef struct uv_timer_s uv_timer_t ; typedef struct uv_prepare_s uv_prepare_t ; typedef struct uv_check_s uv_check_t ; typedef struct uv_idle_s uv_idle_t ; typedef struct uv_async_s uv_async_t ; typedef struct uv_process_s uv_process_t ; typedef struct uv_fs_event_s uv_fs_event_t ; typedef struct uv_fs_poll_s uv_fs_poll_t ; typedef struct uv_signal_s uv_signal_t ; /* Request types. */ typedef struct uv_req_s uv_req_t ; typedef struct uv_getaddrinfo_s uv_getaddrinfo_t ; typedef struct uv_getnameinfo_s uv_getnameinfo_t ; typedef struct uv_shutdown_s uv_shutdown_t ; typedef struct uv_write_s uv_write_t ; typedef struct uv_connect_s uv_connect_t ; typedef struct uv_udp_send_s uv_udp_send_t ; typedef struct uv_fs_s uv_fs_t ; typedef struct uv_work_s uv_work_t ; Handles represent long-lived objects. Async operations on such handles are identified using requests . A request is short-lived (usually used across only one callback\u3002\u8bd1\u6587\uff1a request**\u7684\u4f5c\u7528\u57df\u53ea\u5728\u4e00\u4e2a**callback**\u4e4b\u95f4) and usually indicates one I/O operation on a **handle \uff08 request**\u901a\u5e38\u8868\u793a\u5728\u4e00\u4e2a**handle**\u4e0a\u7684\u4e00\u4e2aI/0\u64cd\u4f5c\uff09. **Requests are used to preserve\uff08\u7ef4\u62a4\uff09 context between the initiation\uff08\u542f\u52a8\uff09 and the callback of individual actions. For example, an UDP socket is represented by a uv_udp_t , while individual writes to the socket use a uv_udp_send_t structure that is passed to the callback after the write is done. SUMMARY :request\u8868\u793a\u5f53handle\u6240watch\u7684event\u53d1\u751f\u7684\u65f6\u5019\uff0c\u8981\u6267\u884c\u7684asynchronous operation\uff0c\u8fd9\u4e9b\u64cd\u4f5c\u901a\u5e38\u662fI/O\u64cd\u4f5c\uff1b Handles are setup by a corresponding: uv_TYPE_init ( uv_loop_t * , uv_TYPE_t * ) function. Callbacks are functions which are called by libuv whenever an event the watcher is interested in has taken place. Application specific logic will usually be implemented in the callback . For example, an IO watcher\u2019s callback will receive the data read from a file, a timer callback will be triggered on timeout and so on.","title":"Handles and Requests\u00b6"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/User-guide/Basics-of-libuv/#idling","text":"Here is an example of using an idle handle . The callback is called once on every turn of the event loop . A use case for idle handles is discussed in Utilities . Let us use an idle watcher to look at the watcher life cycle and see how uv_run() will now block because a watcher is present. The idle watcher is stopped when the count is reached and uv_run() exits since no event watchers are active.","title":"Idling\u00b6"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/User-guide/Basics-of-libuv/#storing-context","text":"In callback based programming style you\u2019ll often want to pass some \u2018context\u2019 \u2013 application specific information \u2013 between the call site and the callback . All handles and requests have a void* data member which you can set to the context and cast back in the callback. This is a common pattern used throughout the C library ecosystem. In addition uv_loop_t also has a similar data member.","title":"Storing context\u00b6"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/User-guide/Utilities/Utilities/","text":"Utilities This chapter catalogues tools and techniques which are useful for common tasks. The libev man page already covers some patterns which can be adopted to libuv through simple API changes. It also covers parts of the libuv API that don\u2019t require entire chapters dedicated to them. Timers Timers invoke the callback after a certain time has elapsed(\u8fc7\u53bb) since the timer was started. libuv timers can also be set to invoke at regular intervals instead of just once. Simple use is to init a watcher and start it with a timeout , and optional repeat . Timers can be stopped at any time. uv_timer_t timer_req ; uv_timer_init ( loop , & timer_req ); uv_timer_start ( & timer_req , callback , 5000 , 2000 ); will start a repeating timer , which first starts 5 seconds (the timeout ) after the execution of uv_timer_start , then repeats every 2 seconds (the repeat ). Use: uv_timer_stop ( & timer_req ); to stop the timer. This can be used safely from within the callback as well. The repeat interval can be modified at any time with: uv_timer_set_repeat ( uv_timer_t * timer , int64_t repeat ); which will take effect when possible . If this function is called from a timer callback, it means: If the timer was non-repeating, the timer has already been stopped. Use uv_timer_start again. If the timer is repeating, the next timeout has already been scheduled, so the old repeat interval will be used once more before the timer switches to the new interval. The utility function: int uv_timer_again ( uv_timer_t * ) applies only to repeating timers and is equivalent to stopping the timer and then starting it with both initial timeout and repeat set to the old repeat value. If the timer hasn\u2019t been started it fails (error code UV_EINVAL ) and returns -1. An actual timer example is in the reference count section . Event loop reference count The event loop only runs as long as there are active handles . This system works by having every handle increase the reference count of the event loop when it is started and decreasing the reference count when stopped. It is also possible to manually change the reference count of handles using: void uv_ref ( uv_handle_t * ); void uv_unref ( uv_handle_t * ); These functions can be used to allow a loop to exit even when a watcher is active or to use custom objects to keep the loop alive. The latter can be used with interval timers. You might have a garbage collector which runs every X seconds, or your network service might send a heartbeat to others periodically(\u5b9a\u65f6\u5730), but you don\u2019t want to have to stop them along all clean exit paths or error scenarios. Or you want the program to exit when all your other watchers are done. In that case just unref the timer immediately after creation so that if it is the only watcher running then uv_run will still exit. This is also used in node.js where some libuv methods are being bubbled up to the JS API. A uv_handle_t (the superclass of all watchers) is created per JS object and can be ref/unrefed. ref-timer/main.c uv_loop_t * loop ; uv_timer_t gc_req ; uv_timer_t fake_job_req ; int main () { loop = uv_default_loop (); uv_timer_init ( loop , & gc_req ); uv_unref (( uv_handle_t * ) & gc_req ); uv_timer_start ( & gc_req , gc , 0 , 2000 ); // could actually be a TCP download or something uv_timer_init ( loop , & fake_job_req ); uv_timer_start ( & fake_job_req , fake_job , 9000 , 0 ); return uv_run ( loop , UV_RUN_DEFAULT ); } We initialize the garbage collector timer, then immediately unref it. Observe how after 9 seconds, when the fake job is done, the program automatically exits, even though the garbage collector is still running. Idler pattern The callbacks of idle handles are invoked once per event loop. The idle callback can be used to perform some very low priority activity. For example, you could dispatch a summary of the daily application performance to the developers for analysis during periods of idleness, or use the application\u2019s CPU time to perform SETI calculations :) An idle watcher is also useful in a GUI application. Say you are using an event loop for a file download. If the TCP socket is still being established and no other events are present your event loop will pause ( block ), which means your progress bar will freeze and the user will face an unresponsive application. In such a case queue up and idle watcher to keep the UI operational. idle-compute/main.c Here we initialize the idle watcher and queue it up along with the actual events we are interested in. crunch_away will now be called repeatedly until the user types something and presses Return. Then it will be interrupted for a brief amount as the loop deals with the input data, after which it will keep calling the idle callback again. idle-compute/main.c Passing data to worker thread When using uv_queue_work you\u2019ll usually need to pass complex data through to the worker thread. The solution is to use a struct and set uv_work_t.data to point to it. A slight variation is to have the uv_work_t itself as the first member of this struct (called a baton [ 1] ). This allows cleaning up the work request and all the data in one free call. Here we create the baton and queue the task. Now the task function can extract the data it needs: We then free the baton which also frees the watcher. External I/O with polling Usually third-party libraries will handle their own I/O, and keep track of their sockets and other files internally. In this case it isn\u2019t possible to use the standard stream I/O operations, but the library can still be integrated into the libuv event loop. All that is required is that the library allow you to access the underlying file descriptors and provide functions that process tasks in small increments as decided by your application. Some libraries though will not allow such access, providing only a standard blocking function which will perform the entire I/O transaction and only then return. It is unwise to use these in the event loop thread, use the libuv-work-queue instead. Of course, this will also mean losing granular control on the library. The uv_poll section of libuv simply watches file descriptors using the operating system notification mechanism. In some sense, all the I/O operations that libuv implements itself are also backed by uv_poll like code. Whenever the OS notices a change of state in file descriptors being polled, libuv will invoke the associated callback. Here we will walk through a simple download manager that will use libcurl to download files. Rather than give all control to libcurl, we\u2019ll instead be using the libuv event loop, and use the non-blocking, async multi interface to progress with the download whenever libuv notifies of I/O readiness. uvwget/main.c - The setup The way each library is integrated with libuv will vary. In the case of libcurl, we can register two callbacks. The socket callback handle_socket is invoked whenever the state of a socket changes and we have to start polling it. start_timeout is called by libcurl to notify us of the next timeout interval, after which we should drive libcurl forward regardless of I/O status. This is so that libcurl can handle errors or do whatever else is required to get the download moving. Our downloader is to be invoked as: $ ./uvwget [url1] [url2] ... So we add each argument as an URL uvwget/main.c - Adding urls We let libcurl directly write the data to a file, but much more is possible if you so desire. start_timeout will be called immediately the first time by libcurl, so things are set in motion. This simply starts a libuv timer which drives curl_multi_socket_action with CURL_SOCKET_TIMEOUT whenever it times out. curl_multi_socket_action is what drives libcurl, and what we call whenever sockets change state. But before we go into that, we need to poll on sockets whenever handle_socket is called. uvwget/main.c - Setting up polling We are interested in the socket fd s , and the action . For every socket we create a uv_poll_t handle if it doesn\u2019t exist, and associate it with the socket using curl_multi_assign . This way socketp points to it whenever the callback is invoked. In the case that the download is done or fails, libcurl requests removal of the poll. So we stop and free the poll handle. Depending on what events libcurl wishes to watch for, we start polling with UV_READABLE or UV_WRITABLE . Now libuv will invoke the poll callback whenever the socket is ready for reading or writing. Calling uv_poll_start multiple times on the same handle is acceptable, it will just update the events mask with the new value. curl_perform is the crux of this program. uvwget/main.c - Driving libcurl. The first thing we do is to stop the timer, since there has been some progress in the interval. Then depending on what event triggered the callback, we set the correct flags. Then we call curl_multi_socket_action with the socket that progressed and the flags informing about what events happened. At this point libcurl does all of its internal tasks in small increments, and will attempt to return as fast as possible, which is exactly what an evented program wants in its main thread. libcurl keeps queueing messages into its own queue about transfer progress. In our case we are only interested in transfers that are completed. So we extract these messages, and clean up handles whose transfers are done. uvwget/main.c - Reading transfer status. Check & Prepare watchers TODO Loading libraries libuv provides a cross platform API to dynamically load shared libraries . This can be used to implement your own plugin/extension/module system and is used by node.js to implement require() support for bindings. The usage is quite simple as long as your library exports the right symbols. Be careful with sanity and security checks when loading third party code, otherwise your program will behave unpredictably. This example implements a very simple plugin system which does nothing except print the name of the plugin. Let us first look at the interface provided to plugin authors. plugin/plugin.h You can similarly add more functions that plugin authors can use to do useful things in your application [ 2] . A sample plugin using this API is: plugin/hello.c Our interface defines that all plugins should have an initialize function which will be called by the application. This plugin is compiled as a shared library and can be loaded by running our application: $ ./plugin libhello.dylib Loading libhello.dylib Registered plugin \"Hello World!\" Note The shared library filename will be different depending on platforms. On Linux it is libhello.so . This is done by using uv_dlopen to first load the shared library libhello.dylib . Then we get access to the initialize function using uv_dlsym and invoke it. plugin/main.c uv_dlopen expects a path to the shared library and sets the opaque uv_lib_t pointer. It returns 0 on success, -1 on error. Use uv_dlerror to get the error message. uv_dlsym stores a pointer to the symbol in the second argument in the third argument. init_plugin_function is a function pointer to the sort of function we are looking for in the application\u2019s plugins. TTY Text terminals have supported basic formatting for a long time, with a pretty standardised command set. This formatting is often used by programs to improve the readability of terminal output. For example grep --colour . libuv provides the uv_tty_t abstraction (a stream) and related functions to implement the ANSI escape codes across all platforms. By this I mean that libuv converts ANSI codes to the Windows equivalent, and provides functions to get terminal information. The first thing to do is to initialize a uv_tty_t with the file descriptor it reads/writes from. This is achieved with: int uv_tty_init(uv_loop_t*, uv_tty_t*, uv_file fd, int readable) Set readable to true if you plan to use uv_read_start() on the stream. It is then best to use uv_tty_set_mode to set the mode to normal which enables most TTY formatting, flow-control and other settings. Other modes are also available. Remember to call uv_tty_reset_mode when your program exits to restore the state of the terminal. Just good manners. Another set of good manners is to be aware of redirection. If the user redirects the output of your command to a file, control sequences should not be written as they impede readability and grep . To check if the file descriptor is indeed a TTY, call uv_guess_handle with the file descriptor and compare the return value with UV_TTY . Here is a simple example which prints white text on a red background: tty/main.c The final TTY helper is uv_tty_get_winsize() which is used to get the width and height of the terminal and returns 0 on success. Here is a small program which does some animation using the function and character position escape codes. tty-gravity/main.c The escape codes are: Code Meaning 2 J Clear part of the screen, 2 is entire screen H Moves cursor to certain position, default top-left n B Moves cursor down by n lines n C Moves cursor right by n columns m Obeys string of display settings, in this case green background (40+2), white text (30+7) As you can see this is very useful to produce nicely formatted output, or even console based arcade games if that tickles your fancy. For fancier control you can try ncurses . [ 1] I was first introduced to the term baton in this context, in Konstantin K\u00e4fer\u2019s excellent slides on writing node.js bindings \u2013 http://kkaefer.github.com/node-cpp-modules/#baton [ 2] mfp is My Fancy Plugin","title":"Utilities"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/User-guide/Utilities/Utilities/#utilities","text":"This chapter catalogues tools and techniques which are useful for common tasks. The libev man page already covers some patterns which can be adopted to libuv through simple API changes. It also covers parts of the libuv API that don\u2019t require entire chapters dedicated to them.","title":"Utilities"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/User-guide/Utilities/Utilities/#timers","text":"Timers invoke the callback after a certain time has elapsed(\u8fc7\u53bb) since the timer was started. libuv timers can also be set to invoke at regular intervals instead of just once. Simple use is to init a watcher and start it with a timeout , and optional repeat . Timers can be stopped at any time. uv_timer_t timer_req ; uv_timer_init ( loop , & timer_req ); uv_timer_start ( & timer_req , callback , 5000 , 2000 ); will start a repeating timer , which first starts 5 seconds (the timeout ) after the execution of uv_timer_start , then repeats every 2 seconds (the repeat ). Use: uv_timer_stop ( & timer_req ); to stop the timer. This can be used safely from within the callback as well. The repeat interval can be modified at any time with: uv_timer_set_repeat ( uv_timer_t * timer , int64_t repeat ); which will take effect when possible . If this function is called from a timer callback, it means: If the timer was non-repeating, the timer has already been stopped. Use uv_timer_start again. If the timer is repeating, the next timeout has already been scheduled, so the old repeat interval will be used once more before the timer switches to the new interval. The utility function: int uv_timer_again ( uv_timer_t * ) applies only to repeating timers and is equivalent to stopping the timer and then starting it with both initial timeout and repeat set to the old repeat value. If the timer hasn\u2019t been started it fails (error code UV_EINVAL ) and returns -1. An actual timer example is in the reference count section .","title":"Timers"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/User-guide/Utilities/Utilities/#event-loop-reference-count","text":"The event loop only runs as long as there are active handles . This system works by having every handle increase the reference count of the event loop when it is started and decreasing the reference count when stopped. It is also possible to manually change the reference count of handles using: void uv_ref ( uv_handle_t * ); void uv_unref ( uv_handle_t * ); These functions can be used to allow a loop to exit even when a watcher is active or to use custom objects to keep the loop alive. The latter can be used with interval timers. You might have a garbage collector which runs every X seconds, or your network service might send a heartbeat to others periodically(\u5b9a\u65f6\u5730), but you don\u2019t want to have to stop them along all clean exit paths or error scenarios. Or you want the program to exit when all your other watchers are done. In that case just unref the timer immediately after creation so that if it is the only watcher running then uv_run will still exit. This is also used in node.js where some libuv methods are being bubbled up to the JS API. A uv_handle_t (the superclass of all watchers) is created per JS object and can be ref/unrefed. ref-timer/main.c uv_loop_t * loop ; uv_timer_t gc_req ; uv_timer_t fake_job_req ; int main () { loop = uv_default_loop (); uv_timer_init ( loop , & gc_req ); uv_unref (( uv_handle_t * ) & gc_req ); uv_timer_start ( & gc_req , gc , 0 , 2000 ); // could actually be a TCP download or something uv_timer_init ( loop , & fake_job_req ); uv_timer_start ( & fake_job_req , fake_job , 9000 , 0 ); return uv_run ( loop , UV_RUN_DEFAULT ); } We initialize the garbage collector timer, then immediately unref it. Observe how after 9 seconds, when the fake job is done, the program automatically exits, even though the garbage collector is still running.","title":"Event loop reference count"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/User-guide/Utilities/Utilities/#idler-pattern","text":"The callbacks of idle handles are invoked once per event loop. The idle callback can be used to perform some very low priority activity. For example, you could dispatch a summary of the daily application performance to the developers for analysis during periods of idleness, or use the application\u2019s CPU time to perform SETI calculations :) An idle watcher is also useful in a GUI application. Say you are using an event loop for a file download. If the TCP socket is still being established and no other events are present your event loop will pause ( block ), which means your progress bar will freeze and the user will face an unresponsive application. In such a case queue up and idle watcher to keep the UI operational. idle-compute/main.c Here we initialize the idle watcher and queue it up along with the actual events we are interested in. crunch_away will now be called repeatedly until the user types something and presses Return. Then it will be interrupted for a brief amount as the loop deals with the input data, after which it will keep calling the idle callback again. idle-compute/main.c","title":"Idler pattern"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/User-guide/Utilities/Utilities/#passing-data-to-worker-thread","text":"When using uv_queue_work you\u2019ll usually need to pass complex data through to the worker thread. The solution is to use a struct and set uv_work_t.data to point to it. A slight variation is to have the uv_work_t itself as the first member of this struct (called a baton [ 1] ). This allows cleaning up the work request and all the data in one free call. Here we create the baton and queue the task. Now the task function can extract the data it needs: We then free the baton which also frees the watcher.","title":"Passing data to worker thread"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/User-guide/Utilities/Utilities/#external-io-with-polling","text":"Usually third-party libraries will handle their own I/O, and keep track of their sockets and other files internally. In this case it isn\u2019t possible to use the standard stream I/O operations, but the library can still be integrated into the libuv event loop. All that is required is that the library allow you to access the underlying file descriptors and provide functions that process tasks in small increments as decided by your application. Some libraries though will not allow such access, providing only a standard blocking function which will perform the entire I/O transaction and only then return. It is unwise to use these in the event loop thread, use the libuv-work-queue instead. Of course, this will also mean losing granular control on the library. The uv_poll section of libuv simply watches file descriptors using the operating system notification mechanism. In some sense, all the I/O operations that libuv implements itself are also backed by uv_poll like code. Whenever the OS notices a change of state in file descriptors being polled, libuv will invoke the associated callback. Here we will walk through a simple download manager that will use libcurl to download files. Rather than give all control to libcurl, we\u2019ll instead be using the libuv event loop, and use the non-blocking, async multi interface to progress with the download whenever libuv notifies of I/O readiness. uvwget/main.c - The setup The way each library is integrated with libuv will vary. In the case of libcurl, we can register two callbacks. The socket callback handle_socket is invoked whenever the state of a socket changes and we have to start polling it. start_timeout is called by libcurl to notify us of the next timeout interval, after which we should drive libcurl forward regardless of I/O status. This is so that libcurl can handle errors or do whatever else is required to get the download moving. Our downloader is to be invoked as: $ ./uvwget [url1] [url2] ... So we add each argument as an URL uvwget/main.c - Adding urls We let libcurl directly write the data to a file, but much more is possible if you so desire. start_timeout will be called immediately the first time by libcurl, so things are set in motion. This simply starts a libuv timer which drives curl_multi_socket_action with CURL_SOCKET_TIMEOUT whenever it times out. curl_multi_socket_action is what drives libcurl, and what we call whenever sockets change state. But before we go into that, we need to poll on sockets whenever handle_socket is called. uvwget/main.c - Setting up polling We are interested in the socket fd s , and the action . For every socket we create a uv_poll_t handle if it doesn\u2019t exist, and associate it with the socket using curl_multi_assign . This way socketp points to it whenever the callback is invoked. In the case that the download is done or fails, libcurl requests removal of the poll. So we stop and free the poll handle. Depending on what events libcurl wishes to watch for, we start polling with UV_READABLE or UV_WRITABLE . Now libuv will invoke the poll callback whenever the socket is ready for reading or writing. Calling uv_poll_start multiple times on the same handle is acceptable, it will just update the events mask with the new value. curl_perform is the crux of this program. uvwget/main.c - Driving libcurl. The first thing we do is to stop the timer, since there has been some progress in the interval. Then depending on what event triggered the callback, we set the correct flags. Then we call curl_multi_socket_action with the socket that progressed and the flags informing about what events happened. At this point libcurl does all of its internal tasks in small increments, and will attempt to return as fast as possible, which is exactly what an evented program wants in its main thread. libcurl keeps queueing messages into its own queue about transfer progress. In our case we are only interested in transfers that are completed. So we extract these messages, and clean up handles whose transfers are done. uvwget/main.c - Reading transfer status.","title":"External I/O with polling"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/User-guide/Utilities/Utilities/#check-prepare-watchers","text":"TODO","title":"Check &amp; Prepare watchers"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/User-guide/Utilities/Utilities/#loading-libraries","text":"libuv provides a cross platform API to dynamically load shared libraries . This can be used to implement your own plugin/extension/module system and is used by node.js to implement require() support for bindings. The usage is quite simple as long as your library exports the right symbols. Be careful with sanity and security checks when loading third party code, otherwise your program will behave unpredictably. This example implements a very simple plugin system which does nothing except print the name of the plugin. Let us first look at the interface provided to plugin authors. plugin/plugin.h You can similarly add more functions that plugin authors can use to do useful things in your application [ 2] . A sample plugin using this API is: plugin/hello.c Our interface defines that all plugins should have an initialize function which will be called by the application. This plugin is compiled as a shared library and can be loaded by running our application: $ ./plugin libhello.dylib Loading libhello.dylib Registered plugin \"Hello World!\" Note The shared library filename will be different depending on platforms. On Linux it is libhello.so . This is done by using uv_dlopen to first load the shared library libhello.dylib . Then we get access to the initialize function using uv_dlsym and invoke it. plugin/main.c uv_dlopen expects a path to the shared library and sets the opaque uv_lib_t pointer. It returns 0 on success, -1 on error. Use uv_dlerror to get the error message. uv_dlsym stores a pointer to the symbol in the second argument in the third argument. init_plugin_function is a function pointer to the sort of function we are looking for in the application\u2019s plugins.","title":"Loading libraries"},{"location":"C/Library/Event-driven-programming/Software-libuv/Doc/User-guide/Utilities/Utilities/#tty","text":"Text terminals have supported basic formatting for a long time, with a pretty standardised command set. This formatting is often used by programs to improve the readability of terminal output. For example grep --colour . libuv provides the uv_tty_t abstraction (a stream) and related functions to implement the ANSI escape codes across all platforms. By this I mean that libuv converts ANSI codes to the Windows equivalent, and provides functions to get terminal information. The first thing to do is to initialize a uv_tty_t with the file descriptor it reads/writes from. This is achieved with: int uv_tty_init(uv_loop_t*, uv_tty_t*, uv_file fd, int readable) Set readable to true if you plan to use uv_read_start() on the stream. It is then best to use uv_tty_set_mode to set the mode to normal which enables most TTY formatting, flow-control and other settings. Other modes are also available. Remember to call uv_tty_reset_mode when your program exits to restore the state of the terminal. Just good manners. Another set of good manners is to be aware of redirection. If the user redirects the output of your command to a file, control sequences should not be written as they impede readability and grep . To check if the file descriptor is indeed a TTY, call uv_guess_handle with the file descriptor and compare the return value with UV_TTY . Here is a simple example which prints white text on a red background: tty/main.c The final TTY helper is uv_tty_get_winsize() which is used to get the width and height of the terminal and returns 0 on success. Here is a small program which does some animation using the function and character position escape codes. tty-gravity/main.c The escape codes are: Code Meaning 2 J Clear part of the screen, 2 is entire screen H Moves cursor to certain position, default top-left n B Moves cursor down by n lines n C Moves cursor right by n columns m Obeys string of display settings, in this case green background (40+2), white text (30+7) As you can see this is very useful to produce nicely formatted output, or even console based arcade games if that tickles your fancy. For fancier control you can try ncurses . [ 1] I was first introduced to the term baton in this context, in Konstantin K\u00e4fer\u2019s excellent slides on writing node.js bindings \u2013 http://kkaefer.github.com/node-cpp-modules/#baton [ 2] mfp is My Fancy Plugin","title":"TTY"},{"location":"C/Pattern/","text":"\u5173\u4e8e\u672c\u7ae0 \u53c2\u8003\u5185\u5bb9\uff1a Patterns in C https://stackoverflow.com/questions/4112796/are-there-any-design-patterns-in-c","title":"Introduction"},{"location":"C/Pattern/#_1","text":"\u53c2\u8003\u5185\u5bb9\uff1a Patterns in C https://stackoverflow.com/questions/4112796/are-there-any-design-patterns-in-c","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"C/Stype-guide/C-stype-guide/","text":"C Style guide umd C Style Guidelines","title":"C-stype-guide"},{"location":"C/Stype-guide/C-stype-guide/#c-style-guide","text":"","title":"C Style guide"},{"location":"C/Stype-guide/C-stype-guide/#umd-c-style-guidelines","text":"","title":"umd C Style Guidelines"},{"location":"C++/Book/","text":"Book Essential C++","title":"Book"},{"location":"C++/Book/#book","text":"Essential C++","title":"Book"},{"location":"C++/C++/","text":"C++ ccppreference C++ language \u7ef4\u57fa\u767e\u79d1 C++","title":"C++"},{"location":"C++/C++/#c","text":"","title":"C++"},{"location":"C++/C++/#ccppreference-c-language","text":"","title":"ccppreference C++ language"},{"location":"C++/C++/#c_1","text":"","title":"\u7ef4\u57fa\u767e\u79d1 C++"},{"location":"C++/IDE/","text":"IDE c++\u7684IDE\u3002 Eclipse IDE for C/C++ Developers \u5982\u4f55\u4f7f\u7528doxygen\u98ce\u683c\u7684\u6ce8\u91ca\uff1f \u5728Window->Preferences\u4e2d\u641c\u7d22\u201cdoxygen\"\uff0c\u7136\u540e\u4f1a\u641c\u7d22\u5230\u201dC/C++\u201c->\"Editor\"\u754c\u9762\uff0c\u5c06workspace default\u8bbe\u7f6e\u4e3adoxygen\u3002","title":"IDE"},{"location":"C++/IDE/#ide","text":"c++\u7684IDE\u3002","title":"IDE"},{"location":"C++/IDE/#eclipse-ide-for-cc-developers","text":"","title":"Eclipse IDE for C/C++ Developers"},{"location":"C++/IDE/#doxygen","text":"\u5728Window->Preferences\u4e2d\u641c\u7d22\u201cdoxygen\"\uff0c\u7136\u540e\u4f1a\u641c\u7d22\u5230\u201dC/C++\u201c->\"Editor\"\u754c\u9762\uff0c\u5c06workspace default\u8bbe\u7f6e\u4e3adoxygen\u3002","title":"\u5982\u4f55\u4f7f\u7528doxygen\u98ce\u683c\u7684\u6ce8\u91ca\uff1f"},{"location":"C++/What-is-new-in-C++/","text":"What is new in C++ python\u7684\u5b98\u65b9\u6587\u6863\u7684\u201cWhat\u2019s New in Python \u00b6 \u201d\u4f1a\u8be6\u7ec6\u7684\u7f57\u5217python\u7684\u5404\u4e2a\u7248\u672c\u7684what is new\uff0c\u4f46\u662f cppreference \u4e2d\u5e76\u6ca1\u6709\u7c7b\u4f3c\u8fbe\u7684\u3001\u4e13\u95e8\u5c31\u67d0\u4e00\u7248\u672c\u7684\u6539\u8fdb\u7684\u5185\u5bb9\uff0c\u800c\u662f\u6742\u7cc5\u8fdb\u4e86\u5404\u4e2a\u5177\u4f53\u7ae0\u8282\u4e2d\uff0c\u8fd9\u4e0d\u5229\u4e8e\u5f00\u53d1\u8005\u638c\u63e1\u8fd9\u95e8\u8bed\u8a00\u7684\u6f14\u8fdb\u8f68\u8ff9\uff0c\u672c\u6587\u5bf9\u6536\u96c6\u4e86\u5173\u4e8e\u8fd9\u65b9\u9762\u7684\u4e00\u4e9b\u5185\u5bb9\u3002 cppreference C++ compiler support \u672c\u8282\u7684\u6807\u9898\u662fc++ compiler support\uff0c\u4ed4\u7ec6\u9605\u8bfb\u539f\u6587\u5c31\u4f1a\u53d1\u73b0\u5b83\u6240\u8ba8\u8bba\u7684\u662f\u5404\u79cdc++ compiler\u5bf9\u5404\u4e2a\u7248\u672cc++\u6240\u5f15\u5165\u7684feature\u7684\u652f\u6301\uff0c\u5e76\u4e14\uff0c\u5b83\u7684\u7f57\u5217\u662f\u975e\u5e38\u8be6\u7ec6\u3001\u4ee5\u65f6\u95f4\u4e3a\u987a\u5e8f\u7684\uff0c\u6240\u4ee5\u53ef\u4ee5\u4f5c\u4e3awhat is new in c++\u3002 \u7ef4\u57fa\u767e\u79d1 C++11 \u7ef4\u57fa\u767e\u79d1\u5bf9\u5404\u4e2a\u7248\u672c\u7684C++\u8fdb\u884c\u4e86\u603b\u7ed3\uff0c\u53ef\u4ee5\u4f5c\u4e3aWhat is new in C++\u3002","title":"What-is-new-in-C++"},{"location":"C++/What-is-new-in-C++/#what-is-new-in-c","text":"python\u7684\u5b98\u65b9\u6587\u6863\u7684\u201cWhat\u2019s New in Python \u00b6 \u201d\u4f1a\u8be6\u7ec6\u7684\u7f57\u5217python\u7684\u5404\u4e2a\u7248\u672c\u7684what is new\uff0c\u4f46\u662f cppreference \u4e2d\u5e76\u6ca1\u6709\u7c7b\u4f3c\u8fbe\u7684\u3001\u4e13\u95e8\u5c31\u67d0\u4e00\u7248\u672c\u7684\u6539\u8fdb\u7684\u5185\u5bb9\uff0c\u800c\u662f\u6742\u7cc5\u8fdb\u4e86\u5404\u4e2a\u5177\u4f53\u7ae0\u8282\u4e2d\uff0c\u8fd9\u4e0d\u5229\u4e8e\u5f00\u53d1\u8005\u638c\u63e1\u8fd9\u95e8\u8bed\u8a00\u7684\u6f14\u8fdb\u8f68\u8ff9\uff0c\u672c\u6587\u5bf9\u6536\u96c6\u4e86\u5173\u4e8e\u8fd9\u65b9\u9762\u7684\u4e00\u4e9b\u5185\u5bb9\u3002","title":"What is new in C++"},{"location":"C++/What-is-new-in-C++/#cppreference-c-compiler-support","text":"\u672c\u8282\u7684\u6807\u9898\u662fc++ compiler support\uff0c\u4ed4\u7ec6\u9605\u8bfb\u539f\u6587\u5c31\u4f1a\u53d1\u73b0\u5b83\u6240\u8ba8\u8bba\u7684\u662f\u5404\u79cdc++ compiler\u5bf9\u5404\u4e2a\u7248\u672cc++\u6240\u5f15\u5165\u7684feature\u7684\u652f\u6301\uff0c\u5e76\u4e14\uff0c\u5b83\u7684\u7f57\u5217\u662f\u975e\u5e38\u8be6\u7ec6\u3001\u4ee5\u65f6\u95f4\u4e3a\u987a\u5e8f\u7684\uff0c\u6240\u4ee5\u53ef\u4ee5\u4f5c\u4e3awhat is new in c++\u3002","title":"cppreference C++ compiler support"},{"location":"C++/What-is-new-in-C++/#c11","text":"\u7ef4\u57fa\u767e\u79d1\u5bf9\u5404\u4e2a\u7248\u672c\u7684C++\u8fdb\u884c\u4e86\u603b\u7ed3\uff0c\u53ef\u4ee5\u4f5c\u4e3aWhat is new in C++\u3002","title":"\u7ef4\u57fa\u767e\u79d1C++11"},{"location":"C++/Comment/Comment/","text":"Comment \u5728c++\u4e2d\u5982\u4f55\u8fdb\u884c\u6ce8\u91ca\uff1f\u5982\u4f55\u6839\u636e\u6ce8\u91ca\u751f\u6210\u6587\u6863\uff1f Doxygen","title":"Comment"},{"location":"C++/Comment/Comment/#comment","text":"\u5728c++\u4e2d\u5982\u4f55\u8fdb\u884c\u6ce8\u91ca\uff1f\u5982\u4f55\u6839\u636e\u6ce8\u91ca\u751f\u6210\u6587\u6863\uff1f","title":"Comment"},{"location":"C++/Comment/Comment/#doxygen","text":"","title":"Doxygen"},{"location":"C++/Guide/Command-line/","text":"Command line arguments \u672c\u7ae0\u8ba8\u8bbac++\u4e2dcommand line arguments\u76f8\u5173\u7684\u95ee\u9898\u3002","title":"Introduction"},{"location":"C++/Guide/Command-line/#command-line-arguments","text":"\u672c\u7ae0\u8ba8\u8bbac++\u4e2dcommand line arguments\u76f8\u5173\u7684\u95ee\u9898\u3002","title":"Command line arguments"},{"location":"C++/Guide/Command-line/Command-line-arguments-parsing/","text":"Command line arguments python\u4e2d\u6709 argparse \u6765\u5e2e\u52a9\u7528\u6237\u5feb\u901fparse command line arguments\uff0c\u90a3c++\u8fd9\u5982\u4f55\u5b9e\u73b0command line arguments parsing\u5462\uff1f\u672c\u6587\u5bf9\u6b64\u8fdb\u884c\u603b\u7ed3\u3002 \u5165\u95e8\u793a\u4f8b Command line arguments in C/C++ \u8fdb\u9636\u793a\u4f8b How to parse command line parameters. \u4f7f\u7528library Boost.Program_options [How to Parse Command Line Arguments in C++? duplicate] jarro2783 / cxxopts","title":"Command-line-arguments-parsing"},{"location":"C++/Guide/Command-line/Command-line-arguments-parsing/#command-line-arguments","text":"python\u4e2d\u6709 argparse \u6765\u5e2e\u52a9\u7528\u6237\u5feb\u901fparse command line arguments\uff0c\u90a3c++\u8fd9\u5982\u4f55\u5b9e\u73b0command line arguments parsing\u5462\uff1f\u672c\u6587\u5bf9\u6b64\u8fdb\u884c\u603b\u7ed3\u3002","title":"Command line arguments"},{"location":"C++/Guide/Command-line/Command-line-arguments-parsing/#_1","text":"Command line arguments in C/C++","title":"\u5165\u95e8\u793a\u4f8b"},{"location":"C++/Guide/Command-line/Command-line-arguments-parsing/#_2","text":"How to parse command line parameters.","title":"\u8fdb\u9636\u793a\u4f8b"},{"location":"C++/Guide/Command-line/Command-line-arguments-parsing/#library","text":"","title":"\u4f7f\u7528library"},{"location":"C++/Guide/Command-line/Command-line-arguments-parsing/#boostprogram_options","text":"","title":"Boost.Program_options"},{"location":"C++/Guide/Command-line/Command-line-arguments-parsing/#how-to-parse-command-line-arguments-in-c-duplicate93","text":"","title":"[How to Parse Command Line Arguments in C++? duplicate]"},{"location":"C++/Guide/Command-line/Command-line-arguments-parsing/#jarro2783cxxopts","text":"","title":"jarro2783/cxxopts"},{"location":"C++/Guide/Concurrency/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u63cf\u8ff0\u5982\u4f55\u5728C++\u4e2d\u8fdb\u884cconcurrency\u7f16\u7a0b\u3002","title":"Introduction"},{"location":"C++/Guide/Concurrency/#_1","text":"\u672c\u7ae0\u63cf\u8ff0\u5982\u4f55\u5728C++\u4e2d\u8fdb\u884cconcurrency\u7f16\u7a0b\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"C++/Guide/Concurrency/CCiA/","text":"C++ concurrency in action","title":"Introduction"},{"location":"C++/Guide/Concurrency/CCiA/#c-concurrency-in-action","text":"","title":"C++ concurrency in action"},{"location":"C++/Guide/Concurrency/CCiA/ccia_code_samples-master/","text":"Companion Source Code for C++ Concurrency in Action 2 nd Edition This repository contains the source code from the second edition of C++ Concurrency in Action , by Anthony Williams. The listings folder contains the listings from the book. Each file is named listing_<chapter-number>.<listing-number>.cpp , so listing_1.1.cpp is the first listing in chapter 1, which is marked as listing 1.1 in the book, and listing_10.3.cpp is the third listing in chapter 10, which is marked as listing 10.3 in the book. The source code is released under the Boost Software License .","title":"Companion Source Code for C++ Concurrency in Action 2nd Edition"},{"location":"C++/Guide/Concurrency/CCiA/ccia_code_samples-master/#companion-source-code-for-c-concurrency-in-action-2nd-edition","text":"This repository contains the source code from the second edition of C++ Concurrency in Action , by Anthony Williams. The listings folder contains the listings from the book. Each file is named listing_<chapter-number>.<listing-number>.cpp , so listing_1.1.cpp is the first listing in chapter 1, which is marked as listing 1.1 in the book, and listing_10.3.cpp is the third listing in chapter 10, which is marked as listing 10.3 in the book. The source code is released under the Boost Software License .","title":"Companion Source Code for C++ Concurrency in Action 2nd Edition"},{"location":"C++/Guide/Resource-management/Resource-management/","text":"Resource management RAII\u7b49\u90fd\u662fC++\u7684resource management\u7b56\u7565\u3002","title":"Resource-management"},{"location":"C++/Guide/Resource-management/Resource-management/#resource-management","text":"RAII\u7b49\u90fd\u662fC++\u7684resource management\u7b56\u7565\u3002","title":"Resource management"},{"location":"C++/Guide/Resource-management/Memory-leak/Memory-leak/","text":"\u5185\u5b58\u6ea2\u51fa \u5185\u5b58\u6ea2\u51fa\u5c31\u662f\u4f60\u8981\u6c42\u5206\u914d\u7684\u5185\u5b58\u8d85\u51fa\u4e86\u7cfb\u7edf\u80fd\u7ed9\u4f60\u7684\uff0c\u7cfb\u7edf\u4e0d\u80fd\u6ee1\u8db3\u9700\u6c42\uff0c\u4e8e\u662f\u4ea7\u751f\u6ea2\u51fa\u3002\u4e00\u4e2a\u76d8\u5b50\u7528\u5c3d\u5404\u79cd\u65b9\u6cd5\u53ea\u80fd\u88c54 \u4e2a\u679c\u5b50\uff0c\u4f60\u88c5\u4e865\u4e2a\uff0c\u7ed3\u679c\u6389\u5012\u5730\u4e0a\u4e0d\u80fd\u5403\u4e86\u3002\u8fd9\u5c31\u662f\u6ea2\u51fa\uff01\u6bd4\u65b9\u8bf4\u6808\uff0c\u6808\u6ee1\u65f6\u518d\u505a\u8fdb \u6808\u5fc5\u5b9a\u4ea7\u751f\u7a7a\u95f4\u6ea2\u51fa\uff0c\u53eb\u4e0a\u6ea2\uff0c\u6808\u7a7a\u65f6\u518d\u505a\u9000\u6808\u4e5f\u4ea7\u751f\u7a7a\u95f4\u6ea2\u51fa\uff0c\u79f0\u4e3a**\u4e0b\u6ea2**\u3002\u5c31\u662f\u5206\u914d\u7684\u5185\u5b58\u4e0d\u8db3\u4ee5\u653e\u4e0b\u6570\u636e\u9879\u5e8f\u5217,\u79f0\u4e3a**\u5185\u5b58\u6ea2\u51fa**. \uff1f\uff1f\u5982\u679c\u7533\u8bf7\u4e0d\u5230\u9700\u8981\u5bb9\u91cf\u7684\u7a7a\u95f4\uff0c\u4f1a\u6709\u4ec0\u4e48\u540e\u679c\uff1f\uff1f\u6211\u8bb0\u5f97\u4e4b\u524d\u5728\u9605\u8bfbAPUE\u7684\u65f6\u5019\uff0c\u91cc\u9762\u6709\u4e00\u4e2a\u5b9e\u4f8b\uff0c\u5728\u4f7f\u7528malloc\u53bb\u7533\u8bf7\u7a7a\u95f4\u540e\uff0c\u4f1a\u5224\u65ad\u7533\u8bf7\u5230\u7684\u7a7a\u95f4\u548c\u7533\u8bf7\u7684\u7a7a\u95f4\u5927\u5c0f\u662f\u5426\u76f8\u7b49\uff0c\u5982\u679c\u4e0d\u76f8\u7b49\uff0c\u662f\u4f1a\u62a5\u9519\u7684\u3002\u9700\u8981\u518d\u770b\u770b\u8fd9\u4e2a\u5b9e\u4f8b\u3002 \u5185\u5b58\u6cc4\u6f0f \u5185\u5b58\u6cc4\u6f0f\u662f\u6307\u4f60\u5411\u7cfb\u7edf\u7533\u8bf7\u5206\u914d\u5185\u5b58\u8fdb\u884c\u4f7f\u7528(new)\uff0c\u53ef\u662f\u4f7f\u7528\u5b8c\u4e86\u4ee5\u540e\u5374\u4e0d\u5f52\u8fd8(delete)\uff0c\u7ed3\u679c\u4f60\u7533\u8bf7\u5230\u7684\u90a3\u5757\u5185\u5b58\u4f60\u81ea\u5df1\u4e5f\u4e0d\u80fd\u518d\u8bbf\u95ee\uff08\u4e5f\u8bb8\u4f60\u628a\u5b83\u7684\u5730\u5740\u7ed9\u5f04\u4e22\u4e86\uff09\uff0c\u800c\u7cfb\u7edf\u4e5f\u4e0d\u80fd\u518d\u6b21\u5c06\u5b83\u5206\u914d\u7ed9\u9700\u8981\u7684\u7a0b\u5e8f\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u8fd9\u7247\u5185\u5b58\u7a7a\u95f4\u662f\u65e0\u6cd5\u518d\u88ab\u4f7f\u7528\u4e86\u3002 \u4ee5\u53d1\u751f\u7684\u65b9\u5f0f\u6765\u5206\u7c7b\uff0c\u5185\u5b58\u6cc4\u6f0f\u53ef\u4ee5\u5206\u4e3a4 \u7c7b\uff1a \u5e38\u53d1\u6027\u5185\u5b58\u6cc4\u6f0f\u3002\u53d1\u751f\u5185\u5b58\u6cc4\u6f0f\u7684\u4ee3\u7801\u4f1a\u88ab\u591a\u6b21\u6267\u884c\u5230\uff0c\u6bcf\u6b21\u88ab\u6267\u884c\u7684\u65f6\u5019\u90fd\u4f1a\u5bfc\u81f4\u4e00\u5757\u5185\u5b58\u6cc4\u6f0f\u3002 \u5076\u53d1\u6027\u5185\u5b58\u6cc4\u6f0f\u3002\u53d1\u751f\u5185\u5b58\u6cc4\u6f0f\u7684\u4ee3\u7801\u53ea\u6709\u5728\u67d0\u4e9b\u7279\u5b9a\u73af\u5883\u6216\u64cd\u4f5c\u8fc7\u7a0b\u4e0b\u624d\u4f1a\u53d1\u751f\u3002\u5e38\u53d1\u6027\u548c\u5076\u53d1\u6027\u662f\u76f8\u5bf9\u7684\u3002\u5bf9\u4e8e\u7279\u5b9a\u7684\u73af\u5883\uff0c\u5076\u53d1\u6027\u7684\u4e5f\u8bb8\u5c31\u53d8\u6210\u4e86\u5e38\u53d1\u6027\u7684\u3002\u6240\u4ee5\u6d4b\u8bd5\u73af\u5883\u548c\u6d4b\u8bd5\u65b9\u6cd5\u5bf9\u68c0\u6d4b\u5185\u5b58\u6cc4\u6f0f\u81f3\u5173\u91cd\u8981\u3002 \u4e00\u6b21\u6027\u5185\u5b58\u6cc4\u6f0f\u3002\u53d1\u751f\u5185\u5b58\u6cc4\u6f0f\u7684\u4ee3\u7801\u53ea\u4f1a\u88ab\u6267\u884c\u4e00\u6b21\uff0c\u6216\u8005\u7531\u4e8e\u7b97\u6cd5\u4e0a\u7684\u7f3a\u9677\uff0c\u5bfc\u81f4\u603b\u4f1a\u6709\u4e00\u5757\u4ec5\u4e14\u4e00\u5757\u5185\u5b58\u53d1\u751f\u6cc4\u6f0f\u3002\u6bd4\u5982\uff0c\u5728\u7c7b\u7684\u6784\u9020\u51fd\u6570\u4e2d\u5206\u914d\u5185\u5b58\uff0c\u5728\u6790\u6784\u51fd\u6570\u4e2d\u5374\u6ca1\u6709\u91ca\u653e\u8be5\u5185\u5b58\uff0c\u6240\u4ee5\u5185\u5b58\u6cc4\u6f0f\u53ea\u4f1a\u53d1\u751f\u4e00\u6b21\u3002 \u9690\u5f0f\u5185\u5b58\u6cc4\u6f0f\u3002\u7a0b\u5e8f\u5728\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u4e0d\u505c\u7684\u5206\u914d\u5185\u5b58\uff0c\u4f46\u662f\u76f4\u5230\u7ed3\u675f\u7684\u65f6\u5019\u624d\u91ca\u653e\u5185\u5b58\u3002\u4e25\u683c\u7684\u8bf4\u8fd9\u91cc\u5e76\u6ca1\u6709\u53d1\u751f\u5185\u5b58\u6cc4\u6f0f\uff0c\u56e0\u4e3a\u6700\u7ec8\u7a0b\u5e8f\u91ca\u653e\u4e86\u6240\u6709\u7533\u8bf7\u7684\u5185\u5b58\u3002\u4f46\u662f\u5bf9\u4e8e\u4e00\u4e2a\u670d\u52a1\u5668\u7a0b\u5e8f\uff0c\u9700\u8981\u8fd0\u884c\u51e0\u5929\uff0c\u51e0\u5468\u751a\u81f3\u51e0\u4e2a\u6708\uff0c\u4e0d\u53ca\u65f6\u91ca\u653e\u5185\u5b58\u4e5f\u53ef\u80fd\u5bfc\u81f4\u6700\u7ec8\u8017\u5c3d\u7cfb\u7edf\u7684\u6240\u6709\u5185\u5b58\u3002\u6240\u4ee5\uff0c\u6211\u4eec\u79f0\u8fd9\u7c7b\u5185\u5b58\u6cc4\u6f0f\u4e3a\u9690\u5f0f\u5185\u5b58\u6cc4\u6f0f\u3002 \u4ece\u7528\u6237\u4f7f\u7528\u7a0b\u5e8f\u7684\u89d2\u5ea6\u6765\u770b\uff0c\u5185\u5b58\u6cc4\u6f0f\u672c\u8eab\u4e0d\u4f1a\u4ea7\u751f\u4ec0\u4e48\u5371\u5bb3\uff0c\u4f5c\u4e3a\u4e00\u822c\u7684\u7528\u6237\uff0c\u6839\u672c\u611f\u89c9\u4e0d\u5230\u5185\u5b58\u6cc4\u6f0f\u7684\u5b58\u5728\u3002\u771f\u6b63\u6709\u5371\u5bb3\u7684\u662f\u5185\u5b58\u6cc4\u6f0f\u7684**\u5806\u79ef**\uff0c\u8fd9\u4f1a\u6700\u7ec8\u6d88\u8017\u5c3d\u7cfb\u7edf\u6240\u6709\u7684\u5185\u5b58\u3002\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u6765\u8bf4\uff0c\u4e00\u6b21\u6027\u5185\u5b58\u6cc4\u6f0f\u5e76\u6ca1\u6709\u4ec0\u4e48\u5371\u5bb3\uff0c\u56e0\u4e3a\u5b83\u4e0d\u4f1a\u5806\u79ef\uff0c\u800c\u9690\u5f0f\u5185\u5b58\u6cc4\u6f0f\u5371\u5bb3\u6027\u5219\u975e\u5e38\u5927\uff0c\u56e0\u4e3a\u8f83\u4e4b\u4e8e\u5e38\u53d1\u6027\u548c\u5076\u53d1\u6027\u5185\u5b58,\u6cc4\u6f0f\u5b83\u66f4\u96be\u88ab\u68c0\u6d4b\u5230\u3002 \u5185\u5b58\u8d8a\u754c \u4f55\u8c13\u5185\u5b58\u8bbf\u95ee\u8d8a\u754c\uff0c\u7b80\u5355\u7684\u8bf4\uff0c\u4f60\u5411\u7cfb\u7edf\u7533\u8bf7\u4e86\u4e00\u5757\u5185\u5b58\uff0c\u5728\u4f7f\u7528\u8fd9\u5757\u5185\u5b58\u7684\u65f6\u5019\uff0c\u8d85\u51fa\u4e86\u4f60\u7533\u8bf7\u7684\u8303\u56f4\u3002 \u5185\u5b58\u8d8a\u754c\u8fd9\u6837\u7684\u9519\u8bef\u5f15\u8d77\u7684\u95ee\u9898\u5b58\u5728\u6781\u5927\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u6709\u65f6\u5927\uff0c\u6709\u65f6\u5c0f\uff0c\u6709\u65f6\u53ef\u80fd\u4e0d\u4f1a\u5bf9\u7a0b\u5e8f\u7684\u8fd0\u884c\u4ea7\u751f\u5f71\u54cd\u3002\u8fd9\u79cd\u9519\u8bef\uff0c\u5927\u90e8\u5206\u60c5\u51b5\u4f1a\u629b\u51faAV\uff08access violation\uff09\u5f02\u5e38\uff0c\u6709\u65f6\u4e0d\u629b\u51fa\u5f02\u5e38, \u6709\u65f6\u5bfc\u81f4\u8f6f\u4ef6\u76f4\u63a5\u5d29\u6e83(\u7c7b\u4f3c\"Abnormal program termination\")\uff1b\u800c\u4e14\u629b\u51fa\u5f02\u5e38\u7684\u5730\u65b9\u5927\u591a\u4e0d\u662f\u8d8a\u754c\u8bbf\u95ee\u7684\u5730\u65b9(\u6bd4\u5982\u4e0b\u9762\u7684\u4f8b\u5b50),\u8ba9\u4eba\u6478\u4e0d\u7740\u5934\u8111; \u4ec0\u4e48\u539f\u56e0\u4f1a\u9020\u6210\u5185\u5b58\u8d8a\u754c\u4f7f\u7528\u5462\uff1f\u6709\u4ee5\u4e0b\u51e0\u79cd\u60c5\u51b5\uff0c\u53ef\u4f9b\u53c2\u8003\uff1a \u4f8b1\uff1a char buf[32] = {0}; for(int i=0; i<n; i++)// n < 32 or n > 32 { buf[i] = 'x'; } .... \u4f8b2: char buf[32] = {0}; string str = \"this is a test sting !!!!\"; sprintf(buf, \"this is a test buf!string:%s\", str.c_str()); //out of buffer space .... \u4f8b3: string str = \"this is a test string!!!!\"; char buf[16] = {0}; strcpy(buf, str.c_str()); //out of buffer space \u4f8b4\uff1a char *tmpc=new char[len-48+1]; memset(tmpc,0,len); //\u6211\u4eec\u7533\u8bf7\u4e86len-48+1\u4e2a\u5b57\u8282\u7684\u5185\u5b58\u7a7a\u95f4,\u4f46\u662f\u5728memeset\u7684\u65f6\u5019\u5374\u586b\u5145\u4e86len\u4e2a\u5b57\u8282\u7684\u7a7a\u95f4, //\u591a\u586b\u5145\u4e8647\u4e2a\u5b57\u8282\u7684\u7a7a\u95f4,\u800c\u8fd9\u4e2a\u8d8a\u754c\u586b\u5145\u53ef\u80fd\u5c31\u975e\u6cd5\u586b\u5145\u4e86tmpStr\u5185\u90e8\u7684\u5185\u5b58\u7a7a\u95f4,\u7834\u574f\u4e86tmpStr\u5185\u90e8\u7684\u7ed3\u6784, //\u4ece\u800c\u9020\u6210std::string\u5728\u51fd\u6570operator+=\u7684\u65f6\u5019\u629b\u51fa\u5f02\u5e38! tmpStr += funCode;//AV\u5f02\u5e38\u629b\u51fa\u7684\u5730\u65b9 \u5e38\u7528\u7684\u5185\u5b58\u64cd\u4f5c\u51fd\u6570\u90fd\u5b58\u5728\u8fd9\u79cd\u9690\u60a3\uff0c\u5e38\u7528\u7684\u5185\u5b58\u64cd\u4f5c\u51fd\u6570\u5982\u4e0b\uff1a sprintf snprintf vsprintf vsnprintf strcpy strncpy strcat memcpy memmove memset bcopy \u5f53\u8fd9\u6837\u7684\u4ee3\u7801\u4e00\u65e6\u8fd0\u884c\uff0c\u9519\u8bef\u5c31\u5728\u6240\u96be\u514d\uff0c\u4f1a\u5e26\u6765\u7684\u540e\u679c\u4e5f\u662f\u4e0d\u786e\u5b9a\u7684\uff0c\u901a\u5e38\u53ef\u80fd\u4f1a\u9020\u6210\u5982\u4e0b\u540e\u679c\uff1a \u7834\u574f\u4e86\u5806\u4e2d\u7684\u5185\u5b58\u5206\u914d\u4fe1\u606f\u6570\u636e\uff0c\u7279\u522b\u662f\u52a8\u6001\u5206\u914d\u7684\u5185\u5b58\u5757\u7684\u5185\u5b58\u4fe1\u606f\u6570\u636e\uff0c\u56e0\u4e3a\u64cd\u4f5c\u7cfb\u7edf\u5728\u5206\u914d\u548c\u91ca\u653e\u5185\u5b58\u5757\u65f6\u9700\u8981\u8bbf\u95ee\u8be5\u6570\u636e\uff0c\u4e00\u65e6\u8be5\u6570\u636e\u88ab\u7834\u574f\uff0c\u4ee5\u4e0b\u7684\u51e0\u79cd\u60c5\u51b5\u90fd\u53ef\u80fd\u4f1a\u51fa\u73b0\u3002 *** glibc detected *** free(): invalid pointer: *** glibc detected *** malloc(): memory corruption: *** glibc detected *** double free or corruption (out): 0x00000000005c18a0 *** *** glibc detected *** corrupted double-linked list: 0x00000000005ab150 *** \u7834\u574f\u4e86\u7a0b\u5e8f\u81ea\u5df1\u7684\u5176\u4ed6\u5bf9\u8c61\u7684\u5185\u5b58\u7a7a\u95f4\uff0c\u8fd9\u79cd\u7834\u574f\u4f1a\u5f71\u54cd\u7a0b\u5e8f\u6267\u884c\u7684\u4e0d\u6b63\u786e\u6027\uff0c\u5f53\u7136\u4e5f\u4f1a\u8bf1\u53d1coredump\uff0c\u5982\u7834\u574f\u4e86\u6307\u9488\u6570\u636e\u3002 \u7834\u574f\u4e86\u7a7a\u95f2\u5185\u5b58\u5757\uff0c\u5f88\u5e78\u8fd0\uff0c\u8fd9\u6837\u4e0d\u4f1a\u4ea7\u751f\u4ec0\u4e48\u95ee\u9898\uff0c\u4f46\u8c01\u77e5\u9053\u4ec0\u4e48\u65f6\u5019\u4e0d\u5e78\u4f1a\u964d\u4e34\u5462\uff1f \u901a\u5e38\uff0c\u4ee3\u7801\u9519\u8bef\u88ab\u6fc0\u53d1\u4e5f\u662f\u5076\u7136\u7684\uff0c\u4e5f\u5c31\u662f\u8bf4\u4e4b\u524d\u4f60\u7684\u7a0b\u5e8f\u4e00\u76f4\u6b63\u5e38\uff0c\u53ef\u80fd\u7531\u4e8e\u4f60\u4e3a\u7c7b\u589e\u52a0\u4e86\u4e24\u4e2a\u6210\u5458\u53d8\u91cf\uff0c\u6216\u8005\u6539\u53d8\u4e86\u67d0\u4e00\u90e8\u5206\u4ee3\u7801\uff0ccoredump\u5c31\u9891\u7e41\u53d1\u751f\uff0c\u800c\u4f60\u589e\u52a0\u7684\u4ee3\u7801\u7edd\u4e0d\u4f1a\u6709\u4efb\u4f55\u95ee\u9898\uff0c\u8fd9\u65f6\u4f60\u5c31\u5e94\u8be5\u8003\u8651\u662f\u5426\u662f\u67d0\u4e9b\u5185\u5b58\u88ab\u7834\u574f\u4e86\u3002 \u6392\u67e5\u7684\u539f\u5219\uff0c\u9996\u5148\u662f\u4fdd\u8bc1\u80fd\u91cd\u73b0\u9519\u8bef\uff0c\u6839\u636e\u9519\u8bef\u4f30\u8ba1\u53ef\u80fd\u7684\u73af\u8282\uff0c\u9010\u6b65\u88c1\u51cf\u4ee3\u7801\uff0c\u7f29\u5c0f\u6392\u67e5\u7a7a\u95f4\u3002\u5982\u679c\u6709\u7528\u5230\u81ea\u5df1\u7f16\u5199\u7684\u52a8\u6001\u5e93\u7684\u60c5\u51b5\uff0c\u8981\u786e\u4fdd\u52a8\u6001\u5e93\u7684\u7f16\u8bd1\u4e0e\u7a0b\u5e8f\u7f16\u8bd1\u7684\u73af\u5883\u4e00\u81f4\u3002 \u7f13\u51b2\u533a\u6ea2\u51fa\uff1a \u7f13\u51b2\u533a\u6ea2\u51fa\u662f\u6307\u5f53\u8ba1\u7b97\u673a\u5411**\u7f13\u51b2\u533a**\u5185\u586b\u5145\u6570\u636e\u4f4d\u6570\u65f6\u8d85\u8fc7\u4e86\u7f13\u51b2\u533a\u672c\u8eab\u7684\u5bb9\u91cf,\u5bfc\u81f4\u6ea2\u51fa\u7684\u6570\u636e\u8986\u76d6\u5728\u5408\u6cd5\u6570\u636e\u4e0a\u3002\u7406\u60f3\u7684\u60c5\u51b5\u662f\u7a0b\u5e8f\u68c0\u67e5\u6570\u636e\u957f\u5ea6\uff0c\u5e76\u4e14\u4e0d\u5141\u8bb8\u8f93\u5165\u8d85\u8fc7\u7f13\u51b2\u533a\u957f\u5ea6\u7684\u5b57\u7b26,\u4f46\u662f\u7edd\u5927\u591a\u6570\u7a0b\u5e8f\u90fd\u4f1a\u5047\u8bbe\u6570\u636e\u957f\u5ea6\u603b\u662f\u4e0e\u6240\u5206\u914d\u7684\u50a8\u5b58\u7a7a\u95f4\u76f8\u5339\u914d,\u8fd9\u5c31\u4e3a\u7f13\u51b2\u533a\u6ea2\u51fa\u57cb\u4e0b\u9690\u60a3.\u64cd\u4f5c\u7cfb\u7edf\u6240\u4f7f\u7528\u7684\u7f13\u51b2\u533a \u53c8\u88ab\u79f0\u4e3a\"\u5806\u6808\". \u5728\u5404\u4e2a\u64cd\u4f5c\u8fdb\u7a0b\u4e4b\u95f4,\u6307\u4ee4\u4f1a\u88ab\u4e34\u65f6\u50a8\u5b58\u5728\"\u5806\u6808\"\u5f53\u4e2d,\"\u5806\u6808\"\u4e5f\u4f1a\u51fa\u73b0\u7f13\u51b2\u533a\u6ea2\u51fa\u3002 \u6808\u6ea2\u51fa\uff1a \u3000\u6808\u6ea2\u51fa\u5c31\u662f\u7f13\u51b2\u533a\u6ea2\u51fa\u7684\u4e00\u79cd\u3002 \u7531\u4e8e\u7f13\u51b2\u533a\u6ea2\u51fa\u800c\u4f7f\u5f97\u6709\u7528\u7684\u5b58\u50a8\u5355\u5143\u88ab\u6539\u5199,\u5f80\u5f80\u4f1a\u5f15\u53d1\u4e0d\u53ef\u9884\u6599\u7684\u540e\u679c\u3002\u7a0b\u5e8f\u5728\u8fd0\u884c\u8fc7\u7a0b\u4e2d\uff0c\u4e3a\u4e86\u4e34\u65f6\u5b58\u53d6\u6570\u636e\u7684\u9700\u8981\uff0c\u4e00\u822c\u90fd\u8981\u5206\u914d\u4e00\u4e9b\u5185\u5b58\u7a7a\u95f4\uff0c\u901a\u5e38\u79f0\u8fd9\u4e9b\u7a7a\u95f4\u4e3a\u7f13\u51b2\u533a\u3002\u5982\u679c\u5411\u7f13\u51b2\u533a\u4e2d\u5199\u5165\u8d85\u8fc7\u5176\u672c\u8eab\u957f\u5ea6\u7684\u6570\u636e\uff0c\u4ee5\u81f4\u4e8e\u7f13\u51b2\u533a\u65e0\u6cd5\u5bb9\u7eb3\uff0c\u5c31\u4f1a\u9020\u6210\u7f13\u51b2\u533a\u4ee5\u5916\u7684\u5b58\u50a8\u5355\u5143\u88ab\u6539\u5199\uff0c\u8fd9\u79cd\u73b0\u8c61\u5c31\u79f0\u4e3a\u7f13\u51b2\u533a\u6ea2\u51fa\u3002 \u6808\u6ea2\u51fa\u5c31\u662f\u7f13\u51b2\u533a\u6ea2\u51fa\u7684\u4e00\u79cd\u3002 \u6628\u5929\u6211\u5c31\u78b0\u5230\u4e86\u6570\u7ec4\u8d8a\u754c\u5bfc\u81f4\u7684\u9519\u8bef\u3002\u8ba9\u6211\u6bd4\u8f83\u597d\u5947\u7684\u662f\uff1a c++\u6ca1\u6709\u6570\u7ec4\u8d8a\u754c\u68c0\u67e5\u673a\u5236 \u6570\u7ec4\u8d8a\u754c\u4e4b\u540e\uff0c\u5c45\u7136\u80fd\u591f\u8bbf\u95ee\u5230\u6570\u636e\uff0c\u867d\u7136\u8fd9\u4e9b\u6570\u636e\u90fd\u662f\u975e\u6cd5\u7684\u3002 \u8fd9\u4e9b\u662f\u9700\u8981\u6211\u8fdb\u884c\u7814\u7a76\u7684 \u5173\u4e8e\u6570\u7ec4\u8d8a\u754c\uff0c\u6d89\u53ca\u5230\u5982\u4e0b\u95ee\u9898\uff1a \u4f7f\u7528char array\u6765\u4fdd\u5b58\u5b57\u7b26\u4e32\uff0c\u8981\u4f7f\u7528\u5982\u4e0b\u5199\u6cd5\uff1a p_arr=new char[strlen(str)+1] +1\u662f\u4e3a\u4e86\u8981\u7ed9'\\0'\u5360\u4e2a\u5ea7\uff0c\u9632\u6b62\u8d8a\u754c\u3002 \u521a\u521a\u6309\u7167\u8fd9\u4e2a\u7f51\u5740http://blog.csdn.net/sxhelijian/article/details/8928528/ \u4e0a\u7684\u4e8b\u4f8b\u7528gdb\u8c03\u8bd5\u4e86\u4e00\u4e0b\uff0c\u5e76\u6ca1\u6709\u53d1\u73b0\u4ec0\u4e48\u5927\u7684\u95ee\u9898\uff0c\u6709\u4e00\u4e2a\u95ee\u9898\u5c31\u662f\uff1a p \u53d8\u91cf \u548ccout\u8f93\u51fa\u7684\u5185\u5bb9\u4e0d\u76f8\u540c\uff0c\u5982\u4e0b (gdb) r Starting program: /home/dk/linux_and_c/cpp/array_out_of_bound/cin_array_2 abcde abcde Breakpoint 1, main () at cin_array_2.cpp:8 8 cout<<a<<endl; (gdb) p a $3 = \"abcd\" (gdb) p b $4 = \"abcd\" (gdb) c Continuing. abcde abcde Program exited normally. \u663e\u7136\u8fd9\u5c31\u662f\u7a0b\u5e8f\u7684\u5f02\u5e38\u6240\u5728\uff0c\u7a0b\u5e8f\u5df2\u7ecf\u53d1\u751f\u4e86\u8d8a\u754c\u3002 \u4ec0\u4e48\u662f\u8d8a\u754c\u8bbf\u95ee\uff1f\uff1f \u53c2\u89c1\u300a\u5185\u5b58\u6ea2\u51fa\u3001\u5185\u5b58\u6cc4\u9732\u3001\u5185\u5b58\u8d8a\u754c\u3001\u7f13\u51b2\u533a\u6ea2\u51fa\u3001\u6808\u6ea2\u51fa\u300b \u68c0\u67e5\u4e0b\u6807\u662f\u5426\u8d8a\u754c\u6570\u7ec4\u7c7b \u53ef\u4ee5\u53c2\u8003\u5982\u4e0b\u4ee3\u7801\uff1a #include <iostream> #include <string> using namespace std; class check { public: check(char*s) { str=new char[strlen(s)+1]; strcpy(str,s); len=strlen(s); } char operator[](int n) { if(n>len-1) { cout<<\"\u6570\u7ec4\u4e0b\u6807\u8d8a\u754c\"<<endl; return ' '; } else { cout<<\"\u6570\u7ec4\u4e0b\u6807\u6ca1\u6709\u8d8a\u754c\"<<endl; return *(str+n); } } void Print(){cout<<str<<endl;} private: char *str; int len; }; void main() { check array(\"GoodMorning\");//\u7c7b\u7684\u6784\u9020\u51fd\u6570 array.Print(); cout<<\"Location 0:\"<<array[0]<<endl;//\u5224\u65ad\u4e0b\u6807\u4e3a0\u662f\u5426\u8d8a\u754c cout<<\"Location 20:\"<<array[20]<<endl;//\u5224\u65ad\u4e0b\u6807\u4e3a20\u662f\u5426\u8d8a\u754c }","title":"Memory-leak"},{"location":"C++/Guide/Resource-management/Memory-leak/Memory-leak/#_1","text":"\u5185\u5b58\u6ea2\u51fa\u5c31\u662f\u4f60\u8981\u6c42\u5206\u914d\u7684\u5185\u5b58\u8d85\u51fa\u4e86\u7cfb\u7edf\u80fd\u7ed9\u4f60\u7684\uff0c\u7cfb\u7edf\u4e0d\u80fd\u6ee1\u8db3\u9700\u6c42\uff0c\u4e8e\u662f\u4ea7\u751f\u6ea2\u51fa\u3002\u4e00\u4e2a\u76d8\u5b50\u7528\u5c3d\u5404\u79cd\u65b9\u6cd5\u53ea\u80fd\u88c54 \u4e2a\u679c\u5b50\uff0c\u4f60\u88c5\u4e865\u4e2a\uff0c\u7ed3\u679c\u6389\u5012\u5730\u4e0a\u4e0d\u80fd\u5403\u4e86\u3002\u8fd9\u5c31\u662f\u6ea2\u51fa\uff01\u6bd4\u65b9\u8bf4\u6808\uff0c\u6808\u6ee1\u65f6\u518d\u505a\u8fdb \u6808\u5fc5\u5b9a\u4ea7\u751f\u7a7a\u95f4\u6ea2\u51fa\uff0c\u53eb\u4e0a\u6ea2\uff0c\u6808\u7a7a\u65f6\u518d\u505a\u9000\u6808\u4e5f\u4ea7\u751f\u7a7a\u95f4\u6ea2\u51fa\uff0c\u79f0\u4e3a**\u4e0b\u6ea2**\u3002\u5c31\u662f\u5206\u914d\u7684\u5185\u5b58\u4e0d\u8db3\u4ee5\u653e\u4e0b\u6570\u636e\u9879\u5e8f\u5217,\u79f0\u4e3a**\u5185\u5b58\u6ea2\u51fa**. \uff1f\uff1f\u5982\u679c\u7533\u8bf7\u4e0d\u5230\u9700\u8981\u5bb9\u91cf\u7684\u7a7a\u95f4\uff0c\u4f1a\u6709\u4ec0\u4e48\u540e\u679c\uff1f\uff1f\u6211\u8bb0\u5f97\u4e4b\u524d\u5728\u9605\u8bfbAPUE\u7684\u65f6\u5019\uff0c\u91cc\u9762\u6709\u4e00\u4e2a\u5b9e\u4f8b\uff0c\u5728\u4f7f\u7528malloc\u53bb\u7533\u8bf7\u7a7a\u95f4\u540e\uff0c\u4f1a\u5224\u65ad\u7533\u8bf7\u5230\u7684\u7a7a\u95f4\u548c\u7533\u8bf7\u7684\u7a7a\u95f4\u5927\u5c0f\u662f\u5426\u76f8\u7b49\uff0c\u5982\u679c\u4e0d\u76f8\u7b49\uff0c\u662f\u4f1a\u62a5\u9519\u7684\u3002\u9700\u8981\u518d\u770b\u770b\u8fd9\u4e2a\u5b9e\u4f8b\u3002","title":"\u5185\u5b58\u6ea2\u51fa"},{"location":"C++/Guide/Resource-management/Memory-leak/Memory-leak/#_2","text":"\u5185\u5b58\u6cc4\u6f0f\u662f\u6307\u4f60\u5411\u7cfb\u7edf\u7533\u8bf7\u5206\u914d\u5185\u5b58\u8fdb\u884c\u4f7f\u7528(new)\uff0c\u53ef\u662f\u4f7f\u7528\u5b8c\u4e86\u4ee5\u540e\u5374\u4e0d\u5f52\u8fd8(delete)\uff0c\u7ed3\u679c\u4f60\u7533\u8bf7\u5230\u7684\u90a3\u5757\u5185\u5b58\u4f60\u81ea\u5df1\u4e5f\u4e0d\u80fd\u518d\u8bbf\u95ee\uff08\u4e5f\u8bb8\u4f60\u628a\u5b83\u7684\u5730\u5740\u7ed9\u5f04\u4e22\u4e86\uff09\uff0c\u800c\u7cfb\u7edf\u4e5f\u4e0d\u80fd\u518d\u6b21\u5c06\u5b83\u5206\u914d\u7ed9\u9700\u8981\u7684\u7a0b\u5e8f\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u8fd9\u7247\u5185\u5b58\u7a7a\u95f4\u662f\u65e0\u6cd5\u518d\u88ab\u4f7f\u7528\u4e86\u3002 \u4ee5\u53d1\u751f\u7684\u65b9\u5f0f\u6765\u5206\u7c7b\uff0c\u5185\u5b58\u6cc4\u6f0f\u53ef\u4ee5\u5206\u4e3a4 \u7c7b\uff1a \u5e38\u53d1\u6027\u5185\u5b58\u6cc4\u6f0f\u3002\u53d1\u751f\u5185\u5b58\u6cc4\u6f0f\u7684\u4ee3\u7801\u4f1a\u88ab\u591a\u6b21\u6267\u884c\u5230\uff0c\u6bcf\u6b21\u88ab\u6267\u884c\u7684\u65f6\u5019\u90fd\u4f1a\u5bfc\u81f4\u4e00\u5757\u5185\u5b58\u6cc4\u6f0f\u3002 \u5076\u53d1\u6027\u5185\u5b58\u6cc4\u6f0f\u3002\u53d1\u751f\u5185\u5b58\u6cc4\u6f0f\u7684\u4ee3\u7801\u53ea\u6709\u5728\u67d0\u4e9b\u7279\u5b9a\u73af\u5883\u6216\u64cd\u4f5c\u8fc7\u7a0b\u4e0b\u624d\u4f1a\u53d1\u751f\u3002\u5e38\u53d1\u6027\u548c\u5076\u53d1\u6027\u662f\u76f8\u5bf9\u7684\u3002\u5bf9\u4e8e\u7279\u5b9a\u7684\u73af\u5883\uff0c\u5076\u53d1\u6027\u7684\u4e5f\u8bb8\u5c31\u53d8\u6210\u4e86\u5e38\u53d1\u6027\u7684\u3002\u6240\u4ee5\u6d4b\u8bd5\u73af\u5883\u548c\u6d4b\u8bd5\u65b9\u6cd5\u5bf9\u68c0\u6d4b\u5185\u5b58\u6cc4\u6f0f\u81f3\u5173\u91cd\u8981\u3002 \u4e00\u6b21\u6027\u5185\u5b58\u6cc4\u6f0f\u3002\u53d1\u751f\u5185\u5b58\u6cc4\u6f0f\u7684\u4ee3\u7801\u53ea\u4f1a\u88ab\u6267\u884c\u4e00\u6b21\uff0c\u6216\u8005\u7531\u4e8e\u7b97\u6cd5\u4e0a\u7684\u7f3a\u9677\uff0c\u5bfc\u81f4\u603b\u4f1a\u6709\u4e00\u5757\u4ec5\u4e14\u4e00\u5757\u5185\u5b58\u53d1\u751f\u6cc4\u6f0f\u3002\u6bd4\u5982\uff0c\u5728\u7c7b\u7684\u6784\u9020\u51fd\u6570\u4e2d\u5206\u914d\u5185\u5b58\uff0c\u5728\u6790\u6784\u51fd\u6570\u4e2d\u5374\u6ca1\u6709\u91ca\u653e\u8be5\u5185\u5b58\uff0c\u6240\u4ee5\u5185\u5b58\u6cc4\u6f0f\u53ea\u4f1a\u53d1\u751f\u4e00\u6b21\u3002 \u9690\u5f0f\u5185\u5b58\u6cc4\u6f0f\u3002\u7a0b\u5e8f\u5728\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u4e0d\u505c\u7684\u5206\u914d\u5185\u5b58\uff0c\u4f46\u662f\u76f4\u5230\u7ed3\u675f\u7684\u65f6\u5019\u624d\u91ca\u653e\u5185\u5b58\u3002\u4e25\u683c\u7684\u8bf4\u8fd9\u91cc\u5e76\u6ca1\u6709\u53d1\u751f\u5185\u5b58\u6cc4\u6f0f\uff0c\u56e0\u4e3a\u6700\u7ec8\u7a0b\u5e8f\u91ca\u653e\u4e86\u6240\u6709\u7533\u8bf7\u7684\u5185\u5b58\u3002\u4f46\u662f\u5bf9\u4e8e\u4e00\u4e2a\u670d\u52a1\u5668\u7a0b\u5e8f\uff0c\u9700\u8981\u8fd0\u884c\u51e0\u5929\uff0c\u51e0\u5468\u751a\u81f3\u51e0\u4e2a\u6708\uff0c\u4e0d\u53ca\u65f6\u91ca\u653e\u5185\u5b58\u4e5f\u53ef\u80fd\u5bfc\u81f4\u6700\u7ec8\u8017\u5c3d\u7cfb\u7edf\u7684\u6240\u6709\u5185\u5b58\u3002\u6240\u4ee5\uff0c\u6211\u4eec\u79f0\u8fd9\u7c7b\u5185\u5b58\u6cc4\u6f0f\u4e3a\u9690\u5f0f\u5185\u5b58\u6cc4\u6f0f\u3002 \u4ece\u7528\u6237\u4f7f\u7528\u7a0b\u5e8f\u7684\u89d2\u5ea6\u6765\u770b\uff0c\u5185\u5b58\u6cc4\u6f0f\u672c\u8eab\u4e0d\u4f1a\u4ea7\u751f\u4ec0\u4e48\u5371\u5bb3\uff0c\u4f5c\u4e3a\u4e00\u822c\u7684\u7528\u6237\uff0c\u6839\u672c\u611f\u89c9\u4e0d\u5230\u5185\u5b58\u6cc4\u6f0f\u7684\u5b58\u5728\u3002\u771f\u6b63\u6709\u5371\u5bb3\u7684\u662f\u5185\u5b58\u6cc4\u6f0f\u7684**\u5806\u79ef**\uff0c\u8fd9\u4f1a\u6700\u7ec8\u6d88\u8017\u5c3d\u7cfb\u7edf\u6240\u6709\u7684\u5185\u5b58\u3002\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u6765\u8bf4\uff0c\u4e00\u6b21\u6027\u5185\u5b58\u6cc4\u6f0f\u5e76\u6ca1\u6709\u4ec0\u4e48\u5371\u5bb3\uff0c\u56e0\u4e3a\u5b83\u4e0d\u4f1a\u5806\u79ef\uff0c\u800c\u9690\u5f0f\u5185\u5b58\u6cc4\u6f0f\u5371\u5bb3\u6027\u5219\u975e\u5e38\u5927\uff0c\u56e0\u4e3a\u8f83\u4e4b\u4e8e\u5e38\u53d1\u6027\u548c\u5076\u53d1\u6027\u5185\u5b58,\u6cc4\u6f0f\u5b83\u66f4\u96be\u88ab\u68c0\u6d4b\u5230\u3002","title":"\u5185\u5b58\u6cc4\u6f0f"},{"location":"C++/Guide/Resource-management/Memory-leak/Memory-leak/#_3","text":"\u4f55\u8c13\u5185\u5b58\u8bbf\u95ee\u8d8a\u754c\uff0c\u7b80\u5355\u7684\u8bf4\uff0c\u4f60\u5411\u7cfb\u7edf\u7533\u8bf7\u4e86\u4e00\u5757\u5185\u5b58\uff0c\u5728\u4f7f\u7528\u8fd9\u5757\u5185\u5b58\u7684\u65f6\u5019\uff0c\u8d85\u51fa\u4e86\u4f60\u7533\u8bf7\u7684\u8303\u56f4\u3002 \u5185\u5b58\u8d8a\u754c\u8fd9\u6837\u7684\u9519\u8bef\u5f15\u8d77\u7684\u95ee\u9898\u5b58\u5728\u6781\u5927\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u6709\u65f6\u5927\uff0c\u6709\u65f6\u5c0f\uff0c\u6709\u65f6\u53ef\u80fd\u4e0d\u4f1a\u5bf9\u7a0b\u5e8f\u7684\u8fd0\u884c\u4ea7\u751f\u5f71\u54cd\u3002\u8fd9\u79cd\u9519\u8bef\uff0c\u5927\u90e8\u5206\u60c5\u51b5\u4f1a\u629b\u51faAV\uff08access violation\uff09\u5f02\u5e38\uff0c\u6709\u65f6\u4e0d\u629b\u51fa\u5f02\u5e38, \u6709\u65f6\u5bfc\u81f4\u8f6f\u4ef6\u76f4\u63a5\u5d29\u6e83(\u7c7b\u4f3c\"Abnormal program termination\")\uff1b\u800c\u4e14\u629b\u51fa\u5f02\u5e38\u7684\u5730\u65b9\u5927\u591a\u4e0d\u662f\u8d8a\u754c\u8bbf\u95ee\u7684\u5730\u65b9(\u6bd4\u5982\u4e0b\u9762\u7684\u4f8b\u5b50),\u8ba9\u4eba\u6478\u4e0d\u7740\u5934\u8111; \u4ec0\u4e48\u539f\u56e0\u4f1a\u9020\u6210\u5185\u5b58\u8d8a\u754c\u4f7f\u7528\u5462\uff1f\u6709\u4ee5\u4e0b\u51e0\u79cd\u60c5\u51b5\uff0c\u53ef\u4f9b\u53c2\u8003\uff1a \u4f8b1\uff1a char buf[32] = {0}; for(int i=0; i<n; i++)// n < 32 or n > 32 { buf[i] = 'x'; } .... \u4f8b2: char buf[32] = {0}; string str = \"this is a test sting !!!!\"; sprintf(buf, \"this is a test buf!string:%s\", str.c_str()); //out of buffer space .... \u4f8b3: string str = \"this is a test string!!!!\"; char buf[16] = {0}; strcpy(buf, str.c_str()); //out of buffer space \u4f8b4\uff1a char *tmpc=new char[len-48+1]; memset(tmpc,0,len); //\u6211\u4eec\u7533\u8bf7\u4e86len-48+1\u4e2a\u5b57\u8282\u7684\u5185\u5b58\u7a7a\u95f4,\u4f46\u662f\u5728memeset\u7684\u65f6\u5019\u5374\u586b\u5145\u4e86len\u4e2a\u5b57\u8282\u7684\u7a7a\u95f4, //\u591a\u586b\u5145\u4e8647\u4e2a\u5b57\u8282\u7684\u7a7a\u95f4,\u800c\u8fd9\u4e2a\u8d8a\u754c\u586b\u5145\u53ef\u80fd\u5c31\u975e\u6cd5\u586b\u5145\u4e86tmpStr\u5185\u90e8\u7684\u5185\u5b58\u7a7a\u95f4,\u7834\u574f\u4e86tmpStr\u5185\u90e8\u7684\u7ed3\u6784, //\u4ece\u800c\u9020\u6210std::string\u5728\u51fd\u6570operator+=\u7684\u65f6\u5019\u629b\u51fa\u5f02\u5e38! tmpStr += funCode;//AV\u5f02\u5e38\u629b\u51fa\u7684\u5730\u65b9 \u5e38\u7528\u7684\u5185\u5b58\u64cd\u4f5c\u51fd\u6570\u90fd\u5b58\u5728\u8fd9\u79cd\u9690\u60a3\uff0c\u5e38\u7528\u7684\u5185\u5b58\u64cd\u4f5c\u51fd\u6570\u5982\u4e0b\uff1a sprintf snprintf vsprintf vsnprintf strcpy strncpy strcat memcpy memmove memset bcopy \u5f53\u8fd9\u6837\u7684\u4ee3\u7801\u4e00\u65e6\u8fd0\u884c\uff0c\u9519\u8bef\u5c31\u5728\u6240\u96be\u514d\uff0c\u4f1a\u5e26\u6765\u7684\u540e\u679c\u4e5f\u662f\u4e0d\u786e\u5b9a\u7684\uff0c\u901a\u5e38\u53ef\u80fd\u4f1a\u9020\u6210\u5982\u4e0b\u540e\u679c\uff1a \u7834\u574f\u4e86\u5806\u4e2d\u7684\u5185\u5b58\u5206\u914d\u4fe1\u606f\u6570\u636e\uff0c\u7279\u522b\u662f\u52a8\u6001\u5206\u914d\u7684\u5185\u5b58\u5757\u7684\u5185\u5b58\u4fe1\u606f\u6570\u636e\uff0c\u56e0\u4e3a\u64cd\u4f5c\u7cfb\u7edf\u5728\u5206\u914d\u548c\u91ca\u653e\u5185\u5b58\u5757\u65f6\u9700\u8981\u8bbf\u95ee\u8be5\u6570\u636e\uff0c\u4e00\u65e6\u8be5\u6570\u636e\u88ab\u7834\u574f\uff0c\u4ee5\u4e0b\u7684\u51e0\u79cd\u60c5\u51b5\u90fd\u53ef\u80fd\u4f1a\u51fa\u73b0\u3002 *** glibc detected *** free(): invalid pointer: *** glibc detected *** malloc(): memory corruption: *** glibc detected *** double free or corruption (out): 0x00000000005c18a0 *** *** glibc detected *** corrupted double-linked list: 0x00000000005ab150 *** \u7834\u574f\u4e86\u7a0b\u5e8f\u81ea\u5df1\u7684\u5176\u4ed6\u5bf9\u8c61\u7684\u5185\u5b58\u7a7a\u95f4\uff0c\u8fd9\u79cd\u7834\u574f\u4f1a\u5f71\u54cd\u7a0b\u5e8f\u6267\u884c\u7684\u4e0d\u6b63\u786e\u6027\uff0c\u5f53\u7136\u4e5f\u4f1a\u8bf1\u53d1coredump\uff0c\u5982\u7834\u574f\u4e86\u6307\u9488\u6570\u636e\u3002 \u7834\u574f\u4e86\u7a7a\u95f2\u5185\u5b58\u5757\uff0c\u5f88\u5e78\u8fd0\uff0c\u8fd9\u6837\u4e0d\u4f1a\u4ea7\u751f\u4ec0\u4e48\u95ee\u9898\uff0c\u4f46\u8c01\u77e5\u9053\u4ec0\u4e48\u65f6\u5019\u4e0d\u5e78\u4f1a\u964d\u4e34\u5462\uff1f \u901a\u5e38\uff0c\u4ee3\u7801\u9519\u8bef\u88ab\u6fc0\u53d1\u4e5f\u662f\u5076\u7136\u7684\uff0c\u4e5f\u5c31\u662f\u8bf4\u4e4b\u524d\u4f60\u7684\u7a0b\u5e8f\u4e00\u76f4\u6b63\u5e38\uff0c\u53ef\u80fd\u7531\u4e8e\u4f60\u4e3a\u7c7b\u589e\u52a0\u4e86\u4e24\u4e2a\u6210\u5458\u53d8\u91cf\uff0c\u6216\u8005\u6539\u53d8\u4e86\u67d0\u4e00\u90e8\u5206\u4ee3\u7801\uff0ccoredump\u5c31\u9891\u7e41\u53d1\u751f\uff0c\u800c\u4f60\u589e\u52a0\u7684\u4ee3\u7801\u7edd\u4e0d\u4f1a\u6709\u4efb\u4f55\u95ee\u9898\uff0c\u8fd9\u65f6\u4f60\u5c31\u5e94\u8be5\u8003\u8651\u662f\u5426\u662f\u67d0\u4e9b\u5185\u5b58\u88ab\u7834\u574f\u4e86\u3002 \u6392\u67e5\u7684\u539f\u5219\uff0c\u9996\u5148\u662f\u4fdd\u8bc1\u80fd\u91cd\u73b0\u9519\u8bef\uff0c\u6839\u636e\u9519\u8bef\u4f30\u8ba1\u53ef\u80fd\u7684\u73af\u8282\uff0c\u9010\u6b65\u88c1\u51cf\u4ee3\u7801\uff0c\u7f29\u5c0f\u6392\u67e5\u7a7a\u95f4\u3002\u5982\u679c\u6709\u7528\u5230\u81ea\u5df1\u7f16\u5199\u7684\u52a8\u6001\u5e93\u7684\u60c5\u51b5\uff0c\u8981\u786e\u4fdd\u52a8\u6001\u5e93\u7684\u7f16\u8bd1\u4e0e\u7a0b\u5e8f\u7f16\u8bd1\u7684\u73af\u5883\u4e00\u81f4\u3002","title":"\u5185\u5b58\u8d8a\u754c"},{"location":"C++/Guide/Resource-management/Memory-leak/Memory-leak/#_4","text":"\u7f13\u51b2\u533a\u6ea2\u51fa\u662f\u6307\u5f53\u8ba1\u7b97\u673a\u5411**\u7f13\u51b2\u533a**\u5185\u586b\u5145\u6570\u636e\u4f4d\u6570\u65f6\u8d85\u8fc7\u4e86\u7f13\u51b2\u533a\u672c\u8eab\u7684\u5bb9\u91cf,\u5bfc\u81f4\u6ea2\u51fa\u7684\u6570\u636e\u8986\u76d6\u5728\u5408\u6cd5\u6570\u636e\u4e0a\u3002\u7406\u60f3\u7684\u60c5\u51b5\u662f\u7a0b\u5e8f\u68c0\u67e5\u6570\u636e\u957f\u5ea6\uff0c\u5e76\u4e14\u4e0d\u5141\u8bb8\u8f93\u5165\u8d85\u8fc7\u7f13\u51b2\u533a\u957f\u5ea6\u7684\u5b57\u7b26,\u4f46\u662f\u7edd\u5927\u591a\u6570\u7a0b\u5e8f\u90fd\u4f1a\u5047\u8bbe\u6570\u636e\u957f\u5ea6\u603b\u662f\u4e0e\u6240\u5206\u914d\u7684\u50a8\u5b58\u7a7a\u95f4\u76f8\u5339\u914d,\u8fd9\u5c31\u4e3a\u7f13\u51b2\u533a\u6ea2\u51fa\u57cb\u4e0b\u9690\u60a3.\u64cd\u4f5c\u7cfb\u7edf\u6240\u4f7f\u7528\u7684\u7f13\u51b2\u533a \u53c8\u88ab\u79f0\u4e3a\"\u5806\u6808\". \u5728\u5404\u4e2a\u64cd\u4f5c\u8fdb\u7a0b\u4e4b\u95f4,\u6307\u4ee4\u4f1a\u88ab\u4e34\u65f6\u50a8\u5b58\u5728\"\u5806\u6808\"\u5f53\u4e2d,\"\u5806\u6808\"\u4e5f\u4f1a\u51fa\u73b0\u7f13\u51b2\u533a\u6ea2\u51fa\u3002 \u6808\u6ea2\u51fa\uff1a \u3000\u6808\u6ea2\u51fa\u5c31\u662f\u7f13\u51b2\u533a\u6ea2\u51fa\u7684\u4e00\u79cd\u3002 \u7531\u4e8e\u7f13\u51b2\u533a\u6ea2\u51fa\u800c\u4f7f\u5f97\u6709\u7528\u7684\u5b58\u50a8\u5355\u5143\u88ab\u6539\u5199,\u5f80\u5f80\u4f1a\u5f15\u53d1\u4e0d\u53ef\u9884\u6599\u7684\u540e\u679c\u3002\u7a0b\u5e8f\u5728\u8fd0\u884c\u8fc7\u7a0b\u4e2d\uff0c\u4e3a\u4e86\u4e34\u65f6\u5b58\u53d6\u6570\u636e\u7684\u9700\u8981\uff0c\u4e00\u822c\u90fd\u8981\u5206\u914d\u4e00\u4e9b\u5185\u5b58\u7a7a\u95f4\uff0c\u901a\u5e38\u79f0\u8fd9\u4e9b\u7a7a\u95f4\u4e3a\u7f13\u51b2\u533a\u3002\u5982\u679c\u5411\u7f13\u51b2\u533a\u4e2d\u5199\u5165\u8d85\u8fc7\u5176\u672c\u8eab\u957f\u5ea6\u7684\u6570\u636e\uff0c\u4ee5\u81f4\u4e8e\u7f13\u51b2\u533a\u65e0\u6cd5\u5bb9\u7eb3\uff0c\u5c31\u4f1a\u9020\u6210\u7f13\u51b2\u533a\u4ee5\u5916\u7684\u5b58\u50a8\u5355\u5143\u88ab\u6539\u5199\uff0c\u8fd9\u79cd\u73b0\u8c61\u5c31\u79f0\u4e3a\u7f13\u51b2\u533a\u6ea2\u51fa\u3002 \u6808\u6ea2\u51fa\u5c31\u662f\u7f13\u51b2\u533a\u6ea2\u51fa\u7684\u4e00\u79cd\u3002 \u6628\u5929\u6211\u5c31\u78b0\u5230\u4e86\u6570\u7ec4\u8d8a\u754c\u5bfc\u81f4\u7684\u9519\u8bef\u3002\u8ba9\u6211\u6bd4\u8f83\u597d\u5947\u7684\u662f\uff1a c++\u6ca1\u6709\u6570\u7ec4\u8d8a\u754c\u68c0\u67e5\u673a\u5236 \u6570\u7ec4\u8d8a\u754c\u4e4b\u540e\uff0c\u5c45\u7136\u80fd\u591f\u8bbf\u95ee\u5230\u6570\u636e\uff0c\u867d\u7136\u8fd9\u4e9b\u6570\u636e\u90fd\u662f\u975e\u6cd5\u7684\u3002 \u8fd9\u4e9b\u662f\u9700\u8981\u6211\u8fdb\u884c\u7814\u7a76\u7684 \u5173\u4e8e\u6570\u7ec4\u8d8a\u754c\uff0c\u6d89\u53ca\u5230\u5982\u4e0b\u95ee\u9898\uff1a \u4f7f\u7528char array\u6765\u4fdd\u5b58\u5b57\u7b26\u4e32\uff0c\u8981\u4f7f\u7528\u5982\u4e0b\u5199\u6cd5\uff1a p_arr=new char[strlen(str)+1] +1\u662f\u4e3a\u4e86\u8981\u7ed9'\\0'\u5360\u4e2a\u5ea7\uff0c\u9632\u6b62\u8d8a\u754c\u3002 \u521a\u521a\u6309\u7167\u8fd9\u4e2a\u7f51\u5740http://blog.csdn.net/sxhelijian/article/details/8928528/ \u4e0a\u7684\u4e8b\u4f8b\u7528gdb\u8c03\u8bd5\u4e86\u4e00\u4e0b\uff0c\u5e76\u6ca1\u6709\u53d1\u73b0\u4ec0\u4e48\u5927\u7684\u95ee\u9898\uff0c\u6709\u4e00\u4e2a\u95ee\u9898\u5c31\u662f\uff1a p \u53d8\u91cf \u548ccout\u8f93\u51fa\u7684\u5185\u5bb9\u4e0d\u76f8\u540c\uff0c\u5982\u4e0b (gdb) r Starting program: /home/dk/linux_and_c/cpp/array_out_of_bound/cin_array_2 abcde abcde Breakpoint 1, main () at cin_array_2.cpp:8 8 cout<<a<<endl; (gdb) p a $3 = \"abcd\" (gdb) p b $4 = \"abcd\" (gdb) c Continuing. abcde abcde Program exited normally. \u663e\u7136\u8fd9\u5c31\u662f\u7a0b\u5e8f\u7684\u5f02\u5e38\u6240\u5728\uff0c\u7a0b\u5e8f\u5df2\u7ecf\u53d1\u751f\u4e86\u8d8a\u754c\u3002","title":"\u7f13\u51b2\u533a\u6ea2\u51fa\uff1a"},{"location":"C++/Guide/Resource-management/Memory-leak/Memory-leak/#_5","text":"\u53c2\u89c1\u300a\u5185\u5b58\u6ea2\u51fa\u3001\u5185\u5b58\u6cc4\u9732\u3001\u5185\u5b58\u8d8a\u754c\u3001\u7f13\u51b2\u533a\u6ea2\u51fa\u3001\u6808\u6ea2\u51fa\u300b","title":"\u4ec0\u4e48\u662f\u8d8a\u754c\u8bbf\u95ee\uff1f\uff1f"},{"location":"C++/Guide/Resource-management/Memory-leak/Memory-leak/#_6","text":"\u53ef\u4ee5\u53c2\u8003\u5982\u4e0b\u4ee3\u7801\uff1a #include <iostream> #include <string> using namespace std; class check { public: check(char*s) { str=new char[strlen(s)+1]; strcpy(str,s); len=strlen(s); } char operator[](int n) { if(n>len-1) { cout<<\"\u6570\u7ec4\u4e0b\u6807\u8d8a\u754c\"<<endl; return ' '; } else { cout<<\"\u6570\u7ec4\u4e0b\u6807\u6ca1\u6709\u8d8a\u754c\"<<endl; return *(str+n); } } void Print(){cout<<str<<endl;} private: char *str; int len; }; void main() { check array(\"GoodMorning\");//\u7c7b\u7684\u6784\u9020\u51fd\u6570 array.Print(); cout<<\"Location 0:\"<<array[0]<<endl;//\u5224\u65ad\u4e0b\u6807\u4e3a0\u662f\u5426\u8d8a\u754c cout<<\"Location 20:\"<<array[20]<<endl;//\u5224\u65ad\u4e0b\u6807\u4e3a20\u662f\u5426\u8d8a\u754c }","title":"\u68c0\u67e5\u4e0b\u6807\u662f\u5426\u8d8a\u754c\u6570\u7ec4\u7c7b"},{"location":"C++/Guide/Resource-management/Memory-leak/Tools/","text":"Tools to find memory leak Valgrind \u7ef4\u57fa\u767e\u79d1 Valgrind \u5b98\u7f51 Valgrind How to find memory leak in a C++ code/project? Memory leak","title":"Tools"},{"location":"C++/Guide/Resource-management/Memory-leak/Tools/#tools-to-find-memory-leak","text":"","title":"Tools to find memory leak"},{"location":"C++/Guide/Resource-management/Memory-leak/Tools/#valgrind","text":"\u7ef4\u57fa\u767e\u79d1 Valgrind \u5b98\u7f51 Valgrind","title":"Valgrind"},{"location":"C++/Guide/Resource-management/Memory-leak/Tools/#how-to-find-memory-leak-in-a-c-codeproject","text":"","title":"How to find memory leak in a C++ code/project?"},{"location":"C++/Guide/Resource-management/Memory-leak/Tools/#memory-leak","text":"","title":"Memory leak"},{"location":"C++/Guide/Serialization/Serialization/","text":"TODO https://isocpp.org/wiki/faq/serialization https://stackoverflow.com/questions/234724/is-it-possible-to-serialize-and-deserialize-a-class-in-c","title":"Serialization"},{"location":"C++/Idiom/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u6587\u603b\u7ed3C++\u7684idiom\uff0c\u4e3b\u8981\u53c2\u8003\uff1a wikibooks More C++ Idioms cppreference Idioms","title":"Introduction"},{"location":"C++/Idiom/#_1","text":"\u672c\u6587\u603b\u7ed3C++\u7684idiom\uff0c\u4e3b\u8981\u53c2\u8003\uff1a wikibooks More C++ Idioms cppreference Idioms","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"C++/Idiom/Summary-of-C++-idiom/","text":"Summary of C++ idiom RAII \u548c The-rule-of-three-five-zero \u5176\u5b9e\u90fd\u662fresource management\u7684\u4e00\u4e9b\u6280\u5de7\uff0c\u5b83\u80fd\u591f\u4fdd\u4f4f\u4f7f\u7528\u8005\u89c4\u907f\u4e00\u4e9b\u9519\u8bef\u3002","title":"Summary-of-C++-idiom"},{"location":"C++/Idiom/Summary-of-C++-idiom/#summary-of-c-idiom","text":"RAII \u548c The-rule-of-three-five-zero \u5176\u5b9e\u90fd\u662fresource management\u7684\u4e00\u4e9b\u6280\u5de7\uff0c\u5b83\u80fd\u591f\u4fdd\u4f4f\u4f7f\u7528\u8005\u89c4\u907f\u4e00\u4e9b\u9519\u8bef\u3002","title":"Summary of C++ idiom"},{"location":"C++/Idiom/Erase-remove-idiom/Erase-remove-idiom/","text":"Erase\u2013remove idiom \u7ef4\u57fa\u767e\u79d1 Erase\u2013remove idiom","title":"Erase-remove-idiom"},{"location":"C++/Idiom/Erase-remove-idiom/Erase-remove-idiom/#eraseremove-idiom","text":"","title":"Erase\u2013remove idiom"},{"location":"C++/Idiom/Erase-remove-idiom/Erase-remove-idiom/#eraseremove-idiom_1","text":"","title":"\u7ef4\u57fa\u767e\u79d1Erase\u2013remove idiom"},{"location":"C++/Idiom/RAII/Essential-C++/","text":"RAII FinallyScopeExit \u672c\u8d28\u662f\u5f53\u9000\u51fascope\u7684\u65f6\u5019\uff0c\u6267\u884c\u67d0\u4e2a\u51fd\u6570\uff0c\u8fd9\u4e2a\u51fd\u6570\u4e00\u822c\u662f\u91ca\u653e\u8d44\u6e90\u7684\u51fd\u6570\u3002 The simplest and neatest c++11 ScopeGuard Boost.ScopeExit with C++11 lambda functions std::experimental::scope_exit scope(exit) in C++11","title":"Essential-C++"},{"location":"C++/Idiom/RAII/Essential-C++/#raii","text":"","title":"RAII"},{"location":"C++/Idiom/RAII/Essential-C++/#finallyscopeexit","text":"\u672c\u8d28\u662f\u5f53\u9000\u51fascope\u7684\u65f6\u5019\uff0c\u6267\u884c\u67d0\u4e2a\u51fd\u6570\uff0c\u8fd9\u4e2a\u51fd\u6570\u4e00\u822c\u662f\u91ca\u653e\u8d44\u6e90\u7684\u51fd\u6570\u3002 The simplest and neatest c++11 ScopeGuard Boost.ScopeExit with C++11 lambda functions std::experimental::scope_exit scope(exit) in C++11","title":"FinallyScopeExit"},{"location":"C++/Idiom/RAII/RAII/","text":"RAII RAII\u662fC++\u7684\u4e00\u4e2a\u91cd\u8981feature\u3002 cppreference RAII Resource Acquisition Is Initialization or RAII, is a C++ programming technique which binds the life cycle of a resource that must be acquired before use (allocated heap memory, thread of execution, open socket, open file, locked mutex, disk space, database connection\u2014anything that exists in limited supply) to the lifetime of an object. RAII guarantees that the resource is available to any function that may access the object (resource availability is a class invariant , eliminating redundant runtime tests). It also guarantees that all resources are released when the lifetime of their controlling object ends, in reverse order of acquisition. Likewise, if resource acquisition fails (the constructor exits with an exception), all resources acquired by every fully-constructed member and base subobject are released in reverse order of initialization. This leverages the core language features ( object lifetime , scope exit , order of initialization and stack unwinding ) to eliminate resource leaks and guarantee exception safety . Another name for this technique is Scope-Bound Resource Management (SBRM), after the basic use case where the lifetime of an RAII object ends due to scope exit. RAII can be summarized as follows: encapsulate each resource into a class, where the constructor acquires the resource and establishes all class invariants or throws an exception if that cannot be done, the destructor releases the resource and never throws exceptions; always use the resource via an instance of a RAII-class that either has automatic storage duration or temporary lifetime itself, or has lifetime that is bounded by the lifetime of an automatic or temporary object Move semantics make it possible to safely transfer resource ownership between objects, across scopes, and in and out of threads, while maintaining resource safety. Classes with open() / close() , lock() / unlock() , or init() / copyFrom() / destroy() member functions are typical examples of non-RAII classes: std :: mutex m ; void bad () { m . lock (); // acquire the mutex f (); // if f() throws an exception, the mutex is never released if ( ! everything_ok ()) return ; // early return, the mutex is never released m . unlock (); // if bad() reaches this statement, the mutex is released } void good () { std :: lock_guard < std :: mutex > lk ( m ); // RAII class: mutex acquisition is initialization f (); // if f() throws an exception, the mutex is released if ( ! everything_ok ()) return ; // early return, the mutex is released } // if good() returns normally, the mutex is released The standard library The C++ library classes that manage their own resources follow RAII: std::string , std::vector , std::thread , and many others acquire their resources in constructors (which throw exceptions on errors), release them in their destructors (which never throw), and don't require explicit cleanup. In addition, the standard library offers several RAII wrappers to manage user-provided resources: std::unique_ptr and std::shared_ptr to manage dynamically-allocated memory or, with a user-provided deleter, any resource represented by a plain pointer; std::lock_guard , std::unique_lock , std::shared_lock to manage mutexes. Notes RAII does not apply to the management of the resources that are not acquired before use: CPU time, cores, and cache capacity, entropy pool capacity, network bandwidth, electric power consumption, stack memory. \u7ef4\u57fa\u767e\u79d1 Resource acquisition is initialization NOTE: \u672c\u6587\u4e3b\u8981\u8ba8\u8bba\u4e86RAII idiom\u7684\u5199\u6cd5\u4ee5\u53ca\u8fd9\u6837\u5199\u7684\u597d\u5904\u3002 Resource acquisition is initialization ( RAII ) is a programming idiom used in several object-oriented languages to describe a particular language behavior. In RAII , holding a resource is a class invariant (), and is tied to object lifetime : resource allocation (or acquisition) is done during object creation (specifically initialization), by the constructor , while resource deallocation (release) is done during object destruction (specifically finalization), by the destructor . Thus the resource is guaranteed to be held between when initialization finishes and finalization starts (holding the resources is a class invariant), and to be held only when the object is alive. Thus if there are no object leaks , there are no resource leaks . NOTE : object-oriented programming\u544a\u8bc9\u6211\u4eec\u4f7f\u7528class\u6765\u63cf\u8ff0\uff0c\u62bd\u8c61\u4e8b\u7269\uff0cobject\u5c31\u662f\u4e00\u4e2aclass\u7684instance\uff1bRAII\u4f7f\u7528\u4e00\u4e2aobject\u6765\u7ba1\u7406resource\uff0c\u8fd9\u662f\u5426\u4e5f\u7b26\u5408object-oriented programming\u5462\uff1f\u6211\u611f\u89c9\u8fd9\u662f\u7b26\u5408object-oriented programming\u7684\u3002 RAII is associated most prominently with C++ where it originated, but also D , Ada , Vala , and Rust . The technique was developed for exception-safe resource management in C++ during 1984\u201389, primarily by Bjarne Stroustrup and Andrew Koenig , and the term itself was coined by Stroustrup. RAII is generally pronounced as an initialism , sometimes pronounced as \"R, A, double I\". Other names for this idiom include Constructor Acquires, Destructor Releases (CADRe) and one particular style of use is called Scope-based Resource Management (SBRM). This latter term is for the special case of automatic variables . RAII ties resources to object lifetime, which may not coincide(\u91cd\u53e0) with entry and exit of a scope. (Notably variables allocated on the free store (heap) have lifetimes unrelated to any given scope.) However, using RAII for automatic variables (SBRM) is the most common use case. NOTE: *Constructor Acquires, Destructor Releases*\u8fd9\u79cd\u63cf\u8ff0\u6bd4\u8d77RAII\u66f4\u52a0\u5bb9\u6613\u7406\u89e3\u3002\u5176\u5b9e\u5bf9RAII\u7684\u597d\u5904\u7684\u7406\u89e3\u4e5f\u5c31\u662f\u4f5c\u8005\u63d0\u51faRAII\u7684\u610f\u56fe\u7684\u7406\u89e3\u8fd8\u6d89\u53ca\u5230c++\u4e2d\u4f55\u65f6\u8c03\u7528\u6790\u6784\u51fd\u6570\u3002\u7ed3\u5408\u540e\u9762\u7684\u5185\u5bb9\uff0c\u53ef\u4ee5\u80af\u5b9a\u7684\u662f\u5728\u4e00\u4e2ascope\u7ed3\u675f\u7684\u65f6\u5019\uff0c\u5c31\u4f1a\u8c03\u7528destructor\u3002\u5e76\u4e14\uff0c\u5728\u9605\u8bfb\u4e86\u540e\u9762\u7684\u5185\u5bb9\u540e\uff0c\u53ef\u4ee5\u80af\u5b9a\u7684\u662fRAII\u7684\u597d\u5904\u4e3b\u8981\u4f53\u73b0\u5728SBRM\uff0c\u5b83\u80fd\u591f\u4fdd\u8bc1\u7a0b\u5e8f\u7684\u5b89\u5168\u6027\u3002 C++11 example H3 The following C++11 example demonstrates usage of RAII for file access and mutex locking: #include <mutex> #include <iostream> #include <string> #include <fstream> #include <stdexcept> void write_to_file ( const std :: string & message ) { // mutex to protect file access (shared across threads) static std :: mutex mutex ; // lock mutex before accessing file std :: lock_guard < std :: mutex > lock ( mutex ); // try to open file std :: ofstream file ( \"example.txt\" ); if ( ! file . is_open ()) throw std :: runtime_error ( \"unable to open file\" ); // write message to file file << message << std :: endl ; // file will be closed 1st when leaving scope (regardless of exception) // mutex will be unlocked 2nd (from lock destructor) when leaving // scope (regardless of exception) } This code is exception-safe because C++ guarantees that all stack objects are destroyed at the end of the enclosing scope , known as stack unwinding . The destructors of both the lock and file objects are therefore guaranteed to be called when returning from the function, whether an exception has been thrown or not.[ 9] \u603b\u7ed3\uff1a\u6700\u540e\u4e00\u53e5\u8bdd\u662f\u975e\u5e38\u91cd\u8981\u7684\uff1a\u65e0\u8bba\u662f\u5426\u629b\u51fa\u5f02\u5e38\uff0c\u5f53\u4ece\u8be5\u51fd\u6570\u8fd4\u56de\u7684\u65f6\u5019\uff0c*lock*\u548c*file*\u7684\u6790\u6784\u51fd\u6570\u90fd\u80fd\u591f\u4fdd\u8bc1\u88ab\u8c03\u7528\u3002\u90a3\u8fd9\u5c31\u5f15\u8d77\u4e86\u6211\u5bf9c++11\u7684\u5f02\u5e38\u7ba1\u7406\u7684\u597d\u5947\u4e86\uff0cc++11\u7684\u5f02\u5e38\u7ba1\u7406\u673a\u5236\u662f\u600e\u6837\u7684\u5462\uff1f Local variables allow easy management of multiple resources within a single function: they are destroyed in the reverse order of their construction, and an object is destroyed only if fully constructed\u2014that is, if no exception propagates from its constructor.[ 10] Using RAII greatly simplifies resource management, reduces overall code size and helps ensure program correctness. RAII is therefore highly recommended in C++, and most of the C++ standard library follows the idiom.[ 11] Benefits The advantages of RAII as a resource management technique are that it provides encapsulation exception safety (for stack resources), locality (it allows acquisition and release logic to be written next to each other). Encapsulation is provided because resource management logic is defined once in the class, not at each call site. Exception safety is provided for stack resources (resources that are released in the same scope as they are acquired) by tying(\u7ed1\u5b9a) the resource to the lifetime of a stack variable (a local variable declared in a given scope): if an exception is thrown, and proper exception handling is in place, the only code that will be executed when exiting the current scope are the destructors of objects declared in that scope. \u603b\u7ed3\uff1a\u5176\u5b9e\u4ece\u8fd9\u6bb5\u8bdd\u4e2d\u4e5f\u662f\u53ef\u4ee5\u63a8\u6d4b\u51fac++\u7684\u5f02\u5e38\u5904\u7406\u673a\u5236\u7684\uff1a\u5728\u4e00\u4e2a\u51fd\u6570\u6267\u884c\u7684\u8fc7\u7a0b\u4e2d\u5982\u679c\u51fa\u73b0\u4e86\u5f02\u5e38\uff0c\u5219\u4f1a\u9000\u51fa\u5f53\u524dscope\u7684\u6267\u884c\uff0c\u4f46\u662f\u5728\u9000\u51fa\u5f53\u524dscope\u4e4b\u524d\u662f\u4f1a\u8c03\u7528\u6240\u6709\u58f0\u660e\u5728\u5f53\u524d\u57df\u4e2d\u7684object\u7684destructor\u7684\u3002 Finally, locality of definition is provided by writing the constructor and destructor definitions next to each other in the class definition. Resource management therefore needs to be tied to the lifespan of suitable objects in order to gain automatic allocation and reclamation . Resources are acquired during initialization, when there is no chance of them being used before they are available, and released with the destruction of the same objects, which is guaranteed to take place even in case of errors. Comparing RAII with the finally construct used in Java, Stroustrup wrote that \u201cIn realistic systems, there are far more resource acquisitions than kinds of resources, so the \"resource acquisition is initialization\" technique leads to less code than use of a \"finally\" construct.\u201d[ 1] Typical uses The RAII design is often used for controlling mutex locks in multi-threaded applications. In that use, the object releases the lock when destroyed(\u5bf9\u8c61\u5728\u88ab\u9500\u6bc1\u7684\u65f6\u5019\u91ca\u653e\u9501). Without RAII in this scenario the potential for deadlock would be high and the logic to lock the mutex would be far from the logic to unlock it . With RAII , the code that locks the mutex essentially includes the logic that the lock will be released when execution leaves the scope of the RAII object(\u4f7f\u7528RAII\uff0c\u9501\u5b9a\u4e92\u65a5\u9501\u7684\u4ee3\u7801\u57fa\u672c\u4e0a\u5305\u62ec\u5f53\u6267\u884c\u79bb\u5f00RAII\u5bf9\u8c61\u7684\u8303\u56f4\u65f6\u5c06\u91ca\u653e\u9501\u7684\u903b\u8f91). Another typical example is interacting with files: We could have an object that represents a file that is open for writing, wherein the file is opened in the constructor and closed when execution leaves the object's scope. In both cases, RAII ensures only that the resource in question is released appropriately; care must still be taken to maintain exception safety. If the code modifying the data structure or file is not exception-safe, the mutex could be unlocked or the file closed with the data structure or file corrupted. Ownership of dynamically allocated objects (memory allocated with new in C++) can also be controlled with RAII , such that the object is released when the RAII (stack-based) object is destroyed. For this purpose, the C++11 standard library defines the smart pointer classes std::unique_ptr for single-owned objects and std::shared_ptr for objects with shared ownership . Similar classes are also available through std::auto_ptr in C++98, and boost::shared_ptr in the Boost libraries . Clang and GCC \"cleanup\" extension for C Both Clang and GNU Compiler Collection implement a non-standard extension to the C language to support RAII: the \"cleanup\" variable attribute.[ 12] The following macro annotates a variable with a given destructor function that it will call when the variable goes out of scope: static inline void fclosep ( FILE ** fp ) { if ( * fp ) fclose ( * fp ); } #define _cleanup_fclose_ __attribute__((cleanup(fclosep))) This macro can then be used as follows: void example_usage () { _cleanup_fclose_ FILE * logfile = fopen ( \"logfile.txt\" , \"w+\" ); fputs ( \"hello logfile!\" , logfile ); } In this example, the compiler arranges for the fclosep function to be called on logfile before example_usage returns. Limitations RAII only works for resources acquired and released (directly or indirectly) by stack-allocated objects , where there is a well-defined static object lifetime. Heap-allocated objects which themselves acquire and release resources are common in many languages, including C++ . RAII depends on heap-based objects to be implicitly or explicitly deleted along all possible execution paths, in order to trigger its resource-releasing destructor (or equivalent).[ 13] :8:27 This can be achieved by using smart pointers to manage all heap objects, with weak-pointers for cyclically referenced objects. In C++ , stack unwinding is only guaranteed to occur if the exception is caught somewhere. This is because \"If no matching handler is found in a program, the function terminate() is called; whether or not the stack is unwound before this call to terminate() is implementation-defined (15.5.1).\" (C++03 standard, \u00a715.3/9).[ 14] This behavior is usually acceptable, since the operating system releases remaining resources like memory, files, sockets, etc. at program termination. Reference counting Perl , Python (in the CPython implementation),[ 15] and PHP [ 16] manage object lifetime by reference counting , which makes it possible to use RAII. Objects that are no longer referenced are immediately destroyed or finalized and released, so a destructor or finalizer can release the resource at that time. However, it is not always idiomatic in such languages, and is specifically discouraged in Python (in favor of context managers and finalizers from the weakref package). However, object lifetimes are not necessarily bound to any scope, and objects may be destroyed non-deterministically or not at all. This makes it possible to accidentally leak resources that should have been released at the end of some scope. Objects stored in a static variable (notably a global variable) may not be finalized when the program terminates, so their resources are not released; CPython makes no guarantee of finalizing such objects, for instance. Further, objects with circular references will not be collected by a simple reference counter, and will live indeterminately long; even if collected (by more sophisticated garbage collection), destruction time and destruction order will be non-deterministic. In CPython there is a cycle detector which detects cycles and finalizes the objects in the cycle, though prior to CPython 3.4, cycles are not collected if any object in the cycle has a finalizer.[[17]] THINKING C++ \u7684RAII\u8ba9\u6211\u60f3\u5230\u4e86python\u4e2d\u7684 with \u3002\u4e0a\u9762\u8fd9\u7bc7\u6587\u7ae0\u4e2d\u7684Reference counting \u7ae0\u8282\u5c31\u8c08\u5230\u4e86\u8fd9\u4e00\u70b9\u3002 TODO https://www.tomdalling.com/blog/software-design/resource-acquisition-is-initialisation-raii-explained/","title":"RAII"},{"location":"C++/Idiom/RAII/RAII/#raii","text":"RAII\u662fC++\u7684\u4e00\u4e2a\u91cd\u8981feature\u3002","title":"RAII"},{"location":"C++/Idiom/RAII/RAII/#cppreference-raii","text":"Resource Acquisition Is Initialization or RAII, is a C++ programming technique which binds the life cycle of a resource that must be acquired before use (allocated heap memory, thread of execution, open socket, open file, locked mutex, disk space, database connection\u2014anything that exists in limited supply) to the lifetime of an object. RAII guarantees that the resource is available to any function that may access the object (resource availability is a class invariant , eliminating redundant runtime tests). It also guarantees that all resources are released when the lifetime of their controlling object ends, in reverse order of acquisition. Likewise, if resource acquisition fails (the constructor exits with an exception), all resources acquired by every fully-constructed member and base subobject are released in reverse order of initialization. This leverages the core language features ( object lifetime , scope exit , order of initialization and stack unwinding ) to eliminate resource leaks and guarantee exception safety . Another name for this technique is Scope-Bound Resource Management (SBRM), after the basic use case where the lifetime of an RAII object ends due to scope exit. RAII can be summarized as follows: encapsulate each resource into a class, where the constructor acquires the resource and establishes all class invariants or throws an exception if that cannot be done, the destructor releases the resource and never throws exceptions; always use the resource via an instance of a RAII-class that either has automatic storage duration or temporary lifetime itself, or has lifetime that is bounded by the lifetime of an automatic or temporary object Move semantics make it possible to safely transfer resource ownership between objects, across scopes, and in and out of threads, while maintaining resource safety. Classes with open() / close() , lock() / unlock() , or init() / copyFrom() / destroy() member functions are typical examples of non-RAII classes: std :: mutex m ; void bad () { m . lock (); // acquire the mutex f (); // if f() throws an exception, the mutex is never released if ( ! everything_ok ()) return ; // early return, the mutex is never released m . unlock (); // if bad() reaches this statement, the mutex is released } void good () { std :: lock_guard < std :: mutex > lk ( m ); // RAII class: mutex acquisition is initialization f (); // if f() throws an exception, the mutex is released if ( ! everything_ok ()) return ; // early return, the mutex is released } // if good() returns normally, the mutex is released","title":"cppreference RAII"},{"location":"C++/Idiom/RAII/RAII/#the-standard-library","text":"The C++ library classes that manage their own resources follow RAII: std::string , std::vector , std::thread , and many others acquire their resources in constructors (which throw exceptions on errors), release them in their destructors (which never throw), and don't require explicit cleanup. In addition, the standard library offers several RAII wrappers to manage user-provided resources: std::unique_ptr and std::shared_ptr to manage dynamically-allocated memory or, with a user-provided deleter, any resource represented by a plain pointer; std::lock_guard , std::unique_lock , std::shared_lock to manage mutexes.","title":"The standard library"},{"location":"C++/Idiom/RAII/RAII/#notes","text":"RAII does not apply to the management of the resources that are not acquired before use: CPU time, cores, and cache capacity, entropy pool capacity, network bandwidth, electric power consumption, stack memory.","title":"Notes"},{"location":"C++/Idiom/RAII/RAII/#resource-acquisition-is-initialization","text":"NOTE: \u672c\u6587\u4e3b\u8981\u8ba8\u8bba\u4e86RAII idiom\u7684\u5199\u6cd5\u4ee5\u53ca\u8fd9\u6837\u5199\u7684\u597d\u5904\u3002 Resource acquisition is initialization ( RAII ) is a programming idiom used in several object-oriented languages to describe a particular language behavior. In RAII , holding a resource is a class invariant (), and is tied to object lifetime : resource allocation (or acquisition) is done during object creation (specifically initialization), by the constructor , while resource deallocation (release) is done during object destruction (specifically finalization), by the destructor . Thus the resource is guaranteed to be held between when initialization finishes and finalization starts (holding the resources is a class invariant), and to be held only when the object is alive. Thus if there are no object leaks , there are no resource leaks . NOTE : object-oriented programming\u544a\u8bc9\u6211\u4eec\u4f7f\u7528class\u6765\u63cf\u8ff0\uff0c\u62bd\u8c61\u4e8b\u7269\uff0cobject\u5c31\u662f\u4e00\u4e2aclass\u7684instance\uff1bRAII\u4f7f\u7528\u4e00\u4e2aobject\u6765\u7ba1\u7406resource\uff0c\u8fd9\u662f\u5426\u4e5f\u7b26\u5408object-oriented programming\u5462\uff1f\u6211\u611f\u89c9\u8fd9\u662f\u7b26\u5408object-oriented programming\u7684\u3002 RAII is associated most prominently with C++ where it originated, but also D , Ada , Vala , and Rust . The technique was developed for exception-safe resource management in C++ during 1984\u201389, primarily by Bjarne Stroustrup and Andrew Koenig , and the term itself was coined by Stroustrup. RAII is generally pronounced as an initialism , sometimes pronounced as \"R, A, double I\". Other names for this idiom include Constructor Acquires, Destructor Releases (CADRe) and one particular style of use is called Scope-based Resource Management (SBRM). This latter term is for the special case of automatic variables . RAII ties resources to object lifetime, which may not coincide(\u91cd\u53e0) with entry and exit of a scope. (Notably variables allocated on the free store (heap) have lifetimes unrelated to any given scope.) However, using RAII for automatic variables (SBRM) is the most common use case. NOTE: *Constructor Acquires, Destructor Releases*\u8fd9\u79cd\u63cf\u8ff0\u6bd4\u8d77RAII\u66f4\u52a0\u5bb9\u6613\u7406\u89e3\u3002\u5176\u5b9e\u5bf9RAII\u7684\u597d\u5904\u7684\u7406\u89e3\u4e5f\u5c31\u662f\u4f5c\u8005\u63d0\u51faRAII\u7684\u610f\u56fe\u7684\u7406\u89e3\u8fd8\u6d89\u53ca\u5230c++\u4e2d\u4f55\u65f6\u8c03\u7528\u6790\u6784\u51fd\u6570\u3002\u7ed3\u5408\u540e\u9762\u7684\u5185\u5bb9\uff0c\u53ef\u4ee5\u80af\u5b9a\u7684\u662f\u5728\u4e00\u4e2ascope\u7ed3\u675f\u7684\u65f6\u5019\uff0c\u5c31\u4f1a\u8c03\u7528destructor\u3002\u5e76\u4e14\uff0c\u5728\u9605\u8bfb\u4e86\u540e\u9762\u7684\u5185\u5bb9\u540e\uff0c\u53ef\u4ee5\u80af\u5b9a\u7684\u662fRAII\u7684\u597d\u5904\u4e3b\u8981\u4f53\u73b0\u5728SBRM\uff0c\u5b83\u80fd\u591f\u4fdd\u8bc1\u7a0b\u5e8f\u7684\u5b89\u5168\u6027\u3002 C++11 example H3 The following C++11 example demonstrates usage of RAII for file access and mutex locking: #include <mutex> #include <iostream> #include <string> #include <fstream> #include <stdexcept> void write_to_file ( const std :: string & message ) { // mutex to protect file access (shared across threads) static std :: mutex mutex ; // lock mutex before accessing file std :: lock_guard < std :: mutex > lock ( mutex ); // try to open file std :: ofstream file ( \"example.txt\" ); if ( ! file . is_open ()) throw std :: runtime_error ( \"unable to open file\" ); // write message to file file << message << std :: endl ; // file will be closed 1st when leaving scope (regardless of exception) // mutex will be unlocked 2nd (from lock destructor) when leaving // scope (regardless of exception) } This code is exception-safe because C++ guarantees that all stack objects are destroyed at the end of the enclosing scope , known as stack unwinding . The destructors of both the lock and file objects are therefore guaranteed to be called when returning from the function, whether an exception has been thrown or not.[ 9] \u603b\u7ed3\uff1a\u6700\u540e\u4e00\u53e5\u8bdd\u662f\u975e\u5e38\u91cd\u8981\u7684\uff1a\u65e0\u8bba\u662f\u5426\u629b\u51fa\u5f02\u5e38\uff0c\u5f53\u4ece\u8be5\u51fd\u6570\u8fd4\u56de\u7684\u65f6\u5019\uff0c*lock*\u548c*file*\u7684\u6790\u6784\u51fd\u6570\u90fd\u80fd\u591f\u4fdd\u8bc1\u88ab\u8c03\u7528\u3002\u90a3\u8fd9\u5c31\u5f15\u8d77\u4e86\u6211\u5bf9c++11\u7684\u5f02\u5e38\u7ba1\u7406\u7684\u597d\u5947\u4e86\uff0cc++11\u7684\u5f02\u5e38\u7ba1\u7406\u673a\u5236\u662f\u600e\u6837\u7684\u5462\uff1f Local variables allow easy management of multiple resources within a single function: they are destroyed in the reverse order of their construction, and an object is destroyed only if fully constructed\u2014that is, if no exception propagates from its constructor.[ 10] Using RAII greatly simplifies resource management, reduces overall code size and helps ensure program correctness. RAII is therefore highly recommended in C++, and most of the C++ standard library follows the idiom.[ 11]","title":"\u7ef4\u57fa\u767e\u79d1Resource acquisition is initialization"},{"location":"C++/Idiom/RAII/RAII/#benefits","text":"The advantages of RAII as a resource management technique are that it provides encapsulation exception safety (for stack resources), locality (it allows acquisition and release logic to be written next to each other). Encapsulation is provided because resource management logic is defined once in the class, not at each call site. Exception safety is provided for stack resources (resources that are released in the same scope as they are acquired) by tying(\u7ed1\u5b9a) the resource to the lifetime of a stack variable (a local variable declared in a given scope): if an exception is thrown, and proper exception handling is in place, the only code that will be executed when exiting the current scope are the destructors of objects declared in that scope. \u603b\u7ed3\uff1a\u5176\u5b9e\u4ece\u8fd9\u6bb5\u8bdd\u4e2d\u4e5f\u662f\u53ef\u4ee5\u63a8\u6d4b\u51fac++\u7684\u5f02\u5e38\u5904\u7406\u673a\u5236\u7684\uff1a\u5728\u4e00\u4e2a\u51fd\u6570\u6267\u884c\u7684\u8fc7\u7a0b\u4e2d\u5982\u679c\u51fa\u73b0\u4e86\u5f02\u5e38\uff0c\u5219\u4f1a\u9000\u51fa\u5f53\u524dscope\u7684\u6267\u884c\uff0c\u4f46\u662f\u5728\u9000\u51fa\u5f53\u524dscope\u4e4b\u524d\u662f\u4f1a\u8c03\u7528\u6240\u6709\u58f0\u660e\u5728\u5f53\u524d\u57df\u4e2d\u7684object\u7684destructor\u7684\u3002 Finally, locality of definition is provided by writing the constructor and destructor definitions next to each other in the class definition. Resource management therefore needs to be tied to the lifespan of suitable objects in order to gain automatic allocation and reclamation . Resources are acquired during initialization, when there is no chance of them being used before they are available, and released with the destruction of the same objects, which is guaranteed to take place even in case of errors. Comparing RAII with the finally construct used in Java, Stroustrup wrote that \u201cIn realistic systems, there are far more resource acquisitions than kinds of resources, so the \"resource acquisition is initialization\" technique leads to less code than use of a \"finally\" construct.\u201d[ 1]","title":"Benefits"},{"location":"C++/Idiom/RAII/RAII/#typical-uses","text":"The RAII design is often used for controlling mutex locks in multi-threaded applications. In that use, the object releases the lock when destroyed(\u5bf9\u8c61\u5728\u88ab\u9500\u6bc1\u7684\u65f6\u5019\u91ca\u653e\u9501). Without RAII in this scenario the potential for deadlock would be high and the logic to lock the mutex would be far from the logic to unlock it . With RAII , the code that locks the mutex essentially includes the logic that the lock will be released when execution leaves the scope of the RAII object(\u4f7f\u7528RAII\uff0c\u9501\u5b9a\u4e92\u65a5\u9501\u7684\u4ee3\u7801\u57fa\u672c\u4e0a\u5305\u62ec\u5f53\u6267\u884c\u79bb\u5f00RAII\u5bf9\u8c61\u7684\u8303\u56f4\u65f6\u5c06\u91ca\u653e\u9501\u7684\u903b\u8f91). Another typical example is interacting with files: We could have an object that represents a file that is open for writing, wherein the file is opened in the constructor and closed when execution leaves the object's scope. In both cases, RAII ensures only that the resource in question is released appropriately; care must still be taken to maintain exception safety. If the code modifying the data structure or file is not exception-safe, the mutex could be unlocked or the file closed with the data structure or file corrupted. Ownership of dynamically allocated objects (memory allocated with new in C++) can also be controlled with RAII , such that the object is released when the RAII (stack-based) object is destroyed. For this purpose, the C++11 standard library defines the smart pointer classes std::unique_ptr for single-owned objects and std::shared_ptr for objects with shared ownership . Similar classes are also available through std::auto_ptr in C++98, and boost::shared_ptr in the Boost libraries .","title":"Typical uses"},{"location":"C++/Idiom/RAII/RAII/#clang-and-gcc-cleanup-extension-for-c","text":"Both Clang and GNU Compiler Collection implement a non-standard extension to the C language to support RAII: the \"cleanup\" variable attribute.[ 12] The following macro annotates a variable with a given destructor function that it will call when the variable goes out of scope: static inline void fclosep ( FILE ** fp ) { if ( * fp ) fclose ( * fp ); } #define _cleanup_fclose_ __attribute__((cleanup(fclosep))) This macro can then be used as follows: void example_usage () { _cleanup_fclose_ FILE * logfile = fopen ( \"logfile.txt\" , \"w+\" ); fputs ( \"hello logfile!\" , logfile ); } In this example, the compiler arranges for the fclosep function to be called on logfile before example_usage returns.","title":"Clang and GCC \"cleanup\" extension for C"},{"location":"C++/Idiom/RAII/RAII/#limitations","text":"RAII only works for resources acquired and released (directly or indirectly) by stack-allocated objects , where there is a well-defined static object lifetime. Heap-allocated objects which themselves acquire and release resources are common in many languages, including C++ . RAII depends on heap-based objects to be implicitly or explicitly deleted along all possible execution paths, in order to trigger its resource-releasing destructor (or equivalent).[ 13] :8:27 This can be achieved by using smart pointers to manage all heap objects, with weak-pointers for cyclically referenced objects. In C++ , stack unwinding is only guaranteed to occur if the exception is caught somewhere. This is because \"If no matching handler is found in a program, the function terminate() is called; whether or not the stack is unwound before this call to terminate() is implementation-defined (15.5.1).\" (C++03 standard, \u00a715.3/9).[ 14] This behavior is usually acceptable, since the operating system releases remaining resources like memory, files, sockets, etc. at program termination.","title":"Limitations"},{"location":"C++/Idiom/RAII/RAII/#reference-counting","text":"Perl , Python (in the CPython implementation),[ 15] and PHP [ 16] manage object lifetime by reference counting , which makes it possible to use RAII. Objects that are no longer referenced are immediately destroyed or finalized and released, so a destructor or finalizer can release the resource at that time. However, it is not always idiomatic in such languages, and is specifically discouraged in Python (in favor of context managers and finalizers from the weakref package). However, object lifetimes are not necessarily bound to any scope, and objects may be destroyed non-deterministically or not at all. This makes it possible to accidentally leak resources that should have been released at the end of some scope. Objects stored in a static variable (notably a global variable) may not be finalized when the program terminates, so their resources are not released; CPython makes no guarantee of finalizing such objects, for instance. Further, objects with circular references will not be collected by a simple reference counter, and will live indeterminately long; even if collected (by more sophisticated garbage collection), destruction time and destruction order will be non-deterministic. In CPython there is a cycle detector which detects cycles and finalizes the objects in the cycle, though prior to CPython 3.4, cycles are not collected if any object in the cycle has a finalizer.[[17]]","title":"Reference counting"},{"location":"C++/Idiom/RAII/RAII/#thinking","text":"C++ \u7684RAII\u8ba9\u6211\u60f3\u5230\u4e86python\u4e2d\u7684 with \u3002\u4e0a\u9762\u8fd9\u7bc7\u6587\u7ae0\u4e2d\u7684Reference counting \u7ae0\u8282\u5c31\u8c08\u5230\u4e86\u8fd9\u4e00\u70b9\u3002","title":"THINKING"},{"location":"C++/Idiom/RAII/RAII/#todo","text":"https://www.tomdalling.com/blog/software-design/resource-acquisition-is-initialisation-raii-explained/","title":"TODO"},{"location":"C++/Idiom/The-rule-of-three-five-zero/The-rule-of-three-five-zero/","text":"The rule of three/five/zero drdobbs C++ Made Easier: The Rule of Three An Example and a Misconception example code NOTE: \u539f\u6587\u7ed9\u51fa\u7684\u8fd9\u4e2a\u4f8b\u5b50\u662f\u975e\u5e38\u5177\u6709\u4ee3\u8868\u6027\u7684\u3002 \u8fd9\u4e2a\u4f8b\u5b50\uff0c\u5bfc\u81f4\u9519\u8bef\u662fdouble free cppreference The rule of three/five/zero Rule of three If a class requires a user-defined destructor , a user-defined copy constructor , or a user-defined copy assignment operator , it almost certainly requires all three. NOTE: \u4e09\u8005\u53ea\u8981\u6709\u5176\u4e00\uff0c\u5c31\u9700\u8981\u6709\u5176\u4e09 example code Classes that manage non-copyable resources through copyable handles may have to declare copy assignment and copy constructor private and not provide their definitions or define them as deleted. This is another application of the rule of three: deleting one and leaving the other to be implicitly-defined will most likely result in errors. NOTE: \u539f\u6587\u7684\u8fd9\u6bb5\u8bdd\u8981\u5982\u4f55\u7406\u89e3\uff1f","title":"The-rule-of-three-five-zero"},{"location":"C++/Idiom/The-rule-of-three-five-zero/The-rule-of-three-five-zero/#the-rule-of-threefivezero","text":"","title":"The rule of three/five/zero"},{"location":"C++/Idiom/The-rule-of-three-five-zero/The-rule-of-three-five-zero/#drdobbs-c-made-easier-the-rule-of-three","text":"","title":"drdobbs C++ Made Easier: The Rule of Three"},{"location":"C++/Idiom/The-rule-of-three-five-zero/The-rule-of-three-five-zero/#an-example-and-a-misconception","text":"example code NOTE: \u539f\u6587\u7ed9\u51fa\u7684\u8fd9\u4e2a\u4f8b\u5b50\u662f\u975e\u5e38\u5177\u6709\u4ee3\u8868\u6027\u7684\u3002 \u8fd9\u4e2a\u4f8b\u5b50\uff0c\u5bfc\u81f4\u9519\u8bef\u662fdouble free","title":"An Example and a Misconception"},{"location":"C++/Idiom/The-rule-of-three-five-zero/The-rule-of-three-five-zero/#cppreference-the-rule-of-threefivezero","text":"","title":"cppreference The rule of three/five/zero"},{"location":"C++/Idiom/The-rule-of-three-five-zero/The-rule-of-three-five-zero/#rule-of-three","text":"If a class requires a user-defined destructor , a user-defined copy constructor , or a user-defined copy assignment operator , it almost certainly requires all three. NOTE: \u4e09\u8005\u53ea\u8981\u6709\u5176\u4e00\uff0c\u5c31\u9700\u8981\u6709\u5176\u4e09 example code Classes that manage non-copyable resources through copyable handles may have to declare copy assignment and copy constructor private and not provide their definitions or define them as deleted. This is another application of the rule of three: deleting one and leaving the other to be implicitly-defined will most likely result in errors. NOTE: \u539f\u6587\u7684\u8fd9\u6bb5\u8bdd\u8981\u5982\u4f55\u7406\u89e3\uff1f","title":"Rule of three"},{"location":"C++/Language-reference/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u7684\u5185\u5bb9\u4e3b\u8981\u6574\u7406\u81ea cppreference.com \uff0c\u5305\u542b\u6211\u9605\u8bfb\u7684\u7b14\u8bb0\uff0c\u5bf9\u5176\u4e2d\u7684\u4e00\u4e9b\u95ee\u9898\u7684\u601d\u8003\u3001\u6574\u7406\u7b49\uff0c\u4e3b\u8981\u662f\u5bf9c++\u8bed\u8a00\u7684\u8bed\u6cd5\u3001c++\u8bed\u8a00\u7684\u8bbe\u8ba1\u8fdb\u884c\u5b66\u4e60\u3002","title":"index"},{"location":"C++/Language-reference/#_1","text":"\u672c\u7ae0\u7684\u5185\u5bb9\u4e3b\u8981\u6574\u7406\u81ea cppreference.com \uff0c\u5305\u542b\u6211\u9605\u8bfb\u7684\u7b14\u8bb0\uff0c\u5bf9\u5176\u4e2d\u7684\u4e00\u4e9b\u95ee\u9898\u7684\u601d\u8003\u3001\u6574\u7406\u7b49\uff0c\u4e3b\u8981\u662f\u5bf9c++\u8bed\u8a00\u7684\u8bed\u6cd5\u3001c++\u8bed\u8a00\u7684\u8bbe\u8ba1\u8fdb\u884c\u5b66\u4e60\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"C++/Language-reference/Array/","text":"Array TODO 2 Dimensional Char Array C++ Two-Dimensional Char Array valarray Promoting a raw pointer to valarray initialize array https://www.dummies.com/programming/cpp/initializing-an-array-in-c/ https://stackoverflow.com/questions/4057948/initializing-a-member-array-in-constructor-initializer https://stackoverflow.com/questions/2983819/how-initialize-array-of-classes","title":"Introduction"},{"location":"C++/Language-reference/Array/#array","text":"","title":"Array"},{"location":"C++/Language-reference/Array/#todo","text":"2 Dimensional Char Array C++ Two-Dimensional Char Array valarray Promoting a raw pointer to valarray","title":"TODO"},{"location":"C++/Language-reference/Array/#initialize-array","text":"https://www.dummies.com/programming/cpp/initializing-an-array-in-c/ https://stackoverflow.com/questions/4057948/initializing-a-member-array-in-constructor-initializer https://stackoverflow.com/questions/2983819/how-initialize-array-of-classes","title":"initialize array"},{"location":"C++/Language-reference/Basic-concept/Basic-concepts/","text":"Basic concepts \u672c\u6587\u662f\u5bf9cppreference Basic concepts \u7684\u9605\u8bfb\u7406\u89e3\uff0c\u8bf4\u5b9e\u8bdd\uff0c\u5b83\u6bd4\u8f83\u4e0d\u597d\u7406\u89e3\uff0c\u8bb0\u5f97\u521d\u6b21\u9605\u8bfb\u5b83\u7684\u65f6\u5019\uff0c\u6211\u5b8c\u5168\u88ab\u5176\u4e2d\u7684\u4e00\u4e9b\u5217\u7684\u6982\u5ff5\u7ed9\u6df7\u6dc6\u4e86\uff0c\u7ecf\u5386\u4e86\u4e00\u6bb5\u65f6\u95f4\u7684\u63a2\u7d22\u3001\u5b66\u4e60\u3001\u4f7f\u7528\u540e\uff0c\u73b0\u5728\u518d\u6765\u9605\u8bfb\u5b83\uff0c\u6709\u4e86\u5b8c\u5168\u4e0d\u540c\u7684\u611f\u53d7\uff1a \u6211\u89c9\u5f97\u5b83\u5bf9C++\u8bed\u8a00\u603b\u7ed3\u5730\u975e\u5e38\u597d\uff0c\u5982\u679c\u80fd\u591f\u5145\u5206\u5730\u7406\u89e3\u5b83\uff0c\u5c31\u80fd\u591f\u5efa\u7acb\u8d77\u5bf9c++\u8bed\u8a00\u7684\u9ad8\u5c4b\u5efa\u74f4\u7684\u89c6\u89d2 \u6211\u89c9\u5f97\u5982\u679c\u6709compiler principle\uff08\u53c2\u89c1\u5de5\u7a0b compiler principle \uff09\u3001programming language\u7684\u57fa\u7840\u77e5\u8bc6\uff0c\u90a3\u4e48\u7406\u89e3\u8d77\u6765\u4f1a\u66f4\u52a0\u5bb9\u6613 \u9700\u8981\u5c06\u5b83\u548cc\u8bed\u8a00\u7684 Basic concepts \u5bf9\u6bd4\u8d77\u6765\u770b cppreference Basic concepts A C++ program is a sequence of text files (typically header and source files) that contain declarations . They undergo translation to become an executable program, which is executed when the C++ implementation calls its main function . Certain words in a C++ program have special meaning, and these are known as keywords . Others can be used as identifiers . Comments are ignored during translation. Certain characters in the program have to be represented with escape sequences . The entities of a C++ program are values, objects , references , structured bindings (since C++17), functions , enumerators , types , class members, templates , template specializations , namespaces , and parameter packs . Preprocessor macros are not C++ entities. NOTE: \u539f\u6587\u7684\u4e0a\u8ff0\u4e09\u6bb5\u5728\u5411\u6211\u4eec\u89e3\u91ca\u201cC++ program\u201d\uff0c\u5305\u62ecwhat is C++ program\u3001C++ program\u7684\u7ec4\u6210\u3002 What is C++ program\uff1f \u5bf9\u4e8e\u95ee\u9898\u201cwhat is C++ program\u201d\uff0c\u8fd9\u4e2a\u5176\u5b9e\u662f\u975e\u5e38\u597d\u7406\u89e3\u7684\uff0c\u5728\u4e0a\u8ff0\u7b2c\u4e00\u6bb5\u4e2d\u7ed9\u51fa\u4e86\u89e3\u91ca\u3002 C++ program\u7684\u7ec4\u6210 \u4e0a\u8ff0\u7b2c\u4e09\u6bb5\u56de\u7b54\u4e86\u95ee\u9898\u201cC++ program\u7684\u7ec4\u6210\u201d\uff0c\u8fd9\u4e00\u6bb5\u4e2d\uff0c\u4f7f\u7528\u201centity\u201d\u7684\u6982\u5ff5\u6765\u63cf\u8ff0C++ program\u7684\u7ec4\u6210\uff0c\u4f5c\u8005\uff08\u5176\u5b9e\u5c31\u662fc++\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\uff09\u8ba4\u4e3a\uff0c\u4e00\u4e2aC++ program\u7531\u4e0a\u8ff0\u6240\u5217\u4e3e\u768411\u79cdentity\u7ec4\u6210\u3002\u5982\u679c\u4f60\u5df2\u7ecf\u6709\u4e86\u7f16\u5199c++ program\u7684\u7ecf\u9a8c\uff0c\u90a3\u4e48\u8bf7\u4f60\u56de\u60f3\u4e00\u4e0b\uff0c\u4f60\u7684c++ program\u662f\u5426\u662f\u7531\u4e0a\u9762\u679a\u4e3e\u7684\u8fd9\u4e9bentity\u6240\u7ec4\u6210\u7684\u3002 \u6bd4\u8f83\u4e0d\u5e78\u7684\u662f\uff0c\u539f\u6587\u5e76\u6ca1\u6709\u7ed9\u51fa\u201centity\u201d\u6982\u5ff5\u7684\u5b9a\u4e49\uff0c\u800c\u4ec5\u4ec5\u544a\u8bc9\u4e86\u8bfb\u8005\u5728\u201cC++ program\u201d\u4e2d\uff0c\u54ea\u4e9b\u662fentity\uff0c\u90a3\u8981\u5982\u4f55\u6765\u7406\u89e3\u201centity\u201d\u5462\uff1f\u65e2\u7136\u5b83\u662f\u4e00\u4e2a\u7531\u201centity\u201d\u662fc++\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u6240**\u62bd\u8c61**\u7684\uff0c\u5728\u6587\u7ae0 Abstraction \u4e2d\u6211\u4eec\u5df2\u7ecf\u5bf9**\u62bd\u8c61**\u8fdb\u884c\u4e86\u603b\u7ed3\uff1a \u62bd\u8c61\u662f\u6982\u62ec\u7684\u8fc7\u7a0b\uff0c\u62bd\u8c61\u662f\u63d0\u53d6\u516c\u5171\u7279\u5f81\u7684\u8fc7\u7a0b\uff0c\u5b83\u6240\u6982\u62ec\u7684\u3001\u6240\u63d0\u53d6\u7684\u516c\u5171\u7279\u5f81\uff0c\u53ef\u4ee5\u4f7f\u7528 concepts \u6765\u8fdb\u884c\u8868\u793a \u663e\u7136\uff0c\u5b83\u662fC++ program\u7684\u7ec4\u6210\u5355\u4f4d\uff0c\u5b83\u662fc++\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u63d0\u4f9b\u7ed9\u7528\u6237\u6765\u4f7f\u7528\u7684\uff0c\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u6765\u770b\uff0cc++\u8bed\u8a00\u7684\u4f7f\u7528\u8005\uff0c\u5728\u8fdb\u884c\u7f16\u7a0b\u7684\u65f6\u5019\uff0c\u5c31\u662f\u5728\u63cf\u8ff0\u4e00\u4e2a\u4e00\u4e2a\u7684entity\u5e76\u4f7f\u7528\u5df2\u7ecf\u63cf\u8ff0\u597d\u7684entity\u3002 \u663e\u7136entity\u662f\u4e00\u4e2a\u6bd4statement\u66f4\u52a0\u5927\u7684\u6982\u5ff5\uff0c\u56e0\u4e3a\u6211\u4eec\u77e5\u9053function\u662f\u7531\u591a\u4e2astatement\u6240\u7ec4\u6210\u7684\uff08\u53c2\u89c1\u6587\u7ae0 Unit \u7684 Programming language\u7684unit of user-defined action \u6bb5\uff09\uff0c\u5173\u4e8e\u6b64\uff0c\u5728\u540e\u9762\u4e5f\u4f1a\u8fdb\u884c\u63cf\u8ff0\u3002 \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0centity\u662fc++ program\u7684\u7ec4\u6210\u5355\u4f4d\uff0c\u5b83\u662f\u4e00\u4e2a\u7f16\u8bd1\u65f6\u7684\u6982\u5ff5\uff0c\u5b83\u9700\u8981\u7531compiler\u6765\u8fdb\u884c\u201c\u7406\u89e3\u201d\uff08\u53c2\u89c1\u5de5\u7a0b compiler-principle \u7684 Chapter 7 Run-Time Environments \uff09\u3002 \u7ecf\u8fc7\u4e0a\u9762\u7684\u5206\u6790\uff0c\u6211\u4eec\u5df2\u7ecf\u6e05\u695a\u4e86entity\u7684\u6982\u5ff5\uff0c\u73b0\u5728\u6211\u4eec\u601d\u8003\u8fd9\u6837\u7684\u4e00\u4e2a\u95ee\u9898\uff1a\u8fd9\u4e9bentity\u4e4b\u95f4\u7684\u5173\u7cfb\u662f\u600e\u6837\u7684\uff1f\u5173\u4e8e\u8fd9\u4e2a\u95ee\u9898\uff0c\u53c2\u89c1\u6587\u7ae0 C++ Entities and Relationships \u3002 entity\u4e5f\u53ef\u4ee5\u770b\u505a\u662f Language construct \u3002 Declartions may introduce entities, associate them with names and define their properties. The declarations that define all properties required to use an entity are definitions . A program must contain only one definition of any non-inline function or variable that is odr-used . NOTE: \u524d\u9762\u63cf\u8ff0\u4e86\u201centity\u201d\u7684\u6982\u5ff5\uff0c\u4e0a\u9762\u8fd9\u6bb5\u5219\u544a\u8bc9\u6211\u4eec\uff0c\u5728c++\u8bed\u8a00\u4e2d\u901a\u8fc7* declartion * \u6765\u5f15\u5165\uff08\u6216\u8005\u8bf4\u201c\u521b\u5efa\u201d\uff09\u201centity\u201d\uff0c\u5728declare\u4e00\u4e2aentity\u7684\u65f6\u5019\uff0c\u7528\u6237\u9700\u8981\u6307\u5b9a\u5b83\u7684\u201cname\u201d\uff0c\u8fd9\u6837\u6211\u4eec\u5c31\u53ef\u4ee5\u901a\u8fc7\u8fd9\u4e2aname\u6765\u4f7f\u7528\u8fd9\u4e2aentity\u4e86\u3002 Definitions of functions include sequences of statements , some of which include expressions , which specify the computations to be performed by the program. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u63cf\u8ff0\u4e86function\u548cstatement\u4e4b\u95f4\u7684\u5173\u7cfb\u3001statement\u548cexpression\u4e4b\u95f4\u7684\u5173\u7cfb Names encountered in a program are associated with the declarations that introduced them using name lookup . Each name is only valid within a part of the program called its scope . Some names have linkage which makes them refer to the same entities when they appear in different scopes or translation units. NOTE: \u901a\u8fc7\u524d\u9762\u7684\u63cf\u8ff0\uff0c\u6211\u4eec\u5df2\u7ecf\u77e5\u9053\u4e86\uff1a\u5728declare\u4e00\u4e2aentity\u7684\u65f6\u5019\uff0c\u6211\u4eec\u4f1a\u7ed9\u5b83\u6307\u5b9a\u4e00\u4e2aname\uff0c\u5728\u8fdb\u884c\u7f16\u7a0b\u7684\u65f6\u5019\uff0c\u6211\u4eec\u901a\u8fc7\u8fd9\u4e2aname\u6765\u5f15\u7528\u8fd9\u4e2aentity\u3002\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u5219\u5bf9\u4e0ename\u76f8\u5173\u7684\u4e00\u4e9b\u5185\u5bb9\u8fdb\u884c\u4e86\u4ecb\u7ecd\u3002\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c name lookup \u662fcompiler\u7684\u4e00\u4e2a\u52a8\u4f5c\u3002 Each object, reference, function, expression in C++ is associated with a type , which may be fundamental , compound, or user-defined , complete or incomplete , etc. NOTE: \u5173\u4e8eobject\uff0c\u5728\u6587\u7ae0Object\u4e2d\u8fdb\u884c\u4e86\u8be6\u7ec6\u5206\u6790\u3002 Declared objects and declared references that are not non-static data members are variables . word\u3001identifier\u3001name\u3001variable \u5982\u679c\u4ece\u8bed\u8a00\u5b66\u7684\u89d2\u5ea6\u6765\u770b\u7684\u8bdd\uff0c\u6211\u4eec\u7f16\u5199\u7684program\u5176\u5b9e\u5c31\u76f8\u5f53\u4e8e\u4e00\u7bc7\u6587\u7ae0\uff0c\u548c\u6211\u4eec\u5e73\u65f6\u5199\u7684\u6587\u7ae0\u4e00\u6837\uff0cprogram\u4e5f\u53ef\u4ee5\u770b\u505a\u662f\u7531\u4e00\u4e2a\u4e00\u4e2a\u7684word\u7ec4\u6210\uff0c\u8fd9\u5c31\u662fword\u7684\u542b\u4e49\u3002\u663e\u7136\uff0cprogram\u4e2d\u7684word\u5305\u62ec\u4e86\u4e24\u5927\u7c7b\uff1a \u7531program language\u4fdd\u7559\u7684\uff0c\u5982keyword\u3001operator\u7b49\u7b49 \u7531\u7528\u6237\u521b\u5efa\u7684\uff1aidentifier \u81f3\u4e8ename\u4e86\uff0c\u6211\u89c9\u5f97\u5b83\u548cidentifier\u7684\u542b\u4e49\u57fa\u672c\u7c7b\u4f3c\uff0c\u6309\u7167\u4e0a\u9762\u7684\u4ecb\u7ecd\uff0c\u5b83\u4e3b\u8981\u662f\u548cdeclaration\u3001entity\u3001scope\u76f8\u5173\u8054\uff0c\u6211\u89c9\u5f97\u8fd9\u4e2a\u53ef\u4ee5\u8fd9\u6837\u8ba4\u4e3a\uff1aname\u6982\u5ff5\u662f\u548centity\u6982\u5ff5\u76f8\u5173\u8054\uff0c\u6216\u8005\u8bf4\uff0c\u6bcf\u4e2aentity\u90fd\u6709\u4e00\u4e2aname\u3002 \u603b\u7684\u6765\u8bf4\uff1aword\u3001identifier\u3001name\uff0c\u90fd\u662f\u9759\u6001\u6982\u5ff5\uff0c\u90fd\u662f\u6709compiler\u6765\u8fdb\u884c\u7406\u89e3\u7684\u3002 variable\u5219\u662f\u4e00\u4e2a\u52a8\u6001\u6982\u5ff5\u3001\u662f\u4e00\u4e2a\u8fd0\u884c\u65f6\u6982\u5ff5\uff0c\u5b83\u6240\u8868\u793a\u7684\u542b\u4e49\u6709\uff1amemory\u3002","title":"Basic-concepts"},{"location":"C++/Language-reference/Basic-concept/Basic-concepts/#basic-concepts","text":"\u672c\u6587\u662f\u5bf9cppreference Basic concepts \u7684\u9605\u8bfb\u7406\u89e3\uff0c\u8bf4\u5b9e\u8bdd\uff0c\u5b83\u6bd4\u8f83\u4e0d\u597d\u7406\u89e3\uff0c\u8bb0\u5f97\u521d\u6b21\u9605\u8bfb\u5b83\u7684\u65f6\u5019\uff0c\u6211\u5b8c\u5168\u88ab\u5176\u4e2d\u7684\u4e00\u4e9b\u5217\u7684\u6982\u5ff5\u7ed9\u6df7\u6dc6\u4e86\uff0c\u7ecf\u5386\u4e86\u4e00\u6bb5\u65f6\u95f4\u7684\u63a2\u7d22\u3001\u5b66\u4e60\u3001\u4f7f\u7528\u540e\uff0c\u73b0\u5728\u518d\u6765\u9605\u8bfb\u5b83\uff0c\u6709\u4e86\u5b8c\u5168\u4e0d\u540c\u7684\u611f\u53d7\uff1a \u6211\u89c9\u5f97\u5b83\u5bf9C++\u8bed\u8a00\u603b\u7ed3\u5730\u975e\u5e38\u597d\uff0c\u5982\u679c\u80fd\u591f\u5145\u5206\u5730\u7406\u89e3\u5b83\uff0c\u5c31\u80fd\u591f\u5efa\u7acb\u8d77\u5bf9c++\u8bed\u8a00\u7684\u9ad8\u5c4b\u5efa\u74f4\u7684\u89c6\u89d2 \u6211\u89c9\u5f97\u5982\u679c\u6709compiler principle\uff08\u53c2\u89c1\u5de5\u7a0b compiler principle \uff09\u3001programming language\u7684\u57fa\u7840\u77e5\u8bc6\uff0c\u90a3\u4e48\u7406\u89e3\u8d77\u6765\u4f1a\u66f4\u52a0\u5bb9\u6613 \u9700\u8981\u5c06\u5b83\u548cc\u8bed\u8a00\u7684 Basic concepts \u5bf9\u6bd4\u8d77\u6765\u770b","title":"Basic concepts"},{"location":"C++/Language-reference/Basic-concept/Basic-concepts/#cppreference-basic-concepts","text":"A C++ program is a sequence of text files (typically header and source files) that contain declarations . They undergo translation to become an executable program, which is executed when the C++ implementation calls its main function . Certain words in a C++ program have special meaning, and these are known as keywords . Others can be used as identifiers . Comments are ignored during translation. Certain characters in the program have to be represented with escape sequences . The entities of a C++ program are values, objects , references , structured bindings (since C++17), functions , enumerators , types , class members, templates , template specializations , namespaces , and parameter packs . Preprocessor macros are not C++ entities. NOTE: \u539f\u6587\u7684\u4e0a\u8ff0\u4e09\u6bb5\u5728\u5411\u6211\u4eec\u89e3\u91ca\u201cC++ program\u201d\uff0c\u5305\u62ecwhat is C++ program\u3001C++ program\u7684\u7ec4\u6210\u3002","title":"cppreference Basic concepts"},{"location":"C++/Language-reference/Basic-concept/Basic-concepts/#what-is-c-program","text":"\u5bf9\u4e8e\u95ee\u9898\u201cwhat is C++ program\u201d\uff0c\u8fd9\u4e2a\u5176\u5b9e\u662f\u975e\u5e38\u597d\u7406\u89e3\u7684\uff0c\u5728\u4e0a\u8ff0\u7b2c\u4e00\u6bb5\u4e2d\u7ed9\u51fa\u4e86\u89e3\u91ca\u3002","title":"What is C++ program\uff1f"},{"location":"C++/Language-reference/Basic-concept/Basic-concepts/#c-program","text":"\u4e0a\u8ff0\u7b2c\u4e09\u6bb5\u56de\u7b54\u4e86\u95ee\u9898\u201cC++ program\u7684\u7ec4\u6210\u201d\uff0c\u8fd9\u4e00\u6bb5\u4e2d\uff0c\u4f7f\u7528\u201centity\u201d\u7684\u6982\u5ff5\u6765\u63cf\u8ff0C++ program\u7684\u7ec4\u6210\uff0c\u4f5c\u8005\uff08\u5176\u5b9e\u5c31\u662fc++\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\uff09\u8ba4\u4e3a\uff0c\u4e00\u4e2aC++ program\u7531\u4e0a\u8ff0\u6240\u5217\u4e3e\u768411\u79cdentity\u7ec4\u6210\u3002\u5982\u679c\u4f60\u5df2\u7ecf\u6709\u4e86\u7f16\u5199c++ program\u7684\u7ecf\u9a8c\uff0c\u90a3\u4e48\u8bf7\u4f60\u56de\u60f3\u4e00\u4e0b\uff0c\u4f60\u7684c++ program\u662f\u5426\u662f\u7531\u4e0a\u9762\u679a\u4e3e\u7684\u8fd9\u4e9bentity\u6240\u7ec4\u6210\u7684\u3002 \u6bd4\u8f83\u4e0d\u5e78\u7684\u662f\uff0c\u539f\u6587\u5e76\u6ca1\u6709\u7ed9\u51fa\u201centity\u201d\u6982\u5ff5\u7684\u5b9a\u4e49\uff0c\u800c\u4ec5\u4ec5\u544a\u8bc9\u4e86\u8bfb\u8005\u5728\u201cC++ program\u201d\u4e2d\uff0c\u54ea\u4e9b\u662fentity\uff0c\u90a3\u8981\u5982\u4f55\u6765\u7406\u89e3\u201centity\u201d\u5462\uff1f\u65e2\u7136\u5b83\u662f\u4e00\u4e2a\u7531\u201centity\u201d\u662fc++\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u6240**\u62bd\u8c61**\u7684\uff0c\u5728\u6587\u7ae0 Abstraction \u4e2d\u6211\u4eec\u5df2\u7ecf\u5bf9**\u62bd\u8c61**\u8fdb\u884c\u4e86\u603b\u7ed3\uff1a \u62bd\u8c61\u662f\u6982\u62ec\u7684\u8fc7\u7a0b\uff0c\u62bd\u8c61\u662f\u63d0\u53d6\u516c\u5171\u7279\u5f81\u7684\u8fc7\u7a0b\uff0c\u5b83\u6240\u6982\u62ec\u7684\u3001\u6240\u63d0\u53d6\u7684\u516c\u5171\u7279\u5f81\uff0c\u53ef\u4ee5\u4f7f\u7528 concepts \u6765\u8fdb\u884c\u8868\u793a \u663e\u7136\uff0c\u5b83\u662fC++ program\u7684\u7ec4\u6210\u5355\u4f4d\uff0c\u5b83\u662fc++\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u63d0\u4f9b\u7ed9\u7528\u6237\u6765\u4f7f\u7528\u7684\uff0c\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u6765\u770b\uff0cc++\u8bed\u8a00\u7684\u4f7f\u7528\u8005\uff0c\u5728\u8fdb\u884c\u7f16\u7a0b\u7684\u65f6\u5019\uff0c\u5c31\u662f\u5728\u63cf\u8ff0\u4e00\u4e2a\u4e00\u4e2a\u7684entity\u5e76\u4f7f\u7528\u5df2\u7ecf\u63cf\u8ff0\u597d\u7684entity\u3002 \u663e\u7136entity\u662f\u4e00\u4e2a\u6bd4statement\u66f4\u52a0\u5927\u7684\u6982\u5ff5\uff0c\u56e0\u4e3a\u6211\u4eec\u77e5\u9053function\u662f\u7531\u591a\u4e2astatement\u6240\u7ec4\u6210\u7684\uff08\u53c2\u89c1\u6587\u7ae0 Unit \u7684 Programming language\u7684unit of user-defined action \u6bb5\uff09\uff0c\u5173\u4e8e\u6b64\uff0c\u5728\u540e\u9762\u4e5f\u4f1a\u8fdb\u884c\u63cf\u8ff0\u3002 \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0centity\u662fc++ program\u7684\u7ec4\u6210\u5355\u4f4d\uff0c\u5b83\u662f\u4e00\u4e2a\u7f16\u8bd1\u65f6\u7684\u6982\u5ff5\uff0c\u5b83\u9700\u8981\u7531compiler\u6765\u8fdb\u884c\u201c\u7406\u89e3\u201d\uff08\u53c2\u89c1\u5de5\u7a0b compiler-principle \u7684 Chapter 7 Run-Time Environments \uff09\u3002 \u7ecf\u8fc7\u4e0a\u9762\u7684\u5206\u6790\uff0c\u6211\u4eec\u5df2\u7ecf\u6e05\u695a\u4e86entity\u7684\u6982\u5ff5\uff0c\u73b0\u5728\u6211\u4eec\u601d\u8003\u8fd9\u6837\u7684\u4e00\u4e2a\u95ee\u9898\uff1a\u8fd9\u4e9bentity\u4e4b\u95f4\u7684\u5173\u7cfb\u662f\u600e\u6837\u7684\uff1f\u5173\u4e8e\u8fd9\u4e2a\u95ee\u9898\uff0c\u53c2\u89c1\u6587\u7ae0 C++ Entities and Relationships \u3002 entity\u4e5f\u53ef\u4ee5\u770b\u505a\u662f Language construct \u3002 Declartions may introduce entities, associate them with names and define their properties. The declarations that define all properties required to use an entity are definitions . A program must contain only one definition of any non-inline function or variable that is odr-used . NOTE: \u524d\u9762\u63cf\u8ff0\u4e86\u201centity\u201d\u7684\u6982\u5ff5\uff0c\u4e0a\u9762\u8fd9\u6bb5\u5219\u544a\u8bc9\u6211\u4eec\uff0c\u5728c++\u8bed\u8a00\u4e2d\u901a\u8fc7* declartion * \u6765\u5f15\u5165\uff08\u6216\u8005\u8bf4\u201c\u521b\u5efa\u201d\uff09\u201centity\u201d\uff0c\u5728declare\u4e00\u4e2aentity\u7684\u65f6\u5019\uff0c\u7528\u6237\u9700\u8981\u6307\u5b9a\u5b83\u7684\u201cname\u201d\uff0c\u8fd9\u6837\u6211\u4eec\u5c31\u53ef\u4ee5\u901a\u8fc7\u8fd9\u4e2aname\u6765\u4f7f\u7528\u8fd9\u4e2aentity\u4e86\u3002 Definitions of functions include sequences of statements , some of which include expressions , which specify the computations to be performed by the program. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u63cf\u8ff0\u4e86function\u548cstatement\u4e4b\u95f4\u7684\u5173\u7cfb\u3001statement\u548cexpression\u4e4b\u95f4\u7684\u5173\u7cfb Names encountered in a program are associated with the declarations that introduced them using name lookup . Each name is only valid within a part of the program called its scope . Some names have linkage which makes them refer to the same entities when they appear in different scopes or translation units. NOTE: \u901a\u8fc7\u524d\u9762\u7684\u63cf\u8ff0\uff0c\u6211\u4eec\u5df2\u7ecf\u77e5\u9053\u4e86\uff1a\u5728declare\u4e00\u4e2aentity\u7684\u65f6\u5019\uff0c\u6211\u4eec\u4f1a\u7ed9\u5b83\u6307\u5b9a\u4e00\u4e2aname\uff0c\u5728\u8fdb\u884c\u7f16\u7a0b\u7684\u65f6\u5019\uff0c\u6211\u4eec\u901a\u8fc7\u8fd9\u4e2aname\u6765\u5f15\u7528\u8fd9\u4e2aentity\u3002\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u5219\u5bf9\u4e0ename\u76f8\u5173\u7684\u4e00\u4e9b\u5185\u5bb9\u8fdb\u884c\u4e86\u4ecb\u7ecd\u3002\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c name lookup \u662fcompiler\u7684\u4e00\u4e2a\u52a8\u4f5c\u3002 Each object, reference, function, expression in C++ is associated with a type , which may be fundamental , compound, or user-defined , complete or incomplete , etc. NOTE: \u5173\u4e8eobject\uff0c\u5728\u6587\u7ae0Object\u4e2d\u8fdb\u884c\u4e86\u8be6\u7ec6\u5206\u6790\u3002 Declared objects and declared references that are not non-static data members are variables .","title":"C++ program\u7684\u7ec4\u6210"},{"location":"C++/Language-reference/Basic-concept/Basic-concepts/#wordidentifiernamevariable","text":"\u5982\u679c\u4ece\u8bed\u8a00\u5b66\u7684\u89d2\u5ea6\u6765\u770b\u7684\u8bdd\uff0c\u6211\u4eec\u7f16\u5199\u7684program\u5176\u5b9e\u5c31\u76f8\u5f53\u4e8e\u4e00\u7bc7\u6587\u7ae0\uff0c\u548c\u6211\u4eec\u5e73\u65f6\u5199\u7684\u6587\u7ae0\u4e00\u6837\uff0cprogram\u4e5f\u53ef\u4ee5\u770b\u505a\u662f\u7531\u4e00\u4e2a\u4e00\u4e2a\u7684word\u7ec4\u6210\uff0c\u8fd9\u5c31\u662fword\u7684\u542b\u4e49\u3002\u663e\u7136\uff0cprogram\u4e2d\u7684word\u5305\u62ec\u4e86\u4e24\u5927\u7c7b\uff1a \u7531program language\u4fdd\u7559\u7684\uff0c\u5982keyword\u3001operator\u7b49\u7b49 \u7531\u7528\u6237\u521b\u5efa\u7684\uff1aidentifier \u81f3\u4e8ename\u4e86\uff0c\u6211\u89c9\u5f97\u5b83\u548cidentifier\u7684\u542b\u4e49\u57fa\u672c\u7c7b\u4f3c\uff0c\u6309\u7167\u4e0a\u9762\u7684\u4ecb\u7ecd\uff0c\u5b83\u4e3b\u8981\u662f\u548cdeclaration\u3001entity\u3001scope\u76f8\u5173\u8054\uff0c\u6211\u89c9\u5f97\u8fd9\u4e2a\u53ef\u4ee5\u8fd9\u6837\u8ba4\u4e3a\uff1aname\u6982\u5ff5\u662f\u548centity\u6982\u5ff5\u76f8\u5173\u8054\uff0c\u6216\u8005\u8bf4\uff0c\u6bcf\u4e2aentity\u90fd\u6709\u4e00\u4e2aname\u3002 \u603b\u7684\u6765\u8bf4\uff1aword\u3001identifier\u3001name\uff0c\u90fd\u662f\u9759\u6001\u6982\u5ff5\uff0c\u90fd\u662f\u6709compiler\u6765\u8fdb\u884c\u7406\u89e3\u7684\u3002 variable\u5219\u662f\u4e00\u4e2a\u52a8\u6001\u6982\u5ff5\u3001\u662f\u4e00\u4e2a\u8fd0\u884c\u65f6\u6982\u5ff5\uff0c\u5b83\u6240\u8868\u793a\u7684\u542b\u4e49\u6709\uff1amemory\u3002","title":"word\u3001identifier\u3001name\u3001variable"},{"location":"C++/Language-reference/Basic-concept/Variable/","text":"Variable c++\u4e2dvariable\u7684\u6982\u5ff5\u548cobject\u7684\u6982\u5ff5\u5bc6\u5207\u76f8\u5173\u3002 learncpp 1.3 \u2014 Introduction to variables","title":"Variable"},{"location":"C++/Language-reference/Basic-concept/Variable/#variable","text":"c++\u4e2dvariable\u7684\u6982\u5ff5\u548cobject\u7684\u6982\u5ff5\u5bc6\u5207\u76f8\u5173\u3002 learncpp 1.3 \u2014 Introduction to variables","title":"Variable"},{"location":"C++/Language-reference/Basic-concept/Data-model/","text":"\u5173\u4e8e\u672c\u7ae0 \u5728python\u6807\u51c6\u6587\u6863\u7684 Data model \u4e2d\u63cf\u8ff0\u4e86python \u8bed\u8a00\u7684data model\uff0c\u6536\u5230python\u6807\u51c6\u6587\u6863\u7684\u542f\u53d1\uff0c\u6211\u89c9\u5f97\u4e5f\u6709\u5fc5\u8981\u4e3ac++\u8bed\u8a00\u4e5f\u521b\u5efa\u63cf\u8ff0\u5b83\u7684data model\u7684\u7ae0\u8282\uff0cc++\u8bed\u8a00\u4e5f\u6709\u5b83\u7684data model\uff0c\u4e0b\u9762\u662fcppreference\u4e2d\u5173\u4e8e\u6b64\u7684\u5185\u5bb9\uff1a Object Memory model","title":"Introduction"},{"location":"C++/Language-reference/Basic-concept/Data-model/#_1","text":"\u5728python\u6807\u51c6\u6587\u6863\u7684 Data model \u4e2d\u63cf\u8ff0\u4e86python \u8bed\u8a00\u7684data model\uff0c\u6536\u5230python\u6807\u51c6\u6587\u6863\u7684\u542f\u53d1\uff0c\u6211\u89c9\u5f97\u4e5f\u6709\u5fc5\u8981\u4e3ac++\u8bed\u8a00\u4e5f\u521b\u5efa\u63cf\u8ff0\u5b83\u7684data model\u7684\u7ae0\u8282\uff0cc++\u8bed\u8a00\u4e5f\u6709\u5b83\u7684data model\uff0c\u4e0b\u9762\u662fcppreference\u4e2d\u5173\u4e8e\u6b64\u7684\u5185\u5bb9\uff1a Object Memory model","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"C++/Language-reference/Basic-concept/Data-model/Object-storage/","text":"","title":"Object-storage"},{"location":"C++/Language-reference/Basic-concept/Data-model/Object/","text":"Object \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u672c\u6587\u4e2d\u7684 object \u5e76\u4e0d\u662f\u6211\u4eec object-oriented programming \u4e2d\u6240\u6307\u7684 object\uff1b\u672c\u6587\u7684 object\u662f\u6307\u201cregion of storage\u201d\u3002\u663e\u7136\uff0c\u5b83\u7684\u542b\u4e49\u4e0eobject-oriented programming \u4e2d\u6240\u6307\u7684 object \u5b8c\u5168\u4e0d\u540c\uff1b \u6b64\u5904\u7684 object \u662f\u4e00\u4e2a runtime \u6982\u5ff5\uff0c\u56e0\u4e3a\u53ea\u6709\u5f53program\u8fd0\u884c\u7684\u65f6\u5019\uff0cobject\u624d\u4f1a\u88ab\u521b\u5efa\u3002 object\u6982\u5ff5\u5bf9\u4e8e\u7406\u89e3\u540e\u9762\u7684\u5185\u5bb9\u975e\u5e38\u91cd\u8981\uff0c\u540e\u8005\u8bf4\uff0c\u540e\u7eed\u7684\u5f88\u591a\u6982\u5ff5\u90fd\u662f\u5efa\u7acb\u5728object\u4e4b\u4e0a\u7684\u3002 cppreference Object C++ programs create, destroy, refer to, access, and manipulate objects . NOTE: \u5728\u4e0a\u4e00\u8282\u6211\u4eec\u63cf\u8ff0\u4e86C++ program\u7684\u7ec4\u6210\uff08\u662f\u9759\u6001\u7684\u3001compile-time\u7684\uff09\uff0c\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u63cf\u8ff0\u4e86C++ program\u5728runtime\u6240\u505a\u7684\u4e8b\u60c5\u3002 Lifetime of object object\u7684initialization\u3002 Variable and object \u4e24\u79cd\u90fd\u662fruntime\u6982\u5ff5\uff0cvariable\u662f\u4e00\u79cdobject\uff0c\u4f46\u662f\u4e0d\u662f\u6240\u6709\u7684object\u90fd\u662fvariable\u3002","title":"Object"},{"location":"C++/Language-reference/Basic-concept/Data-model/Object/#object","text":"\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u672c\u6587\u4e2d\u7684 object \u5e76\u4e0d\u662f\u6211\u4eec object-oriented programming \u4e2d\u6240\u6307\u7684 object\uff1b\u672c\u6587\u7684 object\u662f\u6307\u201cregion of storage\u201d\u3002\u663e\u7136\uff0c\u5b83\u7684\u542b\u4e49\u4e0eobject-oriented programming \u4e2d\u6240\u6307\u7684 object \u5b8c\u5168\u4e0d\u540c\uff1b \u6b64\u5904\u7684 object \u662f\u4e00\u4e2a runtime \u6982\u5ff5\uff0c\u56e0\u4e3a\u53ea\u6709\u5f53program\u8fd0\u884c\u7684\u65f6\u5019\uff0cobject\u624d\u4f1a\u88ab\u521b\u5efa\u3002 object\u6982\u5ff5\u5bf9\u4e8e\u7406\u89e3\u540e\u9762\u7684\u5185\u5bb9\u975e\u5e38\u91cd\u8981\uff0c\u540e\u8005\u8bf4\uff0c\u540e\u7eed\u7684\u5f88\u591a\u6982\u5ff5\u90fd\u662f\u5efa\u7acb\u5728object\u4e4b\u4e0a\u7684\u3002","title":"Object"},{"location":"C++/Language-reference/Basic-concept/Data-model/Object/#cppreference-object","text":"C++ programs create, destroy, refer to, access, and manipulate objects . NOTE: \u5728\u4e0a\u4e00\u8282\u6211\u4eec\u63cf\u8ff0\u4e86C++ program\u7684\u7ec4\u6210\uff08\u662f\u9759\u6001\u7684\u3001compile-time\u7684\uff09\uff0c\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u63cf\u8ff0\u4e86C++ program\u5728runtime\u6240\u505a\u7684\u4e8b\u60c5\u3002","title":"cppreference Object"},{"location":"C++/Language-reference/Basic-concept/Data-model/Object/#lifetime-of-object","text":"object\u7684initialization\u3002","title":"Lifetime of object"},{"location":"C++/Language-reference/Basic-concept/Data-model/Object/#variable-and-object","text":"\u4e24\u79cd\u90fd\u662fruntime\u6982\u5ff5\uff0cvariable\u662f\u4e00\u79cdobject\uff0c\u4f46\u662f\u4e0d\u662f\u6240\u6709\u7684object\u90fd\u662fvariable\u3002","title":"Variable and object"},{"location":"C++/Language-reference/Basic-concept/Data-model/Memory-model/Memory-model/","text":"Memory model cppreference Memory model modernescpp C++ Memory Model","title":"Memory-model"},{"location":"C++/Language-reference/Basic-concept/Data-model/Memory-model/Memory-model/#memory-model","text":"","title":"Memory model"},{"location":"C++/Language-reference/Basic-concept/Data-model/Memory-model/Memory-model/#cppreference-memory-model","text":"","title":"cppreference Memory model"},{"location":"C++/Language-reference/Basic-concept/Data-model/Memory-model/Memory-model/#modernescpp-c-memory-model","text":"","title":"modernescpp C++ Memory Model"},{"location":"C++/Language-reference/Basic-concept/Declarations/Declarators/Pointer-declaration/","text":"","title":"Introduction"},{"location":"C++/Language-reference/Basic-concept/Named-requirements/","text":"","title":"Introduction"},{"location":"C++/Language-reference/Basic-concept/Type-system/Const/","text":"Const const to Non-const Conversion in C++ C++ Avoiding duplication of code in const and non-const getter methods Const Correctness Const Correctness \u00b6 \u0394 casting non const to const in c++","title":"Const"},{"location":"C++/Language-reference/Basic-concept/Type-system/Const/#const","text":"const to Non-const Conversion in C++ C++ Avoiding duplication of code in const and non-const getter methods Const Correctness Const Correctness \u00b6 \u0394 casting non const to const in c++","title":"Const"},{"location":"C++/Language-reference/Basic-concept/Type-system/Type-system/","text":"Type system cppreference Type cppreference Type support library cppreference typeid type cast and conversion static_cast const_cast dynamic_cast reinterpret_cast explicit cast implicit conversions","title":"Type-system"},{"location":"C++/Language-reference/Basic-concept/Type-system/Type-system/#type-system","text":"","title":"Type system"},{"location":"C++/Language-reference/Basic-concept/Type-system/Type-system/#cppreference-type","text":"","title":"cppreference Type"},{"location":"C++/Language-reference/Basic-concept/Type-system/Type-system/#cppreference-type-support-library","text":"","title":"cppreference Type support library"},{"location":"C++/Language-reference/Basic-concept/Type-system/Type-system/#cppreference-typeid","text":"","title":"cppreference typeid"},{"location":"C++/Language-reference/Basic-concept/Type-system/Type-system/#type-cast-and-conversion","text":"static_cast const_cast dynamic_cast reinterpret_cast explicit cast implicit conversions","title":"type cast and conversion"},{"location":"C++/Language-reference/Classes/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u63cf\u8ff0\u5982\u4f55\u4f7f\u7528C++\u8fdb\u884cOOP\u3002","title":"Introduction"},{"location":"C++/Language-reference/Classes/#_1","text":"\u672c\u7ae0\u63cf\u8ff0\u5982\u4f55\u4f7f\u7528C++\u8fdb\u884cOOP\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"C++/Language-reference/Classes/Class/","text":"Classes \u5173\u4e8eOOP\u7684\u7406\u8bba\uff0c\u6211\u4eec\u5df2\u7ecf\u5728\u5176\u4ed6\u7684\u7ae0\u8282\u4e2d\u63cf\u8ff0\u4e86\uff0cC++ \u7684 OOP\u5c5e\u4e8e class-based OOP\uff0c\u73b0\u5728\u6765\u770b\u770bC++\u4e2d\u5982\u4f55\u5b9e\u73b0OOP\u3002 cppreference Classes","title":"Class"},{"location":"C++/Language-reference/Classes/Class/#classes","text":"\u5173\u4e8eOOP\u7684\u7406\u8bba\uff0c\u6211\u4eec\u5df2\u7ecf\u5728\u5176\u4ed6\u7684\u7ae0\u8282\u4e2d\u63cf\u8ff0\u4e86\uff0cC++ \u7684 OOP\u5c5e\u4e8e class-based OOP\uff0c\u73b0\u5728\u6765\u770b\u770bC++\u4e2d\u5982\u4f55\u5b9e\u73b0OOP\u3002","title":"Classes"},{"location":"C++/Language-reference/Classes/Class/#cppreference-classes","text":"","title":"cppreference Classes"},{"location":"C++/Language-reference/Classes/Magic-function/","text":"Magic function","title":"Introduction"},{"location":"C++/Language-reference/Classes/Magic-function/#magic-function","text":"","title":"Magic function"},{"location":"C++/Language-reference/Classes/Magic-function/Implicitly-defined/","text":"Implicitly-defined \u5bf9\u4e8e Constructor \u3001 Destructor \u3001 Assignment \uff0ccompiler\u5728user\u6ca1\u6709\u6307\u5b9a\u7684\u60c5\u51b5\u4e0b\uff0c\u4f1a\u63d0\u4f9b\u9ed8\u8ba4\u5b9e\u73b0\uff0c\u5f53\u7136\uff0c\u8fd9\u79cd\u9ed8\u8ba4\u5b9e\u73b0\u662f\u4e0d\u4e00\u5b9a\u4fdd\u8bc1\u6b63\u786e\u7684\u3002","title":"Implicitly-defined"},{"location":"C++/Language-reference/Classes/Magic-function/Implicitly-defined/#implicitly-defined","text":"\u5bf9\u4e8e Constructor \u3001 Destructor \u3001 Assignment \uff0ccompiler\u5728user\u6ca1\u6709\u6307\u5b9a\u7684\u60c5\u51b5\u4e0b\uff0c\u4f1a\u63d0\u4f9b\u9ed8\u8ba4\u5b9e\u73b0\uff0c\u5f53\u7136\uff0c\u8fd9\u79cd\u9ed8\u8ba4\u5b9e\u73b0\u662f\u4e0d\u4e00\u5b9a\u4fdd\u8bc1\u6b63\u786e\u7684\u3002","title":"Implicitly-defined"},{"location":"C++/Language-reference/Classes/Magic-function/Assignment/Assignment/","text":"Assignment cppreference Copy assignment operator cppreference Move assignment operator","title":"Assignment"},{"location":"C++/Language-reference/Classes/Magic-function/Assignment/Assignment/#assignment","text":"","title":"Assignment"},{"location":"C++/Language-reference/Classes/Magic-function/Assignment/Assignment/#cppreference-copy-assignment-operator","text":"","title":"cppreference Copy assignment operator"},{"location":"C++/Language-reference/Classes/Magic-function/Assignment/Assignment/#cppreference-move-assignment-operator","text":"","title":"cppreference Move assignment operator"},{"location":"C++/Language-reference/Classes/Magic-function/Constructor/","text":"","title":"Introduction"},{"location":"C++/Language-reference/Classes/Magic-function/Constructor/Code-example/","text":"Code example How can I initialize C++ object member variables in the constructor? \u53c2\u89c1 How can I initialize C++ object member variables in the constructor? \u7684 \u56de\u7b54 \u3002 #include <iostream> using namespace std ; class T { public : T () { a = 0 ; std :: cout << \"T default constructor\" << std :: endl ; } T ( int a ) : a ( a ) { std :: cout << \"T constructor\" << std :: endl ; } private : int a ; }; class TT { public : TT () { std :: cout << \"TT default constructor\" << std :: endl ; } TT ( int a ) : t ( a ) { std :: cout << \"TT constructor\" << std :: endl ; } private : T t ; }; int main () { TT tt ; TT tt2 ( 1 ); } \u8f93\u51fa\u5982\u4e0b\uff1a T default constructor TT default constructor T constructor TT constructork \u901a\u8fc7\u4e0a\u8ff0\u8f93\u51fa\u53ef\u4ee5\u770b\u5230\uff0c\u5728 TT \u7684default constructor\u4e2d\uff0c\u5373\u4f7f\u6211\u4eec\u6ca1\u6709\u663e\u5f0f\u5730\u8c03\u7528 T \u7684default constructor\uff0ccompiler\u8fd8\u662f\u8981\u6dfb\u52a0\u5bf9\u5b83\u7684\u8c03\u7528\uff0c\u56e0\u4e3a\u9700\u8981\u4f7f\u7528\u5b83\u6765construct\u5b83\u7684\u6210\u5458\u53d8\u91cf t \u3002","title":"Code-example"},{"location":"C++/Language-reference/Classes/Magic-function/Constructor/Code-example/#code-example","text":"","title":"Code example"},{"location":"C++/Language-reference/Classes/Magic-function/Constructor/Code-example/#how-can-i-initialize-c-object-member-variables-in-the-constructor","text":"\u53c2\u89c1 How can I initialize C++ object member variables in the constructor? \u7684 \u56de\u7b54 \u3002 #include <iostream> using namespace std ; class T { public : T () { a = 0 ; std :: cout << \"T default constructor\" << std :: endl ; } T ( int a ) : a ( a ) { std :: cout << \"T constructor\" << std :: endl ; } private : int a ; }; class TT { public : TT () { std :: cout << \"TT default constructor\" << std :: endl ; } TT ( int a ) : t ( a ) { std :: cout << \"TT constructor\" << std :: endl ; } private : T t ; }; int main () { TT tt ; TT tt2 ( 1 ); } \u8f93\u51fa\u5982\u4e0b\uff1a T default constructor TT default constructor T constructor TT constructork \u901a\u8fc7\u4e0a\u8ff0\u8f93\u51fa\u53ef\u4ee5\u770b\u5230\uff0c\u5728 TT \u7684default constructor\u4e2d\uff0c\u5373\u4f7f\u6211\u4eec\u6ca1\u6709\u663e\u5f0f\u5730\u8c03\u7528 T \u7684default constructor\uff0ccompiler\u8fd8\u662f\u8981\u6dfb\u52a0\u5bf9\u5b83\u7684\u8c03\u7528\uff0c\u56e0\u4e3a\u9700\u8981\u4f7f\u7528\u5b83\u6765construct\u5b83\u7684\u6210\u5458\u53d8\u91cf t \u3002","title":"How can I initialize C++ object member variables in the constructor?"},{"location":"C++/Language-reference/Classes/Magic-function/Constructor/Constructor/","text":"Constructor \u201cConstructor\u201d\u5373\u201c\u6784\u9020\u51fd\u6570\u201d\u3002\u6211\u4eec\u5df2\u7ecf\u77e5\u9053\u4e86object\u662f\u5728runtime\u521b\u5efa\uff0c\u6839\u636eData-model\u7ae0\u8282\u7684\u89c2\u70b9\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06object\u7b80\u5355\u5730\u770b\u505a\u662f\u4e00\u7247\u5185\u5b58\u533a\u57df\uff0c\u663e\u7136\u8fd9\u7247\u5185\u5b58\u533a\u57df\u80af\u5b9a\u4f1a\u5305\u542b non-static data members \uff0c\u90a3\u5f53\u7a0b\u5e8f\u8fd0\u884c\u65f6\uff0c\u5982\u4f55\u6765initialize\u8fd9\u7247\u5185\u5b58\u533a\u57df\u5462\uff1f\u8fd9\u5bf9\u4e8ec++ OOP\u662f\u975e\u5e38\u91cd\u8981\u7684\uff0c\u56e0\u4e3a\u53ea\u6709\u6b63\u786e\u5730\u521d\u59cb\u5316\u540e\uff0cobject\u624d\u80fd\u591f\u6b63\u786e\u5730\u8fd0\u884c\u3002c++\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684constructor\uff0c\u7a0b\u5e8f\u5458\u9700\u8981\u8c28\u614e\u5730\u5b9e\u73b0\u4ee5\u6b63\u786e\u5730initialize\u8fd9\u4e9b\u6570\u636e\u3002\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0cconstructor\u662f\u4e5f\u662f\u4e00\u79cd Initialization \u3002\u672c\u6587\u5bf9c++\u4e2d\u7684constructor\u8fdb\u884c\u603b\u7ed3\u3002 cppreference Non-static data members cppreference Constructors and member initializer lists cppreference Default constructors cppreference Copy constructors cppreference Move constructors cppreference Converting constructor","title":"Constructor"},{"location":"C++/Language-reference/Classes/Magic-function/Constructor/Constructor/#constructor","text":"\u201cConstructor\u201d\u5373\u201c\u6784\u9020\u51fd\u6570\u201d\u3002\u6211\u4eec\u5df2\u7ecf\u77e5\u9053\u4e86object\u662f\u5728runtime\u521b\u5efa\uff0c\u6839\u636eData-model\u7ae0\u8282\u7684\u89c2\u70b9\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06object\u7b80\u5355\u5730\u770b\u505a\u662f\u4e00\u7247\u5185\u5b58\u533a\u57df\uff0c\u663e\u7136\u8fd9\u7247\u5185\u5b58\u533a\u57df\u80af\u5b9a\u4f1a\u5305\u542b non-static data members \uff0c\u90a3\u5f53\u7a0b\u5e8f\u8fd0\u884c\u65f6\uff0c\u5982\u4f55\u6765initialize\u8fd9\u7247\u5185\u5b58\u533a\u57df\u5462\uff1f\u8fd9\u5bf9\u4e8ec++ OOP\u662f\u975e\u5e38\u91cd\u8981\u7684\uff0c\u56e0\u4e3a\u53ea\u6709\u6b63\u786e\u5730\u521d\u59cb\u5316\u540e\uff0cobject\u624d\u80fd\u591f\u6b63\u786e\u5730\u8fd0\u884c\u3002c++\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684constructor\uff0c\u7a0b\u5e8f\u5458\u9700\u8981\u8c28\u614e\u5730\u5b9e\u73b0\u4ee5\u6b63\u786e\u5730initialize\u8fd9\u4e9b\u6570\u636e\u3002\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0cconstructor\u662f\u4e5f\u662f\u4e00\u79cd Initialization \u3002\u672c\u6587\u5bf9c++\u4e2d\u7684constructor\u8fdb\u884c\u603b\u7ed3\u3002","title":"Constructor"},{"location":"C++/Language-reference/Classes/Magic-function/Constructor/Constructor/#cppreference-non-static-data-members","text":"","title":"cppreference Non-static data members"},{"location":"C++/Language-reference/Classes/Magic-function/Constructor/Constructor/#cppreference-constructors-and-member-initializer-lists","text":"","title":"cppreference Constructors and member initializer lists"},{"location":"C++/Language-reference/Classes/Magic-function/Constructor/Constructor/#cppreference-default-constructors","text":"","title":"cppreference Default constructors"},{"location":"C++/Language-reference/Classes/Magic-function/Constructor/Constructor/#cppreference-copy-constructors","text":"","title":"cppreference Copy constructors"},{"location":"C++/Language-reference/Classes/Magic-function/Constructor/Constructor/#cppreference-move-constructors","text":"","title":"cppreference Move constructors"},{"location":"C++/Language-reference/Classes/Magic-function/Constructor/Constructor/#cppreference-converting-constructor","text":"","title":"cppreference Converting constructor"},{"location":"C++/Language-reference/Classes/Magic-function/Constructor/Converting-constructor/","text":"Converting constructor cppreference Converting constructor","title":"Converting-constructor"},{"location":"C++/Language-reference/Classes/Magic-function/Constructor/Converting-constructor/#converting-constructor","text":"","title":"Converting constructor"},{"location":"C++/Language-reference/Classes/Magic-function/Constructor/Converting-constructor/#cppreference-converting-constructor","text":"","title":"cppreference Converting constructor"},{"location":"C++/Language-reference/Classes/Magic-function/Destructor/Destructor/","text":"Destructor cppreference Destructors microsoft Destructors (C++) NOTE: microsoft \u7684\u8fd9\u7bc7\u5199\u7684\u4e5f\u4e0d\u9519","title":"Destructor"},{"location":"C++/Language-reference/Classes/Magic-function/Destructor/Destructor/#destructor","text":"","title":"Destructor"},{"location":"C++/Language-reference/Classes/Magic-function/Destructor/Destructor/#cppreference-destructors","text":"","title":"cppreference Destructors"},{"location":"C++/Language-reference/Classes/Magic-function/Destructor/Destructor/#microsoft-destructors-c","text":"NOTE: microsoft \u7684\u8fd9\u7bc7\u5199\u7684\u4e5f\u4e0d\u9519","title":"microsoft Destructors (C++)"},{"location":"C++/Language-reference/Classes/Magic-function/Destructor/Virtual-destructor/","text":"When to use virtual destructors? Virtual destructors are useful when you can delete an instance of a derived class through a pointer to base class : class Base { // some virtual methods }; class Derived : public Base { ~ Derived () { // Do some important cleanup } }; Here, you'll notice that I didn't declare Base's destructor to be virtual . Now, let's have a look at the following snippet: Base * b = new Derived (); // use b delete b ; // Here's the problem! Since Base's destructor is not virtual and b is a Base* pointing to a Derived object, delete b has undefined behaviour : [In delete b ], if the static type of the object to be deleted is different from its dynamic type , the static type shall be a base class of the dynamic type of the object to be deleted and the static type shall have a virtual destructor or the behavior is undefined . \u603b\u7ed3\uff1a \u4ee5\u4e0b\u662f\u6211\u6d4b\u8bd5\u7684\u4ee3\u7801\uff0c\u53d1\u73b0\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u786e\u5b9e\u5982\u4e0a\u6240\u8bf4\uff0c\u662f\u4e0d\u4f1a\u89e6\u53d1dynamic dispatch\uff0c\u5373\u4e0d\u4f1a\u6267\u884c Derived \u7684\u6790\u6784\u51fd\u6570\uff0c\u800c\u53ea\u4f1a\u6267\u884c\u57fa\u7c7b\u7684\u6784\u9020\u51fd\u6570\u3002 #include <iostream> class Base { public : //\u5fc5\u987b\u8981\u52a0\u4e0apublic\uff0c\u5426\u5219\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u662fprivate // some virtual methods ~ Base () { // Do some important cleanup std :: cout << \"Base destructor\" << std :: endl ; } }; class Derived : public Base { ~ Derived () { // Do some important cleanup std :: cout << \"derived destructor\" << std :: endl ; } }; int main () { Base * b = new Derived (); // use b delete b ; // Here's the problem! } In most implementations, the call to the destructor will be resolved like any non-virtual code, meaning that the destructor of the base class will be called but not the one of the derived class, resulting in a resources leak. To sum up, always make base classes' destructors virtual when they're meant to be manipulated polymorphically. If you want to prevent the deletion of an instance through a base class pointer , you can make the base class destructor protected and nonvirtual ; by doing so, the compiler won't let you call delete on a base class pointer. \u603b\u7ed3\uff1a\u8fd9\u79cd\u901a\u8fc7\u4f7f\u7528\u7f16\u8bd1\u5668\u6765\u4fdd\u8bc1\u6b63\u786e\u6027\u7684\u505a\u6cd5\u662f\u975e\u5e38\u503c\u7684\u501f\u9274\u7684\uff0c\u4f46\u662f\u8fd9\u91cc\u4e3a\u4ec0\u4e48 protected \u800c\u4e0d\u662f private \u5462\uff1f\u56e0\u4e3a\u6211\u5728\u5199\u4e0a\u8ff0\u4ee3\u7801\u7684\u65f6\u5019\uff0c\u7b2c\u4e00\u6b21\u7684\u786e\u662f\u5c06\u5176\u58f0\u660e\u4e3a private \u4e86\u3002\u5176\u5b9e\u8fd9\u91cc\u5c31\u6d89\u53ca\u5230\u4e86c++\u4e2d\u7684destructor\uff0c\u4ee3\u7801\u5982\u4e0b\uff1a #include <iostream> class Base { // some virtual methods //public: virtual ~ Base () { std :: cout << \"base destructor\" << std :: endl ; } }; class Derived : public Base { ~ Derived () { // Do some important cleanup std :: cout << \"derived destructor\" << std :: endl ; } }; int main () { //Base *b = new Derived(); // use b //delete b; // Here's the problem! } \u4e0a\u9762\u8fd9\u6bb5\u4ee3\u7801\u4e00\u65e6\u7f16\u8bd1\u5c31\u4f1a\u62a5\u9519\u3002 You can learn more about virtuality and virtual base class destructor in this article from Herb Sutter .","title":"Virtual-destructor"},{"location":"C++/Language-reference/Classes/Magic-function/Destructor/Virtual-destructor/#when-to-use-virtual-destructors","text":"Virtual destructors are useful when you can delete an instance of a derived class through a pointer to base class : class Base { // some virtual methods }; class Derived : public Base { ~ Derived () { // Do some important cleanup } }; Here, you'll notice that I didn't declare Base's destructor to be virtual . Now, let's have a look at the following snippet: Base * b = new Derived (); // use b delete b ; // Here's the problem! Since Base's destructor is not virtual and b is a Base* pointing to a Derived object, delete b has undefined behaviour : [In delete b ], if the static type of the object to be deleted is different from its dynamic type , the static type shall be a base class of the dynamic type of the object to be deleted and the static type shall have a virtual destructor or the behavior is undefined . \u603b\u7ed3\uff1a \u4ee5\u4e0b\u662f\u6211\u6d4b\u8bd5\u7684\u4ee3\u7801\uff0c\u53d1\u73b0\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u786e\u5b9e\u5982\u4e0a\u6240\u8bf4\uff0c\u662f\u4e0d\u4f1a\u89e6\u53d1dynamic dispatch\uff0c\u5373\u4e0d\u4f1a\u6267\u884c Derived \u7684\u6790\u6784\u51fd\u6570\uff0c\u800c\u53ea\u4f1a\u6267\u884c\u57fa\u7c7b\u7684\u6784\u9020\u51fd\u6570\u3002 #include <iostream> class Base { public : //\u5fc5\u987b\u8981\u52a0\u4e0apublic\uff0c\u5426\u5219\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u662fprivate // some virtual methods ~ Base () { // Do some important cleanup std :: cout << \"Base destructor\" << std :: endl ; } }; class Derived : public Base { ~ Derived () { // Do some important cleanup std :: cout << \"derived destructor\" << std :: endl ; } }; int main () { Base * b = new Derived (); // use b delete b ; // Here's the problem! } In most implementations, the call to the destructor will be resolved like any non-virtual code, meaning that the destructor of the base class will be called but not the one of the derived class, resulting in a resources leak. To sum up, always make base classes' destructors virtual when they're meant to be manipulated polymorphically. If you want to prevent the deletion of an instance through a base class pointer , you can make the base class destructor protected and nonvirtual ; by doing so, the compiler won't let you call delete on a base class pointer. \u603b\u7ed3\uff1a\u8fd9\u79cd\u901a\u8fc7\u4f7f\u7528\u7f16\u8bd1\u5668\u6765\u4fdd\u8bc1\u6b63\u786e\u6027\u7684\u505a\u6cd5\u662f\u975e\u5e38\u503c\u7684\u501f\u9274\u7684\uff0c\u4f46\u662f\u8fd9\u91cc\u4e3a\u4ec0\u4e48 protected \u800c\u4e0d\u662f private \u5462\uff1f\u56e0\u4e3a\u6211\u5728\u5199\u4e0a\u8ff0\u4ee3\u7801\u7684\u65f6\u5019\uff0c\u7b2c\u4e00\u6b21\u7684\u786e\u662f\u5c06\u5176\u58f0\u660e\u4e3a private \u4e86\u3002\u5176\u5b9e\u8fd9\u91cc\u5c31\u6d89\u53ca\u5230\u4e86c++\u4e2d\u7684destructor\uff0c\u4ee3\u7801\u5982\u4e0b\uff1a #include <iostream> class Base { // some virtual methods //public: virtual ~ Base () { std :: cout << \"base destructor\" << std :: endl ; } }; class Derived : public Base { ~ Derived () { // Do some important cleanup std :: cout << \"derived destructor\" << std :: endl ; } }; int main () { //Base *b = new Derived(); // use b //delete b; // Here's the problem! } \u4e0a\u9762\u8fd9\u6bb5\u4ee3\u7801\u4e00\u65e6\u7f16\u8bd1\u5c31\u4f1a\u62a5\u9519\u3002 You can learn more about virtuality and virtual base class destructor in this article from Herb Sutter .","title":"When to use virtual destructors?"},{"location":"C++/Language-reference/Classes/Members/","text":"","title":"Introduction"},{"location":"C++/Language-reference/Classes/Members/Static-members/","text":"static members cppreference static members","title":"Static-members"},{"location":"C++/Language-reference/Classes/Members/Static-members/#static-members","text":"","title":"static members"},{"location":"C++/Language-reference/Classes/Members/Static-members/#cppreference-static-members","text":"","title":"cppreference static members"},{"location":"C++/Language-reference/Exception/Exception/","text":"Exception cppreference Exceptions cppreference Error handling","title":"Exception"},{"location":"C++/Language-reference/Exception/Exception/#exception","text":"","title":"Exception"},{"location":"C++/Language-reference/Exception/Exception/#cppreference-exceptions","text":"","title":"cppreference Exceptions"},{"location":"C++/Language-reference/Exception/Exception/#cppreference-error-handling","text":"","title":"cppreference Error handling"},{"location":"C++/Language-reference/Expressions/","text":"Expressions \"expression\"\u5373\u201c\u8868\u8fbe\u5f0f\u201d\uff0c\u662f\u51e0\u4e4e\u6240\u6709\u7684programming language\u90fd\u4f1a\u6d89\u53ca\u5230\u7684\u4e00\u4e2a\u6982\u5ff5\uff0c\u6211\u4eec\u4f7f\u7528expression\u6765\u8868\u8fbe\u201c\u8ba1\u7b97\u201d\u3002\u8c08\u53caexpression\uff0c\u5c31\u6d89\u53ca\u5230operator\uff0c\u8c08\u53caoperator\u5373\u8bbe\u8ba1\u3002","title":"Introduction"},{"location":"C++/Language-reference/Expressions/#expressions","text":"\"expression\"\u5373\u201c\u8868\u8fbe\u5f0f\u201d\uff0c\u662f\u51e0\u4e4e\u6240\u6709\u7684programming language\u90fd\u4f1a\u6d89\u53ca\u5230\u7684\u4e00\u4e2a\u6982\u5ff5\uff0c\u6211\u4eec\u4f7f\u7528expression\u6765\u8868\u8fbe\u201c\u8ba1\u7b97\u201d\u3002\u8c08\u53caexpression\uff0c\u5c31\u6d89\u53ca\u5230operator\uff0c\u8c08\u53caoperator\u5373\u8bbe\u8ba1\u3002","title":"Expressions"},{"location":"C++/Language-reference/Expressions/Expressions/","text":"Expressions cppreference Expressions","title":"Expressions"},{"location":"C++/Language-reference/Expressions/Expressions/#expressions","text":"","title":"Expressions"},{"location":"C++/Language-reference/Expressions/Expressions/#cppreference-expressions","text":"","title":"cppreference Expressions"},{"location":"C++/Language-reference/Expressions/Memory-allocation/Memory-allocation/","text":"Memory allocation memory\u7684\u7ba1\u7406\u975e\u5e38\u91cd\u8981\u3002memory\u4e5f\u662f\u4e00\u79cdresource\uff0c\u4e0e\u672c\u6587\u76f8\u5173\u7684\u6709\uff1a RAII The-rule-of-three-five-zero new \u548c delete \u4e3b\u8981\u5c31\u662f\u4e24\u79cd\u5f62\u5f0f\uff0c\u4e00\u79cd\u662f cppreference new expression cppreference delete expression","title":"Memory-allocation"},{"location":"C++/Language-reference/Expressions/Memory-allocation/Memory-allocation/#memory-allocation","text":"memory\u7684\u7ba1\u7406\u975e\u5e38\u91cd\u8981\u3002memory\u4e5f\u662f\u4e00\u79cdresource\uff0c\u4e0e\u672c\u6587\u76f8\u5173\u7684\u6709\uff1a RAII The-rule-of-three-five-zero new \u548c delete \u4e3b\u8981\u5c31\u662f\u4e24\u79cd\u5f62\u5f0f\uff0c\u4e00\u79cd\u662f","title":"Memory allocation"},{"location":"C++/Language-reference/Expressions/Memory-allocation/Memory-allocation/#cppreference-new-expression","text":"","title":"cppreference new expression"},{"location":"C++/Language-reference/Expressions/Memory-allocation/Memory-allocation/#cppreference-delete-expression","text":"","title":"cppreference delete expression"},{"location":"C++/Language-reference/Expressions/Operator-overloading/Operator-overloading/","text":"operator overloading \u5bf9\u4e8euser-defined class\uff0c\u901a\u8fc7\u5b9a\u4e49member function\u6765\u5b9e\u73b0operator overloading\uff0c\u6240\u4ee5\u5c06\u8fd9\u90e8\u5206\u80fd\u5426\u653e\u5230\u4e86function\u7ae0\u8282\u3002 cppreference operator overloading","title":"Operator-overloading"},{"location":"C++/Language-reference/Expressions/Operator-overloading/Operator-overloading/#operator-overloading","text":"\u5bf9\u4e8euser-defined class\uff0c\u901a\u8fc7\u5b9a\u4e49member function\u6765\u5b9e\u73b0operator overloading\uff0c\u6240\u4ee5\u5c06\u8fd9\u90e8\u5206\u80fd\u5426\u653e\u5230\u4e86function\u7ae0\u8282\u3002","title":"operator overloading"},{"location":"C++/Language-reference/Expressions/Operator-overloading/Operator-overloading/#cppreference-operator-overloading","text":"","title":"cppreference operator overloading"},{"location":"C++/Language-reference/Functions/Lambda-expression/Lambda-expressions/","text":"Lambda expressions microsoft Lambda Expressions in C++ NOTE: \u8fd9\u7bc7\u8bb2\u89e3\u5730\u975e\u5e38\u597d cppreference Lambda expressions","title":"Lambda expressions"},{"location":"C++/Language-reference/Functions/Lambda-expression/Lambda-expressions/#lambda-expressions","text":"","title":"Lambda expressions"},{"location":"C++/Language-reference/Functions/Lambda-expression/Lambda-expressions/#microsoft-lambda-expressions-in-c","text":"NOTE: \u8fd9\u7bc7\u8bb2\u89e3\u5730\u975e\u5e38\u597d","title":"microsoft Lambda Expressions in C++"},{"location":"C++/Language-reference/Functions/Lambda-expression/Lambda-expressions/#cppreference-lambda-expressions","text":"","title":"cppreference Lambda expressions"},{"location":"C++/Language-reference/Functions/Operator-overloading/Operator-overloading/","text":"Operator overloading \u5728 cppreference \u4e2d\uff0c\u4ee5\u4e0b\u7ae0\u8282\u63cf\u8ff0\u4e86\u4e0eOperator overloading\u76f8\u5173\u7684\u5185\u5bb9\u3002 operator overloading Overload resolution Address of an overloaded function","title":"Operator-overloading"},{"location":"C++/Language-reference/Functions/Operator-overloading/Operator-overloading/#operator-overloading","text":"\u5728 cppreference \u4e2d\uff0c\u4ee5\u4e0b\u7ae0\u8282\u63cf\u8ff0\u4e86\u4e0eOperator overloading\u76f8\u5173\u7684\u5185\u5bb9\u3002 operator overloading Overload resolution Address of an overloaded function","title":"Operator overloading"},{"location":"C++/Language-reference/Initialization/","text":"\u5173\u4e8e\u672c\u7ae0 \"initialization\"\u5373\u201c\u521d\u59cb\u5316\u201d\uff0c\u672c\u7ae0\u63cf\u8ff0c++\u4e2dinitialization\u7684\u6982\u5ff5\u3001\u5982\u4f55\u8fdb\u884cinitialization\u7b49\u5185\u5bb9\u3002","title":"Introduction"},{"location":"C++/Language-reference/Initialization/#_1","text":"\"initialization\"\u5373\u201c\u521d\u59cb\u5316\u201d\uff0c\u672c\u7ae0\u63cf\u8ff0c++\u4e2dinitialization\u7684\u6982\u5ff5\u3001\u5982\u4f55\u8fdb\u884cinitialization\u7b49\u5185\u5bb9\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"C++/Language-reference/Initialization/Initialization/","text":"Initialization \u5148\u770b\u770b learncpp \u7684 1.4 \u2014 Variable assignment and initialization \u4e2d\u5173\u4e8einitialization\u7684\u4ecb\u7ecd\uff0c\u56e0\u4e3a\u5176\u4e2d\u7ed3\u5408\u4e86\u5177\u4f53\u7684\u793a\u4f8b\uff0c\u66f4\u52a0\u5bb9\u6613\u7406\u89e3\uff0c\u7136\u540e\u518d\u6765\u770bcppreference\u4e2d\u5bf9 Initialization \u7684\u66f4\u52a0\u6807\u51c6\u5316\u7684\u5b9a\u4e49\u3002 learncpp 1.4 \u2014 Variable assignment and initialization One downside of assignment is that it requires at least two statements: one to define the variable, and one to assign the value. These two steps can be combined. When a variable is defined, you can also provide an initial value for the variable at the same time. This is called initialization . C++ supports three basic ways to initialize a variable. First, we can do copy initialization by using an equals sign: int width = 5 ; // copy initialization of value 5 into variable width Much like copy assignment, this copies the value on the right-hand side of the equals to the variable being created on the left-hand side. Second, we can do direct initialization by using parenthesis. int width ( 5 ); // direct initialization of value 5 into variable width For simple data types (like integers), copy and direct initialization are essentially the same. But for some advanced types, direct initialization can perform better than copy initialization. Prior to C++11, direct initialization was recommended over copy initialization in most cases because of the performance boost. Initialization VS assignment \u4e24\u8005\u4e4b\u95f4\u7684\u76f8\u540c\u70b9\u662f\u90fd\u4f1a\u6539\u53d8object\u7684\u503c\u3002 cppreference Initialization Initialization of a variable provides its initial value at the time of construction. NOTE: TO READ learncpp 1.6 \u2014 Uninitialized variables and undefined behavior learncpp 8.5b \u2014 Non-static member initialization learncpp 8.5a \u2014 Constructor member initializer lists learncpp 11.4 \u2014 Constructors and initialization of derived classes learncpp 10.7 \u2014 std::initializer_list learncpp 9.12 \u2014 Copy initialization","title":"Initialization"},{"location":"C++/Language-reference/Initialization/Initialization/#initialization","text":"\u5148\u770b\u770b learncpp \u7684 1.4 \u2014 Variable assignment and initialization \u4e2d\u5173\u4e8einitialization\u7684\u4ecb\u7ecd\uff0c\u56e0\u4e3a\u5176\u4e2d\u7ed3\u5408\u4e86\u5177\u4f53\u7684\u793a\u4f8b\uff0c\u66f4\u52a0\u5bb9\u6613\u7406\u89e3\uff0c\u7136\u540e\u518d\u6765\u770bcppreference\u4e2d\u5bf9 Initialization \u7684\u66f4\u52a0\u6807\u51c6\u5316\u7684\u5b9a\u4e49\u3002","title":"Initialization"},{"location":"C++/Language-reference/Initialization/Initialization/#learncpp-14-variable-assignment-and-initialization","text":"One downside of assignment is that it requires at least two statements: one to define the variable, and one to assign the value. These two steps can be combined. When a variable is defined, you can also provide an initial value for the variable at the same time. This is called initialization . C++ supports three basic ways to initialize a variable. First, we can do copy initialization by using an equals sign: int width = 5 ; // copy initialization of value 5 into variable width Much like copy assignment, this copies the value on the right-hand side of the equals to the variable being created on the left-hand side. Second, we can do direct initialization by using parenthesis. int width ( 5 ); // direct initialization of value 5 into variable width For simple data types (like integers), copy and direct initialization are essentially the same. But for some advanced types, direct initialization can perform better than copy initialization. Prior to C++11, direct initialization was recommended over copy initialization in most cases because of the performance boost.","title":"learncpp 1.4 \u2014 Variable assignment and initialization"},{"location":"C++/Language-reference/Initialization/Initialization/#initialization-vs-assignment","text":"\u4e24\u8005\u4e4b\u95f4\u7684\u76f8\u540c\u70b9\u662f\u90fd\u4f1a\u6539\u53d8object\u7684\u503c\u3002","title":"Initialization VS assignment"},{"location":"C++/Language-reference/Initialization/Initialization/#cppreference-initialization","text":"Initialization of a variable provides its initial value at the time of construction. NOTE:","title":"cppreference Initialization"},{"location":"C++/Language-reference/Initialization/Initialization/#to-read","text":"learncpp 1.6 \u2014 Uninitialized variables and undefined behavior learncpp 8.5b \u2014 Non-static member initialization learncpp 8.5a \u2014 Constructor member initializer lists learncpp 11.4 \u2014 Constructors and initialization of derived classes learncpp 10.7 \u2014 std::initializer_list learncpp 9.12 \u2014 Copy initialization","title":"TO READ"},{"location":"C++/Language-reference/Statements/Iteration-statements/For/For/","text":"For cppreference for loop cppreference Range-based for loop","title":"For"},{"location":"C++/Language-reference/Statements/Iteration-statements/For/For/#for","text":"","title":"For"},{"location":"C++/Language-reference/Statements/Iteration-statements/For/For/#cppreference-for-loop","text":"","title":"cppreference for loop"},{"location":"C++/Language-reference/Statements/Iteration-statements/For/For/#cppreference-range-based-for-loop","text":"","title":"cppreference Range-based for loop"},{"location":"C++/Language-reference/draft/specifier/VS-qualifier VS specifier/","text":"qualifier and specifier Correlation between specifier and qualifier? A qualifier and specifier specifier\u7684\u542b\u4e49\u662f\uff1a[\u8ba1] \u8bf4\u660e\u7b26\uff1b\u6307\u793a\u8bed qualifier\u7684\u542b\u4e49\u662f\uff1a\u9650\u5b9a\u7b26\u3001\u9650\u5b9a\u8bcd\u3001\u4fee\u9970\u7b26\u3001\u4fee\u9970\u8bcd \u5176\u5b9e\u4ece\u4e24\u8005\u7684\u542b\u4e49\u5c31\u53ef\u4ee5\u770b\u51fa\u5b83\u4eec\u4e4b\u95f4\u7684\u533a\u522b\u4e86\uff1aspecifier\u7528\u4e8e\u6307\u5b9a\u5230\u5e95\u662f function \uff0c\u8fd8\u662f struct \uff0c\u800cqualifier\u5219\u662f\u4e3a\u4e86\u5728\u6dfb\u52a0\u4e00\u4e9b\u9650\u5236\uff1b \u5982c\u4e2d\u7684 Declarations \uff1a specifiers-and-qualifiers declarators-and-initializers; Correlation between specifier and qualifier? A Most of it doesn't make sense. Specifier and qualifier are defined in the C++ standard. Qualifier is just an integral part of a specifier . For example, type specifier in a declaration can include cv-qualifiers . I don't see the reason to quote everything from the standard on this topic. Cv-qualifiers are not restricted to lvalues. Rvalues of class types can also be cv-qualified. It is possible to cv-qualify an rvalue of non-class type, but it will have no effect and will be ignored. The use of const qualifier that you show in your example with foo is just a syntactic form, which actually means that the const-qualifier is applied to the implied this parameter of the foo method: const A* this . I.e. in this case it does indeed qualify an lvalue, but it is *this , not foo . The term qualifier also appears in the context of qualified names . Name like some_class::some_member (or some_namespace::some_name ) are called qualified names and the some_class:: part is a qualifier . The idea that if something is an lvalue then you can modify it is totally incorrect. There are modifiable*lvalues and *non-modifiable lvalues. An object declared as const int i = 5 is an lvalue, yet you can't modify it. Ordinary functions are also lvalues in C++, yet you can't modify a function.","title":"VS qualifier VS specifier"},{"location":"C++/Language-reference/draft/specifier/VS-qualifier VS specifier/#qualifier-and-specifier","text":"specifier\u7684\u542b\u4e49\u662f\uff1a[\u8ba1] \u8bf4\u660e\u7b26\uff1b\u6307\u793a\u8bed qualifier\u7684\u542b\u4e49\u662f\uff1a\u9650\u5b9a\u7b26\u3001\u9650\u5b9a\u8bcd\u3001\u4fee\u9970\u7b26\u3001\u4fee\u9970\u8bcd \u5176\u5b9e\u4ece\u4e24\u8005\u7684\u542b\u4e49\u5c31\u53ef\u4ee5\u770b\u51fa\u5b83\u4eec\u4e4b\u95f4\u7684\u533a\u522b\u4e86\uff1aspecifier\u7528\u4e8e\u6307\u5b9a\u5230\u5e95\u662f function \uff0c\u8fd8\u662f struct \uff0c\u800cqualifier\u5219\u662f\u4e3a\u4e86\u5728\u6dfb\u52a0\u4e00\u4e9b\u9650\u5236\uff1b \u5982c\u4e2d\u7684 Declarations \uff1a specifiers-and-qualifiers declarators-and-initializers;","title":"qualifier and specifier"},{"location":"C++/Language-reference/draft/specifier/VS-qualifier VS specifier/#correlation-between-specifier-and-qualifier","text":"","title":"Correlation between specifier and qualifier?"},{"location":"C++/Language-reference/draft/specifier/VS-qualifier VS specifier/#a","text":"Most of it doesn't make sense. Specifier and qualifier are defined in the C++ standard. Qualifier is just an integral part of a specifier . For example, type specifier in a declaration can include cv-qualifiers . I don't see the reason to quote everything from the standard on this topic. Cv-qualifiers are not restricted to lvalues. Rvalues of class types can also be cv-qualified. It is possible to cv-qualify an rvalue of non-class type, but it will have no effect and will be ignored. The use of const qualifier that you show in your example with foo is just a syntactic form, which actually means that the const-qualifier is applied to the implied this parameter of the foo method: const A* this . I.e. in this case it does indeed qualify an lvalue, but it is *this , not foo . The term qualifier also appears in the context of qualified names . Name like some_class::some_member (or some_namespace::some_name ) are called qualified names and the some_class:: part is a qualifier . The idea that if something is an lvalue then you can modify it is totally incorrect. There are modifiable*lvalues and *non-modifiable lvalues. An object declared as const int i = 5 is an lvalue, yet you can't modify it. Ordinary functions are also lvalues in C++, yet you can't modify a function.","title":"A"},{"location":"C++/Language-reference/draft/specifier/cpp-ref-qualifier/","text":"const& , & and && specifiers for member functions in C++ What does && mean at the end of a function signature (after the closing parenthesis)? [duplicate] Ref-qualifiers","title":"[const& , & and && specifiers for member functions in C++](https://stackoverflow.com/questions/28066777/const-and-specifiers-for-member-functions-in-c)"},{"location":"C++/Language-reference/draft/specifier/cpp-ref-qualifier/#const-and-specifiers-for-member-functions-in-c","text":"","title":"const&amp; , &amp; and &amp;&amp; specifiers for member functions in C++"},{"location":"C++/Language-reference/draft/specifier/cpp-ref-qualifier/#what-does-mean-at-the-end-of-a-function-signature-after-the-closing-parenthesis-duplicate","text":"","title":"What does &amp;&amp; mean at the end of a function signature (after the closing parenthesis)? [duplicate]"},{"location":"C++/Language-reference/draft/specifier/cpp-ref-qualifier/#ref-qualifiers","text":"","title":"Ref-qualifiers"},{"location":"C++/Language-reference/draft/specifier/cppreference-access-specifiers/","text":"access specifiers Syntax Explanation In detail Public member access Protected member access Private member access Inheritance What are POD types in C++? access specifiers In a member-specification of a class/struct or union , define the accessibility of subsequent\uff08\u540e\u7eed\u7684\uff09 members. In a base-specifier of a derived class declaration, define the accessibility of inherited members of the subsequent base class . \u601d\u8003\uff1adeclaration\u548cspecification\u7684\u533a\u522b\u548c\u8054\u7cfb Syntax **public** **:** member-declarations (1) **protected** **:** member-declarations (2) **private** **:** member-declarations (3) public base_class (4) protected base_class (5) private base_class (6) 1) The members declared after the specifier have public member access 2) The members declared after the specifier have protected member access 3) The members declared after the specifier have private member access 4) Public inheritance : the public and protected members of the base class listed after the specifier keep their member access in the derived class(\u57fa\u7c7b\u7684public\u548cprotected members\u5728\u5b50\u7c7b\u4e2d\u4fdd\u6301\u5176member access) 5) Protected inheritance : the public and protected members of the base class listed after the specifier are protected members of the derived class 6) Private inheritance : the public and protected members of the base class listed after the specifier are private members of the derived class \u603b\u7ed3\uff1a\u663e\u7136 private member of base class\u5728\u5b50\u7c7b\u4e2d\u662f\u65e0\u6cd5\u88ab\u8bbf\u95ee\u7684\uff1b\u663e\u7136\uff0caccess specifier\u80fd\u591f\u63a7\u5236\u4e24\u4e2a\u65b9\u9762\uff1a \u7528\u6237\u8bbf\u95eemember\u7684\u6743\u9650 \u57fa\u7c7b\u6210\u5458\u5728\u5b50\u7c7b\u4e2d\u7684\u8bbf\u95ee\u6743\u9650 \u601d\u8003\uff1abase class\u7684private member\u5728derived class\u4e2d\u80fd\u5426\u88ab\u8bbf\u95ee\uff1f Explanation The name of every class member (static, non-static, function, type, etc) has an associated \"member access\". When a name of the member is used anywhere a program, its access is checked, and if it does not satisfy the access rules, the program does not compile: \u603b\u7ed3\uff1a\u663e\u7136\uff0cmember access check\u662f \u53d1\u751f\u5728\u7f16\u8bd1\u671f\u7684 Run this code #include <iostream> class Example { public : // all declarations after this point are public void add ( int x ) { // member \"add\" has public access n += x ; // OK: private Example::n can be accessed from Example::add } private : // all declarations after this point are private int n = 0 ; // member \"n\" has private access }; int main () { Example e ; e . add ( 1 ); // OK: public Example::add can be accessed from main // e.n = 7; // Error: private Example::n cannot be accessed from main } Access specifiers give the author of the class the ability to decide which class members are accessible to the users of the class (that is, the interface ) and which members are for internal use of the class (the implementation ) \u603b\u7ed3\uff1a\u8fd9\u6bb5\u8bdd\u7ed9\u51fa\u4e86c++\u4e2d\u63d0\u4f9baccess specifier\u7684\u76ee\u7684 In detail \u603b\u7ed3\uff1a\u4e0b\u9762\u8fd9\u6bb5\u4e3b\u8981\u8bb2\u89e3\u7684\u662faccess rule\uff0c\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u4e0b\u9762\u7684\u8bba\u8ff0\u5176\u5b9e\u5305\u62ec\u4e86class member access\u548cnon class\u4e24\u79cd\u60c5\u51b5\u3002 All members of a class (bodies of member functions , initializers of member objects, and the entire nested class definitions ) have access to all the names to which a class can access\uff08\u4e00\u4e2a\u7c7b\u7684\u6240\u6709\u6210\u5458\u80fd\u591f\u8bbf\u95ee\u6240\u6709\u7ed9\u7c7b\u80fd\u591f\u8bbf\u95ee\u7684names). A local class within a member function has access to all the names the member function itself can access. A class defined with the keyword class has private access for its members and its base classes by default. A class defined with the keyword struct has public access for its members and its base classes by default. A union has public access for its members by default. \u603b\u7ed3\uff1a\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u662f\u6bd4\u8f83\u6982\u62ec\u6027\u7684\uff0c\u5b83\u7684\u542b\u4e49\u662f\uff1a\u65e0\u8bba\u662f\u6210\u5458\u51fd\u6570\uff0c\u8fd8\u662f\u7ee7\u627f\uff0c\u5728\u4e0d\u6307\u5b9aaccess specifier\u7684\u65f6\u5019\uff0c class \u7684\u9ed8\u8ba4\u6743\u9650\u662f private \uff0c struct \u7684\u9ed8\u8ba4\u6743\u9650\u662f public \u3002 To grant access to additional functions or classes to protected or private members, a friendship declaration may be used. \u603b\u7ed3\uff1a\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u610f\u601d\u662f\uff1a\u901a\u8fc7 friendship declaration \u53ef\u4ee5\u5c06\u4e00\u4e2a\u7c7b\u7684 protected or private members \u7684access\u6388\u4e88\u53e6\u5916\u7684function\u548cclass\u3002 Accessibility applies to all names with no regard to their origin, so a name introduced by a typedef or using declarations is checked, not the name it refers to. \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u610f\u601d\u662f\uff1aAccessibility\u68c0\u67e5\u4ec5\u4ec5\u4f5c\u7528\u4e8enames\uff0c\u800c\u65e0\u9700\u8003\u8651\u8fd9\u4e9bnames\u7684\u6765\u6e90\uff0c\u56e0\u6b64\u68c0\u67e5\u7531 typedef \u6216 using declarations \u5f15\u5165\u7684\u540d\u79f0\uff0c\u800c\u4e0d\u662f\u5b83\u6240\u5f15\u7528\u7684\u540d\u79f0\u3002 class A : X { class B { }; // B is private in A public : typedef B BB ; // BB is public }; void f () { A :: B y ; // error, A::B is private A :: BB x ; // OK, A::BB is public } \u603b\u7ed3\uff1a\u4e0a\u9762\u8fd9\u6bb5\u4ee3\u7801\u4e2d\uff0c\u9700\u8981\u6ce8\u610f\u7684\u662fclass B\u662fclass A\u7684member\uff0c\u7531\u4e8eauthor of class\u6ca1\u6709\u6307\u5b9aaccess specifier\uff0c\u6240\u4ee5\u5b83\u7684access\u9ed8\u8ba4\u662fprivate\u3002 Member access does not affect visibility : names of private and privately-inherited members are visible and considered by overload resolution , implicit conversions to inaccessible base classes are still considered, etc. \u603b\u7ed3\uff1a\u8fd9\u4e00\u6bb5\u63cf\u8ff0\u4e86member access\u548cvisibility\u7684\u5173\u7cfb\u3002 Member access check is the last step after any given language construct is interpreted. The intent of this rule is that replacing any private with public never alters the behavior of the program. Access checking for the names used in default function arguments (\u51fd\u6570\u9ed8\u8ba4\u53c2\u6570) as well as in the default template parameters is performed at the point of declaration, not at the point of use. Access rules for the names of virtual functions are checked at the call point using the type of the expression used to denote the object for which the member function is called. The access of the final overrider is ignored. \u603b\u7ed3\uff1a\u9700\u8981\u6ce8\u610f\u7684\u662f\u8fd9\u4e09\u6bb5\u8bdd\u63cf\u8ff0\u7684\u662faccess check\u53d1\u751f\u7684\u65f6\u673a\u3002\u7b2c\u4e00\u6bb5\u8bdd\u548c\u7b2c\u4e8c\u6bb5\u8bdd\u5206\u522b\u63cf\u8ff0\u4e86**Member access check**\u548c**Access checking**\uff0c\u663e\u7136\uff0c\u524d\u8005\u662f\u5173\u4e8eclass\u7684\uff0c\u800c\u540e\u8005\u5219\u4e3anon class\u3002 \u7b2c\u4e09\u6bb5\u8bdd\u7684\u7406\u89e3\u9700\u8981\u7ed3\u5408\u4e0b\u9762\u7684\u8fd9\u4e2a\u4f8b\u5b50\u6765\uff0c\u5e76\u4e14\u5176\u4e2d\u8fd8\u5305\u62ec\u4e00\u4e9b\u4e0d\u5bb9\u6613\u7406\u89e3\u7684\u540d\u8bcd\uff0c\u6bd4\u5982\uff0cfinal overrider\uff0c\u53c2\u89c1\u4e0b\u9762\u7684virtual function specifier\u7ae0\u8282\u5373\u53ef\u77e5\u3002\u53d8\u91cf b \u7684static type\u662f B \uff0c\u5176dynamic type\u662f D \uff0c\u7b2c\u4e09\u6bb5\u8bdd\u7684\u610f\u601d\u662f\u5bf9\u4e8evirtual functions\u7684access check\u662f\u901a\u8fc7\u5176\u8c03\u7528\u8005\u7684static type\u6765\u8fdb\u884c\u7684\uff0c\u6240\u4ee5\u5bf9\u53d8\u91cf b \u800c\u8a00\uff0c\u5176\u6210\u5458 f() \u662fpublic\u7684\uff0c b \u7684\u6210\u5458 f() \u7684final overrider\u662f\u5b9a\u4e49\u5728\u5176dynamic type D \u4e2d\u7684\u6210\u5458 f() \uff0c\u6240\u4ee5 b.f() \u6700\u7ec8\u8c03\u7528\u7684\u662f\u5176dynamic type D \u4e2d\u7684\u6210\u5458 f() \u3002\u663e\u7136\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0cThe access of the final overrider is ignored\u3002 struct B { virtual int f (); }; // f is public in B class D : public B { private : int f (); }; // f is private in D void f () { D d ; B & b = d ; b . f (); // OK: B::f() is public, D::f() is invoked even though it's private d . f (); // error: D::f() is private } A name that is private according to unqualified name lookup , may be accessible through qualified name lookup: class A { }; class B : private A { }; class C : public B { A * p ; // error: unqualified name lookup finds A as the private base of B :: A * q ; // OK, qualified name lookup finds the namespace-level declaration }; A name that is accessible through multiple paths in the inheritance graph has the access of the path with the most access: class W { public : void f (); }; class A : private virtual W { }; class B : public virtual W { }; class C : public A , public B { void f () { W :: f (); } // OK, W is accessible to C through B }; Any number of access specifiers may appear within a class, in any order. Member access specifiers may affect class layout: the addresses of non-static data members are only guaranteed to increase in order of declaration for the members with the same access. For StandardLayoutType , all non-static data members must have the same access. When a member is redeclared within the same class, it must do so under the same member access: struct S { class A ; // S::A is public private : class A {}; // error: cannot change access }; Public member access Public members form a part of the public interface of the class (other parts of the public interface are the non-member functions found by ADL ). A public member of a class is accessible everywhere. class S { public : // n, f, E, A, B, C, U are public members int n ; static void f () {} enum E { A , B , C }; struct U {}; }; int main () { S :: f (); // S::f is accessible in main S s ; s . n = S :: B ; // S::n and S::B are accesisble in main S :: U x ; // S::U is accessible in main } Protected member access Protected members form the interface for the derived classes (which is distinct from the public interface of the class). A protected member of a class Base can only be accessed 1) by the members and friends of Base 2) by the members and friends (until C++17) of any class derived from Base , but only when operating on an object of a type that is derived from Base (including this ) struct Base { protected: int i; private: void g(Base& b, struct Derived& d); }; struct Derived : Base { void f(Base& b, Derived& d) // member function of a derived class { ++d.i; // okay: the type of d is Derived ++i; // okay: the type of the implied '*this' is Derived // ++b.i; // error: can't access a protected member through Base // (Otherwise it would be possible to change other derived classes, // like a hypothetical Derived2, base implementation) } }; void Base::g(Base& b, Derived& d) // member function of Base { ++i; // okay ++b.i; // okay ++d.i; // okay } void x(Base& b, Derived& d) // non-member non-friend { // ++b.i; // error: no access from non-member // ++d.i; // error: no access from non-member } When a pointer to a protected member is formed, it must use a derived class in its declaration: struct Base { protected: int i; }; struct Derived : Base { void f() { // int Base::* ptr = &Base::i; // error: must name using Derived int Base::* ptr = &Derived::i; // okay } }; Private member access Private members form the implementation of a class, as well as the private interface for the other members of the class. A private member of a class can only be accessed by the members and friends of that class, regardless of whether the members are on the same or different instances: class S { private: int n; // S::n is private public: S() : n(10) {} // this->n is accessible in S::S S(const S& other) : n(other.n) {} // other.n is accessible in S::S }; The explicit cast (C-style and function-style) allows casting from a derived lvalue to reference to its private base, or from a pointer to derived to a pointer to its private base. Inheritance See derived classes for the meaning of public, protected, and private inheritance. What are POD types in C++?","title":"Cppreference access specifiers"},{"location":"C++/Language-reference/draft/specifier/cppreference-access-specifiers/#access-specifiers","text":"In a member-specification of a class/struct or union , define the accessibility of subsequent\uff08\u540e\u7eed\u7684\uff09 members. In a base-specifier of a derived class declaration, define the accessibility of inherited members of the subsequent base class . \u601d\u8003\uff1adeclaration\u548cspecification\u7684\u533a\u522b\u548c\u8054\u7cfb","title":"access specifiers"},{"location":"C++/Language-reference/draft/specifier/cppreference-access-specifiers/#syntax","text":"**public** **:** member-declarations (1) **protected** **:** member-declarations (2) **private** **:** member-declarations (3) public base_class (4) protected base_class (5) private base_class (6) 1) The members declared after the specifier have public member access 2) The members declared after the specifier have protected member access 3) The members declared after the specifier have private member access 4) Public inheritance : the public and protected members of the base class listed after the specifier keep their member access in the derived class(\u57fa\u7c7b\u7684public\u548cprotected members\u5728\u5b50\u7c7b\u4e2d\u4fdd\u6301\u5176member access) 5) Protected inheritance : the public and protected members of the base class listed after the specifier are protected members of the derived class 6) Private inheritance : the public and protected members of the base class listed after the specifier are private members of the derived class \u603b\u7ed3\uff1a\u663e\u7136 private member of base class\u5728\u5b50\u7c7b\u4e2d\u662f\u65e0\u6cd5\u88ab\u8bbf\u95ee\u7684\uff1b\u663e\u7136\uff0caccess specifier\u80fd\u591f\u63a7\u5236\u4e24\u4e2a\u65b9\u9762\uff1a \u7528\u6237\u8bbf\u95eemember\u7684\u6743\u9650 \u57fa\u7c7b\u6210\u5458\u5728\u5b50\u7c7b\u4e2d\u7684\u8bbf\u95ee\u6743\u9650 \u601d\u8003\uff1abase class\u7684private member\u5728derived class\u4e2d\u80fd\u5426\u88ab\u8bbf\u95ee\uff1f","title":"Syntax"},{"location":"C++/Language-reference/draft/specifier/cppreference-access-specifiers/#explanation","text":"The name of every class member (static, non-static, function, type, etc) has an associated \"member access\". When a name of the member is used anywhere a program, its access is checked, and if it does not satisfy the access rules, the program does not compile: \u603b\u7ed3\uff1a\u663e\u7136\uff0cmember access check\u662f \u53d1\u751f\u5728\u7f16\u8bd1\u671f\u7684 Run this code #include <iostream> class Example { public : // all declarations after this point are public void add ( int x ) { // member \"add\" has public access n += x ; // OK: private Example::n can be accessed from Example::add } private : // all declarations after this point are private int n = 0 ; // member \"n\" has private access }; int main () { Example e ; e . add ( 1 ); // OK: public Example::add can be accessed from main // e.n = 7; // Error: private Example::n cannot be accessed from main } Access specifiers give the author of the class the ability to decide which class members are accessible to the users of the class (that is, the interface ) and which members are for internal use of the class (the implementation ) \u603b\u7ed3\uff1a\u8fd9\u6bb5\u8bdd\u7ed9\u51fa\u4e86c++\u4e2d\u63d0\u4f9baccess specifier\u7684\u76ee\u7684","title":"Explanation"},{"location":"C++/Language-reference/draft/specifier/cppreference-access-specifiers/#in-detail","text":"\u603b\u7ed3\uff1a\u4e0b\u9762\u8fd9\u6bb5\u4e3b\u8981\u8bb2\u89e3\u7684\u662faccess rule\uff0c\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u4e0b\u9762\u7684\u8bba\u8ff0\u5176\u5b9e\u5305\u62ec\u4e86class member access\u548cnon class\u4e24\u79cd\u60c5\u51b5\u3002 All members of a class (bodies of member functions , initializers of member objects, and the entire nested class definitions ) have access to all the names to which a class can access\uff08\u4e00\u4e2a\u7c7b\u7684\u6240\u6709\u6210\u5458\u80fd\u591f\u8bbf\u95ee\u6240\u6709\u7ed9\u7c7b\u80fd\u591f\u8bbf\u95ee\u7684names). A local class within a member function has access to all the names the member function itself can access. A class defined with the keyword class has private access for its members and its base classes by default. A class defined with the keyword struct has public access for its members and its base classes by default. A union has public access for its members by default. \u603b\u7ed3\uff1a\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u662f\u6bd4\u8f83\u6982\u62ec\u6027\u7684\uff0c\u5b83\u7684\u542b\u4e49\u662f\uff1a\u65e0\u8bba\u662f\u6210\u5458\u51fd\u6570\uff0c\u8fd8\u662f\u7ee7\u627f\uff0c\u5728\u4e0d\u6307\u5b9aaccess specifier\u7684\u65f6\u5019\uff0c class \u7684\u9ed8\u8ba4\u6743\u9650\u662f private \uff0c struct \u7684\u9ed8\u8ba4\u6743\u9650\u662f public \u3002 To grant access to additional functions or classes to protected or private members, a friendship declaration may be used. \u603b\u7ed3\uff1a\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u610f\u601d\u662f\uff1a\u901a\u8fc7 friendship declaration \u53ef\u4ee5\u5c06\u4e00\u4e2a\u7c7b\u7684 protected or private members \u7684access\u6388\u4e88\u53e6\u5916\u7684function\u548cclass\u3002 Accessibility applies to all names with no regard to their origin, so a name introduced by a typedef or using declarations is checked, not the name it refers to. \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u610f\u601d\u662f\uff1aAccessibility\u68c0\u67e5\u4ec5\u4ec5\u4f5c\u7528\u4e8enames\uff0c\u800c\u65e0\u9700\u8003\u8651\u8fd9\u4e9bnames\u7684\u6765\u6e90\uff0c\u56e0\u6b64\u68c0\u67e5\u7531 typedef \u6216 using declarations \u5f15\u5165\u7684\u540d\u79f0\uff0c\u800c\u4e0d\u662f\u5b83\u6240\u5f15\u7528\u7684\u540d\u79f0\u3002 class A : X { class B { }; // B is private in A public : typedef B BB ; // BB is public }; void f () { A :: B y ; // error, A::B is private A :: BB x ; // OK, A::BB is public } \u603b\u7ed3\uff1a\u4e0a\u9762\u8fd9\u6bb5\u4ee3\u7801\u4e2d\uff0c\u9700\u8981\u6ce8\u610f\u7684\u662fclass B\u662fclass A\u7684member\uff0c\u7531\u4e8eauthor of class\u6ca1\u6709\u6307\u5b9aaccess specifier\uff0c\u6240\u4ee5\u5b83\u7684access\u9ed8\u8ba4\u662fprivate\u3002 Member access does not affect visibility : names of private and privately-inherited members are visible and considered by overload resolution , implicit conversions to inaccessible base classes are still considered, etc. \u603b\u7ed3\uff1a\u8fd9\u4e00\u6bb5\u63cf\u8ff0\u4e86member access\u548cvisibility\u7684\u5173\u7cfb\u3002 Member access check is the last step after any given language construct is interpreted. The intent of this rule is that replacing any private with public never alters the behavior of the program. Access checking for the names used in default function arguments (\u51fd\u6570\u9ed8\u8ba4\u53c2\u6570) as well as in the default template parameters is performed at the point of declaration, not at the point of use. Access rules for the names of virtual functions are checked at the call point using the type of the expression used to denote the object for which the member function is called. The access of the final overrider is ignored. \u603b\u7ed3\uff1a\u9700\u8981\u6ce8\u610f\u7684\u662f\u8fd9\u4e09\u6bb5\u8bdd\u63cf\u8ff0\u7684\u662faccess check\u53d1\u751f\u7684\u65f6\u673a\u3002\u7b2c\u4e00\u6bb5\u8bdd\u548c\u7b2c\u4e8c\u6bb5\u8bdd\u5206\u522b\u63cf\u8ff0\u4e86**Member access check**\u548c**Access checking**\uff0c\u663e\u7136\uff0c\u524d\u8005\u662f\u5173\u4e8eclass\u7684\uff0c\u800c\u540e\u8005\u5219\u4e3anon class\u3002 \u7b2c\u4e09\u6bb5\u8bdd\u7684\u7406\u89e3\u9700\u8981\u7ed3\u5408\u4e0b\u9762\u7684\u8fd9\u4e2a\u4f8b\u5b50\u6765\uff0c\u5e76\u4e14\u5176\u4e2d\u8fd8\u5305\u62ec\u4e00\u4e9b\u4e0d\u5bb9\u6613\u7406\u89e3\u7684\u540d\u8bcd\uff0c\u6bd4\u5982\uff0cfinal overrider\uff0c\u53c2\u89c1\u4e0b\u9762\u7684virtual function specifier\u7ae0\u8282\u5373\u53ef\u77e5\u3002\u53d8\u91cf b \u7684static type\u662f B \uff0c\u5176dynamic type\u662f D \uff0c\u7b2c\u4e09\u6bb5\u8bdd\u7684\u610f\u601d\u662f\u5bf9\u4e8evirtual functions\u7684access check\u662f\u901a\u8fc7\u5176\u8c03\u7528\u8005\u7684static type\u6765\u8fdb\u884c\u7684\uff0c\u6240\u4ee5\u5bf9\u53d8\u91cf b \u800c\u8a00\uff0c\u5176\u6210\u5458 f() \u662fpublic\u7684\uff0c b \u7684\u6210\u5458 f() \u7684final overrider\u662f\u5b9a\u4e49\u5728\u5176dynamic type D \u4e2d\u7684\u6210\u5458 f() \uff0c\u6240\u4ee5 b.f() \u6700\u7ec8\u8c03\u7528\u7684\u662f\u5176dynamic type D \u4e2d\u7684\u6210\u5458 f() \u3002\u663e\u7136\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0cThe access of the final overrider is ignored\u3002 struct B { virtual int f (); }; // f is public in B class D : public B { private : int f (); }; // f is private in D void f () { D d ; B & b = d ; b . f (); // OK: B::f() is public, D::f() is invoked even though it's private d . f (); // error: D::f() is private } A name that is private according to unqualified name lookup , may be accessible through qualified name lookup: class A { }; class B : private A { }; class C : public B { A * p ; // error: unqualified name lookup finds A as the private base of B :: A * q ; // OK, qualified name lookup finds the namespace-level declaration }; A name that is accessible through multiple paths in the inheritance graph has the access of the path with the most access: class W { public : void f (); }; class A : private virtual W { }; class B : public virtual W { }; class C : public A , public B { void f () { W :: f (); } // OK, W is accessible to C through B }; Any number of access specifiers may appear within a class, in any order. Member access specifiers may affect class layout: the addresses of non-static data members are only guaranteed to increase in order of declaration for the members with the same access. For StandardLayoutType , all non-static data members must have the same access. When a member is redeclared within the same class, it must do so under the same member access: struct S { class A ; // S::A is public private : class A {}; // error: cannot change access };","title":"In detail"},{"location":"C++/Language-reference/draft/specifier/cppreference-access-specifiers/#public-member-access","text":"Public members form a part of the public interface of the class (other parts of the public interface are the non-member functions found by ADL ). A public member of a class is accessible everywhere. class S { public : // n, f, E, A, B, C, U are public members int n ; static void f () {} enum E { A , B , C }; struct U {}; }; int main () { S :: f (); // S::f is accessible in main S s ; s . n = S :: B ; // S::n and S::B are accesisble in main S :: U x ; // S::U is accessible in main }","title":"Public member access"},{"location":"C++/Language-reference/draft/specifier/cppreference-access-specifiers/#protected-member-access","text":"Protected members form the interface for the derived classes (which is distinct from the public interface of the class). A protected member of a class Base can only be accessed 1) by the members and friends of Base 2) by the members and friends (until C++17) of any class derived from Base , but only when operating on an object of a type that is derived from Base (including this ) struct Base { protected: int i; private: void g(Base& b, struct Derived& d); }; struct Derived : Base { void f(Base& b, Derived& d) // member function of a derived class { ++d.i; // okay: the type of d is Derived ++i; // okay: the type of the implied '*this' is Derived // ++b.i; // error: can't access a protected member through Base // (Otherwise it would be possible to change other derived classes, // like a hypothetical Derived2, base implementation) } }; void Base::g(Base& b, Derived& d) // member function of Base { ++i; // okay ++b.i; // okay ++d.i; // okay } void x(Base& b, Derived& d) // non-member non-friend { // ++b.i; // error: no access from non-member // ++d.i; // error: no access from non-member } When a pointer to a protected member is formed, it must use a derived class in its declaration: struct Base { protected: int i; }; struct Derived : Base { void f() { // int Base::* ptr = &Base::i; // error: must name using Derived int Base::* ptr = &Derived::i; // okay } };","title":"Protected member access"},{"location":"C++/Language-reference/draft/specifier/cppreference-access-specifiers/#private-member-access","text":"Private members form the implementation of a class, as well as the private interface for the other members of the class. A private member of a class can only be accessed by the members and friends of that class, regardless of whether the members are on the same or different instances: class S { private: int n; // S::n is private public: S() : n(10) {} // this->n is accessible in S::S S(const S& other) : n(other.n) {} // other.n is accessible in S::S }; The explicit cast (C-style and function-style) allows casting from a derived lvalue to reference to its private base, or from a pointer to derived to a pointer to its private base.","title":"Private member access"},{"location":"C++/Language-reference/draft/specifier/cppreference-access-specifiers/#inheritance","text":"See derived classes for the meaning of public, protected, and private inheritance.","title":"Inheritance"},{"location":"C++/Language-reference/draft/specifier/cppreference-access-specifiers/#what-are-pod-types-in-c","text":"","title":"What are POD types in C++?"},{"location":"C++/Language-reference/draft/specifier/cppreference-cv(const-and-volatile)-type-qualifiers/","text":"english volatile in c++ Why does volatile exist? Why do we use volatile keyword in C++? cv (const and volatile) type qualifiers Explanation Keywords Notes supply volatile: The Multithreaded Programmer's Best Friend Just a Little Keyword Using volatile with User-Defined Types volatile, Critical Sections, and Race Conditions LockingPtr Back to Primitive Types volatile Member Functions Summary Acknowledgements english volatile \u6613\u53d8\u7684 notoriously \u81ed\u540d\u662d\u8457 devise \u8bbe\u8ba1 tame \u5236\u670d glitch \u6545\u969c disposes of \u5904\u7406\uff0c\u5356\u6389 volatile in c++ Why does volatile exist? C++ and the Perils of Double-Checked Locking \u2217 volatile: The Multithreaded Programmer's Best Friend Const and volatile Why do we use volatile keyword in C++? \u8fd9\u4e2a\u89e3\u91ca\u662f\u975e\u5e38\u597d\u7684\u3002 cv (const and volatile) type qualifiers \u603b\u7ed3\uff1a\u5176\u5b9e\u770b\u4e86\u8fd9\u4e2a\u4e4b\u540e\uff0c\u624d\u53d1\u89c9\u81ea\u5df1\u5bf9c++\u7684type system\u7684\u8ba4\u77e5\u662f\u6d45\u8584\u7684\uff0c\u539f\u6765c++\u4e2d\uff0c\u901a\u8fc7\u8fd9\u4e9bspecifier\u662f\u53ef\u4ee5\u8fdb\u4e00\u6b65\u5bf9type\u8fdb\u884c\u4fee\u9970\u7684\uff0c\u4ece\u800c\u53ef\u4ee5\u63d0\u4f9b\u66f4\u52a0\u4e30\u5bcc\u7684\u8bed\u4e49\u3002 Appear in any type specifier, including decl-specifier-seq of declaration grammar , to specify constness or volatility of the object being declared or of the type being named. const - defines that the type is constant . volatile - defines that the type is volatile . mutable - applies to non-static class members of non-reference non-const type and specifies that the member does not affect the externally visible state of the class (as often used for mutexes, memo caches, lazy evaluation, and access instrumentation). mutable members of const class instances are modifiable. (Note: the C++ language grammar treats mutable as a storage-class-specifier , but it does not affect storage class.) \u603b\u7ed3\uff1a\u663e\u7136mutable\u548cconst\u7684\u4ece\u8bed\u4e49\u6765\u770b\u662f\u76f8\u53cd\u7684\uff0cmutable\u548cvolatile\u7684\u4ece\u5b57\u9762\u542b\u4e49\u4e0a\u6765\u770b\u662f\u76f8\u8fd1\u7684\u3002\u4f46\u662f\u5b9e\u9645\u4e0a\u6211\u770b\u5230mutable\u548cconst\u662f\u662f\u53ef\u4ee5\u4e00\u8d77\u4f7f\u7528\u7684\uff0c\u5e76\u4e14\u5f53\u6d89\u53ca\u5230\u5bf9\u8c61\u548c\u5bf9\u8c61\u4e4b\u95f4\u7684\u5173\u7cfb\uff08\u6bd4\u5982\u4e00\u4e2a\u5bf9\u8c61\u4f5c\u4e3a\u53e6\u5916\u4e00\u4e2a\u5bf9\u8c61\u7684\u6210\u5458\u53d8\u91cf\uff09\uff0c\u90a3\u4e48\u8fd9\u4e09\u4e2aspecifier\u548c\u8fd9\u4e9b\u5173\u7cfb\u7684\u7ec4\u5408\u60c5\u51b5\u5c31\u662f\u975e\u5e38\u590d\u6742\u7684\u4e86\uff0c\u5e76\u4e14\u4e0b\u9762\u7684\u4ecb\u7ecd\u4e5f\u662f\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u6765\u8fdb\u884c\u7684\u3002\u6240\u4ee5\u51c6\u786e\u628a\u63e1\u4ed6\u4eec\u7684\u8bed\u4e49\u662f\u975e\u5e38\u91cd\u8981\u7684\u3002\u4ece\u540e\u7eed\u7684\u4ecb\u7ecd\u6765\u770b\uff0c\u5b83\u4e3b\u8981\u662f\u4ecb\u7ecd const \u548c volatile \uff0c\u800c mutable \u4ec5\u4ec5\u662f\u4f5c\u4e3a\u76f8\u5173\u5185\u5bb9\u3002\u663e\u7136\uff0c mutable \u5e76\u4e0d\u5c5e\u4e8e**cv type qualifiers**\u4e4b\u5217\uff0c\u4f46 mutable \u548c**cv type qualifiers**\u53c8\u6709\u975e\u5e38\u91cd\u8981\u7684\u8054\u7cfb\uff0c\u4ece\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u53ef\u4ee5\u770b\u51fa\uff1amutable\u548cconst\u7684\u8bed\u4e49\u662f\u76f8\u53cd\u7684\uff0c\u5e76\u4e14\uff0c mutable members of const class instances are modifiable. Explanation For any type T (including incomplete types), other than function type or reference type , there are three more distinct types in the C++ type system : const-qualified T , volatile-qualified T const-volatile-qualified T . Note: array types are considered to have the same cv-qualification as their element types. When an object is first created, the cv-qualifiers used (which could be part of decl-specifier-seq or part of a declarator in a declaration , or part of type-id in a new-expression ) determine the constness or volatility of the object, as follows: const object - an object whose type is const-qualified , or a non-mutable subobject of a const object . Such object cannot be modified: attempt to do so directly is a compile-time error, and attempt to do so indirectly (e.g., by modifying the const object through a reference or pointer to non-const type) results in undefined behavior (\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528 const_cast \u5c06\u4e00\u4e2aconst object\u8f6c\u6362\u4e3anon-const object\uff0c\u4f46\u662f\u5982\u679c\u4fee\u6539\u8f6c\u6362\u540e\u7684object\uff0c\u5219\u662f\u4f1a\u5bfc\u81f4undefined behavior\u7684\uff0c\u5728 \u8fd9\u7bc7\u6587\u7ae0 \u4e2d\u5bf9\u8fd9\u4e2a\u5185\u5bb9\u6709\u4ecb\u7ecd). volatile object - an object whose type is volatile-qualified , or a subobject of a volatile object , or a mutable subobject of a const-volatile object . Every access (read or write operation, member function call, etc.) made through a glvalue expression of volatile-qualified type is treated as a visible side-effect for the purposes of optimization (that is, within a single thread of execution, volatile accesses cannot be optimized out or reordered with another visible side effect that is sequenced-before or sequenced-after the volatile access. This makes volatile objects suitable for communication with a signal handler , but not with another thread of execution, see std::memory_order ). Any attempt to refer to a volatile object through a non-volatile glvalue (e.g. through a reference or pointer to non-volatile type) results in undefined behavior. const volatile object - an object whose type is const-volatile-qualified, a non-mutable subobject of a const volatile object, a const subobject of a volatile object, or a non-mutable volatile subobject of a const object. Behaves as both a const object and as a volatile object. This section is incomplete Reason: should discuss more about the differences between cv-qualified objects and cv-qualified expressions | There is partial ordering of cv-qualifiers by the order of increasing restrictions. The type can be said more or less cv-qualified then: unqualified < const unqualified < volatile unqualified < const volatile const < const volatile volatile < const volatile References and pointers to cv-qualified types may be implicitly converted to references and pointers to more cv-qualified types. In particular, the following conversions are allowed: reference/pointer to unqualified type can be converted to reference/pointer to const reference/pointer to unqualified type can be converted to reference/pointer to volatile reference/pointer to unqualified type can be converted to reference/pointer to const volatile reference/pointer to const type can be converted to reference/pointer to const volatile reference/pointer to volatile type can be converted to reference/pointer to const volatile Note: additional restrictions are imposed on multi-level pointers. To convert a reference or a pointer to a cv-qualified type to a reference or pointer to a less cv-qualified type, const_cast must be used. Keywords const , volatile , mutable Notes The const qualifier used on a declaration of a non-local non-volatile variable that is not declared extern gives it internal linkage . This is different from C where const file scope variables have external linkage. supply Note, however, that cv-qualifiers applied to an array type actually apply to its elements. The cv-qualified and cv-unqualified types are distinct. That is int is a distinct type from const int volatile: The Multithreaded Programmer's Best Friend The volatile keyword was devised(\u8bbe\u8ba1) to prevent compiler optimizations that might render code incorrect in the presence of certain asynchronous events. \u603b\u7ed3\uff1a\u5408\u7406\u5730\u5229\u7528compiler optimization\u662f\u975e\u5e38\u91cd\u8981\u7684\u3002 I don't want to spoil your mood, but this column addresses the dreaded topic of multithreaded programming(\u6211\u4e0d\u60f3\u7834\u574f\u4f60\u7684\u5fc3\u60c5\uff0c\u4f46\u672c\u4e13\u680f\u89e3\u51b3\u4e86\u591a\u7ebf\u7a0b\u7f16\u7a0b\u7684\u53ef\u6015\u4e3b\u9898). If \u2014 as the previous installment of Generic says \u2014 exception-safe programming is hard, it's child's play compared to multithreaded programming( \u5f02\u5e38\u5b89\u5168\u7f16\u7a0b\u5f88\u96be\uff0c\u90a3\u4e48\u4e0e\u591a\u7ebf\u7a0b\u7f16\u7a0b\u76f8\u6bd4\uff0c\u5b83\u5c31\u662f\u5b69\u5b50\u7684\u6e38\u620f). Programs using multiple threads are notoriously hard to write, prove correct, debug, maintain, and tame in general. Incorrect multithreaded programs might run for years without a glitch, only to unexpectedly run amok because some critical timing condition has been met. Needless to say(\u6bcb\u5eb8\u7f6e\u7591), a programmer writing multithreaded code needs all the help she can get. This column focuses on race conditions \u2014 a common source of trouble in multithreaded programs \u2014 and provides you with insights and tools on how to avoid them and, amazingly enough, have the compiler work hard at helping you with that(\u4ee4\u4eba\u60ca\u8bb6\u7684\u662f\uff0c\u8ba9\u7f16\u8bd1\u5668\u52aa\u529b\u5e2e\u52a9\u60a8\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898). Just a Little Keyword Although both C and C++ Standards are conspicuously silent when it comes to threads, they do make a little concession(\u8ba9\u6b65) to multithreading, in the form of the volatile keyword. Just like its better-known counterpart(\u5bf9\u5e94) const , volatile is a type modifier . It's intended to be used in conjunction with variables that are accessed and modified in different threads. Basically, without volatile , either writing multithreaded programs becomes impossible, or the compiler wastes vast optimization opportunities. An explanation is in order. Consider the following code: class Gadget { public : void Wait () { while ( ! flag_ ) { Sleep ( 1000 ); // sleeps for 1000 milliseconds } } void Wakeup () { flag_ = true ; } ... private : bool flag_ ; }; The purpose of Gadget::Wait above is to check the flag_ member variable every second and return when that variable has been set to true by another thread. At least that's what its programmer intended, but, alas, Wait is incorrect. Suppose the compiler figures out that Sleep(1000) is a call into an external library that cannot possibly modify the member variable flag_ . Then the compiler concludes that it can cache flag_ in a register and use that register instead of accessing the slower on-board memory . This is an excellent optimization for single-threaded code, but in this case, it harms correctness: after you call Wait for some Gadget object, although another thread calls Wakeup , Wait will loop forever. This is because the change of flag_ will not be reflected in the register that caches flag_ . The optimization is too ... optimistic. Caching variables in registers is a very valuable optimization that applies most of the time, so it would be a pity to waste it. C and C++ give you the chance to explicitly disable such caching. If you use the volatile modifier on a variable, the compiler won't cache that variable in registers \u2014 each access will hit the actual memory location of that variable. So all you have to do to make Gadget 's Wait / Wakeup combo work is to qualify(\u4fee\u9970\uff0c\u9650\u5b9a) flag_ appropriately: class Gadget { public : ... as above ... private : volatile bool flag_ ; }; Most explanations of the rationale(\u57fa\u672c\u539f\u7406) and usage of volatile stop here and advise you to volatile -qualify the primitive types that you use in multiple threads. However, there is much more you can do with volatile , because it is part of C++'s wonderful type system. Using volatile with User-Defined Types You can volatile -qualify not only primitive types , but also user-defined types . In that case, volatile modifies the type in a way similar to const . (You can also apply const and volatile to the same type simultaneously.) Unlike const , volatile discriminates(\u533a\u5206) between primitive types and user-defined types . Namely, unlike classes, primitive types still support all of their operations (addition, multiplication, assignment, etc.) when volatile -qualified. For example, you can assign a non- volatile int to a volatile int , but you cannot assign a non- volatile object to a volatile object. \u603b\u7ed3\uff1a\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u610f\u601d\u662f\uff0c\u5bf9\u4e8e**primitive types** \u548c**user-defined types**\uff0c\u5bf9**primitive types** \u800c\u8a00\uff0c volatile \u5e76\u4e0d\u6539\u53d8\u5176operations\uff0c\u4f46\u662f\u5bf9\u4e8e **user-defined types**\u800c\u8a00\uff0c volatile \u5219\u4f1a\u6539\u53d8\u5176operations\u3002 Let's illustrate how volatile works on user-defined types on an example. class Gadget { public : void Foo () volatile ; void Bar (); ... private : String name_ ; int state_ ; }; ... Gadget regularGadget ; volatile Gadget volatileGadget ; If you think volatile is not that useful with objects, prepare for some surprise. volatileGadget . Foo (); // ok, volatile fun called for // volatile object regularGadget . Foo (); // ok, volatile fun called for // non-volatile object volatileGadget . Bar (); // error! Non-volatile function called for // volatile object! The conversion from a non-qualified type to its volatile counterpart is trivial. However, just as with const , you cannot make the trip back from volatile to non-qualified . You must use a cast: Gadget & ref = const_cast < Gadget &> ( volatileGadget ); ref . Bar (); // ok A volatile -qualified class gives access only to a subset of its interface, a subset that is under the control of the class implementer. Users can gain full access to that type's interface only by using a const_cast . In addition, just like const ness, volatile ness propagates from the class to its members (for example, volatileGadget.name_ and volatileGadget.state_ are volatile variables)\u4f46\u662f\u5e76\u4e0d\u4f1apropagate to member method. \u603b\u7ed3\uff1a\u8fd9\u6bb5\u63cf\u8ff0\u4e86\u7ed9object\u6dfb\u52a0 volatile \u6240\u5e26\u6765\u7684\u6548\u679c\u3002 volatile, Critical Sections, and Race Conditions The simplest and the most often-used synchronization device in multithreaded programs is the mutex . A mutex exposes the Acquire and Release primitives. Once you call Acquire in some thread, any other thread calling Acquire will block. Later, when that thread calls Release , precisely one thread blocked in an Acquire call will be released. In other words, for a given mutex , only one thread can get processor time in between a call to Acquire and a call to Release . The executing code between a call to Acquire and a call to Release is called a critical section . (Windows terminology is a bit confusing because it calls the mutex itself a critical section, while \"mutex\" is actually an inter-process mutex. It would have been nice if they were called thread mutex and process mutex.) Mutexes are used to protect data against race conditions . By definition, a race condition occurs when the effect of more threads on data depends on how threads are scheduled. Race conditions appear when two or more threads compete for using the same data. Because threads can interrupt(\u6253\u65ad) each other at arbitrary moments in time, data can be corrupted(\u635f\u574f) or misinterpreted. Consequently, changes and sometimes accesses to data must be carefully protected with critical sections. In object-oriented programming, this usually means that you store a mutex in a class as a member variable and use it whenever you access that class' state. Experienced multithreaded programmers might have yawned(\u6253\u54c8\u6b20) reading the two paragraphs above, but their purpose is to provide an intellectual workout, because now we will link with the volatile connection. We do this by drawing a parallel between the C++ types' world and the threading semantics world. Outside a critical section , any thread might interrupt any other at any time; there is no control, so consequently variables accessible from multiple threads are volatile . This is in keeping with the original intent of volatile \u2014 that of preventing the compiler from unwittingly caching values used by multiple threads at once. Inside a critical section defined by a mutex , only one thread has access. Consequently, inside a critical section, the executing code has single-threaded semantics . The controlled variable is not volatile anymore \u2014 you can remove the volatile qualifier. In short, data shared between threads is conceptually volatile outside a critical section, and non- volatile inside a critical section. \u601d\u8003\uff1a\u5bf9\u4e8edata shared between threads\u800c\u8a00\uff0cinside a critical section\uff0c\u5b83\u4eec\u80fd\u5426\u662f volatile \u7684\uff1f You enter a critical section by locking a mutex . You remove the volatile qualifier from a type by applying a const_cast . If we manage to put these two operations together, we create a connection between C++'s type system and an application's threading semantics . We can make the compiler check race conditions for us. LockingPtr We need a tool that collects a mutex acquisition and a const_cast . Let's develop a LockingPtr class template that you initialize with a volatile object obj and a mutex mtx . During its lifetime, a LockingPtr keeps mtx acquired. Also, LockingPtr offers access to the volatile -stripped obj (\u901a\u8fc7const_cast\u5c06 volatile \u53bb\u9664). The access is offered in a smart pointer fashion, through operator-> and operator* . The const_cast is performed inside LockingPtr . The cast is semantically valid because LockingPtr keeps the mutex acquired for its lifetime. First, let's define the skeleton of a class Mutex with which LockingPtr will work: class Mutex { public : void Acquire (); void Release (); ... }; To use LockingPtr , you implement Mutex using your operating system's native data structures and primitive functions. LockingPtr is templated with the type of the controlled variable. For example, if you want to control a Widget , you use a LockingPtr <Widget> that you initialize with a variable of type volatile Widget . LockingPtr 's definition is very simple. LockingPtr implements an unsophisticated smart pointer. It focuses solely on collecting a const_cast and a critical section. template < typename T > class LockingPtr { public : // Constructors/destructors LockingPtr ( volatile T & obj , Mutex & mtx ) : pObj_ ( const_cast < T *> ( & obj )), pMtx_ ( & mtx ) { mtx . Lock (); } ~ LockingPtr () { pMtx_ -> Unlock (); } // Pointer behavior T & operator * () { return * pObj_ ; } T * operator -> () { return pObj_ ; } private : T * pObj_ ; Mutex * pMtx_ ; LockingPtr ( const LockingPtr & ); LockingPtr & operator = ( const LockingPtr & ); }; In spite of its simplicity, LockingPtr is a very useful aid in writing correct multithreaded code. You should define objects that are shared between threads as volatile and never use const_cast with them \u2014 always use LockingPtr automatic objects. Let's illustrate this with an example. Say you have two threads that share a vector<char> object: class SyncBuf { public : void Thread1 (); void Thread2 (); private : typedef vector < char > BufT ; volatile BufT buffer_ ; Mutex mtx_ ; // controls access to buffer_ }; Inside a thread function, you simply use a LockingPtr<BufT> to get controlled access to the buffer_ member variable: void SyncBuf :: Thread1 () { LockingPtr < BufT > lpBuf ( buffer_ , mtx_ ); BufT :: iterator i = lpBuf -> begin (); for (; i != lpBuf -> end (); ++ i ) { ... use * i ... } } The code is very easy to write and understand \u2014 whenever you need to use buffer_ , you must create a LockingPtr<BufT> pointing to it. Once you do that, you have access to vector 's entire interface. \u603b\u7ed3\uff1a\u4ece\u4e0a\u9762\u7684\u4ee3\u7801\u53ef\u4ee5\u770b\u51fa\uff0c\u4e00\u4e2a volatile object\u662f\u65e0\u6cd5\u8bbf\u95ee\u5176 non-volatile \u65b9\u6cd5\u7684\u3002 The nice part is that if you make a mistake, the compiler will point it out: void SyncBuf :: Thread2 () { // Error! Cannot access 'begin' for a volatile object BufT :: iterator i = buffer_ . begin (); // Error! Cannot access 'end' for a volatile object for (; i != lpBuf -> end (); ++ i ) { ... use * i ... } } You cannot access any function of buffer_ until you either apply a const_cast or use LockingPtr . The difference is that LockingPtr offers an ordered way of applying const_cast to volatile variables. \u603b\u7ed3\uff1a\u56e0\u4e3a\u5728 LockingPtr \u51fd\u6570\u7684\u6784\u9020\u51fd\u6570\u4e2d\uff0c\u4f1a\u8fdb\u884c Lock \uff0c\u6240\u4ee5\u5982\u679c\u52a0\u9501\u5931\u8d25\uff0c\u5219\u4f1a\u4e00\u76f4\u88abblock\u3002 LockingPtr is remarkably expressive. If you only need to call one function, you can create an unnamed temporary LockingPtr object and use it directly: unsigned int SyncBuf :: Size () { return LockingPtr < BufT > ( buffer_ , mtx_ ) -> size (); } Back to Primitive Types We saw how nicely volatile protects objects against uncontrolled access and how LockingPtr provides a simple and effective way of writing thread-safe code. Let's now return to primitive types , which are treated differently by volatile . Let's consider an example where multiple threads share a variable of type int . class Counter { public : ... void Increment () { ++ ctr_ ; } void Decrement () { \u2014 ctr_ ; } private : int ctr_ ; }; If Increment and Decrement are to be called from different threads, the fragment above is buggy. First, ctr_ must be volatile . Second, even a seemingly atomic operation such as ++ctr_ is actually a three-stage operation (\u5e76\u975e\u539f\u5b50\u64cd\u4f5c). Memory itself has no arithmetic capabilities. When incrementing a variable, the processor: Reads that variable in a register Increments the value in the register Writes the result back to memory This three-step operation is called RMW (Read-Modify-Write). During the Modify part of an RMW operation, most processors free the memory bus in order to give other processors access to the memory. If at that time another processor performs a RMW operation on the same variable, we have a race condition : the second write overwrites the effect of the first. To avoid that, you can rely, again, on LockingPtr : class Counter { public : ... void Increment () { ++* LockingPtr < int > ( ctr_ , mtx_ ); } void Decrement () { \u2014 * LockingPtr < int > ( ctr_ , mtx_ ); } private : volatile int ctr_ ; Mutex mtx_ ; }; Now the code is correct, but its quality is inferior when compared to SyncBuf 's code. Why? Because with Counter , the compiler will not warn you if you mistakenly access ctr_ directly (without locking it). The compiler compiles ++ctr_ if ctr_ is volatile , although the generated code is simply incorrect. The compiler is not your ally(\u76df\u53cb) anymore, and only your attention can help you avoid race conditions. \u603b\u7ed3\uff1a\u8fd9\u6bb5\u8bdd\u4e2d\u7684\u610f\u601d\u5176\u5b9e\u5728\u524d\u9762\u7684 Using volatile with User-Defined Types \u7ae0\u8282\u4e2d\u5df2\u7ecf\u63cf\u8ff0\u4e86\uff0c\u4e0d\u8fc7\u8fd9\u91cc\u7ed3\u5408\u4e86race condition\u4e00\u8d77\u6765\u8bf4\u7684\u3002 What should you do then? Simply encapsulate the primitive data that you use in higher-level structures and use volatile with those structures. Paradoxically(\u77db\u76fe\u7684\u662f), it's worse to use volatile directly with built-ins, in spite of the fact that initially this was the usage intent of volatile ! volatile Member Functions So far, we've had classes that aggregate(\u805a\u5408) volatile data members; now let's think of designing classes that in turn will be part of larger objects and shared between threads. Here is where volatile member functions can be of great help. When designing your class, you volatile -qualify only those member functions that are thread safe. You must assume that code from the outside will call the volatile functions from any code at any time( \u60a8\u5fc5\u987b\u5047\u8bbe\u6765\u81ea\u5916\u90e8\u7684\u4ee3\u7801\u5c06\u968f\u65f6\u4ece\u4efb\u4f55\u4ee3\u7801\u8c03\u7528volatile\u51fd\u6570). Don't forget: volatile equals free multithreaded code and no critical section ; non- volatile equals single-threaded scenario or inside a critical section(\u4e0d\u8981\u5fd8\u8bb0\uff1avolatile\u7b49\u4e8e\u514d\u8d39\u7684\u591a\u7ebf\u7a0b\u4ee3\u7801\u5e76\u4e14\u6ca1\u6709**critical section**; non- volatile \u7b49\u4e8e\u5355\u7ebf\u7a0b\u573a\u666f\u6216\u5904\u4e8e**critical section**\u3002). For example, you define a class Widget that implements an operation in two variants \u2014 a thread-safe one and a fast, unprotected one. class Widget { public : void Operation () volatile ; void Operation (); ... private : Mutex mtx_ ; }; Notice the use of overloading. Now Widget 's user can invoke Operation using a uniform syntax either for volatile objects and get thread safety, or for regular objects and get speed. The user must be careful about defining the shared Widget objects as volatile . When implementing a volatile member function, the first operation is usually to lock this with a LockingPtr . Then the work is done by using the non- volatile sibling: void Widget :: Operation () volatile { LockingPtr < Widget > lpThis ( * this , mtx_ ); lpThis -> Operation (); // invokes the non-volatile function } Summary When writing multithreaded programs, you can use volatile to your advantage. You must stick to the following rules: Define all shared objects as volatile . Don't use volatile directly with primitive types. When defining shared classes, use volatile member functions to express thread safety. If you do this, and if you use the simple generic component LockingPtr , you can write thread-safe code and worry much less about race conditions, because the compiler will worry for you and will diligently point out the spots where you are wrong. A couple of projects I've been involved with use volatile and LockingPtr to great effect. The code is clean and understandable. I recall a couple of deadlocks, but I prefer deadlocks to race conditions because they are so much easier to debug. There were virtually no problems related to race conditions. But then you never know. Acknowledgements Many thanks to James Kanze and Sorin Jianu who helped with insightful ideas.","title":"Cppreference cv(const and volatile) type qualifiers"},{"location":"C++/Language-reference/draft/specifier/cppreference-cv(const-and-volatile)-type-qualifiers/#english","text":"volatile \u6613\u53d8\u7684 notoriously \u81ed\u540d\u662d\u8457 devise \u8bbe\u8ba1 tame \u5236\u670d glitch \u6545\u969c disposes of \u5904\u7406\uff0c\u5356\u6389","title":"english"},{"location":"C++/Language-reference/draft/specifier/cppreference-cv(const-and-volatile)-type-qualifiers/#volatile-in-c","text":"","title":"volatile in c++"},{"location":"C++/Language-reference/draft/specifier/cppreference-cv(const-and-volatile)-type-qualifiers/#why-does-volatile-exist","text":"C++ and the Perils of Double-Checked Locking \u2217 volatile: The Multithreaded Programmer's Best Friend Const and volatile","title":"Why does volatile exist?"},{"location":"C++/Language-reference/draft/specifier/cppreference-cv(const-and-volatile)-type-qualifiers/#why-do-we-use-volatile-keyword-in-c","text":"\u8fd9\u4e2a\u89e3\u91ca\u662f\u975e\u5e38\u597d\u7684\u3002","title":"Why do we use volatile keyword in C++?"},{"location":"C++/Language-reference/draft/specifier/cppreference-cv(const-and-volatile)-type-qualifiers/#cv-const-and-volatile-type-qualifiers","text":"\u603b\u7ed3\uff1a\u5176\u5b9e\u770b\u4e86\u8fd9\u4e2a\u4e4b\u540e\uff0c\u624d\u53d1\u89c9\u81ea\u5df1\u5bf9c++\u7684type system\u7684\u8ba4\u77e5\u662f\u6d45\u8584\u7684\uff0c\u539f\u6765c++\u4e2d\uff0c\u901a\u8fc7\u8fd9\u4e9bspecifier\u662f\u53ef\u4ee5\u8fdb\u4e00\u6b65\u5bf9type\u8fdb\u884c\u4fee\u9970\u7684\uff0c\u4ece\u800c\u53ef\u4ee5\u63d0\u4f9b\u66f4\u52a0\u4e30\u5bcc\u7684\u8bed\u4e49\u3002 Appear in any type specifier, including decl-specifier-seq of declaration grammar , to specify constness or volatility of the object being declared or of the type being named. const - defines that the type is constant . volatile - defines that the type is volatile . mutable - applies to non-static class members of non-reference non-const type and specifies that the member does not affect the externally visible state of the class (as often used for mutexes, memo caches, lazy evaluation, and access instrumentation). mutable members of const class instances are modifiable. (Note: the C++ language grammar treats mutable as a storage-class-specifier , but it does not affect storage class.) \u603b\u7ed3\uff1a\u663e\u7136mutable\u548cconst\u7684\u4ece\u8bed\u4e49\u6765\u770b\u662f\u76f8\u53cd\u7684\uff0cmutable\u548cvolatile\u7684\u4ece\u5b57\u9762\u542b\u4e49\u4e0a\u6765\u770b\u662f\u76f8\u8fd1\u7684\u3002\u4f46\u662f\u5b9e\u9645\u4e0a\u6211\u770b\u5230mutable\u548cconst\u662f\u662f\u53ef\u4ee5\u4e00\u8d77\u4f7f\u7528\u7684\uff0c\u5e76\u4e14\u5f53\u6d89\u53ca\u5230\u5bf9\u8c61\u548c\u5bf9\u8c61\u4e4b\u95f4\u7684\u5173\u7cfb\uff08\u6bd4\u5982\u4e00\u4e2a\u5bf9\u8c61\u4f5c\u4e3a\u53e6\u5916\u4e00\u4e2a\u5bf9\u8c61\u7684\u6210\u5458\u53d8\u91cf\uff09\uff0c\u90a3\u4e48\u8fd9\u4e09\u4e2aspecifier\u548c\u8fd9\u4e9b\u5173\u7cfb\u7684\u7ec4\u5408\u60c5\u51b5\u5c31\u662f\u975e\u5e38\u590d\u6742\u7684\u4e86\uff0c\u5e76\u4e14\u4e0b\u9762\u7684\u4ecb\u7ecd\u4e5f\u662f\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u6765\u8fdb\u884c\u7684\u3002\u6240\u4ee5\u51c6\u786e\u628a\u63e1\u4ed6\u4eec\u7684\u8bed\u4e49\u662f\u975e\u5e38\u91cd\u8981\u7684\u3002\u4ece\u540e\u7eed\u7684\u4ecb\u7ecd\u6765\u770b\uff0c\u5b83\u4e3b\u8981\u662f\u4ecb\u7ecd const \u548c volatile \uff0c\u800c mutable \u4ec5\u4ec5\u662f\u4f5c\u4e3a\u76f8\u5173\u5185\u5bb9\u3002\u663e\u7136\uff0c mutable \u5e76\u4e0d\u5c5e\u4e8e**cv type qualifiers**\u4e4b\u5217\uff0c\u4f46 mutable \u548c**cv type qualifiers**\u53c8\u6709\u975e\u5e38\u91cd\u8981\u7684\u8054\u7cfb\uff0c\u4ece\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u53ef\u4ee5\u770b\u51fa\uff1amutable\u548cconst\u7684\u8bed\u4e49\u662f\u76f8\u53cd\u7684\uff0c\u5e76\u4e14\uff0c mutable members of const class instances are modifiable.","title":"cv (const and volatile) type qualifiers"},{"location":"C++/Language-reference/draft/specifier/cppreference-cv(const-and-volatile)-type-qualifiers/#explanation","text":"For any type T (including incomplete types), other than function type or reference type , there are three more distinct types in the C++ type system : const-qualified T , volatile-qualified T const-volatile-qualified T . Note: array types are considered to have the same cv-qualification as their element types. When an object is first created, the cv-qualifiers used (which could be part of decl-specifier-seq or part of a declarator in a declaration , or part of type-id in a new-expression ) determine the constness or volatility of the object, as follows: const object - an object whose type is const-qualified , or a non-mutable subobject of a const object . Such object cannot be modified: attempt to do so directly is a compile-time error, and attempt to do so indirectly (e.g., by modifying the const object through a reference or pointer to non-const type) results in undefined behavior (\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528 const_cast \u5c06\u4e00\u4e2aconst object\u8f6c\u6362\u4e3anon-const object\uff0c\u4f46\u662f\u5982\u679c\u4fee\u6539\u8f6c\u6362\u540e\u7684object\uff0c\u5219\u662f\u4f1a\u5bfc\u81f4undefined behavior\u7684\uff0c\u5728 \u8fd9\u7bc7\u6587\u7ae0 \u4e2d\u5bf9\u8fd9\u4e2a\u5185\u5bb9\u6709\u4ecb\u7ecd). volatile object - an object whose type is volatile-qualified , or a subobject of a volatile object , or a mutable subobject of a const-volatile object . Every access (read or write operation, member function call, etc.) made through a glvalue expression of volatile-qualified type is treated as a visible side-effect for the purposes of optimization (that is, within a single thread of execution, volatile accesses cannot be optimized out or reordered with another visible side effect that is sequenced-before or sequenced-after the volatile access. This makes volatile objects suitable for communication with a signal handler , but not with another thread of execution, see std::memory_order ). Any attempt to refer to a volatile object through a non-volatile glvalue (e.g. through a reference or pointer to non-volatile type) results in undefined behavior. const volatile object - an object whose type is const-volatile-qualified, a non-mutable subobject of a const volatile object, a const subobject of a volatile object, or a non-mutable volatile subobject of a const object. Behaves as both a const object and as a volatile object. This section is incomplete Reason: should discuss more about the differences between cv-qualified objects and cv-qualified expressions | There is partial ordering of cv-qualifiers by the order of increasing restrictions. The type can be said more or less cv-qualified then: unqualified < const unqualified < volatile unqualified < const volatile const < const volatile volatile < const volatile References and pointers to cv-qualified types may be implicitly converted to references and pointers to more cv-qualified types. In particular, the following conversions are allowed: reference/pointer to unqualified type can be converted to reference/pointer to const reference/pointer to unqualified type can be converted to reference/pointer to volatile reference/pointer to unqualified type can be converted to reference/pointer to const volatile reference/pointer to const type can be converted to reference/pointer to const volatile reference/pointer to volatile type can be converted to reference/pointer to const volatile Note: additional restrictions are imposed on multi-level pointers. To convert a reference or a pointer to a cv-qualified type to a reference or pointer to a less cv-qualified type, const_cast must be used.","title":"Explanation"},{"location":"C++/Language-reference/draft/specifier/cppreference-cv(const-and-volatile)-type-qualifiers/#keywords","text":"const , volatile , mutable","title":"Keywords"},{"location":"C++/Language-reference/draft/specifier/cppreference-cv(const-and-volatile)-type-qualifiers/#notes","text":"The const qualifier used on a declaration of a non-local non-volatile variable that is not declared extern gives it internal linkage . This is different from C where const file scope variables have external linkage.","title":"Notes"},{"location":"C++/Language-reference/draft/specifier/cppreference-cv(const-and-volatile)-type-qualifiers/#supply","text":"Note, however, that cv-qualifiers applied to an array type actually apply to its elements. The cv-qualified and cv-unqualified types are distinct. That is int is a distinct type from const int","title":"supply"},{"location":"C++/Language-reference/draft/specifier/cppreference-cv(const-and-volatile)-type-qualifiers/#volatile-the-multithreaded-programmers-best-friend","text":"The volatile keyword was devised(\u8bbe\u8ba1) to prevent compiler optimizations that might render code incorrect in the presence of certain asynchronous events. \u603b\u7ed3\uff1a\u5408\u7406\u5730\u5229\u7528compiler optimization\u662f\u975e\u5e38\u91cd\u8981\u7684\u3002 I don't want to spoil your mood, but this column addresses the dreaded topic of multithreaded programming(\u6211\u4e0d\u60f3\u7834\u574f\u4f60\u7684\u5fc3\u60c5\uff0c\u4f46\u672c\u4e13\u680f\u89e3\u51b3\u4e86\u591a\u7ebf\u7a0b\u7f16\u7a0b\u7684\u53ef\u6015\u4e3b\u9898). If \u2014 as the previous installment of Generic says \u2014 exception-safe programming is hard, it's child's play compared to multithreaded programming( \u5f02\u5e38\u5b89\u5168\u7f16\u7a0b\u5f88\u96be\uff0c\u90a3\u4e48\u4e0e\u591a\u7ebf\u7a0b\u7f16\u7a0b\u76f8\u6bd4\uff0c\u5b83\u5c31\u662f\u5b69\u5b50\u7684\u6e38\u620f). Programs using multiple threads are notoriously hard to write, prove correct, debug, maintain, and tame in general. Incorrect multithreaded programs might run for years without a glitch, only to unexpectedly run amok because some critical timing condition has been met. Needless to say(\u6bcb\u5eb8\u7f6e\u7591), a programmer writing multithreaded code needs all the help she can get. This column focuses on race conditions \u2014 a common source of trouble in multithreaded programs \u2014 and provides you with insights and tools on how to avoid them and, amazingly enough, have the compiler work hard at helping you with that(\u4ee4\u4eba\u60ca\u8bb6\u7684\u662f\uff0c\u8ba9\u7f16\u8bd1\u5668\u52aa\u529b\u5e2e\u52a9\u60a8\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898).","title":"volatile: The Multithreaded Programmer's Best Friend"},{"location":"C++/Language-reference/draft/specifier/cppreference-cv(const-and-volatile)-type-qualifiers/#just-a-little-keyword","text":"Although both C and C++ Standards are conspicuously silent when it comes to threads, they do make a little concession(\u8ba9\u6b65) to multithreading, in the form of the volatile keyword. Just like its better-known counterpart(\u5bf9\u5e94) const , volatile is a type modifier . It's intended to be used in conjunction with variables that are accessed and modified in different threads. Basically, without volatile , either writing multithreaded programs becomes impossible, or the compiler wastes vast optimization opportunities. An explanation is in order. Consider the following code: class Gadget { public : void Wait () { while ( ! flag_ ) { Sleep ( 1000 ); // sleeps for 1000 milliseconds } } void Wakeup () { flag_ = true ; } ... private : bool flag_ ; }; The purpose of Gadget::Wait above is to check the flag_ member variable every second and return when that variable has been set to true by another thread. At least that's what its programmer intended, but, alas, Wait is incorrect. Suppose the compiler figures out that Sleep(1000) is a call into an external library that cannot possibly modify the member variable flag_ . Then the compiler concludes that it can cache flag_ in a register and use that register instead of accessing the slower on-board memory . This is an excellent optimization for single-threaded code, but in this case, it harms correctness: after you call Wait for some Gadget object, although another thread calls Wakeup , Wait will loop forever. This is because the change of flag_ will not be reflected in the register that caches flag_ . The optimization is too ... optimistic. Caching variables in registers is a very valuable optimization that applies most of the time, so it would be a pity to waste it. C and C++ give you the chance to explicitly disable such caching. If you use the volatile modifier on a variable, the compiler won't cache that variable in registers \u2014 each access will hit the actual memory location of that variable. So all you have to do to make Gadget 's Wait / Wakeup combo work is to qualify(\u4fee\u9970\uff0c\u9650\u5b9a) flag_ appropriately: class Gadget { public : ... as above ... private : volatile bool flag_ ; }; Most explanations of the rationale(\u57fa\u672c\u539f\u7406) and usage of volatile stop here and advise you to volatile -qualify the primitive types that you use in multiple threads. However, there is much more you can do with volatile , because it is part of C++'s wonderful type system.","title":"Just a Little Keyword"},{"location":"C++/Language-reference/draft/specifier/cppreference-cv(const-and-volatile)-type-qualifiers/#using-volatile-with-user-defined-types","text":"You can volatile -qualify not only primitive types , but also user-defined types . In that case, volatile modifies the type in a way similar to const . (You can also apply const and volatile to the same type simultaneously.) Unlike const , volatile discriminates(\u533a\u5206) between primitive types and user-defined types . Namely, unlike classes, primitive types still support all of their operations (addition, multiplication, assignment, etc.) when volatile -qualified. For example, you can assign a non- volatile int to a volatile int , but you cannot assign a non- volatile object to a volatile object. \u603b\u7ed3\uff1a\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u610f\u601d\u662f\uff0c\u5bf9\u4e8e**primitive types** \u548c**user-defined types**\uff0c\u5bf9**primitive types** \u800c\u8a00\uff0c volatile \u5e76\u4e0d\u6539\u53d8\u5176operations\uff0c\u4f46\u662f\u5bf9\u4e8e **user-defined types**\u800c\u8a00\uff0c volatile \u5219\u4f1a\u6539\u53d8\u5176operations\u3002 Let's illustrate how volatile works on user-defined types on an example. class Gadget { public : void Foo () volatile ; void Bar (); ... private : String name_ ; int state_ ; }; ... Gadget regularGadget ; volatile Gadget volatileGadget ; If you think volatile is not that useful with objects, prepare for some surprise. volatileGadget . Foo (); // ok, volatile fun called for // volatile object regularGadget . Foo (); // ok, volatile fun called for // non-volatile object volatileGadget . Bar (); // error! Non-volatile function called for // volatile object! The conversion from a non-qualified type to its volatile counterpart is trivial. However, just as with const , you cannot make the trip back from volatile to non-qualified . You must use a cast: Gadget & ref = const_cast < Gadget &> ( volatileGadget ); ref . Bar (); // ok A volatile -qualified class gives access only to a subset of its interface, a subset that is under the control of the class implementer. Users can gain full access to that type's interface only by using a const_cast . In addition, just like const ness, volatile ness propagates from the class to its members (for example, volatileGadget.name_ and volatileGadget.state_ are volatile variables)\u4f46\u662f\u5e76\u4e0d\u4f1apropagate to member method. \u603b\u7ed3\uff1a\u8fd9\u6bb5\u63cf\u8ff0\u4e86\u7ed9object\u6dfb\u52a0 volatile \u6240\u5e26\u6765\u7684\u6548\u679c\u3002","title":"Using volatile with User-Defined Types"},{"location":"C++/Language-reference/draft/specifier/cppreference-cv(const-and-volatile)-type-qualifiers/#volatile-critical-sections-and-race-conditions","text":"The simplest and the most often-used synchronization device in multithreaded programs is the mutex . A mutex exposes the Acquire and Release primitives. Once you call Acquire in some thread, any other thread calling Acquire will block. Later, when that thread calls Release , precisely one thread blocked in an Acquire call will be released. In other words, for a given mutex , only one thread can get processor time in between a call to Acquire and a call to Release . The executing code between a call to Acquire and a call to Release is called a critical section . (Windows terminology is a bit confusing because it calls the mutex itself a critical section, while \"mutex\" is actually an inter-process mutex. It would have been nice if they were called thread mutex and process mutex.) Mutexes are used to protect data against race conditions . By definition, a race condition occurs when the effect of more threads on data depends on how threads are scheduled. Race conditions appear when two or more threads compete for using the same data. Because threads can interrupt(\u6253\u65ad) each other at arbitrary moments in time, data can be corrupted(\u635f\u574f) or misinterpreted. Consequently, changes and sometimes accesses to data must be carefully protected with critical sections. In object-oriented programming, this usually means that you store a mutex in a class as a member variable and use it whenever you access that class' state. Experienced multithreaded programmers might have yawned(\u6253\u54c8\u6b20) reading the two paragraphs above, but their purpose is to provide an intellectual workout, because now we will link with the volatile connection. We do this by drawing a parallel between the C++ types' world and the threading semantics world. Outside a critical section , any thread might interrupt any other at any time; there is no control, so consequently variables accessible from multiple threads are volatile . This is in keeping with the original intent of volatile \u2014 that of preventing the compiler from unwittingly caching values used by multiple threads at once. Inside a critical section defined by a mutex , only one thread has access. Consequently, inside a critical section, the executing code has single-threaded semantics . The controlled variable is not volatile anymore \u2014 you can remove the volatile qualifier. In short, data shared between threads is conceptually volatile outside a critical section, and non- volatile inside a critical section. \u601d\u8003\uff1a\u5bf9\u4e8edata shared between threads\u800c\u8a00\uff0cinside a critical section\uff0c\u5b83\u4eec\u80fd\u5426\u662f volatile \u7684\uff1f You enter a critical section by locking a mutex . You remove the volatile qualifier from a type by applying a const_cast . If we manage to put these two operations together, we create a connection between C++'s type system and an application's threading semantics . We can make the compiler check race conditions for us.","title":"volatile, Critical Sections, and Race Conditions"},{"location":"C++/Language-reference/draft/specifier/cppreference-cv(const-and-volatile)-type-qualifiers/#lockingptr","text":"We need a tool that collects a mutex acquisition and a const_cast . Let's develop a LockingPtr class template that you initialize with a volatile object obj and a mutex mtx . During its lifetime, a LockingPtr keeps mtx acquired. Also, LockingPtr offers access to the volatile -stripped obj (\u901a\u8fc7const_cast\u5c06 volatile \u53bb\u9664). The access is offered in a smart pointer fashion, through operator-> and operator* . The const_cast is performed inside LockingPtr . The cast is semantically valid because LockingPtr keeps the mutex acquired for its lifetime. First, let's define the skeleton of a class Mutex with which LockingPtr will work: class Mutex { public : void Acquire (); void Release (); ... }; To use LockingPtr , you implement Mutex using your operating system's native data structures and primitive functions. LockingPtr is templated with the type of the controlled variable. For example, if you want to control a Widget , you use a LockingPtr <Widget> that you initialize with a variable of type volatile Widget . LockingPtr 's definition is very simple. LockingPtr implements an unsophisticated smart pointer. It focuses solely on collecting a const_cast and a critical section. template < typename T > class LockingPtr { public : // Constructors/destructors LockingPtr ( volatile T & obj , Mutex & mtx ) : pObj_ ( const_cast < T *> ( & obj )), pMtx_ ( & mtx ) { mtx . Lock (); } ~ LockingPtr () { pMtx_ -> Unlock (); } // Pointer behavior T & operator * () { return * pObj_ ; } T * operator -> () { return pObj_ ; } private : T * pObj_ ; Mutex * pMtx_ ; LockingPtr ( const LockingPtr & ); LockingPtr & operator = ( const LockingPtr & ); }; In spite of its simplicity, LockingPtr is a very useful aid in writing correct multithreaded code. You should define objects that are shared between threads as volatile and never use const_cast with them \u2014 always use LockingPtr automatic objects. Let's illustrate this with an example. Say you have two threads that share a vector<char> object: class SyncBuf { public : void Thread1 (); void Thread2 (); private : typedef vector < char > BufT ; volatile BufT buffer_ ; Mutex mtx_ ; // controls access to buffer_ }; Inside a thread function, you simply use a LockingPtr<BufT> to get controlled access to the buffer_ member variable: void SyncBuf :: Thread1 () { LockingPtr < BufT > lpBuf ( buffer_ , mtx_ ); BufT :: iterator i = lpBuf -> begin (); for (; i != lpBuf -> end (); ++ i ) { ... use * i ... } } The code is very easy to write and understand \u2014 whenever you need to use buffer_ , you must create a LockingPtr<BufT> pointing to it. Once you do that, you have access to vector 's entire interface. \u603b\u7ed3\uff1a\u4ece\u4e0a\u9762\u7684\u4ee3\u7801\u53ef\u4ee5\u770b\u51fa\uff0c\u4e00\u4e2a volatile object\u662f\u65e0\u6cd5\u8bbf\u95ee\u5176 non-volatile \u65b9\u6cd5\u7684\u3002 The nice part is that if you make a mistake, the compiler will point it out: void SyncBuf :: Thread2 () { // Error! Cannot access 'begin' for a volatile object BufT :: iterator i = buffer_ . begin (); // Error! Cannot access 'end' for a volatile object for (; i != lpBuf -> end (); ++ i ) { ... use * i ... } } You cannot access any function of buffer_ until you either apply a const_cast or use LockingPtr . The difference is that LockingPtr offers an ordered way of applying const_cast to volatile variables. \u603b\u7ed3\uff1a\u56e0\u4e3a\u5728 LockingPtr \u51fd\u6570\u7684\u6784\u9020\u51fd\u6570\u4e2d\uff0c\u4f1a\u8fdb\u884c Lock \uff0c\u6240\u4ee5\u5982\u679c\u52a0\u9501\u5931\u8d25\uff0c\u5219\u4f1a\u4e00\u76f4\u88abblock\u3002 LockingPtr is remarkably expressive. If you only need to call one function, you can create an unnamed temporary LockingPtr object and use it directly: unsigned int SyncBuf :: Size () { return LockingPtr < BufT > ( buffer_ , mtx_ ) -> size (); }","title":"LockingPtr"},{"location":"C++/Language-reference/draft/specifier/cppreference-cv(const-and-volatile)-type-qualifiers/#back-to-primitive-types","text":"We saw how nicely volatile protects objects against uncontrolled access and how LockingPtr provides a simple and effective way of writing thread-safe code. Let's now return to primitive types , which are treated differently by volatile . Let's consider an example where multiple threads share a variable of type int . class Counter { public : ... void Increment () { ++ ctr_ ; } void Decrement () { \u2014 ctr_ ; } private : int ctr_ ; }; If Increment and Decrement are to be called from different threads, the fragment above is buggy. First, ctr_ must be volatile . Second, even a seemingly atomic operation such as ++ctr_ is actually a three-stage operation (\u5e76\u975e\u539f\u5b50\u64cd\u4f5c). Memory itself has no arithmetic capabilities. When incrementing a variable, the processor: Reads that variable in a register Increments the value in the register Writes the result back to memory This three-step operation is called RMW (Read-Modify-Write). During the Modify part of an RMW operation, most processors free the memory bus in order to give other processors access to the memory. If at that time another processor performs a RMW operation on the same variable, we have a race condition : the second write overwrites the effect of the first. To avoid that, you can rely, again, on LockingPtr : class Counter { public : ... void Increment () { ++* LockingPtr < int > ( ctr_ , mtx_ ); } void Decrement () { \u2014 * LockingPtr < int > ( ctr_ , mtx_ ); } private : volatile int ctr_ ; Mutex mtx_ ; }; Now the code is correct, but its quality is inferior when compared to SyncBuf 's code. Why? Because with Counter , the compiler will not warn you if you mistakenly access ctr_ directly (without locking it). The compiler compiles ++ctr_ if ctr_ is volatile , although the generated code is simply incorrect. The compiler is not your ally(\u76df\u53cb) anymore, and only your attention can help you avoid race conditions. \u603b\u7ed3\uff1a\u8fd9\u6bb5\u8bdd\u4e2d\u7684\u610f\u601d\u5176\u5b9e\u5728\u524d\u9762\u7684 Using volatile with User-Defined Types \u7ae0\u8282\u4e2d\u5df2\u7ecf\u63cf\u8ff0\u4e86\uff0c\u4e0d\u8fc7\u8fd9\u91cc\u7ed3\u5408\u4e86race condition\u4e00\u8d77\u6765\u8bf4\u7684\u3002 What should you do then? Simply encapsulate the primitive data that you use in higher-level structures and use volatile with those structures. Paradoxically(\u77db\u76fe\u7684\u662f), it's worse to use volatile directly with built-ins, in spite of the fact that initially this was the usage intent of volatile !","title":"Back to Primitive Types"},{"location":"C++/Language-reference/draft/specifier/cppreference-cv(const-and-volatile)-type-qualifiers/#volatile-member-functions","text":"So far, we've had classes that aggregate(\u805a\u5408) volatile data members; now let's think of designing classes that in turn will be part of larger objects and shared between threads. Here is where volatile member functions can be of great help. When designing your class, you volatile -qualify only those member functions that are thread safe. You must assume that code from the outside will call the volatile functions from any code at any time( \u60a8\u5fc5\u987b\u5047\u8bbe\u6765\u81ea\u5916\u90e8\u7684\u4ee3\u7801\u5c06\u968f\u65f6\u4ece\u4efb\u4f55\u4ee3\u7801\u8c03\u7528volatile\u51fd\u6570). Don't forget: volatile equals free multithreaded code and no critical section ; non- volatile equals single-threaded scenario or inside a critical section(\u4e0d\u8981\u5fd8\u8bb0\uff1avolatile\u7b49\u4e8e\u514d\u8d39\u7684\u591a\u7ebf\u7a0b\u4ee3\u7801\u5e76\u4e14\u6ca1\u6709**critical section**; non- volatile \u7b49\u4e8e\u5355\u7ebf\u7a0b\u573a\u666f\u6216\u5904\u4e8e**critical section**\u3002). For example, you define a class Widget that implements an operation in two variants \u2014 a thread-safe one and a fast, unprotected one. class Widget { public : void Operation () volatile ; void Operation (); ... private : Mutex mtx_ ; }; Notice the use of overloading. Now Widget 's user can invoke Operation using a uniform syntax either for volatile objects and get thread safety, or for regular objects and get speed. The user must be careful about defining the shared Widget objects as volatile . When implementing a volatile member function, the first operation is usually to lock this with a LockingPtr . Then the work is done by using the non- volatile sibling: void Widget :: Operation () volatile { LockingPtr < Widget > lpThis ( * this , mtx_ ); lpThis -> Operation (); // invokes the non-volatile function }","title":"volatile Member Functions"},{"location":"C++/Language-reference/draft/specifier/cppreference-cv(const-and-volatile)-type-qualifiers/#summary","text":"When writing multithreaded programs, you can use volatile to your advantage. You must stick to the following rules: Define all shared objects as volatile . Don't use volatile directly with primitive types. When defining shared classes, use volatile member functions to express thread safety. If you do this, and if you use the simple generic component LockingPtr , you can write thread-safe code and worry much less about race conditions, because the compiler will worry for you and will diligently point out the spots where you are wrong. A couple of projects I've been involved with use volatile and LockingPtr to great effect. The code is clean and understandable. I recall a couple of deadlocks, but I prefer deadlocks to race conditions because they are so much easier to debug. There were virtually no problems related to race conditions. But then you never know.","title":"Summary"},{"location":"C++/Language-reference/draft/specifier/cppreference-cv(const-and-volatile)-type-qualifiers/#acknowledgements","text":"Many thanks to James Kanze and Sorin Jianu who helped with insightful ideas.","title":"Acknowledgements"},{"location":"C++/Language-reference/draft/specifier/cppreference-virtual-function-specifier/","text":"virtual function specifier The virtual specifier specifies that a non-static member function is virtual and supports dynamic dispatch . It may only appear in the decl-specifier-seq of the initial declaration of a non-static member function (i.e., when it is declared in the class definition). Explanation Virtual functions are member functions whose behavior can be overridden in derived classes . As opposed to non-virtual functions, the overridden behavior is preserved even if there is no compile-time information about the actual type of the class. If a derived class is handled using pointer or reference to the base class, a call to an overridden virtual function would invoke the behavior defined in the derived class . This behavior is suppressed(\u6291\u5236) if the function is selected using qualified name lookup (that is, if the function's name appears to the right of the scope resolution operator :: ). Run this code #include <iostream> struct Base { virtual void f () { std :: cout << \"base \\n \" ; } }; struct Derived : Base { void f () override { // 'override' is optional std :: cout << \"derived \\n \" ; } }; int main () { Base b ; Derived d ; // virtual function call through reference Base & br = b ; // the type of br is Base& Base & dr = d ; // the type of dr is Base& as well br . f (); // prints \"base\" dr . f (); // prints \"derived\" // virtual function call through pointer Base * bp = & b ; // the type of bp is Base* Base * dp = & d ; // the type of dp is Base* as well bp -> f (); // prints \"base\" dp -> f (); // prints \"derived\" // non-virtual function call br . Base :: f (); // prints \"base\" dr . Base :: f (); // prints \"base\" } In detail If some member function vf is declared as virtual in a class Base , and some class Derived , which is derived, directly or indirectly, from Base , has a declaration for member function with the same name parameter type list (but not the return type) cv-qualifiers ref-qualifiers Then this function in the class Derived is also virtual (whether or not the keyword virtual is used in its declaration) and overrides Base::vf (whether or not the word override is used in its declaration). Base::vf does not need to be visible (can be declared private , or inherited using private inheritance ) to be overridden. class B { virtual void do_f (); // private member public : void f () { do_f (); } // public interface }; struct D : public B { void do_f () override ; // overrides B::do_f }; int main () { D d ; B * bp = & d ; bp -> f (); // internally calls D::do_f(); } For every virtual function , there is the final overrider , which is executed when a virtual function call is made\uff08\u663e\u7136\u8fd9\u548c overload resolution \u6709\u5173\uff09. A virtual member function vf of a base class Base is the final overrider unless the derived class declares or inherits (through multiple inheritance) another function that overrides vf . struct A { virtual void f (); }; // A::f is virtual struct B : A { void f (); }; // B::f overrides A::f in B struct C : virtual B { void f (); }; // C::f overrides A::f in C struct D : virtual B {}; // D does not introduce an overrider, B::f is final in D struct E : C , D { // E does not introduce an overrider, C::f is final in E using A :: f ; // not a function declaration, just makes A::f visible to lookup }; int main () { E e ; e . f (); // virtual call calls C::f, the final overrider in e e . E :: f (); // non-virtual call calls A::f, which is visible in E } \u601d\u8003\uff1a TODO \u90a3\u4e48\u4e0a\u9762\u7684\u4ee3\u7801\u53ef\u4ee5\u7f16\u8bd1\u901a\u8fc7\u5417\uff1f If a function has more than one final overrider, the program is ill-formed: struct A { virtual void f (); }; struct VB1 : virtual A { void f (); // overrides A::f }; struct VB2 : virtual A { void f (); // overrides A::f }; // struct Error : VB1, VB2 { // // Error: A::f has two final overriders in Error // }; struct Okay : VB1 , VB2 { void f (); // OK: this is the final overrider for A::f }; struct VB1a : virtual A {}; // does not declare an overrider struct Da : VB1a , VB2 { // in Da, the final overrider of A::f is VB2::f }; A function with the same name but different parameter list does not override the base function of the same name, but hides it: when unqualified name lookup examines the scope of the derived class , the lookup finds the declaration and does not examine the base class . struct B { virtual void f (); }; struct D : B { void f ( int ); // D::f hides B::f (wrong parameter list) }; struct D2 : D { void f (); // D2::f overrides B::f (doesn't matter that it's not visible) }; int main () { B b ; B & b_as_b = b ; D d ; B & d_as_b = d ; D & d_as_d = d ; D2 d2 ; B & d2_as_b = d2 ; D & d2_as_d = d2 ; b_as_b . f (); // calls B::f() d_as_b . f (); // calls B::f() d2_as_b . f (); // calls D2::f() d_as_d . f (); // Error: lookup in D finds only f(int) d2_as_d . f (); // Error: lookup in D finds only f(int) } If a function is declared with the specifier override , but does not override a virtual function, the program is ill-formed: struct B { virtual void f ( int ); }; struct D : B { virtual void f ( int ) override ; // OK, D::f(int) overrides B::f(int) virtual void f(long) override; // Error: f(long) does not override B::f(int) }; If a function is declared with the specifier final , and another function attempts to override it, the program is ill-formed: struct B { virtual void f () const final ; }; struct D : B { void f () const ; // Error: D::f attempts to override final B::f }; Non-member functions and static member functions cannot be virtual. Functions templates cannot be declared virtual . This applies only to functions that are themselves templates - a regular member function of a class template can be declared virtual. Virtual functions (whether declared virtual or overriding one) cannot have any associated constraints. struct A { virtual void f() requires true; // Error: constrained virtual function }; If an overriding function specifies contract conditions , it must specify the same list contract conditions as the functions it overrides; no diagnostic is required if corresponding conditions will always evaluate to the same value. Otherwise, it is considered to have the list of contract conditions from one of its overriden functions; the names in the contract conditions are bound and the semantic constraints are checked at the point where the contract conditions appear. struct A { virtual void f(int i) [[expects: i > x]]; virtual void g(int i) [[expects: i < x]]; virtual void h(int i) [[expects: i < 0]]; int x; }; struct B : A { virtual void f(int i); // OK, 'x' in precondition means A::x virtual void g(int i) [[expects: i < x]]; // error virtual void h(int i) [[expects: i < 1]]; // error std::string x; }; struct C : A { virtual void f(int i) [[expects: i > x]]; // OK virtual void g(int i) [[expects: i < A::x]]; // ill-formed, no diagnostic required }; If a contract condition of a virtual function f odr-uses *this, the class of which f is a direct member must be an unambiguous and accessible base class of any class in which f is overridden. struct A { virtual void g() [[expects: x == 0]]; // odr-uses *this int x = 42; }; struct B : A { }; struct C : A, B { virtual void g(); //error, A is an ambiguous base }; If a function overrides more than one function, all of the overridden functions must have the same list of contract conditions; no diagnostic is required if corresponding conditions will always evaluate to the same value. struct A { virtual void g() [[expects: x == 0]]; // x means A::x int x = 42; }; int x = 42; struct B { virtual void g() [[expects: x == 0]]; // x means ::x } struct C : A, B { virtual void g(); //error }; (since C++20) Default arguments for virtual functions are substituted at the compile time. Covariant return types If the function Derived::f overrides a function Base::f , their return types must either be the same or be covariant . Two types are covariant if they satisfy all of the following requirements: both types are pointers or references (lvalue or rvalue) to classes. Multi-level pointers or references are not allowed. the referenced/pointed-to class in the return type of Base::f() must be a unambiguous and accessible direct or indirect base class of the referenced/pointed-to class of the return type of Derived::f() . the return type of Derived::f() must be equally or less cv-qualified than the return type of Base::f() . The class in the return type of Derived::f must be either Derived itself, or must be a complete type at the point of declaration of Derived::f . When a virtual function call is made, the type returned by the final overrider is implicitly converted to the return type of the overridden function that was called: class B {}; struct Base { virtual void vf1(); virtual void vf2(); virtual void vf3(); virtual B* vf4(); virtual B* vf5(); }; class D : private B { friend struct Derived; // in Derived, B is an accessible base of D }; class A; // forward-declared class is an incomplete type struct Derived : public Base { void vf1(); // virtual, overrides Base::vf1() void vf2(int); // non-virtual, hides Base::vf2() // char vf3(); // Error: overrides Base::vf3, but has different // and non-covariant return type D* vf4(); // overrides Base::vf4() and has covariant return type // A* vf5(); // Error: A is incomplete type }; int main() { Derived d; Base& br = d; Derived& dr = d; br.vf1(); // calls Derived::vf1() br.vf2(); // calls Base::vf2() // dr.vf2(); // Error: vf2(int) hides vf2() B* p = br.vf4(); // calls Derived::vf4() and converts the result to B* D* q = dr.vf4(); // calls Derived::vf4() and does not convert // the result to B* } Virtual destructor Even though destructors are not inherited, if a base class declares its destructor virtual , the derived destructor always overrides it. This makes it possible to delete dynamically allocated objects of polymorphic type through pointers to base. class Base { public : virtual ~ Base () { /* releases Base's resources */ } }; class Derived : public Base { ~ Derived () { /* releases Derived's resources */ } }; int main () { Base * b = new Derived ; delete b ; // Makes a virtual function call to Base::~Base() // since it is virtual, it calls Derived::~Derived() which can // release resources of the derived class, and then calls // Base::~Base() following the usual order of destruction } Moreover, if a class is polymorphic (declares or inherits at least one virtual function), and its destructor is not virtual, deleting it is undefined behavior regardless of whether there are resources that would be leaked if the derived destructor is not invoked. A useful guideline is that the destructor of any base class must be public and virtual or protected and non-virtual . During construction and destruction When a virtual function is called directly or indirectly from a constructor or from a destructor (including during the construction or destruction of the class\u2019s non-static data members, e.g. in a member initializer list ), and the object to which the call applies is the object under construction or destruction, the function called is the final overrider in the constructor\u2019s or destructor\u2019s class and not one overriding it in a more-derived class. In other words, during construction or destruction, the more-derived classes do not exist. When constructing a complex class with multiple branches, within a constructor that belongs to one branch, polymorphism is restricted to that class and its bases: if it obtains a pointer or reference to a base subobject outside this subhierarchy, and attempts to invoke a virtual function call (e.g. using explicit member access), the behavior is undefined: struct V { virtual void f (); virtual void g (); }; struct A : virtual V { virtual void f (); // A::f is the final overrider of V::f in A }; struct B : virtual V { virtual void g (); // B::g is the final overrider of V::g in B B ( V * , A * ); }; struct D : A , B { virtual void f (); // D::f is the final overrider of V::f in D virtual void g (); // D::g is the final overrider of V::g in D // note: A is initialized before B D () : B (( A * ) this , this ) { } }; // the constructor of B, called from the constructor of D B :: B ( V * v , A * a ) { f (); // virtual call to V::f (although D has the final overrider, D doesn't exist) g (); // virtual call to B::g, which is the final overrider in B v -> g (); // v's type V is base of B, virtual call calls B::g as before a -> f (); // a\u2019s type A is not a base of B. it belongs to a different branch of the // hierarchy. Attempting a virtual call through that branch causes // undefined behavior even though A was already fully constructed in this // case (it was constructed before B since it appears before B in the list // of the bases of D). In practice, the virtual call to A::f will be // attempted using B's virtual member function table, since that's what // is active during B's construction) } See also derived classes and modes of inheritance override specifier (since C++11) final specifier (since C++11)","title":"[virtual function specifier](https://en.cppreference.com/w/cpp/language/virtual)"},{"location":"C++/Language-reference/draft/specifier/cppreference-virtual-function-specifier/#virtual-function-specifier","text":"The virtual specifier specifies that a non-static member function is virtual and supports dynamic dispatch . It may only appear in the decl-specifier-seq of the initial declaration of a non-static member function (i.e., when it is declared in the class definition).","title":"virtual function specifier"},{"location":"C++/Language-reference/draft/specifier/cppreference-virtual-function-specifier/#explanation","text":"Virtual functions are member functions whose behavior can be overridden in derived classes . As opposed to non-virtual functions, the overridden behavior is preserved even if there is no compile-time information about the actual type of the class. If a derived class is handled using pointer or reference to the base class, a call to an overridden virtual function would invoke the behavior defined in the derived class . This behavior is suppressed(\u6291\u5236) if the function is selected using qualified name lookup (that is, if the function's name appears to the right of the scope resolution operator :: ). Run this code #include <iostream> struct Base { virtual void f () { std :: cout << \"base \\n \" ; } }; struct Derived : Base { void f () override { // 'override' is optional std :: cout << \"derived \\n \" ; } }; int main () { Base b ; Derived d ; // virtual function call through reference Base & br = b ; // the type of br is Base& Base & dr = d ; // the type of dr is Base& as well br . f (); // prints \"base\" dr . f (); // prints \"derived\" // virtual function call through pointer Base * bp = & b ; // the type of bp is Base* Base * dp = & d ; // the type of dp is Base* as well bp -> f (); // prints \"base\" dp -> f (); // prints \"derived\" // non-virtual function call br . Base :: f (); // prints \"base\" dr . Base :: f (); // prints \"base\" }","title":"Explanation"},{"location":"C++/Language-reference/draft/specifier/cppreference-virtual-function-specifier/#in-detail","text":"If some member function vf is declared as virtual in a class Base , and some class Derived , which is derived, directly or indirectly, from Base , has a declaration for member function with the same name parameter type list (but not the return type) cv-qualifiers ref-qualifiers Then this function in the class Derived is also virtual (whether or not the keyword virtual is used in its declaration) and overrides Base::vf (whether or not the word override is used in its declaration). Base::vf does not need to be visible (can be declared private , or inherited using private inheritance ) to be overridden. class B { virtual void do_f (); // private member public : void f () { do_f (); } // public interface }; struct D : public B { void do_f () override ; // overrides B::do_f }; int main () { D d ; B * bp = & d ; bp -> f (); // internally calls D::do_f(); } For every virtual function , there is the final overrider , which is executed when a virtual function call is made\uff08\u663e\u7136\u8fd9\u548c overload resolution \u6709\u5173\uff09. A virtual member function vf of a base class Base is the final overrider unless the derived class declares or inherits (through multiple inheritance) another function that overrides vf . struct A { virtual void f (); }; // A::f is virtual struct B : A { void f (); }; // B::f overrides A::f in B struct C : virtual B { void f (); }; // C::f overrides A::f in C struct D : virtual B {}; // D does not introduce an overrider, B::f is final in D struct E : C , D { // E does not introduce an overrider, C::f is final in E using A :: f ; // not a function declaration, just makes A::f visible to lookup }; int main () { E e ; e . f (); // virtual call calls C::f, the final overrider in e e . E :: f (); // non-virtual call calls A::f, which is visible in E } \u601d\u8003\uff1a TODO \u90a3\u4e48\u4e0a\u9762\u7684\u4ee3\u7801\u53ef\u4ee5\u7f16\u8bd1\u901a\u8fc7\u5417\uff1f If a function has more than one final overrider, the program is ill-formed: struct A { virtual void f (); }; struct VB1 : virtual A { void f (); // overrides A::f }; struct VB2 : virtual A { void f (); // overrides A::f }; // struct Error : VB1, VB2 { // // Error: A::f has two final overriders in Error // }; struct Okay : VB1 , VB2 { void f (); // OK: this is the final overrider for A::f }; struct VB1a : virtual A {}; // does not declare an overrider struct Da : VB1a , VB2 { // in Da, the final overrider of A::f is VB2::f }; A function with the same name but different parameter list does not override the base function of the same name, but hides it: when unqualified name lookup examines the scope of the derived class , the lookup finds the declaration and does not examine the base class . struct B { virtual void f (); }; struct D : B { void f ( int ); // D::f hides B::f (wrong parameter list) }; struct D2 : D { void f (); // D2::f overrides B::f (doesn't matter that it's not visible) }; int main () { B b ; B & b_as_b = b ; D d ; B & d_as_b = d ; D & d_as_d = d ; D2 d2 ; B & d2_as_b = d2 ; D & d2_as_d = d2 ; b_as_b . f (); // calls B::f() d_as_b . f (); // calls B::f() d2_as_b . f (); // calls D2::f() d_as_d . f (); // Error: lookup in D finds only f(int) d2_as_d . f (); // Error: lookup in D finds only f(int) } If a function is declared with the specifier override , but does not override a virtual function, the program is ill-formed: struct B { virtual void f ( int ); }; struct D : B { virtual void f ( int ) override ; // OK, D::f(int) overrides B::f(int) virtual void f(long) override; // Error: f(long) does not override B::f(int) }; If a function is declared with the specifier final , and another function attempts to override it, the program is ill-formed: struct B { virtual void f () const final ; }; struct D : B { void f () const ; // Error: D::f attempts to override final B::f }; Non-member functions and static member functions cannot be virtual. Functions templates cannot be declared virtual . This applies only to functions that are themselves templates - a regular member function of a class template can be declared virtual. Virtual functions (whether declared virtual or overriding one) cannot have any associated constraints. struct A { virtual void f() requires true; // Error: constrained virtual function }; If an overriding function specifies contract conditions , it must specify the same list contract conditions as the functions it overrides; no diagnostic is required if corresponding conditions will always evaluate to the same value. Otherwise, it is considered to have the list of contract conditions from one of its overriden functions; the names in the contract conditions are bound and the semantic constraints are checked at the point where the contract conditions appear. struct A { virtual void f(int i) [[expects: i > x]]; virtual void g(int i) [[expects: i < x]]; virtual void h(int i) [[expects: i < 0]]; int x; }; struct B : A { virtual void f(int i); // OK, 'x' in precondition means A::x virtual void g(int i) [[expects: i < x]]; // error virtual void h(int i) [[expects: i < 1]]; // error std::string x; }; struct C : A { virtual void f(int i) [[expects: i > x]]; // OK virtual void g(int i) [[expects: i < A::x]]; // ill-formed, no diagnostic required }; If a contract condition of a virtual function f odr-uses *this, the class of which f is a direct member must be an unambiguous and accessible base class of any class in which f is overridden. struct A { virtual void g() [[expects: x == 0]]; // odr-uses *this int x = 42; }; struct B : A { }; struct C : A, B { virtual void g(); //error, A is an ambiguous base }; If a function overrides more than one function, all of the overridden functions must have the same list of contract conditions; no diagnostic is required if corresponding conditions will always evaluate to the same value. struct A { virtual void g() [[expects: x == 0]]; // x means A::x int x = 42; }; int x = 42; struct B { virtual void g() [[expects: x == 0]]; // x means ::x } struct C : A, B { virtual void g(); //error }; (since C++20) Default arguments for virtual functions are substituted at the compile time.","title":"In detail"},{"location":"C++/Language-reference/draft/specifier/cppreference-virtual-function-specifier/#covariant-return-types","text":"If the function Derived::f overrides a function Base::f , their return types must either be the same or be covariant . Two types are covariant if they satisfy all of the following requirements: both types are pointers or references (lvalue or rvalue) to classes. Multi-level pointers or references are not allowed. the referenced/pointed-to class in the return type of Base::f() must be a unambiguous and accessible direct or indirect base class of the referenced/pointed-to class of the return type of Derived::f() . the return type of Derived::f() must be equally or less cv-qualified than the return type of Base::f() . The class in the return type of Derived::f must be either Derived itself, or must be a complete type at the point of declaration of Derived::f . When a virtual function call is made, the type returned by the final overrider is implicitly converted to the return type of the overridden function that was called: class B {}; struct Base { virtual void vf1(); virtual void vf2(); virtual void vf3(); virtual B* vf4(); virtual B* vf5(); }; class D : private B { friend struct Derived; // in Derived, B is an accessible base of D }; class A; // forward-declared class is an incomplete type struct Derived : public Base { void vf1(); // virtual, overrides Base::vf1() void vf2(int); // non-virtual, hides Base::vf2() // char vf3(); // Error: overrides Base::vf3, but has different // and non-covariant return type D* vf4(); // overrides Base::vf4() and has covariant return type // A* vf5(); // Error: A is incomplete type }; int main() { Derived d; Base& br = d; Derived& dr = d; br.vf1(); // calls Derived::vf1() br.vf2(); // calls Base::vf2() // dr.vf2(); // Error: vf2(int) hides vf2() B* p = br.vf4(); // calls Derived::vf4() and converts the result to B* D* q = dr.vf4(); // calls Derived::vf4() and does not convert // the result to B* }","title":"Covariant return types"},{"location":"C++/Language-reference/draft/specifier/cppreference-virtual-function-specifier/#virtual-destructor","text":"Even though destructors are not inherited, if a base class declares its destructor virtual , the derived destructor always overrides it. This makes it possible to delete dynamically allocated objects of polymorphic type through pointers to base. class Base { public : virtual ~ Base () { /* releases Base's resources */ } }; class Derived : public Base { ~ Derived () { /* releases Derived's resources */ } }; int main () { Base * b = new Derived ; delete b ; // Makes a virtual function call to Base::~Base() // since it is virtual, it calls Derived::~Derived() which can // release resources of the derived class, and then calls // Base::~Base() following the usual order of destruction } Moreover, if a class is polymorphic (declares or inherits at least one virtual function), and its destructor is not virtual, deleting it is undefined behavior regardless of whether there are resources that would be leaked if the derived destructor is not invoked. A useful guideline is that the destructor of any base class must be public and virtual or protected and non-virtual .","title":"Virtual destructor"},{"location":"C++/Language-reference/draft/specifier/cppreference-virtual-function-specifier/#during-construction-and-destruction","text":"When a virtual function is called directly or indirectly from a constructor or from a destructor (including during the construction or destruction of the class\u2019s non-static data members, e.g. in a member initializer list ), and the object to which the call applies is the object under construction or destruction, the function called is the final overrider in the constructor\u2019s or destructor\u2019s class and not one overriding it in a more-derived class. In other words, during construction or destruction, the more-derived classes do not exist. When constructing a complex class with multiple branches, within a constructor that belongs to one branch, polymorphism is restricted to that class and its bases: if it obtains a pointer or reference to a base subobject outside this subhierarchy, and attempts to invoke a virtual function call (e.g. using explicit member access), the behavior is undefined: struct V { virtual void f (); virtual void g (); }; struct A : virtual V { virtual void f (); // A::f is the final overrider of V::f in A }; struct B : virtual V { virtual void g (); // B::g is the final overrider of V::g in B B ( V * , A * ); }; struct D : A , B { virtual void f (); // D::f is the final overrider of V::f in D virtual void g (); // D::g is the final overrider of V::g in D // note: A is initialized before B D () : B (( A * ) this , this ) { } }; // the constructor of B, called from the constructor of D B :: B ( V * v , A * a ) { f (); // virtual call to V::f (although D has the final overrider, D doesn't exist) g (); // virtual call to B::g, which is the final overrider in B v -> g (); // v's type V is base of B, virtual call calls B::g as before a -> f (); // a\u2019s type A is not a base of B. it belongs to a different branch of the // hierarchy. Attempting a virtual call through that branch causes // undefined behavior even though A was already fully constructed in this // case (it was constructed before B since it appears before B in the list // of the bases of D). In practice, the virtual call to A::f will be // attempted using B's virtual member function table, since that's what // is active during B's construction) }","title":"During construction and destruction"},{"location":"C++/Language-reference/draft/specifier/cppreference-virtual-function-specifier/#see-also","text":"derived classes and modes of inheritance override specifier (since C++11) final specifier (since C++11)","title":"See also"},{"location":"C++/Language-reference/draft/specifier/creference-storage-class specifiers/","text":"Storage-class specifiers Explanation Storage duration Linkage Linkage and libraries Keywords Notes Example Storage-class specifiers Specify storage duration and linkage of objects and functions: auto - automatic duration and no linkage register - automatic duration and no linkage; address of this variable cannot be taken static - static duration and internal linkage (unless at block scope) extern - static duration and external linkage (unless already declared internal) _Thread_local - thread storage duration \u5176\u5b9e\u8fd9\u662f\u975e\u5e38\u7b80\u5355\u7684\uff0c\u4e00\u4e2aname\uff0c\u8981\u4e48\u662f\u5728\u672ctranslation unit\u4e2d\u5b9a\u4e49\uff0c\u8981\u4e48\u662f\u5728\u53e6\u5916 \u4e00\u4e2atranslation unit\u4e2d\u5b9a\u4e49\uff1b\u5982\u679c\u4e00\u4e2aname\u662f\u5728\u53e6\u5916\u4e00\u4e2atranslation unit\u4e2d\u5b9a\u4e49\u7684\uff0c\u90a3\u4e48\u5728\u672c translation unit \u4e2d\u5b83\u5c31\u662fexternal linkage\uff1b SUMMARY : _Thread_local \u548c\u524d\u9762\u7684\u4e09\u4e2a specifier \u4e0d\u540c\u7684\u662f\u5b83\u4ec5\u4ec5specify storage duration\u800c\u6ca1\u6709specify linkage\uff1b\u5982\u4e0b\u9762\u7684 Explanation \u4e2d\u6240\u4ecb\u7ecd\u7684\uff0c\u5f53\u8fd8\u9700\u8981\u6307\u5b9alinkage\u7684\u65f6\u5019\uff0c\u9700\u8981\u548c static \u548c extern \u4e00\u8d77\u6765\u4f7f\u7528\uff1b SUMMARY : c\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u63d0\u4f9b\u8fd9\u4e9bkey word\u6765\u5141\u8bb8\u7528\u6237\u5bf9variable\u7684storage duration\u6216 Lifetime \u548clinkage\u8fdb\u884c\u63a7\u5236\uff0c\u8fd9\u79cd\u901a\u8fc7specifier\u6765\u63a7\u5236program\u7684runtime\u884c\u4e3a\u7684\u601d\u60f3\u5728\u300ahow to master programming language.md\u300b\u4e2d\u5df2\u7ecf\u63cf\u8ff0\u4e86\uff1bstorage duration\u6216 Lifetime \u662fruntime\u6982\u5ff5\uff1b SUMMARY : \u62e5\u6709linkage\u7684entity\u7684storage duration\u90fd\u662fstatic duration\uff1b Explanation Storage-class specifiers appear in declarations . At most one specifier may be used, except that _Thread_local may be combined with static or extern to adjust linkage (since C11). The storage-class specifiers determine two independent properties of the names they declare: storage duration and linkage . 1) The auto specifier is only allowed for objects declared at block scope (except function parameter lists). It indicates automatic storage duration and no linkage , which are the defaults for these kinds of declarations. 2) The register specifier is only allowed for objects declared at block scope , including function parameter lists . It indicates automatic storage duration and no linkage (which is the default for these kinds of declarations), but additionally hints the optimizer to store the value of this variable in a CPU register if possible. Regardless of whether this optimization takes place or not, variables declared register cannot be used as arguments to the address-of operator , cannot use alignas (since C11), and register arrays are not convertible to pointers. SUMMARY : \u4ece\u8fd9\u91cc\u4e5f\u53ef\u4ee5\u770b\u51faC\u8bed\u8a00\u7684\u80fd\u529b\u662f\u6709\u9650\u7684\uff0c\u5b83\u8fd8\u4f9d\u8d56\u4e8ecompiler\u5bf9\u5b83\u7684\u7ffb\u8bd1\uff0c\u800cprogrammer\u53ea\u80fd\u591f\u7ed9compiler\u4e00\u4e9bhint\uff1b 3) The static specifier specifies both static storage duration (unless combined with _Thread_local \u6b64\u5904unless\u8868\u793a\u7684\u662f\u5bf9\u524d\u9762\u7684\u8bba\u65ad\u7684\u5426\u5b9a\uff0c\u5373\u5b83\u4e0d\u7b26\u5408\u524d\u9762\u7684\u8bba\u65ad) (since C11)and internal linkage (unless used at block scope). It can be used with functions at file scope and with variables at both file and block scope , but not in function parameter lists. 4) The extern specifier specifies static storage duration (unless combined with _Thread_local ) (since C11) and external linkage. It can be used with function and object declarations in both file and block scope (excluding function parameter lists). If extern appears on a redeclaration of an identifier that was already declared with internal linkage, the linkage remains internal. Otherwise (if the prior declaration was external, no-linkage, or is not in scope), the linkage is external. 5) _Thread_local indicates thread storage duration . It cannot be used with function declarations. If it is used on a declaration of an object, it must be present on every declaration of the same object. If it is used on a block-scope declaration, it must be combined with either static or extern to decide linkage. If no storage-class specifier is provided, the defaults are: extern for all functions extern for objects at file scope auto for objects at block scope For any struct or union declared with a storage-class specifier, the storage duration (but not linkage) applies to their members, recursively. Function declarations at block scope can use extern or none at all\uff08\u4e0d\u80fd\u591f\u4f7f\u7528 static \uff09. Function declarations at file scope can use extern or static . Function parameters cannot use any storage-class specifiers other than register . Note that static has special meaning in function parameters of array type. Storage duration Every object has a property called storage duration , which limits the object lifetime . There are four kinds of storage duration in C: automatic storage duration. The storage is allocated when the block in which the object was declared is entered and deallocated when it is exited by any means ( goto , return , reaching the end). One exception is the VLAs ; their storage is allocated when the declaration is executed, not on block entry, and deallocated when the declaration goes out of scope, not than when the block is exited (since C99). If the block is entered recursively, a new allocation is performed for every recursion level. All function parameters and non- static block-scope objects have this storage duration, as well as compound literals used at block scope. SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u6ca1\u6709\u641e\u61c2\uff0c\u5176\u5b9e\u6839\u6e90\u5728\u4e8e\u5bf9 VLAs \u6ca1\u6709\u7406\u89e3\u900f\u5f7b\uff1b SUMMARY : automatic\u7684object\u7684\u4e00\u79cd\u5178\u578b\u7684\u6848\u4f8b\u5c31\u662f\uff1a\u4f4d\u4e8estack\u4e0a\u7684\uff0c\u5b83\u4eec\u662f\u5728\u51fd\u6570\u88ab\u8c03\u7528\u7684\u65f6\u5019\u88ab\u6267\u884c\u7684\uff1b\u6700\u540e\u4e00\u6bb5\u8bdd\u7684\u603b\u7ed3\u662f\u975e\u5e38\u597d\u7684\uff1b static storage duration. The storage duration is the entire execution of the program, and the value stored in the object is initialized only once, prior to main function . All objects declared static and all objects with either internal or external linkage that aren't declared _Thread_local (since C11) have this storage duration. SUMMARY : \u5173\u4e8e static \u548c _Thread_local \u5728 Explanation \u4e2d\u7684\u89e3\u91ca\u662f\u975e\u5e38\u6e05\u695a\u7684\uff1b thread storage duration. The storage duration is the entire execution of the thread in which it was created, and the value stored in the object is initialized when the thread is started. Each thread has its own, distinct, object. If the thread that executes the expression that accesses this object is not the thread that executed its\uff08\u6307\u4ee3\u524d\u9762\u7684this object\uff09 initialization, the behavior is implementation-defined. All objects declared _Thread_local have this storage duration. SUMMARY : \u6700\u540e\u4e00\u53e5\u8bdd\u6ca1\u6709\u641e\u61c2 allocated storage duration. The storage is allocated and deallocated on request, using dynamic memory allocation functions. Linkage Linkage refers to the ability of an identifier (variable or function) to be referred to in other scopes. If a variable or function with the same identifier is declared in several scopes, but cannot be referred to from all of them, then several instances of the variable are generated. The following linkages are recognized: no linkage . The identifier can be referred to only from the scope it is in. All function parameters and all non- extern block-scope variables (including the ones declared static ) have this linkage. internal linkage . The identifier can be referred to from all scopes in the current translation unit . All static file-scope identifiers (both functions and variables) have this linkage. external linkage . The identifier can be referred to from any other translation units in the entire program. All non- static functions, all extern variables (unless earlier declared static ), and all file-scope non- static variables have this linkage. If the same identifier appears with both internal and external linkage in the same translation unit, the behavior is undefined. This is possible when tentative definitions are used. Linkage and libraries Declarations with external linkage are commonly made available in header files so that all translation units that #include the file may refer to the same identifier that are defined elsewhere. Any declaration with internal linkage that appears in a header file results in a separate and distinct object in each translation unit that includes that file. SUMMARY : linkage\u548c #include Library interface: // flib.h #ifndef FLIB_H #define FLIB_H void f ( void ); // function declaration with external linkage extern int state ; // variable declaration with external linkage static const int size = 5 ; // definition of a read-only variable with internal linkage enum { MAX = 10 }; // constant definition inline int sum ( int a , int b ) { return a + b ; } // inline function definition #endif // FLIB_H Library implementation: // flib.c #include \"flib.h\" static void local_f ( int s ) {} // definition with internal linkage (only used in this file) static int local_state ; // definition with internal linkage (only used in this file) int state ; // definition with external linkage (used by main.c) void f ( void ) { local_f ( state );} // definition with external linkage (used by main.c) Application code: // main.c #include \"flib.h\" int main ( void ) { int x [ MAX ] = { size }; // uses the constant and the read-only variable state = 7 ; // modifies state in flib.c f (); // calls f() in flib.c } Keywords auto , register , static , extern , _Thread_local Notes The keyword _Thread_local is usually used through the convenience macro thread_local , defined in the header threads.h . The typedef specifier is formally listed as a storage-class specifier in the C language grammar, but it is used to declare type names and does not specify storage. Names at file scope that are const and not extern have external linkage in C (as the default for all file-scope declarations), but internal linkage in C++. Example #include <stdio.h> #include <stdlib.h> /* static storage duration */ int A ; int main ( void ) { printf ( \"&A = %p \\n \" , ( void * ) & A ); /* automatic storage duration */ int A = 1 ; // hides global A printf ( \"&A = %p \\n \" , ( void * ) & A ); /* allocated storage duration */ int * ptr_1 = malloc ( sizeof ( int )); /* start allocated storage duration */ printf ( \"address of int in allocated memory = %p \\n \" , ( void * ) ptr_1 ); free ( ptr_1 ); /* stop allocated storage duration */ }","title":"Creference storage class specifiers"},{"location":"C++/Language-reference/draft/specifier/creference-storage-class specifiers/#storage-class-specifiers","text":"Specify storage duration and linkage of objects and functions: auto - automatic duration and no linkage register - automatic duration and no linkage; address of this variable cannot be taken static - static duration and internal linkage (unless at block scope) extern - static duration and external linkage (unless already declared internal) _Thread_local - thread storage duration \u5176\u5b9e\u8fd9\u662f\u975e\u5e38\u7b80\u5355\u7684\uff0c\u4e00\u4e2aname\uff0c\u8981\u4e48\u662f\u5728\u672ctranslation unit\u4e2d\u5b9a\u4e49\uff0c\u8981\u4e48\u662f\u5728\u53e6\u5916 \u4e00\u4e2atranslation unit\u4e2d\u5b9a\u4e49\uff1b\u5982\u679c\u4e00\u4e2aname\u662f\u5728\u53e6\u5916\u4e00\u4e2atranslation unit\u4e2d\u5b9a\u4e49\u7684\uff0c\u90a3\u4e48\u5728\u672c translation unit \u4e2d\u5b83\u5c31\u662fexternal linkage\uff1b SUMMARY : _Thread_local \u548c\u524d\u9762\u7684\u4e09\u4e2a specifier \u4e0d\u540c\u7684\u662f\u5b83\u4ec5\u4ec5specify storage duration\u800c\u6ca1\u6709specify linkage\uff1b\u5982\u4e0b\u9762\u7684 Explanation \u4e2d\u6240\u4ecb\u7ecd\u7684\uff0c\u5f53\u8fd8\u9700\u8981\u6307\u5b9alinkage\u7684\u65f6\u5019\uff0c\u9700\u8981\u548c static \u548c extern \u4e00\u8d77\u6765\u4f7f\u7528\uff1b SUMMARY : c\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u63d0\u4f9b\u8fd9\u4e9bkey word\u6765\u5141\u8bb8\u7528\u6237\u5bf9variable\u7684storage duration\u6216 Lifetime \u548clinkage\u8fdb\u884c\u63a7\u5236\uff0c\u8fd9\u79cd\u901a\u8fc7specifier\u6765\u63a7\u5236program\u7684runtime\u884c\u4e3a\u7684\u601d\u60f3\u5728\u300ahow to master programming language.md\u300b\u4e2d\u5df2\u7ecf\u63cf\u8ff0\u4e86\uff1bstorage duration\u6216 Lifetime \u662fruntime\u6982\u5ff5\uff1b SUMMARY : \u62e5\u6709linkage\u7684entity\u7684storage duration\u90fd\u662fstatic duration\uff1b","title":"Storage-class specifiers"},{"location":"C++/Language-reference/draft/specifier/creference-storage-class specifiers/#explanation","text":"Storage-class specifiers appear in declarations . At most one specifier may be used, except that _Thread_local may be combined with static or extern to adjust linkage (since C11). The storage-class specifiers determine two independent properties of the names they declare: storage duration and linkage . 1) The auto specifier is only allowed for objects declared at block scope (except function parameter lists). It indicates automatic storage duration and no linkage , which are the defaults for these kinds of declarations. 2) The register specifier is only allowed for objects declared at block scope , including function parameter lists . It indicates automatic storage duration and no linkage (which is the default for these kinds of declarations), but additionally hints the optimizer to store the value of this variable in a CPU register if possible. Regardless of whether this optimization takes place or not, variables declared register cannot be used as arguments to the address-of operator , cannot use alignas (since C11), and register arrays are not convertible to pointers. SUMMARY : \u4ece\u8fd9\u91cc\u4e5f\u53ef\u4ee5\u770b\u51faC\u8bed\u8a00\u7684\u80fd\u529b\u662f\u6709\u9650\u7684\uff0c\u5b83\u8fd8\u4f9d\u8d56\u4e8ecompiler\u5bf9\u5b83\u7684\u7ffb\u8bd1\uff0c\u800cprogrammer\u53ea\u80fd\u591f\u7ed9compiler\u4e00\u4e9bhint\uff1b 3) The static specifier specifies both static storage duration (unless combined with _Thread_local \u6b64\u5904unless\u8868\u793a\u7684\u662f\u5bf9\u524d\u9762\u7684\u8bba\u65ad\u7684\u5426\u5b9a\uff0c\u5373\u5b83\u4e0d\u7b26\u5408\u524d\u9762\u7684\u8bba\u65ad) (since C11)and internal linkage (unless used at block scope). It can be used with functions at file scope and with variables at both file and block scope , but not in function parameter lists. 4) The extern specifier specifies static storage duration (unless combined with _Thread_local ) (since C11) and external linkage. It can be used with function and object declarations in both file and block scope (excluding function parameter lists). If extern appears on a redeclaration of an identifier that was already declared with internal linkage, the linkage remains internal. Otherwise (if the prior declaration was external, no-linkage, or is not in scope), the linkage is external. 5) _Thread_local indicates thread storage duration . It cannot be used with function declarations. If it is used on a declaration of an object, it must be present on every declaration of the same object. If it is used on a block-scope declaration, it must be combined with either static or extern to decide linkage. If no storage-class specifier is provided, the defaults are: extern for all functions extern for objects at file scope auto for objects at block scope For any struct or union declared with a storage-class specifier, the storage duration (but not linkage) applies to their members, recursively. Function declarations at block scope can use extern or none at all\uff08\u4e0d\u80fd\u591f\u4f7f\u7528 static \uff09. Function declarations at file scope can use extern or static . Function parameters cannot use any storage-class specifiers other than register . Note that static has special meaning in function parameters of array type.","title":"Explanation"},{"location":"C++/Language-reference/draft/specifier/creference-storage-class specifiers/#storage-duration","text":"Every object has a property called storage duration , which limits the object lifetime . There are four kinds of storage duration in C: automatic storage duration. The storage is allocated when the block in which the object was declared is entered and deallocated when it is exited by any means ( goto , return , reaching the end). One exception is the VLAs ; their storage is allocated when the declaration is executed, not on block entry, and deallocated when the declaration goes out of scope, not than when the block is exited (since C99). If the block is entered recursively, a new allocation is performed for every recursion level. All function parameters and non- static block-scope objects have this storage duration, as well as compound literals used at block scope. SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u6ca1\u6709\u641e\u61c2\uff0c\u5176\u5b9e\u6839\u6e90\u5728\u4e8e\u5bf9 VLAs \u6ca1\u6709\u7406\u89e3\u900f\u5f7b\uff1b SUMMARY : automatic\u7684object\u7684\u4e00\u79cd\u5178\u578b\u7684\u6848\u4f8b\u5c31\u662f\uff1a\u4f4d\u4e8estack\u4e0a\u7684\uff0c\u5b83\u4eec\u662f\u5728\u51fd\u6570\u88ab\u8c03\u7528\u7684\u65f6\u5019\u88ab\u6267\u884c\u7684\uff1b\u6700\u540e\u4e00\u6bb5\u8bdd\u7684\u603b\u7ed3\u662f\u975e\u5e38\u597d\u7684\uff1b static storage duration. The storage duration is the entire execution of the program, and the value stored in the object is initialized only once, prior to main function . All objects declared static and all objects with either internal or external linkage that aren't declared _Thread_local (since C11) have this storage duration. SUMMARY : \u5173\u4e8e static \u548c _Thread_local \u5728 Explanation \u4e2d\u7684\u89e3\u91ca\u662f\u975e\u5e38\u6e05\u695a\u7684\uff1b thread storage duration. The storage duration is the entire execution of the thread in which it was created, and the value stored in the object is initialized when the thread is started. Each thread has its own, distinct, object. If the thread that executes the expression that accesses this object is not the thread that executed its\uff08\u6307\u4ee3\u524d\u9762\u7684this object\uff09 initialization, the behavior is implementation-defined. All objects declared _Thread_local have this storage duration. SUMMARY : \u6700\u540e\u4e00\u53e5\u8bdd\u6ca1\u6709\u641e\u61c2 allocated storage duration. The storage is allocated and deallocated on request, using dynamic memory allocation functions.","title":"Storage duration"},{"location":"C++/Language-reference/draft/specifier/creference-storage-class specifiers/#linkage","text":"Linkage refers to the ability of an identifier (variable or function) to be referred to in other scopes. If a variable or function with the same identifier is declared in several scopes, but cannot be referred to from all of them, then several instances of the variable are generated. The following linkages are recognized: no linkage . The identifier can be referred to only from the scope it is in. All function parameters and all non- extern block-scope variables (including the ones declared static ) have this linkage. internal linkage . The identifier can be referred to from all scopes in the current translation unit . All static file-scope identifiers (both functions and variables) have this linkage. external linkage . The identifier can be referred to from any other translation units in the entire program. All non- static functions, all extern variables (unless earlier declared static ), and all file-scope non- static variables have this linkage. If the same identifier appears with both internal and external linkage in the same translation unit, the behavior is undefined. This is possible when tentative definitions are used.","title":"Linkage"},{"location":"C++/Language-reference/draft/specifier/creference-storage-class specifiers/#linkage-and-libraries","text":"Declarations with external linkage are commonly made available in header files so that all translation units that #include the file may refer to the same identifier that are defined elsewhere. Any declaration with internal linkage that appears in a header file results in a separate and distinct object in each translation unit that includes that file. SUMMARY : linkage\u548c #include Library interface: // flib.h #ifndef FLIB_H #define FLIB_H void f ( void ); // function declaration with external linkage extern int state ; // variable declaration with external linkage static const int size = 5 ; // definition of a read-only variable with internal linkage enum { MAX = 10 }; // constant definition inline int sum ( int a , int b ) { return a + b ; } // inline function definition #endif // FLIB_H Library implementation: // flib.c #include \"flib.h\" static void local_f ( int s ) {} // definition with internal linkage (only used in this file) static int local_state ; // definition with internal linkage (only used in this file) int state ; // definition with external linkage (used by main.c) void f ( void ) { local_f ( state );} // definition with external linkage (used by main.c) Application code: // main.c #include \"flib.h\" int main ( void ) { int x [ MAX ] = { size }; // uses the constant and the read-only variable state = 7 ; // modifies state in flib.c f (); // calls f() in flib.c }","title":"Linkage and libraries"},{"location":"C++/Language-reference/draft/specifier/creference-storage-class specifiers/#keywords","text":"auto , register , static , extern , _Thread_local","title":"Keywords"},{"location":"C++/Language-reference/draft/specifier/creference-storage-class specifiers/#notes","text":"The keyword _Thread_local is usually used through the convenience macro thread_local , defined in the header threads.h . The typedef specifier is formally listed as a storage-class specifier in the C language grammar, but it is used to declare type names and does not specify storage. Names at file scope that are const and not extern have external linkage in C (as the default for all file-scope declarations), but internal linkage in C++.","title":"Notes"},{"location":"C++/Language-reference/draft/specifier/creference-storage-class specifiers/#example","text":"#include <stdio.h> #include <stdlib.h> /* static storage duration */ int A ; int main ( void ) { printf ( \"&A = %p \\n \" , ( void * ) & A ); /* automatic storage duration */ int A = 1 ; // hides global A printf ( \"&A = %p \\n \" , ( void * ) & A ); /* allocated storage duration */ int * ptr_1 = malloc ( sizeof ( int )); /* start allocated storage duration */ printf ( \"address of int in allocated memory = %p \\n \" , ( void * ) ptr_1 ); free ( ptr_1 ); /* stop allocated storage duration */ }","title":"Example"},{"location":"C++/Library/A-list-of-open-source-Cpp-libraries/","text":"A list of open source C++ libraries cppreference A list of open source C++ libraries Awesome C++","title":"A-list-of-open-source-Cpp-libraries"},{"location":"C++/Library/A-list-of-open-source-Cpp-libraries/#a-list-of-open-source-c-libraries","text":"","title":"A list of open source C++ libraries"},{"location":"C++/Library/A-list-of-open-source-Cpp-libraries/#cppreference-a-list-of-open-source-c-libraries","text":"","title":"cppreference A list of open source C++ libraries"},{"location":"C++/Library/A-list-of-open-source-Cpp-libraries/#awesome-c","text":"","title":"Awesome C++"},{"location":"C++/Library/Evented-IO-library/","text":"Evented IO library libsourcey","title":"Evented-IO-library"},{"location":"C++/Library/Evented-IO-library/#evented-io-library","text":"libsourcey","title":"Evented IO library"},{"location":"C++/Library/Plugin-system/","text":"Plugin system pluga","title":"Plugin-system"},{"location":"C++/Library/Plugin-system/#plugin-system","text":"","title":"Plugin system"},{"location":"C++/Library/Plugin-system/#pluga","text":"","title":"pluga"},{"location":"C++/Library/Abseil/Abseil/","text":"Abseil","title":"Abseil"},{"location":"C++/Library/Abseil/Abseil/#abseil","text":"","title":"Abseil"},{"location":"C++/Library/Atomic-operations-library/Atomic-operations-library/","text":"Atomic operations library cppreference Atomic operations library","title":"Atomic-operations-library"},{"location":"C++/Library/Atomic-operations-library/Atomic-operations-library/#atomic-operations-library","text":"","title":"Atomic operations library"},{"location":"C++/Library/Atomic-operations-library/Atomic-operations-library/#cppreference-atomic-operations-library","text":"","title":"cppreference Atomic operations library"},{"location":"C++/Library/STL/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u63cf\u8ff0STL\uff0cc++\u7684\u6700\u6700\u91cd\u8981\u7684library\u3002","title":"Introduction"},{"location":"C++/Library/STL/#_1","text":"\u672c\u7ae0\u63cf\u8ff0STL\uff0cc++\u7684\u6700\u6700\u91cd\u8981\u7684library\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"C++/Library/STL/Design-pattern-of-STL/","text":"https://stackoverflow.com/questions/2698474/design-patterns-used-in-stlstandard-template-library http://www.josuttis.com/libbook/ https://www.eventhelix.com/RealtimeMantra/Patterns/stl_design_patterns.htm https://justinmeiners.github.io/sgi-stl-docs/design_documents.html","title":"Design-pattern-of-STL"},{"location":"C++/Library/STL/STL/","text":"STL \u7ef4\u57fa\u767e\u79d1 Standard Template Library It provides four components called algorithms , containers , functions , and iterators . NOTE: \u53c2\u89c1\u4e0b\u9762\u7684\u7ae0\u8282 The STL achieves its results through the use of templates . This approach provides compile-time polymorphism that is often more efficient than traditional run-time polymorphism . The STL was created as the first library of generic algorithms and data structures for C++, with four ideas in mind: generic programming , abstractness without loss of efficiency, the Von Neumann computation model , and value semantics . NOTE: STL\u7684\u8bbe\u8ba1\u7406\u5ff5\u3002 Composition Containers Iterators Algorithms Functions NOTE: \u5728\u672c\u6587\u4e2d\uff0c\u6240\u8c13\u7684\u201cfunction\u201d\uff0c\u5176\u5b9e\u5c31\u662ffunctor\u3002 Criticisms Other issues NOTE: \u539f\u6587\u7684\u8fd9\u4e00\u6bb5\u662f\u975e\u5e38\u503c\u5f97\u4e00\u8bfb\u7684\uff0c\u5176\u4e2d\u6240\u63cf\u8ff0\u7684\u95ee\u9898\uff0c\u5176\u5b9e\u662f\u5f88\u591aprogrammer\u90fd\u975e\u5e38\u4efb\u610f\u8303\u7684 Initialization of STL containers with constants within the source code is not as easy as data structures inherited from C (addressed in C++11 with initializer lists ). STL containers are not intended to be used as base classes (their destructors are deliberately non-virtual); deriving from a container is a common mistake. NOTE: \u8fd9\u4e00\u70b9\u9700\u8981\u6ce8\u610f The concept of iterators as implemented by STL can be difficult to understand at first: for example, if a value pointed to by the iterator is deleted, the iterator itself is then no longer valid. This is a common source of errors. Most implementations of the STL provide a debug mode that is slower, but can locate such errors if used. A similar problem exists in other languages, for example Java . Ranges have been proposed as a safer, more flexible alternative to iterators. Certain iteration patterns do not map to the STL iterator model. For example, callback enumeration APIs cannot be made to fit the STL model without the use of coroutines , which are platform-dependent or unavailable, and will be outside the C++ standard until C++20. NOTE: geeksforgeeks The C++ Standard Template Library (STL) Design pattern of STL","title":"STL"},{"location":"C++/Library/STL/STL/#stl","text":"","title":"STL"},{"location":"C++/Library/STL/STL/#standard-template-library","text":"It provides four components called algorithms , containers , functions , and iterators . NOTE: \u53c2\u89c1\u4e0b\u9762\u7684\u7ae0\u8282 The STL achieves its results through the use of templates . This approach provides compile-time polymorphism that is often more efficient than traditional run-time polymorphism . The STL was created as the first library of generic algorithms and data structures for C++, with four ideas in mind: generic programming , abstractness without loss of efficiency, the Von Neumann computation model , and value semantics . NOTE: STL\u7684\u8bbe\u8ba1\u7406\u5ff5\u3002","title":"\u7ef4\u57fa\u767e\u79d1Standard Template Library"},{"location":"C++/Library/STL/STL/#composition","text":"","title":"Composition"},{"location":"C++/Library/STL/STL/#containers","text":"","title":"Containers"},{"location":"C++/Library/STL/STL/#iterators","text":"","title":"Iterators"},{"location":"C++/Library/STL/STL/#algorithms","text":"","title":"Algorithms"},{"location":"C++/Library/STL/STL/#functions","text":"NOTE: \u5728\u672c\u6587\u4e2d\uff0c\u6240\u8c13\u7684\u201cfunction\u201d\uff0c\u5176\u5b9e\u5c31\u662ffunctor\u3002","title":"Functions"},{"location":"C++/Library/STL/STL/#criticisms","text":"","title":"Criticisms"},{"location":"C++/Library/STL/STL/#other-issues","text":"NOTE: \u539f\u6587\u7684\u8fd9\u4e00\u6bb5\u662f\u975e\u5e38\u503c\u5f97\u4e00\u8bfb\u7684\uff0c\u5176\u4e2d\u6240\u63cf\u8ff0\u7684\u95ee\u9898\uff0c\u5176\u5b9e\u662f\u5f88\u591aprogrammer\u90fd\u975e\u5e38\u4efb\u610f\u8303\u7684 Initialization of STL containers with constants within the source code is not as easy as data structures inherited from C (addressed in C++11 with initializer lists ). STL containers are not intended to be used as base classes (their destructors are deliberately non-virtual); deriving from a container is a common mistake. NOTE: \u8fd9\u4e00\u70b9\u9700\u8981\u6ce8\u610f The concept of iterators as implemented by STL can be difficult to understand at first: for example, if a value pointed to by the iterator is deleted, the iterator itself is then no longer valid. This is a common source of errors. Most implementations of the STL provide a debug mode that is slower, but can locate such errors if used. A similar problem exists in other languages, for example Java . Ranges have been proposed as a safer, more flexible alternative to iterators. Certain iteration patterns do not map to the STL iterator model. For example, callback enumeration APIs cannot be made to fit the STL model without the use of coroutines , which are platform-dependent or unavailable, and will be outside the C++ standard until C++20. NOTE:","title":"Other issues"},{"location":"C++/Library/STL/STL/#geeksforgeeks-the-c-standard-template-library-stl","text":"","title":"geeksforgeeks The C++ Standard Template Library (STL)"},{"location":"C++/Library/STL/STL/#design-pattern-of-stl","text":"","title":"Design pattern of STL"},{"location":"C++/Library/STL/Algorithm/","text":"","title":"Introduction"},{"location":"C++/Library/STL/Containers-library/Containers-library/","text":"Containers library cppreference Containers library","title":"Containers-library"},{"location":"C++/Library/STL/Containers-library/Containers-library/#containers-library","text":"","title":"Containers library"},{"location":"C++/Library/STL/Containers-library/Containers-library/#cppreference-containers-library","text":"","title":"cppreference Containers library"},{"location":"C++/Library/STL/Containers-library/Emplace_back/Emplace_back/","text":"emplace_back push_back vs emplace_back Copy constructor and emplace_back() in C++ Tip of the Week #112: emplace vs. push_back \u8fd9\u7bc7\u4ecb\u7ecd\u5730\u975e\u5e38\u597d emplace_back \u5982\u4f55\u9009\u62e9constructor\uff1f 20200404 \u4eca\u5929\u78b0\u5230\u4e86\u8fd9\u6837\u7684\u4e00\u4e2a\u95ee\u9898\uff1a class CIStockInfoWrapper { CIStockInfoWrapper ( int MktType , std :: string Code ) : m_MktType ( MktType ), m_Code ( Code ) { m_HQInfo = new HQInfo ( m_Code , m_MktType ); } }; ...... std :: list < CIStockInfoWrapper > m_HQInfoList ; m_HQInfoList . emplace_back ( MktType , std :: to_string ( i )); \u5982\u679c\u5c06 CIStockInfoWrapper(int MktType, std::string Code) \u7684\u8bf4\u660e\u4fee\u6539\u4e3a CIStockInfoWrapper(int MktType, std::string& Code) \uff0c\u5219\u7a0b\u5e8f\u5c31\u7f16\u8bd1\u62a5\u9519\uff1a hq_client_wrapper/mock_hq_accessor.h:73:63: required from here /usr/include/c++/4.8.2/bits/stl_list.h:114:71: \u9519\u8bef\uff1a\u5bf9\u2018CIStockInfoWrapper::CIStockInfoWrapper(int&, std::basic_string<char>)\u2019\u7684\u8c03\u7528\u6ca1\u6709\u5339\u914d\u7684\u51fd\u6570 : __detail::_List_node_base(), _M_data(std::forward<_Args>(__args)...) ./hq_client_wrapper/hqsvr_stock_info_wrapper.h:22:7: \u9644\u6ce8\uff1a \u5907\u9009\u9700\u8981 1 \u5b9e\u53c2\uff0c\u4f46\u63d0\u4f9b\u4e86 2 \u4e2a","title":"Emplace_back"},{"location":"C++/Library/STL/Containers-library/Emplace_back/Emplace_back/#emplace_back","text":"","title":"emplace_back"},{"location":"C++/Library/STL/Containers-library/Emplace_back/Emplace_back/#push_back-vs-emplace_back","text":"","title":"push_back vs emplace_back"},{"location":"C++/Library/STL/Containers-library/Emplace_back/Emplace_back/#copy-constructor-and-emplace_back-in-c","text":"","title":"Copy constructor and emplace_back() in C++"},{"location":"C++/Library/STL/Containers-library/Emplace_back/Emplace_back/#tip-of-the-week-112-emplace-vs-push_back","text":"\u8fd9\u7bc7\u4ecb\u7ecd\u5730\u975e\u5e38\u597d","title":"Tip of the Week #112: emplace vs. push_back"},{"location":"C++/Library/STL/Containers-library/Emplace_back/Emplace_back/#emplace_backconstructor","text":"","title":"emplace_back\u5982\u4f55\u9009\u62e9constructor\uff1f"},{"location":"C++/Library/STL/Containers-library/Emplace_back/Emplace_back/#20200404","text":"\u4eca\u5929\u78b0\u5230\u4e86\u8fd9\u6837\u7684\u4e00\u4e2a\u95ee\u9898\uff1a class CIStockInfoWrapper { CIStockInfoWrapper ( int MktType , std :: string Code ) : m_MktType ( MktType ), m_Code ( Code ) { m_HQInfo = new HQInfo ( m_Code , m_MktType ); } }; ...... std :: list < CIStockInfoWrapper > m_HQInfoList ; m_HQInfoList . emplace_back ( MktType , std :: to_string ( i )); \u5982\u679c\u5c06 CIStockInfoWrapper(int MktType, std::string Code) \u7684\u8bf4\u660e\u4fee\u6539\u4e3a CIStockInfoWrapper(int MktType, std::string& Code) \uff0c\u5219\u7a0b\u5e8f\u5c31\u7f16\u8bd1\u62a5\u9519\uff1a hq_client_wrapper/mock_hq_accessor.h:73:63: required from here /usr/include/c++/4.8.2/bits/stl_list.h:114:71: \u9519\u8bef\uff1a\u5bf9\u2018CIStockInfoWrapper::CIStockInfoWrapper(int&, std::basic_string<char>)\u2019\u7684\u8c03\u7528\u6ca1\u6709\u5339\u914d\u7684\u51fd\u6570 : __detail::_List_node_base(), _M_data(std::forward<_Args>(__args)...) ./hq_client_wrapper/hqsvr_stock_info_wrapper.h:22:7: \u9644\u6ce8\uff1a \u5907\u9009\u9700\u8981 1 \u5b9e\u53c2\uff0c\u4f46\u63d0\u4f9b\u4e86 2 \u4e2a","title":"20200404"},{"location":"C++/Library/STL/Containers-library/List/Operation/","text":"Operation \u672c\u6587\u63cf\u8ff0\u5bf9list\u7684\u5404\u79cd\u64cd\u4f5c\u3002 Iteration \u4e00\u8fb9\u904d\u5386\u4e00\u8fb9\u5220\u9664 \u4f7f\u7528 while #include <list> #include <iostream> int main (){ std :: list < int > l = { 1 , 2 , 3 , 4 , 5 }; while ( not l . empty ()){ auto it = l . begin (); std :: cout <<* it << std :: endl ; l . pop_front (); // \u5220\u9664 } } \u4f7f\u7528 for #include <list> #include <iostream> int main () { std :: list < int > l = { 1 , 2 , 3 , 4 , 5 }; for ( int i = 0 ; i < 3 ; ++ i , l . pop_front ()) { auto it = l . begin (); std :: cout << * it << std :: endl ; } } \u6309\u6279\u6b21\u904d\u5386 \u4f7f\u7528\u4e0a\u9762\u63d0\u53ca\u7684\u201c\u4e00\u8fb9\u904d\u5386\u4e00\u8fb9\u5220\u9664\u201d\u7b56\u7565\u3002 #include <list> #include <iostream> #include <cmath> int main () { std :: list < int > l = { 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 }; int batch_size = 4 ; int batch_num = std :: ceil ( l . size () / double ( batch_size )); for ( int batch = 0 ; batch < batch_num ; ++ batch ) { std :: cout << \"\u7b2c[\" << batch << \"]\u6279\" << std :: endl ; for ( int i = 0 ; i < batch_size and not l . empty (); ++ i , l . pop_front ()) { auto it = l . begin (); std :: cout << * it << std :: endl ; } } } \u5408\u5e76\u4e24\u4e2alist cppreference std::list<T,Allocator>::splice cppreference std::list<T,Allocator>::merge","title":"Operation"},{"location":"C++/Library/STL/Containers-library/List/Operation/#operation","text":"\u672c\u6587\u63cf\u8ff0\u5bf9list\u7684\u5404\u79cd\u64cd\u4f5c\u3002","title":"Operation"},{"location":"C++/Library/STL/Containers-library/List/Operation/#iteration","text":"","title":"Iteration"},{"location":"C++/Library/STL/Containers-library/List/Operation/#_1","text":"\u4f7f\u7528 while #include <list> #include <iostream> int main (){ std :: list < int > l = { 1 , 2 , 3 , 4 , 5 }; while ( not l . empty ()){ auto it = l . begin (); std :: cout <<* it << std :: endl ; l . pop_front (); // \u5220\u9664 } } \u4f7f\u7528 for #include <list> #include <iostream> int main () { std :: list < int > l = { 1 , 2 , 3 , 4 , 5 }; for ( int i = 0 ; i < 3 ; ++ i , l . pop_front ()) { auto it = l . begin (); std :: cout << * it << std :: endl ; } }","title":"\u4e00\u8fb9\u904d\u5386\u4e00\u8fb9\u5220\u9664"},{"location":"C++/Library/STL/Containers-library/List/Operation/#_2","text":"\u4f7f\u7528\u4e0a\u9762\u63d0\u53ca\u7684\u201c\u4e00\u8fb9\u904d\u5386\u4e00\u8fb9\u5220\u9664\u201d\u7b56\u7565\u3002 #include <list> #include <iostream> #include <cmath> int main () { std :: list < int > l = { 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 }; int batch_size = 4 ; int batch_num = std :: ceil ( l . size () / double ( batch_size )); for ( int batch = 0 ; batch < batch_num ; ++ batch ) { std :: cout << \"\u7b2c[\" << batch << \"]\u6279\" << std :: endl ; for ( int i = 0 ; i < batch_size and not l . empty (); ++ i , l . pop_front ()) { auto it = l . begin (); std :: cout << * it << std :: endl ; } } }","title":"\u6309\u6279\u6b21\u904d\u5386"},{"location":"C++/Library/STL/Containers-library/List/Operation/#list","text":"","title":"\u5408\u5e76\u4e24\u4e2alist"},{"location":"C++/Library/STL/Containers-library/List/Operation/#cppreference-stdlisttallocatorsplice","text":"","title":"cppreference std::list&lt;T,Allocator&gt;::splice"},{"location":"C++/Library/STL/Containers-library/List/Operation/#cppreference-stdlisttallocatormerge","text":"","title":"cppreference std::list&lt;T,Allocator&gt;::merge"},{"location":"C++/Library/STL/Containers-library/Map/Operation/","text":"Operation \u672c\u6587\u63cf\u8ff0\u5bf9map\u7684\u5404\u79cd\u64cd\u4f5c\u3002 Iteration \u53c2\u8003\u6587\u7ae0\uff1a C++ Loop through Map How to Iterate over a map in C++ \u4f7f\u7528\u666e\u901a\u7684iterator \u5173\u4e8emap\u7684iterator\uff0c\u53c2\u89c1 \u4f7f\u7528 for map < string , int >:: iterator it ; for ( it = symbolTable . begin (); it != symbolTable . end (); it ++ ) { std :: cout << it -> first // string (key) << ':' << it -> second // string's value << std :: endl ; } \u4f7f\u7528 while #include <iostream> #include <map> #include <string> #include <iterator> #include <algorithm> int main () { std :: map < std :: string , int > mapOfWordCount ; // Insert Element in map mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"first\" , 1 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"second\" , 2 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"third\" , 3 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"third\" , 4 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"third\" , 5 )); // Create a map iterator and point to beginning of map std :: map < std :: string , int >:: iterator it = mapOfWordCount . begin (); // Iterate over the map using Iterator till end. while ( it != mapOfWordCount . end ()) { // Accessing KEY from element pointed by it. std :: string word = it -> first ; // Accessing VALUE from element pointed by it. int count = it -> second ; std :: cout << word << \" :: \" << count << std :: endl ; // Increment the Iterator to point to next entry it ++ ; } return 0 ; } Iterating over the map using C++11 range based for loop \u53c2\u89c1 Range-based for loop #include <map> #include <string> #include <iterator> #include <algorithm> int main () { std :: map < std :: string , int > mapOfWordCount ; // Insert Element in map mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"first\" , 1 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"second\" , 2 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"third\" , 3 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"third\" , 4 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"third\" , 5 )); // Create a map iterator and point to beginning of map std :: map < std :: string , int >:: iterator it = mapOfWordCount . begin (); // Iterate over the map using c++11 range based for loop for ( std :: pair < std :: string , int > element : mapOfWordCount ) { // Accessing KEY from element std :: string word = element . first ; // Accessing VALUE from element. int count = element . second ; std :: cout << word << \" :: \" << count << std :: endl ; } return 0 ; } \u56e0\u4e3amap\u4e2d\u7684\u5143\u7d20\u7684\u7c7b\u578b\u662f std::pair \u3002 \u4f7f\u7528type inference for ( auto const & x : symbolTable ) { std :: cout << x . first // string (key) << ':' << x . second // string's value << std :: endl ; } \u4f7f\u7528 Structured binding for ( auto const & [ key , val ] : symbolTable ) { std :: cout << key // string (key) << ':' << val // string's value << std :: endl ; } Iterating over the map using std::for_each and lambda function #include <iostream> #include <map> #include <string> #include <iterator> #include <algorithm> int main () { std :: map < std :: string , int > mapOfWordCount ; // Insert Element in map mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"first\" , 1 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"second\" , 2 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"third\" , 3 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"third\" , 4 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"third\" , 5 )); // Create a map iterator and point to beginning of map std :: map < std :: string , int >:: iterator it = mapOfWordCount . begin (); // Iterate over a map using std::for_each and Lambda function std :: for_each ( mapOfWordCount . begin (), mapOfWordCount . end (), []( std :: pair < std :: string , int > element ){ // Accessing KEY from element std :: string word = element . first ; // Accessing VALUE from element. int count = element . second ; std :: cout << word << \" :: \" << count << std :: endl ; }); return 0 ; } \u8fd9\u79cd\u5199\u6cd5\u6709\u4e9b\u7c7b\u4f3c\u4e8e\u51fd\u6570\u5f0f\u7f16\u7a0b\u3002 \u5220\u9664map\u4e2d\u7b26\u5408\u6761\u4ef6\u7684\u5143\u7d20 https://www.cnblogs.com/dabaopku/p/3912662.html https://bbs.csdn.net/topics/391899953 https://blog.csdn.net/tieshuxianrezhang/article/details/79221646 https://stackoverflow.com/questions/800955/remove-if-equivalent-for-stdmap https://en.cppreference.com/w/cpp/algorithm/remove http://www.cplusplus.com/forum/general/131917/ values like python dict How to copy all Values from a Map to a Vector in C++ Getting a list of values from a map How to retrieve all keys (or values) from a std::map and put them into a vector?","title":"Operation"},{"location":"C++/Library/STL/Containers-library/Map/Operation/#operation","text":"\u672c\u6587\u63cf\u8ff0\u5bf9map\u7684\u5404\u79cd\u64cd\u4f5c\u3002","title":"Operation"},{"location":"C++/Library/STL/Containers-library/Map/Operation/#iteration","text":"\u53c2\u8003\u6587\u7ae0\uff1a C++ Loop through Map How to Iterate over a map in C++","title":"Iteration"},{"location":"C++/Library/STL/Containers-library/Map/Operation/#iterator","text":"\u5173\u4e8emap\u7684iterator\uff0c\u53c2\u89c1 \u4f7f\u7528 for map < string , int >:: iterator it ; for ( it = symbolTable . begin (); it != symbolTable . end (); it ++ ) { std :: cout << it -> first // string (key) << ':' << it -> second // string's value << std :: endl ; } \u4f7f\u7528 while #include <iostream> #include <map> #include <string> #include <iterator> #include <algorithm> int main () { std :: map < std :: string , int > mapOfWordCount ; // Insert Element in map mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"first\" , 1 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"second\" , 2 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"third\" , 3 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"third\" , 4 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"third\" , 5 )); // Create a map iterator and point to beginning of map std :: map < std :: string , int >:: iterator it = mapOfWordCount . begin (); // Iterate over the map using Iterator till end. while ( it != mapOfWordCount . end ()) { // Accessing KEY from element pointed by it. std :: string word = it -> first ; // Accessing VALUE from element pointed by it. int count = it -> second ; std :: cout << word << \" :: \" << count << std :: endl ; // Increment the Iterator to point to next entry it ++ ; } return 0 ; }","title":"\u4f7f\u7528\u666e\u901a\u7684iterator"},{"location":"C++/Library/STL/Containers-library/Map/Operation/#iterating-over-the-map-using-c11-range-based-for-loop","text":"\u53c2\u89c1 Range-based for loop #include <map> #include <string> #include <iterator> #include <algorithm> int main () { std :: map < std :: string , int > mapOfWordCount ; // Insert Element in map mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"first\" , 1 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"second\" , 2 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"third\" , 3 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"third\" , 4 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"third\" , 5 )); // Create a map iterator and point to beginning of map std :: map < std :: string , int >:: iterator it = mapOfWordCount . begin (); // Iterate over the map using c++11 range based for loop for ( std :: pair < std :: string , int > element : mapOfWordCount ) { // Accessing KEY from element std :: string word = element . first ; // Accessing VALUE from element. int count = element . second ; std :: cout << word << \" :: \" << count << std :: endl ; } return 0 ; } \u56e0\u4e3amap\u4e2d\u7684\u5143\u7d20\u7684\u7c7b\u578b\u662f std::pair \u3002","title":"Iterating over the map using C++11 range based for loop"},{"location":"C++/Library/STL/Containers-library/Map/Operation/#type-inference","text":"for ( auto const & x : symbolTable ) { std :: cout << x . first // string (key) << ':' << x . second // string's value << std :: endl ; } \u4f7f\u7528 Structured binding for ( auto const & [ key , val ] : symbolTable ) { std :: cout << key // string (key) << ':' << val // string's value << std :: endl ; }","title":"\u4f7f\u7528type inference"},{"location":"C++/Library/STL/Containers-library/Map/Operation/#iterating-over-the-map-using-stdfor_each-and-lambda-function","text":"#include <iostream> #include <map> #include <string> #include <iterator> #include <algorithm> int main () { std :: map < std :: string , int > mapOfWordCount ; // Insert Element in map mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"first\" , 1 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"second\" , 2 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"third\" , 3 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"third\" , 4 )); mapOfWordCount . insert ( std :: pair < std :: string , int > ( \"third\" , 5 )); // Create a map iterator and point to beginning of map std :: map < std :: string , int >:: iterator it = mapOfWordCount . begin (); // Iterate over a map using std::for_each and Lambda function std :: for_each ( mapOfWordCount . begin (), mapOfWordCount . end (), []( std :: pair < std :: string , int > element ){ // Accessing KEY from element std :: string word = element . first ; // Accessing VALUE from element. int count = element . second ; std :: cout << word << \" :: \" << count << std :: endl ; }); return 0 ; } \u8fd9\u79cd\u5199\u6cd5\u6709\u4e9b\u7c7b\u4f3c\u4e8e\u51fd\u6570\u5f0f\u7f16\u7a0b\u3002","title":"Iterating over the map using std::for_each and lambda function"},{"location":"C++/Library/STL/Containers-library/Map/Operation/#map","text":"https://www.cnblogs.com/dabaopku/p/3912662.html https://bbs.csdn.net/topics/391899953 https://blog.csdn.net/tieshuxianrezhang/article/details/79221646 https://stackoverflow.com/questions/800955/remove-if-equivalent-for-stdmap https://en.cppreference.com/w/cpp/algorithm/remove http://www.cplusplus.com/forum/general/131917/","title":"\u5220\u9664map\u4e2d\u7b26\u5408\u6761\u4ef6\u7684\u5143\u7d20"},{"location":"C++/Library/STL/Containers-library/Map/Operation/#values-like-python-dict","text":"How to copy all Values from a Map to a Vector in C++ Getting a list of values from a map How to retrieve all keys (or values) from a std::map and put them into a vector?","title":"values like python dict"},{"location":"C++/Library/STL/Iterator-library/Iterator-hierarchy/","text":"graph TD A[iterator]-->B[back_insert_iterator] iterator Input Output Forward Bidirectional Random Access","title":"Iterator-hierarchy"},{"location":"C++/Library/STL/Iterator-library/Iterator-invalidation/","text":"","title":"Iterator-invalidation"},{"location":"C++/Library/STL/Iterator-library/Iterator-library/","text":"Iterator library cppreference Iterator library","title":"Iterator-library"},{"location":"C++/Library/STL/Iterator-library/Iterator-library/#iterator-library","text":"","title":"Iterator library"},{"location":"C++/Library/STL/Iterator-library/Iterator-library/#cppreference-iterator-library","text":"","title":"cppreference Iterator library"},{"location":"C++/Library/STL/Iterator-library/Iterator-primer/","text":"Iterator primer \u4e0b\u9762\u8fd9\u7bc7\u6587\u7ae0\u662f\u6211\u9605\u8bfb\u8fc7\u7684\u5173\u4e8ec++ iterator\u4ecb\u7ecd\u5730\u6bd4\u8f83\u597d\u7684\u6587\u7ae0\uff0c\u53ef\u4ee5\u4f5c\u4e3ac++ iterator\u7684\u5165\u95e8\u8bfb\u7269\u3002 C++ Iterators This is a quick summary of iterators in the Standard Template Library. For information on defining iterators for new containers, see here . Iterator : a pointer-like object that can be incremented with ++ , dereferenced with * , and compared against another iterator with != . Iterators are generated by STL container member functions, such as begin() and end() . Some containers return iterators that support only the above operations, while others return iterators that can move forward and backward, be compared with < , and so on. The generic algorithms use iterators just as you use pointers in C to get elements from and store elements to various containers. Passing and returning iterators makes the algorithms more generic, because the algorithms will work for any containers, including ones you invent, as long as you define iterators for them more efficient (as discussed here) Some algorithms can work with the minimal iterators, others may require the extra features. So a certain algorithm may require certain containers because only those containers can return the necessary kind of iterators. An Example Here's an example call to copy() , an algorithm that we'll use in our examples below: copy ( v . begin (), v . end (), l . begin ()); copy() takes three arguments, all iterators: an iterator pointing to the first location to copy from an iterator pointing one element past to the last location to copy from an iterator pointing to the first location to copy into In this case, v and l are some STL containers and begin() and end() are member functions that return iterators pointing to locations within those containers. Note 1: begin() returns a location you can dereference. end() does not. Dereferencing the end pointer is an error. The end pointer is only to be used to see when you've reached it. Note 2: copy() assumes that the destination already has room for the elements being copied. It would be an error to copy into an empty list or vector. However, this limitation is easily overcome with insert operators . Iterator Classes Iterators are divided into classes. These are not real C++ classes , but simply categories of kind of iterators. Each category specifies the operations the iterator supports. For example, some iterators support incrementing but not decrementing, some support dereferencing for getting data but not for storing data, some support scalar arithmetic, i.e., adding n , and some don't. Each STL container defines what class of iterators it can return. Each algorithm specifies what class of iterators it requires(\u5982\u4f55\u6765\u5b9e\u73b0). The more powerful iterator classes are usually subclasses of the weaker ones, so if an algorithm requires a minimal iterator, it will work just fine with an iterator with more power. NOTE: \u4e0d\u652f\u6301decrement\u7684\u5178\u578b\u4f8b\u5b50\u5c31\u662f\u5355\u5411\u94fe\u8868\u3002 InputIterator InputIterator is a useful but limited class of iterators. If iter is an InputIterator , you can use: ++iter and iter++ to increment it, i.e., advance the pointer to the next element *iter to dereference it, i.e., get the element pointed to == and != to compare it another iterator (typically the \"end\" iterator) All STL containers can return at least this level of iterator. Here's typical code that prints out everything in a vector: vector < int > v ; vector < int >:: iterator iter ; v . push_back ( 1 ); v . push_back ( 2 ); v . push_back ( 3 ); for ( iter = v . begin (); iter != v . end (); iter ++ ) cout << ( * iter ) << endl ; This is called an input iterator because you can only use it to \"read\" data from a container. You can't use it to store data, that is, *iter = 4; is illegal if iter is no more than an input iterator. It will work for the iterator above because vectors return iterators more powerful than just input iterators. But if iter were an istream iterator (discussed shortly), then the above restriction would apply. OutputIterator OutputIterator is another limited class of iterators, basically the opposite of InputIterator . If iter is an OutputIterator , you can use: ++iter and iter++ to increment it, i.e., advance the pointer to the next element *iter = ... to store data in the location pointed to Output iterators are only for storing. If something is no more an output iterator, you can't read from it with *iter , nor can you test it with == and != . It may seem like an iterator you can only write to, not read from, is about as sensible as Barnstable Bear in Pogo who could write but not read what he wrote. But there are two very useful subclasses of OutputIterator : insert operators ostream iterators NOTE: output\u5373\u8f93\u51fa\uff0c\u5373write\uff0c\u6240\u4ee5 OutputIterator \u80fd\u591f\u88ab\u5199;input\u5373\u8f93\u5165\uff0c\u5373read\uff0c\u6240\u4ee5 InputIterator \u80fd\u591f\u88ab\u8bfb\u3002 Insert Iterators Insert iterators let you \"point\" to some location in a container and insert elements. You do this with just dereferencing and assignment: *iter = value; This inserts the value in the place pointed to by the iterator. If you assign again, a new value will be inserted. Whether value goes before or after the previous value depends on what kind of insert operator you've created. Notice that you don't need to increment the iterator. You just keep assigning. You create an insert iterator with one of the following: back_inserter< container > returns an OutputIterator pointing to the end of the container. Output to this iterator gets added to the end of the container, using the container's push_back() operation. front_inserter< container > returns an OutputIterator pointing to the front of the container. Output to this iterator gets added to the front of the container, using the container's push_front() operation. inserter< container, iterator > returns an OutputIterator pointing to the location pointed to by iterator of the container. Output to this iterator gets added to the container from that point forward, using the container's insert() operation. An example of using the insert iterators appears when describing istream iterators . Ostream OutputIterator Ostream iterators let you \"point\" to an output stream and insert elements into it, i.e., write to the output stream. We can construct an ostream iterator from a C++ output stream as follows: ostream_iterator < int > outIter ( cout , \" \" ); ... copy ( v . begin (), v . end (), outIter ); The first line defines outIter to be an ostream iterator for integers. The \" \" means \"put a space between each integer.\" If we'd said \"\\n\" then outIter would put a newline between each integer. The second line uses the generic algorithm copy() to copy our vector v from beginning to end to cout . Note how much simpler this is than the equivalent for loop with cout and << . NOTE:\u5f80\u8f93\u51fa\u6d41\u4e2d\u5199 Istream InputIterator Istream iterators for input streams work similarly to ostream iterators. Istream iterators are InputIterators . The following code fragment constructs an istream iterator that reads integers from cin and copies them into a vector v . We use a back_inserter to add the elements to the end of the vector, which could be empty: copy ( istream_iterator < int > ( cin ), istream_iterator < int > (), back_inserter ( v ) ); The first argument to copy calls an istream iterator constructor that simply points to the input stream cin . The second argument calls a special constructor that creates a pointer to \"the end of the input.\" What this actually means, especially for terminal input, depends on your operating system. So the above says \"copy from the current item in the input sream to the end of the input stream into the container v.\" NOTE:\u4ece\u8f93\u5165\u6d41\u4e2d\u8bfb ForwardIterator ForwardIterator combines InputIterator and OutputIterator . You can use them to read and write to a container. They also support: saving and reusing A trivial example of this is iterSaved = iter ; iter ++ ; cout << \"Previous element is \" << ( * iterSaved ) << endl ; cout << \"Current element is \" << ( * iter ) << endl ; This will work if the iterators are ForwardIterator 's. Note that it can't work for InputIterator 's and OutputIterator 's, such as istream and ostream iterators. I/O streams such as standard input and output don't support backing up and starting over\uff08\u91cd\u65b0\u542f\u52a8\uff09. Note: A saved iterator is only valid if the underlying container is not modified. If you insert elements or otherwise change the container, using a saved iterator will have undefined behavior. BidirectionalIterator If iter is a BidirectionalIterator , you can use: all ForwardIterator operations --iter and iter-- to decrement it, i.e., advance the pointer to the previous element RandomAccessIterator If iter1 and iter2 are RandomAccessIterator 's, you can use: all BidirectionalIterator operations standard pointer arithmetic, i.e., iter + n , iter - n , iter += n , iter -= n , and iter1 - iter2 (but not iter1 + iter2 ) all comparisons, i.e., iter1 > iter2 , iter1 < iter2 , iter1 >= iter2 , and iter1 <= iter2 Since BidirectionalIterator 's support ++ and --, don't they support these operations too? The answer is that RandomAccessIterator 's support these operations in constant time . That is, you can jump N elements in the same time it takes to jump 1 element. So an STL list container can return a BidirectionalIterator , but not a RandomAccessIterator . Vectors and deques can return RandomAccessIterator 's. Why Iterators Make Code General and Efficient There are two rules for making container-based code general and efficient: Never pass containers into a function. Pass iterators instead. Never return containers. Return -- or pass -- iterators instead. Generality Suppose we wanted to define product() to multiply together the numbers in a container. We can immediately reject any definition like this: double product( vector<double> v ) ... because it's not general; it only works for vectors inefficient; it copies the container But we could define it like this: template < class Container > double product ( const Container & container ) { Container :: iterator i = container . begin (); double prod = 1 ; while ( i != container . end () ) prod *= * i ++ ; return prod ; } This definition seems general. It works for any STL container, e.g., vector < double > nums ; ... return product ( nums ); Unfortunately, it won't work with regular arrays, e.g., double nums [] = { 1.2 , 3.0 , 3.5 , 2.8 }; return product ( nums ); because there are no begin() or end() methods for regular C-style arrays. Furthermore, it doesn't let us calculate the product of a subrange of the container. The following definition is clearly more general: template < class Iter > double product ( Iter start , Iter stop ) { double prod = 1 ; while ( start != stop ) prod *= * start ++ ; return prod ; } This works fine with regular arrays: double nums [] = { 1.2 , 3.0 , 3.5 , 2.8 }; return product ( nums , nums + 4 ); as well as with STL containers and subranges. Efficiency Both definitions of product() above are efficient. Neither copies the container involved. But consider a function -- let's call it generate() -- that has to generate multiple answers. There are two common situations: There's a container of objects and generate() is supposed to return certain ones, e.g., all the odd numbers in the container. There is no container. generate() is supposed to generate new objects, e.g., all the prime numbers less than N. The obvious way to define generate() is like this: template < class Container > Container generate () { Container temp ; ... return temp ; } We would call generate() like this: vector < int > v = generate < vector < int > > ( ... ); but this has two bad properties: It's ugly to write calls to generate() generate() creates a container which then has to be copied and returned If the container already exists and generate() is returning a subset of the elements in it, e.g., all the odd numbers, then the thing to do is to pass generate() iterators pointing to the start and end, as usual, and have generate() return an iterator pointing to the first answer, if any, else the end iterator The template for this kind of definition is simple: template < class Iter > Iter generate ( Iter start , Iter stop ) { Iter temp ; ... set temp to first answer ... return temp ; } The following loop would then get the answers and print or store them, as desired: vector<int> nums; ... vector<int>::iterator ans = generate( nums.begin(), nums.end() ); while ( ans != nums.end() ) { process ans ans = generate( ans, nums.end() ); } If the container does not exist , you have to be a little smarter. In particular, both of the following are very bad (and won't even compile without some more work): template <class Container> Container & generate() { Container temp; ... return temp; } template <class Container> Container::iterator generate() { Container temp; ... return temp.begin(); } Both of these return references to temp which no longer exists when generate() exits. The following is better template <class Container> Container * generate() { Container *temp = new Container(); ... return temp; } but now we're dealing with pointers and we have to guarantee that the container that generate() dynamically allocates gets deallocated by some other piece of code. Otherwise, we have a bad memory leak. Avoid code that allocates memory in one place and deallocates it in another. The clever way to solve this problem is to do this: template <class Iter> void generate( Iter iter ) { ... *iter++ = ...; ... } In other words, don't have any container in generate() at all. Just pass generate() an iterator to store answers in. As before, what container to use (if any) is up to the calling code. Two ways we could call generate() are: generate( back_inserter( v ) ); // stores answers in v generate( ostream_iterator<type>( cout, \"\\n\" ) ); //print answers As before, by using iterators, we have made generate() far more useful and general and efficient than any version that takes or returns containers. Warning : generate() has to be a template function for this to work. If generate() is actually a member function of some class, then generate() has to be a template member function . Older compilers (and some current ones, alas) have poor support for template member functions.","title":"Iterator-primer"},{"location":"C++/Library/STL/Iterator-library/Iterator-primer/#iterator-primer","text":"\u4e0b\u9762\u8fd9\u7bc7\u6587\u7ae0\u662f\u6211\u9605\u8bfb\u8fc7\u7684\u5173\u4e8ec++ iterator\u4ecb\u7ecd\u5730\u6bd4\u8f83\u597d\u7684\u6587\u7ae0\uff0c\u53ef\u4ee5\u4f5c\u4e3ac++ iterator\u7684\u5165\u95e8\u8bfb\u7269\u3002","title":"Iterator primer"},{"location":"C++/Library/STL/Iterator-library/Iterator-primer/#c-iterators","text":"This is a quick summary of iterators in the Standard Template Library. For information on defining iterators for new containers, see here . Iterator : a pointer-like object that can be incremented with ++ , dereferenced with * , and compared against another iterator with != . Iterators are generated by STL container member functions, such as begin() and end() . Some containers return iterators that support only the above operations, while others return iterators that can move forward and backward, be compared with < , and so on. The generic algorithms use iterators just as you use pointers in C to get elements from and store elements to various containers. Passing and returning iterators makes the algorithms more generic, because the algorithms will work for any containers, including ones you invent, as long as you define iterators for them more efficient (as discussed here) Some algorithms can work with the minimal iterators, others may require the extra features. So a certain algorithm may require certain containers because only those containers can return the necessary kind of iterators.","title":"C++ Iterators"},{"location":"C++/Library/STL/Iterator-library/Iterator-primer/#an-example","text":"Here's an example call to copy() , an algorithm that we'll use in our examples below: copy ( v . begin (), v . end (), l . begin ()); copy() takes three arguments, all iterators: an iterator pointing to the first location to copy from an iterator pointing one element past to the last location to copy from an iterator pointing to the first location to copy into In this case, v and l are some STL containers and begin() and end() are member functions that return iterators pointing to locations within those containers. Note 1: begin() returns a location you can dereference. end() does not. Dereferencing the end pointer is an error. The end pointer is only to be used to see when you've reached it. Note 2: copy() assumes that the destination already has room for the elements being copied. It would be an error to copy into an empty list or vector. However, this limitation is easily overcome with insert operators .","title":"An Example"},{"location":"C++/Library/STL/Iterator-library/Iterator-primer/#iterator-classes","text":"Iterators are divided into classes. These are not real C++ classes , but simply categories of kind of iterators. Each category specifies the operations the iterator supports. For example, some iterators support incrementing but not decrementing, some support dereferencing for getting data but not for storing data, some support scalar arithmetic, i.e., adding n , and some don't. Each STL container defines what class of iterators it can return. Each algorithm specifies what class of iterators it requires(\u5982\u4f55\u6765\u5b9e\u73b0). The more powerful iterator classes are usually subclasses of the weaker ones, so if an algorithm requires a minimal iterator, it will work just fine with an iterator with more power. NOTE: \u4e0d\u652f\u6301decrement\u7684\u5178\u578b\u4f8b\u5b50\u5c31\u662f\u5355\u5411\u94fe\u8868\u3002","title":"Iterator Classes"},{"location":"C++/Library/STL/Iterator-library/Iterator-primer/#inputiterator","text":"InputIterator is a useful but limited class of iterators. If iter is an InputIterator , you can use: ++iter and iter++ to increment it, i.e., advance the pointer to the next element *iter to dereference it, i.e., get the element pointed to == and != to compare it another iterator (typically the \"end\" iterator) All STL containers can return at least this level of iterator. Here's typical code that prints out everything in a vector: vector < int > v ; vector < int >:: iterator iter ; v . push_back ( 1 ); v . push_back ( 2 ); v . push_back ( 3 ); for ( iter = v . begin (); iter != v . end (); iter ++ ) cout << ( * iter ) << endl ; This is called an input iterator because you can only use it to \"read\" data from a container. You can't use it to store data, that is, *iter = 4; is illegal if iter is no more than an input iterator. It will work for the iterator above because vectors return iterators more powerful than just input iterators. But if iter were an istream iterator (discussed shortly), then the above restriction would apply.","title":"InputIterator"},{"location":"C++/Library/STL/Iterator-library/Iterator-primer/#outputiterator","text":"OutputIterator is another limited class of iterators, basically the opposite of InputIterator . If iter is an OutputIterator , you can use: ++iter and iter++ to increment it, i.e., advance the pointer to the next element *iter = ... to store data in the location pointed to Output iterators are only for storing. If something is no more an output iterator, you can't read from it with *iter , nor can you test it with == and != . It may seem like an iterator you can only write to, not read from, is about as sensible as Barnstable Bear in Pogo who could write but not read what he wrote. But there are two very useful subclasses of OutputIterator : insert operators ostream iterators NOTE: output\u5373\u8f93\u51fa\uff0c\u5373write\uff0c\u6240\u4ee5 OutputIterator \u80fd\u591f\u88ab\u5199;input\u5373\u8f93\u5165\uff0c\u5373read\uff0c\u6240\u4ee5 InputIterator \u80fd\u591f\u88ab\u8bfb\u3002","title":"OutputIterator"},{"location":"C++/Library/STL/Iterator-library/Iterator-primer/#insert-iterators","text":"Insert iterators let you \"point\" to some location in a container and insert elements. You do this with just dereferencing and assignment: *iter = value; This inserts the value in the place pointed to by the iterator. If you assign again, a new value will be inserted. Whether value goes before or after the previous value depends on what kind of insert operator you've created. Notice that you don't need to increment the iterator. You just keep assigning. You create an insert iterator with one of the following: back_inserter< container > returns an OutputIterator pointing to the end of the container. Output to this iterator gets added to the end of the container, using the container's push_back() operation. front_inserter< container > returns an OutputIterator pointing to the front of the container. Output to this iterator gets added to the front of the container, using the container's push_front() operation. inserter< container, iterator > returns an OutputIterator pointing to the location pointed to by iterator of the container. Output to this iterator gets added to the container from that point forward, using the container's insert() operation. An example of using the insert iterators appears when describing istream iterators .","title":"Insert Iterators"},{"location":"C++/Library/STL/Iterator-library/Iterator-primer/#ostream-outputiterator","text":"Ostream iterators let you \"point\" to an output stream and insert elements into it, i.e., write to the output stream. We can construct an ostream iterator from a C++ output stream as follows: ostream_iterator < int > outIter ( cout , \" \" ); ... copy ( v . begin (), v . end (), outIter ); The first line defines outIter to be an ostream iterator for integers. The \" \" means \"put a space between each integer.\" If we'd said \"\\n\" then outIter would put a newline between each integer. The second line uses the generic algorithm copy() to copy our vector v from beginning to end to cout . Note how much simpler this is than the equivalent for loop with cout and << . NOTE:\u5f80\u8f93\u51fa\u6d41\u4e2d\u5199","title":"Ostream OutputIterator"},{"location":"C++/Library/STL/Iterator-library/Iterator-primer/#istream-inputiterator","text":"Istream iterators for input streams work similarly to ostream iterators. Istream iterators are InputIterators . The following code fragment constructs an istream iterator that reads integers from cin and copies them into a vector v . We use a back_inserter to add the elements to the end of the vector, which could be empty: copy ( istream_iterator < int > ( cin ), istream_iterator < int > (), back_inserter ( v ) ); The first argument to copy calls an istream iterator constructor that simply points to the input stream cin . The second argument calls a special constructor that creates a pointer to \"the end of the input.\" What this actually means, especially for terminal input, depends on your operating system. So the above says \"copy from the current item in the input sream to the end of the input stream into the container v.\" NOTE:\u4ece\u8f93\u5165\u6d41\u4e2d\u8bfb","title":"Istream InputIterator"},{"location":"C++/Library/STL/Iterator-library/Iterator-primer/#forwarditerator","text":"ForwardIterator combines InputIterator and OutputIterator . You can use them to read and write to a container. They also support: saving and reusing A trivial example of this is iterSaved = iter ; iter ++ ; cout << \"Previous element is \" << ( * iterSaved ) << endl ; cout << \"Current element is \" << ( * iter ) << endl ; This will work if the iterators are ForwardIterator 's. Note that it can't work for InputIterator 's and OutputIterator 's, such as istream and ostream iterators. I/O streams such as standard input and output don't support backing up and starting over\uff08\u91cd\u65b0\u542f\u52a8\uff09. Note: A saved iterator is only valid if the underlying container is not modified. If you insert elements or otherwise change the container, using a saved iterator will have undefined behavior.","title":"ForwardIterator"},{"location":"C++/Library/STL/Iterator-library/Iterator-primer/#bidirectionaliterator","text":"If iter is a BidirectionalIterator , you can use: all ForwardIterator operations --iter and iter-- to decrement it, i.e., advance the pointer to the previous element","title":"BidirectionalIterator"},{"location":"C++/Library/STL/Iterator-library/Iterator-primer/#randomaccessiterator","text":"If iter1 and iter2 are RandomAccessIterator 's, you can use: all BidirectionalIterator operations standard pointer arithmetic, i.e., iter + n , iter - n , iter += n , iter -= n , and iter1 - iter2 (but not iter1 + iter2 ) all comparisons, i.e., iter1 > iter2 , iter1 < iter2 , iter1 >= iter2 , and iter1 <= iter2 Since BidirectionalIterator 's support ++ and --, don't they support these operations too? The answer is that RandomAccessIterator 's support these operations in constant time . That is, you can jump N elements in the same time it takes to jump 1 element. So an STL list container can return a BidirectionalIterator , but not a RandomAccessIterator . Vectors and deques can return RandomAccessIterator 's.","title":"RandomAccessIterator"},{"location":"C++/Library/STL/Iterator-library/Iterator-primer/#why-iterators-make-code-general-and-efficient","text":"There are two rules for making container-based code general and efficient: Never pass containers into a function. Pass iterators instead. Never return containers. Return -- or pass -- iterators instead.","title":"Why Iterators Make Code General and Efficient"},{"location":"C++/Library/STL/Iterator-library/Iterator-primer/#generality","text":"Suppose we wanted to define product() to multiply together the numbers in a container. We can immediately reject any definition like this: double product( vector<double> v ) ... because it's not general; it only works for vectors inefficient; it copies the container But we could define it like this: template < class Container > double product ( const Container & container ) { Container :: iterator i = container . begin (); double prod = 1 ; while ( i != container . end () ) prod *= * i ++ ; return prod ; } This definition seems general. It works for any STL container, e.g., vector < double > nums ; ... return product ( nums ); Unfortunately, it won't work with regular arrays, e.g., double nums [] = { 1.2 , 3.0 , 3.5 , 2.8 }; return product ( nums ); because there are no begin() or end() methods for regular C-style arrays. Furthermore, it doesn't let us calculate the product of a subrange of the container. The following definition is clearly more general: template < class Iter > double product ( Iter start , Iter stop ) { double prod = 1 ; while ( start != stop ) prod *= * start ++ ; return prod ; } This works fine with regular arrays: double nums [] = { 1.2 , 3.0 , 3.5 , 2.8 }; return product ( nums , nums + 4 ); as well as with STL containers and subranges.","title":"Generality"},{"location":"C++/Library/STL/Iterator-library/Iterator-primer/#efficiency","text":"Both definitions of product() above are efficient. Neither copies the container involved. But consider a function -- let's call it generate() -- that has to generate multiple answers. There are two common situations: There's a container of objects and generate() is supposed to return certain ones, e.g., all the odd numbers in the container. There is no container. generate() is supposed to generate new objects, e.g., all the prime numbers less than N. The obvious way to define generate() is like this: template < class Container > Container generate () { Container temp ; ... return temp ; } We would call generate() like this: vector < int > v = generate < vector < int > > ( ... ); but this has two bad properties: It's ugly to write calls to generate() generate() creates a container which then has to be copied and returned If the container already exists and generate() is returning a subset of the elements in it, e.g., all the odd numbers, then the thing to do is to pass generate() iterators pointing to the start and end, as usual, and have generate() return an iterator pointing to the first answer, if any, else the end iterator The template for this kind of definition is simple: template < class Iter > Iter generate ( Iter start , Iter stop ) { Iter temp ; ... set temp to first answer ... return temp ; } The following loop would then get the answers and print or store them, as desired: vector<int> nums; ... vector<int>::iterator ans = generate( nums.begin(), nums.end() ); while ( ans != nums.end() ) { process ans ans = generate( ans, nums.end() ); } If the container does not exist , you have to be a little smarter. In particular, both of the following are very bad (and won't even compile without some more work): template <class Container> Container & generate() { Container temp; ... return temp; } template <class Container> Container::iterator generate() { Container temp; ... return temp.begin(); } Both of these return references to temp which no longer exists when generate() exits. The following is better template <class Container> Container * generate() { Container *temp = new Container(); ... return temp; } but now we're dealing with pointers and we have to guarantee that the container that generate() dynamically allocates gets deallocated by some other piece of code. Otherwise, we have a bad memory leak. Avoid code that allocates memory in one place and deallocates it in another. The clever way to solve this problem is to do this: template <class Iter> void generate( Iter iter ) { ... *iter++ = ...; ... } In other words, don't have any container in generate() at all. Just pass generate() an iterator to store answers in. As before, what container to use (if any) is up to the calling code. Two ways we could call generate() are: generate( back_inserter( v ) ); // stores answers in v generate( ostream_iterator<type>( cout, \"\\n\" ) ); //print answers As before, by using iterators, we have made generate() far more useful and general and efficient than any version that takes or returns containers. Warning : generate() has to be a template function for this to work. If generate() is actually a member function of some class, then generate() has to be a template member function . Older compilers (and some current ones, alas) have poor support for template member functions.","title":"Efficiency"},{"location":"C++/Library/STL/Iterator-library/cpp-zip/","text":"Sequence-zip function for c++11? A So I wrote this zip before when I was bored, I decided to post it because it's different than the others in that it doesn't use boost and looks more like the c++ stdlib. template < typename Iterator > void advance_all ( Iterator & iterator ) { ++ iterator ; } template < typename Iterator , typename ... Iterators > void advance_all ( Iterator & iterator , Iterators & ... iterators ) { ++ iterator ; advance_all ( iterators ...); } template < typename Function , typename Iterator , typename ... Iterators > Function zip ( Function func , Iterator begin , Iterator end , Iterators ... iterators ) { for (; begin != end ; ++ begin , advance_all ( iterators ...)) func ( * begin , * ( iterators )... ); //could also make this a tuple return func ; } Example use: int main () { std :: vector < int > v1 { 1 , 2 , 3 }; std :: vector < int > v2 { 3 , 2 , 1 }; std :: vector < float > v3 { 1.2 , 2.4 , 9.0 }; std :: vector < float > v4 { 1.2 , 2.4 , 9.0 }; zip ( []( int i , int j , float k , float l ){ std :: cout << i << \" \" << j << \" \" << k << \" \" << l << std :: endl ; }, v1 . begin (), v1 . end (), v2 . begin (), v3 . begin (), v4 . begin ()); } A If you like operator overloading, here are three possibilities. The first two are using std::pair<> and std::tuple<> , respectively, as iterators; the third extends this to range-based for . Note that not everyone will like these definitions of the operators, so it's best to keep them in a separate namespace and have a using namespace in the functions (not files!) where you'd like to use these. #include <iostream> #include <utility> #include <vector> #include <tuple> // put these in namespaces so we don't pollute global namespace pair_iterators { template < typename T1 , typename T2 > std :: pair < T1 , T2 > operator ++ ( std :: pair < T1 , T2 >& it ) { ++ it . first ; ++ it . second ; return it ; } } namespace tuple_iterators { // you might want to make this generic (via param pack) template < typename T1 , typename T2 , typename T3 > auto operator ++ ( std :: tuple < T1 , T2 , T3 >& it ) { ++ ( std :: get < 0 > ( it ) ); ++ ( std :: get < 1 > ( it ) ); ++ ( std :: get < 2 > ( it ) ); return it ; } template < typename T1 , typename T2 , typename T3 > auto operator * ( const std :: tuple < T1 , T2 , T3 >& it ) { return std :: tie ( * ( std :: get < 0 > ( it ) ), * ( std :: get < 1 > ( it ) ), * ( std :: get < 2 > ( it ) ) ); } // needed due to ADL-only lookup template < typename ... Args > struct tuple_c { std :: tuple < Args ... > containers ; }; template < typename ... Args > auto tie_c ( const Args & ... args ) { tuple_c < Args ... > ret = { std :: tie ( args ...) }; return ret ; } template < typename T1 , typename T2 , typename T3 > auto begin ( const tuple_c < T1 , T2 , T3 >& c ) { return std :: make_tuple ( std :: get < 0 > ( c . containers ). begin (), std :: get < 1 > ( c . containers ). begin (), std :: get < 2 > ( c . containers ). begin () ); } template < typename T1 , typename T2 , typename T3 > auto end ( const tuple_c < T1 , T2 , T3 >& c ) { return std :: make_tuple ( std :: get < 0 > ( c . containers ). end (), std :: get < 1 > ( c . containers ). end (), std :: get < 2 > ( c . containers ). end () ); } // implement cbegin(), cend() as needed } int main () { using namespace pair_iterators ; using namespace tuple_iterators ; std :: vector < double > ds = { 0.0 , 0.1 , 0.2 }; std :: vector < int > is = { 1 , 2 , 3 }; std :: vector < char > cs = { 'a' , 'b' , 'c' }; // classical, iterator-style using pairs for ( auto its = std :: make_pair ( ds . begin (), is . begin ()), end = std :: make_pair ( ds . end (), is . end () ); its != end ; ++ its ) { std :: cout << \"1. \" << * ( its . first ) + * ( its . second ) << \" \" << std :: endl ; } // classical, iterator-style using tuples for ( auto its = std :: make_tuple ( ds . begin (), is . begin (), cs . begin ()), end = std :: make_tuple ( ds . end (), is . end (), cs . end () ); its != end ; ++ its ) { std :: cout << \"2. \" << * ( std :: get < 0 > ( its )) + * ( std :: get < 1 > ( its )) << \" \" << * ( std :: get < 2 > ( its )) << \" \" << std :: endl ; } // range for using tuples for ( const auto & d_i_c : tie_c ( ds , is , cs ) ) { std :: cout << \"3. \" << std :: get < 0 > ( d_i_c ) + std :: get < 1 > ( d_i_c ) << \" \" << std :: get < 2 > ( d_i_c ) << \" \" << std :: endl ; } } #include <iostream> #include <utility> #include <vector> #include <tuple> namespace tuple_iterators { // you might want to make this generic (via param pack) template < typename ... Args > auto operator ++ ( std :: tuple < Args ... >& it ) { int size = std :: tuple_size < std :: tuple < Args ... > >:: value ; for ( int i = 0 ; i < size ; ++ i ){ ++ ( std :: get < i > ( it ) ); } return it ; } } int main () { using namespace tuple_iterators ; std :: vector < double > ds = { 0.0 , 0.1 , 0.2 }; std :: vector < int > is = { 1 , 2 , 3 }; std :: vector < char > cs = { 'a' , 'b' , 'c' }; // classical, iterator-style using tuples for ( auto its = std :: make_tuple ( ds . begin (), is . begin (), cs . begin ()), end = std :: make_tuple ( ds . end (), is . end (), cs . end () ); its != end ; ++ its ) { std :: cout << \"2. \" << * ( std :: get < 0 > ( its )) + * ( std :: get < 1 > ( its )) << \" \" << * ( std :: get < 2 > ( its )) << \" \" << std :: endl ; } }","title":"[Sequence-zip function for c++11?](https://stackoverflow.com/questions/8511035/sequence-zip-function-for-c11)"},{"location":"C++/Library/STL/Iterator-library/cpp-zip/#sequence-zip-function-for-c11","text":"","title":"Sequence-zip function for c++11?"},{"location":"C++/Library/STL/Iterator-library/cpp-zip/#a","text":"So I wrote this zip before when I was bored, I decided to post it because it's different than the others in that it doesn't use boost and looks more like the c++ stdlib. template < typename Iterator > void advance_all ( Iterator & iterator ) { ++ iterator ; } template < typename Iterator , typename ... Iterators > void advance_all ( Iterator & iterator , Iterators & ... iterators ) { ++ iterator ; advance_all ( iterators ...); } template < typename Function , typename Iterator , typename ... Iterators > Function zip ( Function func , Iterator begin , Iterator end , Iterators ... iterators ) { for (; begin != end ; ++ begin , advance_all ( iterators ...)) func ( * begin , * ( iterators )... ); //could also make this a tuple return func ; } Example use: int main () { std :: vector < int > v1 { 1 , 2 , 3 }; std :: vector < int > v2 { 3 , 2 , 1 }; std :: vector < float > v3 { 1.2 , 2.4 , 9.0 }; std :: vector < float > v4 { 1.2 , 2.4 , 9.0 }; zip ( []( int i , int j , float k , float l ){ std :: cout << i << \" \" << j << \" \" << k << \" \" << l << std :: endl ; }, v1 . begin (), v1 . end (), v2 . begin (), v3 . begin (), v4 . begin ()); }","title":"A"},{"location":"C++/Library/STL/Iterator-library/cpp-zip/#a_1","text":"If you like operator overloading, here are three possibilities. The first two are using std::pair<> and std::tuple<> , respectively, as iterators; the third extends this to range-based for . Note that not everyone will like these definitions of the operators, so it's best to keep them in a separate namespace and have a using namespace in the functions (not files!) where you'd like to use these. #include <iostream> #include <utility> #include <vector> #include <tuple> // put these in namespaces so we don't pollute global namespace pair_iterators { template < typename T1 , typename T2 > std :: pair < T1 , T2 > operator ++ ( std :: pair < T1 , T2 >& it ) { ++ it . first ; ++ it . second ; return it ; } } namespace tuple_iterators { // you might want to make this generic (via param pack) template < typename T1 , typename T2 , typename T3 > auto operator ++ ( std :: tuple < T1 , T2 , T3 >& it ) { ++ ( std :: get < 0 > ( it ) ); ++ ( std :: get < 1 > ( it ) ); ++ ( std :: get < 2 > ( it ) ); return it ; } template < typename T1 , typename T2 , typename T3 > auto operator * ( const std :: tuple < T1 , T2 , T3 >& it ) { return std :: tie ( * ( std :: get < 0 > ( it ) ), * ( std :: get < 1 > ( it ) ), * ( std :: get < 2 > ( it ) ) ); } // needed due to ADL-only lookup template < typename ... Args > struct tuple_c { std :: tuple < Args ... > containers ; }; template < typename ... Args > auto tie_c ( const Args & ... args ) { tuple_c < Args ... > ret = { std :: tie ( args ...) }; return ret ; } template < typename T1 , typename T2 , typename T3 > auto begin ( const tuple_c < T1 , T2 , T3 >& c ) { return std :: make_tuple ( std :: get < 0 > ( c . containers ). begin (), std :: get < 1 > ( c . containers ). begin (), std :: get < 2 > ( c . containers ). begin () ); } template < typename T1 , typename T2 , typename T3 > auto end ( const tuple_c < T1 , T2 , T3 >& c ) { return std :: make_tuple ( std :: get < 0 > ( c . containers ). end (), std :: get < 1 > ( c . containers ). end (), std :: get < 2 > ( c . containers ). end () ); } // implement cbegin(), cend() as needed } int main () { using namespace pair_iterators ; using namespace tuple_iterators ; std :: vector < double > ds = { 0.0 , 0.1 , 0.2 }; std :: vector < int > is = { 1 , 2 , 3 }; std :: vector < char > cs = { 'a' , 'b' , 'c' }; // classical, iterator-style using pairs for ( auto its = std :: make_pair ( ds . begin (), is . begin ()), end = std :: make_pair ( ds . end (), is . end () ); its != end ; ++ its ) { std :: cout << \"1. \" << * ( its . first ) + * ( its . second ) << \" \" << std :: endl ; } // classical, iterator-style using tuples for ( auto its = std :: make_tuple ( ds . begin (), is . begin (), cs . begin ()), end = std :: make_tuple ( ds . end (), is . end (), cs . end () ); its != end ; ++ its ) { std :: cout << \"2. \" << * ( std :: get < 0 > ( its )) + * ( std :: get < 1 > ( its )) << \" \" << * ( std :: get < 2 > ( its )) << \" \" << std :: endl ; } // range for using tuples for ( const auto & d_i_c : tie_c ( ds , is , cs ) ) { std :: cout << \"3. \" << std :: get < 0 > ( d_i_c ) + std :: get < 1 > ( d_i_c ) << \" \" << std :: get < 2 > ( d_i_c ) << \" \" << std :: endl ; } } #include <iostream> #include <utility> #include <vector> #include <tuple> namespace tuple_iterators { // you might want to make this generic (via param pack) template < typename ... Args > auto operator ++ ( std :: tuple < Args ... >& it ) { int size = std :: tuple_size < std :: tuple < Args ... > >:: value ; for ( int i = 0 ; i < size ; ++ i ){ ++ ( std :: get < i > ( it ) ); } return it ; } } int main () { using namespace tuple_iterators ; std :: vector < double > ds = { 0.0 , 0.1 , 0.2 }; std :: vector < int > is = { 1 , 2 , 3 }; std :: vector < char > cs = { 'a' , 'b' , 'c' }; // classical, iterator-style using tuples for ( auto its = std :: make_tuple ( ds . begin (), is . begin (), cs . begin ()), end = std :: make_tuple ( ds . end (), is . end (), cs . end () ); its != end ; ++ its ) { std :: cout << \"2. \" << * ( std :: get < 0 > ( its )) + * ( std :: get < 1 > ( its )) << \" \" << * ( std :: get < 2 > ( its )) << \" \" << std :: endl ; } }","title":"A"},{"location":"C++/Pattern/","text":"\u5173\u4e8e\u672c\u7ae0 \u53c2\u8003\u5185\u5bb9\uff1a \u7f51\u7ad9 c++patterns","title":"Introduction"},{"location":"C++/Pattern/#_1","text":"\u53c2\u8003\u5185\u5bb9\uff1a \u7f51\u7ad9 c++patterns","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"C++/Stype-guide/Cpp-stype-guide/","text":"Google C++ Style Guide","title":"Cpp-stype-guide"},{"location":"C++/Stype-guide/Cpp-stype-guide/#google-c-style-guide","text":"","title":"Google C++ Style Guide"},{"location":"Eiffel/Eiffel/","text":"Eiffel \u5728 LLVM \u4e2d\u63d0\u53ca\uff0c\u201cLLVM has been awarded the 2012 ACM Software System Award !\u201d\uff0c\u4e8e\u662f\u6211\u67e5\u770b\u4e86 ACM Software System Award \uff0c\u65e0\u610f\u4e2d\u53d1\u73b02006\u5e74\uff0c\u8be5\u5956\u6388\u4e88\u7ed9\u4e86 Bertrand Meyer For designing and developing the Eiffel programming language, method and environment, embodying the Design by Contract approach to software development and other features that facilitate the construction of reliable, extendible and efficient software. \u4e8e\u662f\u6211\u53d1\u73b0\u4e86\u8fd9\u95e8\u8bed\u8a00\u3002 \u7ef4\u57fa\u767e\u79d1 Eiffel (programming language) Eiffel","title":"Eiffel"},{"location":"Eiffel/Eiffel/#eiffel","text":"\u5728 LLVM \u4e2d\u63d0\u53ca\uff0c\u201cLLVM has been awarded the 2012 ACM Software System Award !\u201d\uff0c\u4e8e\u662f\u6211\u67e5\u770b\u4e86 ACM Software System Award \uff0c\u65e0\u610f\u4e2d\u53d1\u73b02006\u5e74\uff0c\u8be5\u5956\u6388\u4e88\u7ed9\u4e86 Bertrand Meyer For designing and developing the Eiffel programming language, method and environment, embodying the Design by Contract approach to software development and other features that facilitate the construction of reliable, extendible and efficient software. \u4e8e\u662f\u6211\u53d1\u73b0\u4e86\u8fd9\u95e8\u8bed\u8a00\u3002","title":"Eiffel"},{"location":"Eiffel/Eiffel/#eiffel-programming-language","text":"","title":"\u7ef4\u57fa\u767e\u79d1Eiffel (programming language)"},{"location":"Eiffel/Eiffel/#eiffel_1","text":"","title":"Eiffel"},{"location":"Java/","text":"","title":"Introduction"},{"location":"JavaScript/","text":"","title":"Introduction"},{"location":"JavaScript/Software/Software-event-driven-programming/Software-node.js/Node.js-About Node.js/","text":"About Node.js\u00ae As an asynchronous event driven JavaScript runtime , Node is designed to build scalable network applications. In the following \"hello world\" example, many connections can be handled concurrently. Upon each connection the callback is fired, but if there is no work to be done, Node will sleep. \u603b\u7ed3\uff1a\u663e\u7136\u5728Node.js\u4e2dNode\u6709\u7740\u7279\u6b8a\u7684\u542b\u4e49\uff0c\u73b0\u5728\u60f3\u6765\u5b83\u7684\u542b\u4e49\u5e94\u8be5\u5c31\u662f\u201c\u8282\u70b9\u201d\u3002\u65e2\u7136Node.js\u662f\u4e00\u4e2a**JavaScript runtime**\uff0c\u5219\u5b83\u5c31\u53ef\u4ee5\u8fd0\u884cJavaScript\u4ee3\u7801\uff0c\u663e\u7136\u5b83\u5c31\u76f8\u5f53\u4e8e\u4e00\u4e2aJavaScript\u7684\u89e3\u91ca\u5668\uff0c\u80fd\u591f\u89e3\u91ca\u6267\u884cJavaScript\u4ee3\u7801\uff0c\u5c31\u597d\u6bd4python\u89e3\u91ca\u5668\u4e00\u822c\u3002\u76ee\u524d\u7684\u8fd9\u7bc7\u6587\u7ae0\u4e3b\u8981\u4ececoncurrency model\u7684\u89d2\u5ea6\u6765\u63cf\u8ff0node.js\uff0c\u6211\u7684\u4e00\u4e2a\u597d\u5947\u662f\uff0c\u50cfVue.js\u8fd9\u6837\u7684\u6846\u67b6\u4e3a\u4f55\u80fd\u591f\u57fa\u4e8enode.js\u800c\u6784\u5efa\u5462\uff1f const http = require ( 'http' ); const hostname = '127.0.0.1' ; const port = 3000 ; const server = http . createServer (( req , res ) => { res . statusCode = 200 ; res . setHeader ( 'Content-Type' , 'text/plain' ); res . end ( 'Hello World\\n' ); }); server . listen ( port , hostname , () => { console . log ( `Server running at http:// ${ hostname } : ${ port } /` ); }); This is in contrast to today's more common concurrency model where OS threads are employed. Thread-based networking is relatively inefficient and very difficult to use. Furthermore, users of Node are free from worries of dead-locking the process, since there are no locks. Almost no function in Node directly performs I/O , so the process never blocks. Because nothing blocks, scalable systems are very reasonable to develop in Node. If some of this language is unfamiliar, there is a full article on Blocking vs Non-Blocking . Node is similar in design to, and influenced by, systems like Ruby's Event Machine or Python's Twisted . Node takes the event model a bit further. It presents an event loop as a runtime construct instead of as a library. In other systems there is always a blocking call to start the event-loop ( \u5728\u5176\u4ed6\u7cfb\u7edf\u4e2d\uff0c\u59cb\u7ec8\u5b58\u5728\u963b\u585e\u8c03\u7528\u4ee5\u542f\u52a8\u4e8b\u4ef6\u5faa\u73af). Typically behavior is defined through callbacks at the beginning of a script and at the end starts a server\uff08\u542f\u52a8\u4e00\u4e2a\u670d\u52a1\u4ee5\u54cd\u5e94\u4e8b\u4ef6\uff09 through a blocking call like EventMachine::run() . In Node there is no such start-the-event-loop call . Node simply enters the event loop after executing the input script. Node exits the event loop when there are no more callbacks to perform. This behavior is like browser JavaScript \u2014 the event loop is hidden from the user. \u601d\u8003\uff1aIt presents an event loop as a runtime construct instead of as a library.\u8fd9\u53e5\u597d\u8981\u5982\u4f55\u6765\u8fdb\u884c\u7406\u89e3\uff1f\u5176\u4e2d\u7684runtime construct\u662f\u8fd0\u884c\u65f6\u6784\u5efa\u7684\u610f\u601d\u3002 \u603b\u7ed3\uff1a\u8fd9\u6bb5\u8bdd\u6982\u62ec\u7684\u63cf\u8ff0\u4e86node.js\u7684event model\u3002 HTTP is a first class citizen in Node, designed with streaming and low latency in mind. This makes Node well suited for the foundation of a web library or framework. Just because Node is designed without threads, doesn't mean you cannot take advantage of multiple cores in your environment. Child processes can be spawned by using our child_process.fork() API, and are designed to be easy to communicate with. Built upon that same interface is the cluster module, which allows you to share sockets between processes to enable load balancing over your cores.","title":"Node.js-About Node.js"},{"location":"JavaScript/Software/Software-event-driven-programming/Software-node.js/Node.js-About Node.js/#about-nodejs","text":"As an asynchronous event driven JavaScript runtime , Node is designed to build scalable network applications. In the following \"hello world\" example, many connections can be handled concurrently. Upon each connection the callback is fired, but if there is no work to be done, Node will sleep. \u603b\u7ed3\uff1a\u663e\u7136\u5728Node.js\u4e2dNode\u6709\u7740\u7279\u6b8a\u7684\u542b\u4e49\uff0c\u73b0\u5728\u60f3\u6765\u5b83\u7684\u542b\u4e49\u5e94\u8be5\u5c31\u662f\u201c\u8282\u70b9\u201d\u3002\u65e2\u7136Node.js\u662f\u4e00\u4e2a**JavaScript runtime**\uff0c\u5219\u5b83\u5c31\u53ef\u4ee5\u8fd0\u884cJavaScript\u4ee3\u7801\uff0c\u663e\u7136\u5b83\u5c31\u76f8\u5f53\u4e8e\u4e00\u4e2aJavaScript\u7684\u89e3\u91ca\u5668\uff0c\u80fd\u591f\u89e3\u91ca\u6267\u884cJavaScript\u4ee3\u7801\uff0c\u5c31\u597d\u6bd4python\u89e3\u91ca\u5668\u4e00\u822c\u3002\u76ee\u524d\u7684\u8fd9\u7bc7\u6587\u7ae0\u4e3b\u8981\u4ececoncurrency model\u7684\u89d2\u5ea6\u6765\u63cf\u8ff0node.js\uff0c\u6211\u7684\u4e00\u4e2a\u597d\u5947\u662f\uff0c\u50cfVue.js\u8fd9\u6837\u7684\u6846\u67b6\u4e3a\u4f55\u80fd\u591f\u57fa\u4e8enode.js\u800c\u6784\u5efa\u5462\uff1f const http = require ( 'http' ); const hostname = '127.0.0.1' ; const port = 3000 ; const server = http . createServer (( req , res ) => { res . statusCode = 200 ; res . setHeader ( 'Content-Type' , 'text/plain' ); res . end ( 'Hello World\\n' ); }); server . listen ( port , hostname , () => { console . log ( `Server running at http:// ${ hostname } : ${ port } /` ); }); This is in contrast to today's more common concurrency model where OS threads are employed. Thread-based networking is relatively inefficient and very difficult to use. Furthermore, users of Node are free from worries of dead-locking the process, since there are no locks. Almost no function in Node directly performs I/O , so the process never blocks. Because nothing blocks, scalable systems are very reasonable to develop in Node. If some of this language is unfamiliar, there is a full article on Blocking vs Non-Blocking . Node is similar in design to, and influenced by, systems like Ruby's Event Machine or Python's Twisted . Node takes the event model a bit further. It presents an event loop as a runtime construct instead of as a library. In other systems there is always a blocking call to start the event-loop ( \u5728\u5176\u4ed6\u7cfb\u7edf\u4e2d\uff0c\u59cb\u7ec8\u5b58\u5728\u963b\u585e\u8c03\u7528\u4ee5\u542f\u52a8\u4e8b\u4ef6\u5faa\u73af). Typically behavior is defined through callbacks at the beginning of a script and at the end starts a server\uff08\u542f\u52a8\u4e00\u4e2a\u670d\u52a1\u4ee5\u54cd\u5e94\u4e8b\u4ef6\uff09 through a blocking call like EventMachine::run() . In Node there is no such start-the-event-loop call . Node simply enters the event loop after executing the input script. Node exits the event loop when there are no more callbacks to perform. This behavior is like browser JavaScript \u2014 the event loop is hidden from the user. \u601d\u8003\uff1aIt presents an event loop as a runtime construct instead of as a library.\u8fd9\u53e5\u597d\u8981\u5982\u4f55\u6765\u8fdb\u884c\u7406\u89e3\uff1f\u5176\u4e2d\u7684runtime construct\u662f\u8fd0\u884c\u65f6\u6784\u5efa\u7684\u610f\u601d\u3002 \u603b\u7ed3\uff1a\u8fd9\u6bb5\u8bdd\u6982\u62ec\u7684\u63cf\u8ff0\u4e86node.js\u7684event model\u3002 HTTP is a first class citizen in Node, designed with streaming and low latency in mind. This makes Node well suited for the foundation of a web library or framework. Just because Node is designed without threads, doesn't mean you cannot take advantage of multiple cores in your environment. Child processes can be spawned by using our child_process.fork() API, and are designed to be easy to communicate with. Built upon that same interface is the cluster module, which allows you to share sockets between processes to enable load balancing over your cores.","title":"About Node.js\u00ae"},{"location":"JavaScript/Software/Software-event-driven-programming/Software-node.js/Node.js-core-concepts/Node.js-How-does-Node.js-manage-timers-internally/","text":"How does Node.js manage timers internally Timers are an essential part in the Javascript developer tool set. The timers API has been with us a long time, dating back to the days when Javascript was limited to the browser. This API provides us with the setTimeout , clearTimeout , setInterval and clearInterval methods which allows us to schedule code for later execution, either once or repeatedly. Thanks to Node.js timer module , these methods (along with a few others, such as setImmediate and clearImmediate ) are also available natively in node code. On top of user code and 3 rd -party libraries using timers, timers are also used internally by the Node.js platform itself. For example, a dedicated timer is used with each TCP connection to detect a possible connection timeout . It\u2019s very possible that Node.js will have to manage a large number of timers , so it\u2019s important that the implementation will be highly efficient. In this post I will look at the way Node.js manages these timers under the hood. SUMMARY : \u5728node.js\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u4e5f\u662f\u9700\u8981timer\u529f\u80fd\u7684\uff1b\u6240\u4ee5node.js\u5185\u90e8\u662f\u9700\u8981\u7ef4\u62a4\u5927\u91cf\u7684timer\u7684\uff1b\u4ee5\u6b64\u7c7b\u63a8\uff0c\u5728OS\u4e2d\uff0c\u4e5f\u662f\u5982\u6b64\uff1b Before tackling the timers implementation, it\u2019s worthwhile to examine Node.js implementation of linked lists; they play a large role in the timers implementation, and have some interesting parts to them as well. Linked Lists The relevant code is quite short, and contain all the methods you\u2019d expect to find in a linked list implementation, such as create , append , remove , peek , shift , isEmpty . Timers Each Timer instance is initialized with msec argument which determines the delay (in millisecond) until timeout. It\u2019s quite intuitive that if we initialized two timers with the same msec argument, then the second timer will timeout either with or after the first. Node.js uses this and organizes the Timers by indexing them according to their msec : all Timers with the same msec value will form a linked list, ordered by creation time (there are actually two indexes, one for refed timers and one for unrefed timers, but we\u2019ll ignore this fact for now. See here to read about the difference). In this example, we initialized 6 timers. T1 , T2 , T3 were initialized with 50 msec, T4 with 10 msec and T5,T6 with 200 msec. Each Timers list is backed up by a TimerWrap , which is a wrapper over a uv_timer_t , a native libuv timer type . Since we know the timers in each list are ordered by non-decreasing timeout, a single TimerWrap is enough, as we can reuse it between timeouts.","title":"Node.js-How-does-Node.js-manage-timers-internally"},{"location":"JavaScript/Software/Software-event-driven-programming/Software-node.js/Node.js-core-concepts/Node.js-How-does-Node.js-manage-timers-internally/#how-does-nodejs-manage-timers-internally","text":"Timers are an essential part in the Javascript developer tool set. The timers API has been with us a long time, dating back to the days when Javascript was limited to the browser. This API provides us with the setTimeout , clearTimeout , setInterval and clearInterval methods which allows us to schedule code for later execution, either once or repeatedly. Thanks to Node.js timer module , these methods (along with a few others, such as setImmediate and clearImmediate ) are also available natively in node code. On top of user code and 3 rd -party libraries using timers, timers are also used internally by the Node.js platform itself. For example, a dedicated timer is used with each TCP connection to detect a possible connection timeout . It\u2019s very possible that Node.js will have to manage a large number of timers , so it\u2019s important that the implementation will be highly efficient. In this post I will look at the way Node.js manages these timers under the hood. SUMMARY : \u5728node.js\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u4e5f\u662f\u9700\u8981timer\u529f\u80fd\u7684\uff1b\u6240\u4ee5node.js\u5185\u90e8\u662f\u9700\u8981\u7ef4\u62a4\u5927\u91cf\u7684timer\u7684\uff1b\u4ee5\u6b64\u7c7b\u63a8\uff0c\u5728OS\u4e2d\uff0c\u4e5f\u662f\u5982\u6b64\uff1b Before tackling the timers implementation, it\u2019s worthwhile to examine Node.js implementation of linked lists; they play a large role in the timers implementation, and have some interesting parts to them as well.","title":"How does Node.js manage timers internally"},{"location":"JavaScript/Software/Software-event-driven-programming/Software-node.js/Node.js-core-concepts/Node.js-How-does-Node.js-manage-timers-internally/#linked-lists","text":"The relevant code is quite short, and contain all the methods you\u2019d expect to find in a linked list implementation, such as create , append , remove , peek , shift , isEmpty .","title":"Linked Lists"},{"location":"JavaScript/Software/Software-event-driven-programming/Software-node.js/Node.js-core-concepts/Node.js-How-does-Node.js-manage-timers-internally/#timers","text":"Each Timer instance is initialized with msec argument which determines the delay (in millisecond) until timeout. It\u2019s quite intuitive that if we initialized two timers with the same msec argument, then the second timer will timeout either with or after the first. Node.js uses this and organizes the Timers by indexing them according to their msec : all Timers with the same msec value will form a linked list, ordered by creation time (there are actually two indexes, one for refed timers and one for unrefed timers, but we\u2019ll ignore this fact for now. See here to read about the difference). In this example, we initialized 6 timers. T1 , T2 , T3 were initialized with 50 msec, T4 with 10 msec and T5,T6 with 200 msec. Each Timers list is backed up by a TimerWrap , which is a wrapper over a uv_timer_t , a native libuv timer type . Since we know the timers in each list are ordered by non-decreasing timeout, a single TimerWrap is enough, as we can reuse it between timeouts.","title":"Timers"},{"location":"JavaScript/Software/Software-event-driven-programming/Software-node.js/Node.js-core-concepts/Node.js-Overview-of-Blocking-vs-Non-Blocking/","text":"Overview of Blocking vs Non-Blocking This overview covers the difference between blocking and non-blocking calls in Node.js. This overview will refer to the event loop and libuv but no prior knowledge of those topics is required. Readers are assumed to have a basic understanding of the JavaScript language and Node.js callback pattern . \"I/O\" refers primarily to interaction with the system's disk and network supported by libuv . Blocking Blocking is when the execution of additional JavaScript in the Node.js process must wait until a non-JavaScript operation completes(\u963b\u585e\u662f\u5728Node.js\u8fdb\u7a0b\u4e2d\u6267\u884cadditional JavaScript\u65f6\uff0c\u5fc5\u987b\u7b49\u5f85\u975eJavaScript\u64cd\u4f5c\u5b8c\u6210). This happens because the event loop is unable to continue running JavaScript while a blocking operation is occurring(\u8fd9\u662f\u56e0\u4e3a\u5728\u53d1\u751f\u963b\u585e\u64cd\u4f5c\u65f6\uff0c**event loop**\u65e0\u6cd5\u7ee7\u7eed\u8fd0\u884cJavaScript). In Node.js, JavaScript that exhibits poor performance due to being CPU intensive (CPU\u5bc6\u96c6\u578b) rather than waiting on a non-JavaScript operation, such as I/O, isn't typically referred to as blocking . Synchronous methods (\u540c\u6b65\u64cd\u4f5c) in the Node.js standard library that use libuv are the most commonly used blocking operations. Native modules may also have blocking methods. All of the I/O methods in the Node.js standard library provide asynchronous versions , which are non-blocking , and accept callback functions . Some methods also have blocking counterparts, which have names that end with Sync . Comparing Code Blocking methods execute synchronously and non-blocking methods execute asynchronously . Using the File System module as an example, this is a synchronous file read: const fs = require ( 'fs' ); const data = fs . readFileSync ( '/file.md' ); // blocks here until file is read And here is an equivalent asynchronous example: const fs = require ( 'fs' ); fs . readFile ( '/file.md' , ( err , data ) => { if ( err ) throw err ; }); The first example appears simpler than the second but has the disadvantage of the second line blocking the execution of any additional JavaScript until the entire file is read. Note that in the synchronous version if an error is thrown it will need to be caught or the process will crash. In the asynchronous version, it is up to the author to decide whether an error should throw as shown. Let's expand our example a little bit: const fs = require ( 'fs' ); const data = fs . readFileSync ( '/file.md' ); // blocks here until file is read console . log ( data ); // moreWork(); will run after console.log And here is a similar, but not equivalent asynchronous example: const fs = require ( 'fs' ); fs . readFile ( '/file.md' , ( err , data ) => { if ( err ) throw err ; console . log ( data ); }); // moreWork(); will run before console.log In the first example above, console.log will be called before moreWork() . In the second example fs.readFile() is non-blocking so JavaScript execution can continue and moreWork() will be called first. The ability to run moreWork() without waiting for the file read to complete is a key design choice that allows for higher throughput(\u541e\u5410\u91cf). Concurrency and Throughput JavaScript execution in Node.js is single threaded, so concurrency refers to the event loop's capacity to execute JavaScript callback functions after completing other work. Any code that is expected to run in a concurrent manner must allow the event loop to continue running as non-JavaScript operations, like I/O, are occurring. As an example, let's consider a case where each request to a web server takes 50ms to complete and 45ms of that 50ms is database I/O that can be done asynchronously. Choosing non-blocking asynchronous operations frees up that 45ms per request to handle other requests. This is a significant difference in capacity just by choosing to use non-blocking methods instead of blocking methods. The event loop is different than models in many other languages where additional threads may be created to handle concurrent work. Dangers of Mixing Blocking and Non-Blocking Code There are some patterns that should be avoided when dealing with I/O. Let's look at an example: const fs = require('fs'); fs.readFile('/file.md', (err, data) => { if (err) throw err; console.log(data); }); fs.unlinkSync('/file.md'); In the above example, fs.unlinkSync() is likely to be run before fs.readFile() , which would delete file.md before it is actually read. A better way to write this that is completely non-blocking and guaranteed to execute in the correct order is: const fs = require('fs'); fs.readFile('/file.md', (readFileErr, data) => { if (readFileErr) throw readFileErr; console.log(data); fs.unlink('/file.md', (unlinkErr) => { if (unlinkErr) throw unlinkErr; }); }); The above places a non-blocking call to fs.unlink() within the callback of fs.readFile() which guarantees the correct order of operations. Additional Resources libuv About Node.js","title":"Node.js-Overview-of-Blocking-vs-Non-Blocking"},{"location":"JavaScript/Software/Software-event-driven-programming/Software-node.js/Node.js-core-concepts/Node.js-Overview-of-Blocking-vs-Non-Blocking/#overview-of-blocking-vs-non-blocking","text":"This overview covers the difference between blocking and non-blocking calls in Node.js. This overview will refer to the event loop and libuv but no prior knowledge of those topics is required. Readers are assumed to have a basic understanding of the JavaScript language and Node.js callback pattern . \"I/O\" refers primarily to interaction with the system's disk and network supported by libuv .","title":"Overview of Blocking vs Non-Blocking"},{"location":"JavaScript/Software/Software-event-driven-programming/Software-node.js/Node.js-core-concepts/Node.js-Overview-of-Blocking-vs-Non-Blocking/#blocking","text":"Blocking is when the execution of additional JavaScript in the Node.js process must wait until a non-JavaScript operation completes(\u963b\u585e\u662f\u5728Node.js\u8fdb\u7a0b\u4e2d\u6267\u884cadditional JavaScript\u65f6\uff0c\u5fc5\u987b\u7b49\u5f85\u975eJavaScript\u64cd\u4f5c\u5b8c\u6210). This happens because the event loop is unable to continue running JavaScript while a blocking operation is occurring(\u8fd9\u662f\u56e0\u4e3a\u5728\u53d1\u751f\u963b\u585e\u64cd\u4f5c\u65f6\uff0c**event loop**\u65e0\u6cd5\u7ee7\u7eed\u8fd0\u884cJavaScript). In Node.js, JavaScript that exhibits poor performance due to being CPU intensive (CPU\u5bc6\u96c6\u578b) rather than waiting on a non-JavaScript operation, such as I/O, isn't typically referred to as blocking . Synchronous methods (\u540c\u6b65\u64cd\u4f5c) in the Node.js standard library that use libuv are the most commonly used blocking operations. Native modules may also have blocking methods. All of the I/O methods in the Node.js standard library provide asynchronous versions , which are non-blocking , and accept callback functions . Some methods also have blocking counterparts, which have names that end with Sync .","title":"Blocking"},{"location":"JavaScript/Software/Software-event-driven-programming/Software-node.js/Node.js-core-concepts/Node.js-Overview-of-Blocking-vs-Non-Blocking/#comparing-code","text":"Blocking methods execute synchronously and non-blocking methods execute asynchronously . Using the File System module as an example, this is a synchronous file read: const fs = require ( 'fs' ); const data = fs . readFileSync ( '/file.md' ); // blocks here until file is read And here is an equivalent asynchronous example: const fs = require ( 'fs' ); fs . readFile ( '/file.md' , ( err , data ) => { if ( err ) throw err ; }); The first example appears simpler than the second but has the disadvantage of the second line blocking the execution of any additional JavaScript until the entire file is read. Note that in the synchronous version if an error is thrown it will need to be caught or the process will crash. In the asynchronous version, it is up to the author to decide whether an error should throw as shown. Let's expand our example a little bit: const fs = require ( 'fs' ); const data = fs . readFileSync ( '/file.md' ); // blocks here until file is read console . log ( data ); // moreWork(); will run after console.log And here is a similar, but not equivalent asynchronous example: const fs = require ( 'fs' ); fs . readFile ( '/file.md' , ( err , data ) => { if ( err ) throw err ; console . log ( data ); }); // moreWork(); will run before console.log In the first example above, console.log will be called before moreWork() . In the second example fs.readFile() is non-blocking so JavaScript execution can continue and moreWork() will be called first. The ability to run moreWork() without waiting for the file read to complete is a key design choice that allows for higher throughput(\u541e\u5410\u91cf).","title":"Comparing Code"},{"location":"JavaScript/Software/Software-event-driven-programming/Software-node.js/Node.js-core-concepts/Node.js-Overview-of-Blocking-vs-Non-Blocking/#concurrency-and-throughput","text":"JavaScript execution in Node.js is single threaded, so concurrency refers to the event loop's capacity to execute JavaScript callback functions after completing other work. Any code that is expected to run in a concurrent manner must allow the event loop to continue running as non-JavaScript operations, like I/O, are occurring. As an example, let's consider a case where each request to a web server takes 50ms to complete and 45ms of that 50ms is database I/O that can be done asynchronously. Choosing non-blocking asynchronous operations frees up that 45ms per request to handle other requests. This is a significant difference in capacity just by choosing to use non-blocking methods instead of blocking methods. The event loop is different than models in many other languages where additional threads may be created to handle concurrent work.","title":"Concurrency and Throughput"},{"location":"JavaScript/Software/Software-event-driven-programming/Software-node.js/Node.js-core-concepts/Node.js-Overview-of-Blocking-vs-Non-Blocking/#dangers-of-mixing-blocking-and-non-blocking-code","text":"There are some patterns that should be avoided when dealing with I/O. Let's look at an example: const fs = require('fs'); fs.readFile('/file.md', (err, data) => { if (err) throw err; console.log(data); }); fs.unlinkSync('/file.md'); In the above example, fs.unlinkSync() is likely to be run before fs.readFile() , which would delete file.md before it is actually read. A better way to write this that is completely non-blocking and guaranteed to execute in the correct order is: const fs = require('fs'); fs.readFile('/file.md', (readFileErr, data) => { if (readFileErr) throw readFileErr; console.log(data); fs.unlink('/file.md', (unlinkErr) => { if (unlinkErr) throw unlinkErr; }); }); The above places a non-blocking call to fs.unlink() within the callback of fs.readFile() which guarantees the correct order of operations.","title":"Dangers of Mixing Blocking and Non-Blocking Code"},{"location":"JavaScript/Software/Software-event-driven-programming/Software-node.js/Node.js-core-concepts/Node.js-Overview-of-Blocking-vs-Non-Blocking/#additional-resources","text":"libuv About Node.js","title":"Additional Resources"},{"location":"JavaScript/Software/Software-event-driven-programming/Software-node.js/Node.js-core-concepts/Node.js-The-Node.js-Event-Loop-Timers-and-process.nextTick()/","text":"The Node.js Event Loop, Timers, and process.nextTick() What is the Event Loop? The event loop is what allows Node.js to perform non-blocking I/O operations \u2014 despite the fact that JavaScript is single-threaded \u2014 by offloading operations to the system kernel whenever possible. Since most modern kernels are multi-threaded, they can handle multiple operations executing in the background. When one of these operations completes, the kernel tells Node.js so that the appropriate callback may be added to the poll queue to eventually be executed. We'll explain this in further detail later in this topic. Event Loop Explained When Node.js starts, it initializes the event loop , processes(\u5904\u7406) the provided input script (or drops into the REPL , which is not covered in this document) which may make async API calls, schedule timers , or call process.nextTick() , then begins processing the event loop . The following diagram shows a simplified overview of the event loop 's order of operations. \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500>\u2502 timers \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 pending callbacks \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 idle, prepare \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 incoming: \u2502 \u2502 \u2502 poll \u2502<\u2500\u2500\u2500\u2500\u2500\u2524 connections, \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 data, etc. \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 check \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2524 close callbacks \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 note: each box will be referred to as a \"phase\" of the event loop. Each phase has a FIFO queue of callbacks to execute. While each phase is special in its own way, generally, when the event loop enters a given phase, it will perform any operations specific to that phase, then execute callbacks in that phase's queue until the queue has been exhausted or the maximum number of callbacks has executed. When the queue has been exhausted or the callback limit is reached, the event loop will move to the next phase, and so on.","title":"Node.js-The-Node.js-Event-Loop-Timers-and-process.nextTick()"},{"location":"JavaScript/Software/Software-event-driven-programming/Software-node.js/Node.js-core-concepts/Node.js-The-Node.js-Event-Loop-Timers-and-process.nextTick()/#the-nodejs-event-loop-timers-and-processnexttick","text":"","title":"The Node.js Event Loop, Timers, and process.nextTick()"},{"location":"JavaScript/Software/Software-event-driven-programming/Software-node.js/Node.js-core-concepts/Node.js-The-Node.js-Event-Loop-Timers-and-process.nextTick()/#what-is-the-event-loop","text":"The event loop is what allows Node.js to perform non-blocking I/O operations \u2014 despite the fact that JavaScript is single-threaded \u2014 by offloading operations to the system kernel whenever possible. Since most modern kernels are multi-threaded, they can handle multiple operations executing in the background. When one of these operations completes, the kernel tells Node.js so that the appropriate callback may be added to the poll queue to eventually be executed. We'll explain this in further detail later in this topic.","title":"What is the Event Loop?"},{"location":"JavaScript/Software/Software-event-driven-programming/Software-node.js/Node.js-core-concepts/Node.js-The-Node.js-Event-Loop-Timers-and-process.nextTick()/#event-loop-explained","text":"When Node.js starts, it initializes the event loop , processes(\u5904\u7406) the provided input script (or drops into the REPL , which is not covered in this document) which may make async API calls, schedule timers , or call process.nextTick() , then begins processing the event loop . The following diagram shows a simplified overview of the event loop 's order of operations. \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500>\u2502 timers \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 pending callbacks \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 idle, prepare \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 incoming: \u2502 \u2502 \u2502 poll \u2502<\u2500\u2500\u2500\u2500\u2500\u2524 connections, \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 data, etc. \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 check \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2524 close callbacks \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 note: each box will be referred to as a \"phase\" of the event loop. Each phase has a FIFO queue of callbacks to execute. While each phase is special in its own way, generally, when the event loop enters a given phase, it will perform any operations specific to that phase, then execute callbacks in that phase's queue until the queue has been exhausted or the maximum number of callbacks has executed. When the queue has been exhausted or the callback limit is reached, the event loop will move to the next phase, and so on.","title":"Event Loop Explained"},{"location":"Python/Books/","text":"Books The Hitchhiker\u2019s Guide to Python \u00b6","title":"Books"},{"location":"Python/Books/#books","text":"","title":"Books"},{"location":"Python/Books/#the-hitchhikers-guide-to-python","text":"","title":"The Hitchhiker\u2019s Guide to Python\u00b6"},{"location":"Python/Glossary/Abstract-base-class/","text":"abstract base class Abstract base classes complement duck-typing by providing a way to define interfaces when other techniques like hasattr() would be clumsy or subtly wrong (for example with magic methods ). ABCs introduce virtual subclasses , which are classes that don\u2019t inherit from a class but are still recognized by isinstance() and issubclass() ; see the abc module documentation. Python comes with many built-in ABCs for data structures (in the collections.abc module), numbers (in the numbers module), streams (in the io module), import finders and loaders (in the importlib.abc module). You can create your own ABCs with the abc module.","title":"Abstract-base-class"},{"location":"Python/Glossary/Abstract-base-class/#abstract-base-class","text":"Abstract base classes complement duck-typing by providing a way to define interfaces when other techniques like hasattr() would be clumsy or subtly wrong (for example with magic methods ). ABCs introduce virtual subclasses , which are classes that don\u2019t inherit from a class but are still recognized by isinstance() and issubclass() ; see the abc module documentation. Python comes with many built-in ABCs for data structures (in the collections.abc module), numbers (in the numbers module), streams (in the io module), import finders and loaders (in the importlib.abc module). You can create your own ABCs with the abc module.","title":"abstract base class"},{"location":"Python/Glossary/Argument-and-parameter/","text":"What is the difference between arguments and parameters? Parameters are defined by the names that appear in a function definition, whereas arguments are the values actually passed to a function when calling it. Parameters define what types of arguments a function can accept. For example, given the function definition: def func ( foo , bar = None , ** kwargs ): pass foo , bar and kwargs are parameters of func . However, when calling func , for example: func ( 42 , bar = 314 , extra = somevar ) the values 42 , 314 , and somevar are arguments. What's the difference between an argument and a parameter? A A parameter is a variable in a method definition. When a method is called, the arguments are the data you pass into the method's parameters. public void MyMethod ( string myParam ) { } ... string myArg1 = \"this is my argument\" ; myClass . MyMethod ( myArg1 );","title":"Argument-and-parameter"},{"location":"Python/Glossary/Argument-and-parameter/#what-is-the-difference-between-arguments-and-parameters","text":"Parameters are defined by the names that appear in a function definition, whereas arguments are the values actually passed to a function when calling it. Parameters define what types of arguments a function can accept. For example, given the function definition: def func ( foo , bar = None , ** kwargs ): pass foo , bar and kwargs are parameters of func . However, when calling func , for example: func ( 42 , bar = 314 , extra = somevar ) the values 42 , 314 , and somevar are arguments.","title":"What is the difference between arguments and parameters?"},{"location":"Python/Glossary/Argument-and-parameter/#whats-the-difference-between-an-argument-and-a-parameter","text":"A A parameter is a variable in a method definition. When a method is called, the arguments are the data you pass into the method's parameters. public void MyMethod ( string myParam ) { } ... string myArg1 = \"this is my argument\" ; myClass . MyMethod ( myArg1 );","title":"What's the difference between an argument and a parameter?"},{"location":"Python/How-to/Iterate/Iterate/","text":"","title":"Introduction"},{"location":"Python/How-to/Lazy-import/Lazy-importing/","text":"google python lazy-loading module","title":"Lazy-importing"},{"location":"Python/Language/python-able/","text":"subscriptable iterable __iter__() callable","title":"subscriptable"},{"location":"Python/Language/python-able/#subscriptable","text":"","title":"subscriptable"},{"location":"Python/Language/python-able/#iterable","text":"__iter__()","title":"iterable"},{"location":"Python/Language/python-able/#callable","text":"","title":"callable"},{"location":"Python/Language/python-dot-operator-and-attribute-access/","text":"class TestBase : Name = 'TestBase' def __init__ ( self ): self . name = 'testbase' class T1 ( TestBase ): pass class T2 ( TestBase ): pass t1 = T1 () t2 = T2 () id ( t1 . Name ) == id ( t2 . Name ) class TestBase : Name = 'TestBase' @classmethod def ChangeName ( cls , name ): cls . Name = name def __init__ ( self ): self . name = 'testbase' class T1 ( TestBase ): pass class T2 ( TestBase ): pass t1.ChangeName('T1') id(t1.Name)==id(t2.Name) python = operator python . operator \u5982: t1 . test = 'a' \u8fd9\u6bb5\u4ee3\u7801\u662f\u80fd\u591f\u6b63\u786e\u8fd0\u884c\u7684\uff0c\u5b83\u5728 t1 \u4e2d\u6dfb\u52a0\u4e86 tests \u5c5e\u6027\u3002 t1 . Name \u5219\u662f\u7eaf\u7cb9\u7684\u5c5e\u6027access\u3002","title":"Python dot operator and attribute access"},{"location":"Python/Language/Developer's-guide/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u4e3b\u8981\u8bb0\u5f55\u6211\u5bf9 cpython \u7684\u5b9e\u73b0\u7684\u63a2\u7d22\uff0c\u4e3b\u8981\u51fa\u4e8e\u6211\u5bf9python\u7a0b\u5e8f\u7684\u8fd0\u884c\u673a\u5236\u7684\u597d\u5947\u3002 \u5173\u4e8ecpython\u7684\u5b9e\u73b0\u7684\u4ecb\u7ecd\u975e\u5e38\u591a\uff0c\u672c\u8282\u5c06\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u7684\u89d2\u5ea6\u6765\u5206\u6790cpython\u7684\u5b9e\u73b0\u3002\u5b83\u4f5c\u4e3a\u4e00\u4e2a\u975e\u5e38\u6210\u529f\u7684\u5927\u578b\u8f6f\u4ef6\uff0c\u5176\u5b9e\u73b0\u65b9\u5f0f\u662f\u503c\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u5b66\u4e60\u7684\uff0c\u9664\u6b64\u4e4b\u5916\uff0c\u5176\u7ba1\u7406\u65b9\u5f0f\uff0c\u8d28\u91cf\u4fdd\u8bc1\u7b49\u65b9\u9762\u4e5f\u662f\u975e\u5e38\u503c\u5f97\u5b66\u4e60\u7684\u3002 cpython\u7684\u5b9e\u73b0\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u4e2a\u6210\u529f\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5178\u8303\u6765\u8fdb\u884c\u5b66\u4e60\uff1a \u5982\u4f55\u505a\u8f6f\u4ef6\u5de5\u7a0b\u7684 \u5982\u4f55\u4fdd\u8bc1\u8d28\u91cf\u7684 \u5982\u4f55\u5b9e\u73b0\u7684 \u5982\u4f55\u6765\u8fdb\u884c\u534f\u4f5c\u5f00\u53d1 \u5982\u4f55\u8de8\u5e73\u53f0 \u8fd9\u4e00\u7cfb\u5217\u90fd\u662f\u503c\u7684\u6211\u4eec\u5b66\u4e60\u7684 \u4e3b\u8981\u4ee5Unix-like system\u4e3a\u4f8b\u6765\u8fdb\u884c\u8bf4\u660e\uff0cWindows\u5e73\u53f0\u7684\u5ffd\u7565\u3002 \u8fd9\u4e2a\u7cfb\u5217\u6211\u51b3\u5b9a\u4ece \u5982\u4e0b\u65b9\u9762\u8fdb\u884c\u7ec4\u7ec7\uff1a Part 1: Introduction to CPython \u4ecb\u7ecdpython\u548ccpython Source Code \u63cf\u8ff0cpython\u7684\u6e90\u4ee3\u7801\u7ec4\u7ec7\uff0c\u5b98\u65b9\u4ecb\u7ecd\uff1a 23.1. CPython Source Code Layout \u00b6 1.8. Directory structure \u00b6 cpython build system \u63cf\u8ff0cpython\u7684build system\uff0c\u8fd9\u90e8\u5206\u662f\u5f88\u591a\u6587\u7ae0\u4e2d\u90fd\u6ca1\u6709\u7684\uff0c\u9700\u8981\u597d\u597d\u7684\u8fdb\u884c\u4ecb\u7ecd Compiling CPython linux The Python Language Specification \u53c2\u89c1https://realpython.com/cpython-source-code-guide/#part-1-introduction-to-cpython \u9700\u8981\u5bf9\u5176\u4e2d\u6d89\u53ca\u5230\u7684\u77e5\u8bc6\u8fdb\u884c\u8bf4\u660e\u3002 \u5b98\u65b9\u8d44\u6e90\uff1a Changing CPython\u2019s Grammar \u00b6 cpython\u5b9e\u73b0\u5206\u6790 \u67b6\u6784 compiler + interpreter / virtual machine \u4e24\u8005\u4e4b\u95f4\u7684\u63a5\u53e3\u662fPython bytecode\uff1a dis \u2014 Disassembler for Python bytecode \u00b6 Bytecode \u5165\u53e3 \u6cbf\u7740python\u7a0b\u5e8f\u7684\u6267\u884c\u6765\u9010\u6b65\u8fdb\u884c\u5206\u6790 \u53c2\u89c1 Part 2: The Python Interpreter Process Memory Management in CPython bytecode dis \u2014 Disassembler for Python bytecode \u00b6 TODO python AST https://greentreesnakes.readthedocs.io/en/latest/ cpython\u7684\u6307\u4ee4\u662f\u600e\u6837\u7684\uff1f \u4eceAST\u2192CFG\u2192byte code cpython\u63d0\u4f9b\u4e86\u4e00\u4e9b\u5217\u7684build-in type\uff0cbuild-in function\u4f9bprogrammer\u4f7f\u7528\uff0cbyte code\u662f\u5426\u662f\u57fa\u4e8e\u8fd9\u4e9bbuild-in\u7684\uff1f\u5373byte code\u6700\u7ec8\u88ab\u89e3\u91ca\u6267\u884c\u7684\u65f6\u5019\u5176\u5b9e\u8c03\u7528\u7684\u8fd8\u662f\u53ea\u5199build-in\u7684\u65b9\u6cd5\uff1f\u6211\u89c9\u5f97\u5e94\u8be5\u662f\u8fd9\u6837\u7684\u3002","title":"Introduction"},{"location":"Python/Language/Developer's-guide/#_1","text":"\u672c\u7ae0\u4e3b\u8981\u8bb0\u5f55\u6211\u5bf9 cpython \u7684\u5b9e\u73b0\u7684\u63a2\u7d22\uff0c\u4e3b\u8981\u51fa\u4e8e\u6211\u5bf9python\u7a0b\u5e8f\u7684\u8fd0\u884c\u673a\u5236\u7684\u597d\u5947\u3002 \u5173\u4e8ecpython\u7684\u5b9e\u73b0\u7684\u4ecb\u7ecd\u975e\u5e38\u591a\uff0c\u672c\u8282\u5c06\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u7684\u89d2\u5ea6\u6765\u5206\u6790cpython\u7684\u5b9e\u73b0\u3002\u5b83\u4f5c\u4e3a\u4e00\u4e2a\u975e\u5e38\u6210\u529f\u7684\u5927\u578b\u8f6f\u4ef6\uff0c\u5176\u5b9e\u73b0\u65b9\u5f0f\u662f\u503c\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u5b66\u4e60\u7684\uff0c\u9664\u6b64\u4e4b\u5916\uff0c\u5176\u7ba1\u7406\u65b9\u5f0f\uff0c\u8d28\u91cf\u4fdd\u8bc1\u7b49\u65b9\u9762\u4e5f\u662f\u975e\u5e38\u503c\u5f97\u5b66\u4e60\u7684\u3002 cpython\u7684\u5b9e\u73b0\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u4e2a\u6210\u529f\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5178\u8303\u6765\u8fdb\u884c\u5b66\u4e60\uff1a \u5982\u4f55\u505a\u8f6f\u4ef6\u5de5\u7a0b\u7684 \u5982\u4f55\u4fdd\u8bc1\u8d28\u91cf\u7684 \u5982\u4f55\u5b9e\u73b0\u7684 \u5982\u4f55\u6765\u8fdb\u884c\u534f\u4f5c\u5f00\u53d1 \u5982\u4f55\u8de8\u5e73\u53f0 \u8fd9\u4e00\u7cfb\u5217\u90fd\u662f\u503c\u7684\u6211\u4eec\u5b66\u4e60\u7684 \u4e3b\u8981\u4ee5Unix-like system\u4e3a\u4f8b\u6765\u8fdb\u884c\u8bf4\u660e\uff0cWindows\u5e73\u53f0\u7684\u5ffd\u7565\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Python/Language/Developer's-guide/#_2","text":"","title":"\u8fd9\u4e2a\u7cfb\u5217\u6211\u51b3\u5b9a\u4ece \u5982\u4e0b\u65b9\u9762\u8fdb\u884c\u7ec4\u7ec7\uff1a"},{"location":"Python/Language/Developer's-guide/#part-1-introduction-to-cpython","text":"\u4ecb\u7ecdpython\u548ccpython","title":"Part 1: Introduction to CPython"},{"location":"Python/Language/Developer's-guide/#source-code","text":"\u63cf\u8ff0cpython\u7684\u6e90\u4ee3\u7801\u7ec4\u7ec7\uff0c\u5b98\u65b9\u4ecb\u7ecd\uff1a 23.1. CPython Source Code Layout \u00b6 1.8. Directory structure \u00b6","title":"Source Code"},{"location":"Python/Language/Developer's-guide/#cpython-build-system","text":"\u63cf\u8ff0cpython\u7684build system\uff0c\u8fd9\u90e8\u5206\u662f\u5f88\u591a\u6587\u7ae0\u4e2d\u90fd\u6ca1\u6709\u7684\uff0c\u9700\u8981\u597d\u597d\u7684\u8fdb\u884c\u4ecb\u7ecd","title":"cpython build system"},{"location":"Python/Language/Developer's-guide/#compiling-cpython-linux","text":"","title":"Compiling CPython linux"},{"location":"Python/Language/Developer's-guide/#the-python-language-specification","text":"\u53c2\u89c1https://realpython.com/cpython-source-code-guide/#part-1-introduction-to-cpython \u9700\u8981\u5bf9\u5176\u4e2d\u6d89\u53ca\u5230\u7684\u77e5\u8bc6\u8fdb\u884c\u8bf4\u660e\u3002 \u5b98\u65b9\u8d44\u6e90\uff1a Changing CPython\u2019s Grammar \u00b6","title":"The Python Language Specification"},{"location":"Python/Language/Developer's-guide/#cpython","text":"","title":"cpython\u5b9e\u73b0\u5206\u6790"},{"location":"Python/Language/Developer's-guide/#_3","text":"compiler + interpreter / virtual machine \u4e24\u8005\u4e4b\u95f4\u7684\u63a5\u53e3\u662fPython bytecode\uff1a dis \u2014 Disassembler for Python bytecode \u00b6 Bytecode","title":"\u67b6\u6784"},{"location":"Python/Language/Developer's-guide/#_4","text":"\u6cbf\u7740python\u7a0b\u5e8f\u7684\u6267\u884c\u6765\u9010\u6b65\u8fdb\u884c\u5206\u6790 \u53c2\u89c1 Part 2: The Python Interpreter Process","title":"\u5165\u53e3"},{"location":"Python/Language/Developer's-guide/#memory-management-in-cpython","text":"","title":"Memory Management in CPython"},{"location":"Python/Language/Developer's-guide/#bytecode","text":"dis \u2014 Disassembler for Python bytecode \u00b6","title":"bytecode"},{"location":"Python/Language/Developer's-guide/#todo","text":"","title":"TODO"},{"location":"Python/Language/Developer's-guide/#python-ast","text":"https://greentreesnakes.readthedocs.io/en/latest/","title":"python AST"},{"location":"Python/Language/Developer's-guide/#cpython_1","text":"\u4eceAST\u2192CFG\u2192byte code cpython\u63d0\u4f9b\u4e86\u4e00\u4e9b\u5217\u7684build-in type\uff0cbuild-in function\u4f9bprogrammer\u4f7f\u7528\uff0cbyte code\u662f\u5426\u662f\u57fa\u4e8e\u8fd9\u4e9bbuild-in\u7684\uff1f\u5373byte code\u6700\u7ec8\u88ab\u89e3\u91ca\u6267\u884c\u7684\u65f6\u5019\u5176\u5b9e\u8c03\u7528\u7684\u8fd8\u662f\u53ea\u5199build-in\u7684\u65b9\u6cd5\uff1f\u6211\u89c9\u5f97\u5e94\u8be5\u662f\u8fd9\u6837\u7684\u3002","title":"cpython\u7684\u6307\u4ee4\u662f\u600e\u6837\u7684\uff1f"},{"location":"Python/Language/Developer's-guide/build-cpython/","text":"cpython\u7684build system \u4f7f\u7528\u7684\u662f GNU Autotools \u5982\u4f55\u4f7f\u7528 Autoconf \u6765\u751f\u6210configure\u6587\u4ef6\uff1f\u662f\u7684\uff0c\u57281.5. Regenerate configure \u00b6 \u4e2d\uff0c\u6709\u8fd9\u6837\u7684\u63cf\u8ff0\uff1a Python\u2019s configure script is generated from configure.ac using Autoconf. Instead of editing configure , edit configure.ac and then run autoreconf to regenerate configure and a number of other files (such as pyconfig.h ). \u5173\u4e8econfigure\u6587\u4ef6\uff0c\u53c2\u89c1\uff1a configure script \u3002 Makefile.pre \u662f\u7531 configure \u751f\u6210\u7684\u3002 pyconfig.h /* pyconfig.h. Generated from pyconfig.h.in by configure. / / pyconfig.h.in. Generated from configure.ac by autoheader. */","title":"cpython\u7684build system"},{"location":"Python/Language/Developer's-guide/build-cpython/#cpythonbuild-system","text":"\u4f7f\u7528\u7684\u662f GNU Autotools \u5982\u4f55\u4f7f\u7528 Autoconf \u6765\u751f\u6210configure\u6587\u4ef6\uff1f\u662f\u7684\uff0c\u57281.5. Regenerate configure \u00b6 \u4e2d\uff0c\u6709\u8fd9\u6837\u7684\u63cf\u8ff0\uff1a Python\u2019s configure script is generated from configure.ac using Autoconf. Instead of editing configure , edit configure.ac and then run autoreconf to regenerate configure and a number of other files (such as pyconfig.h ). \u5173\u4e8econfigure\u6587\u4ef6\uff0c\u53c2\u89c1\uff1a configure script \u3002 Makefile.pre \u662f\u7531 configure \u751f\u6210\u7684\u3002","title":"cpython\u7684build system"},{"location":"Python/Language/Developer's-guide/build-cpython/#pyconfigh","text":"/* pyconfig.h. Generated from pyconfig.h.in by configure. / / pyconfig.h.in. Generated from configure.ac by autoheader. */","title":"pyconfig.h"},{"location":"Python/Language/Developer's-guide/github-CPython-Internals/","text":"CPython-Internals","title":"**[CPython-Internals](https://github.com/zpoint/CPython-Internals)**"},{"location":"Python/Language/Developer's-guide/github-CPython-Internals/#cpython-internals","text":"","title":"CPython-Internals"},{"location":"Python/Language/Developer's-guide/python-implementation-interpreted-or-compiled/","text":"Is Python interpreted or compiled? Yes. Is Python interpreted or compiled? Yes. A common question: \u201cIs Python interpreted or compiled?\u201d Usually, the asker has a simple model of the world in mind, and as is typical, the world is more complicated. In the simple model of the world, \u201ccompile\u201d means to convert a program in a high-level language into a binary executable full of machine code (CPU instructions). When you compile a C program, this is what happens. The result is a file that your operating system can run for you. In the simple definition of \u201cinterpreted\u201d, executing a program means reading the source file a line at a time, and doing what it says. This is the way some shells operate. But the real world is not so limited. Making real programming languages useful and powerful involves a wider range of possibilities about how they work. Compiling is a more general idea: take a program in one language (or form), and convert it into another language or form. Usually the source form is a higher-level language than the destination form, such as when converting from C to machine code. But converting from JavaScript 8 to JavaScript 5 is also a kind of compiling. In Python, the source is compiled into a much simpler form called bytecode . These are instructions similar in spirit to CPU instructions, but instead of being executed by the CPU, they are executed by software called a virtual machine. (These are not VM\u2019s that emulate entire operating systems, just a simplified CPU execution environment.) Here\u2019s an example of a short Python function, and its bytecode: >>> import dis >>> def example ( x ): ... for i in range ( x ): ... print ( 2 * i ) ... >>> dis . dis ( example ) 2 0 SETUP_LOOP 28 ( to 30 ) 2 LOAD_GLOBAL 0 ( range ) 4 LOAD_FAST 0 ( x ) 6 CALL_FUNCTION 1 8 GET_ITER >> 10 FOR_ITER 16 ( to 28 ) 12 STORE_FAST 1 ( i ) 3 14 LOAD_GLOBAL 1 ( print ) 16 LOAD_CONST 1 ( 2 ) 18 LOAD_FAST 1 ( i ) 20 BINARY_MULTIPLY 22 CALL_FUNCTION 1 24 POP_TOP 26 JUMP_ABSOLUTE 10 >> 28 POP_BLOCK >> 30 LOAD_CONST 0 ( None ) 32 RETURN_VALUE >>> The dis module in the Python standard library is the disassembler that can show you Python bytecode . It\u2019s also the best (but not great) documentation for the bytecode itself. If you want to know more about how Python\u2019s bytecode works, there are lots of conference talks about bytecode . The software that executes bytecode can be written in any language: byterun is an implementation in Python (!), which is useful only as an educational exercise. An important aspect of Python\u2019s compilation to bytecode is that it\u2019s entirely implicit(\u5b8c\u5168\u662f\u9690\u5f0f\u7684\uff0c\u5373\u7528\u6237\u611f\u77e5\u4e0d\u5230). You never invoke a compiler, you simply run a .py file. The Python implementation compiles the files as needed. This is different than Java, for example, where you have to run the Java compiler to turn Java source into compiled class files. For this reason, Java is often called a compiled language , while Python is called an interpreted language . But both compile to bytecode , and then both execute the bytecode with a software implementation of a virtual machine . Another important Python feature is its interactive prompt. You can type Python statements and have them immediately executed. This interactivity is usually missing in \u201ccompiled\u201d languages, but even at the Python interactive prompt, your Python is compiled to bytecode, and then the bytecode is executed. This immediate execution, and Python\u2019s lack of an explicit compile step, are why people call the Python executable \u201cthe Python interpreter.\u201d By the way, even this is a simplified description of how these languages can work. \u201cCompiled\u201d languages like Java and C can have interactive prompts, but they are not at the center of those worlds in the same way that Python\u2019s is. Java originally always compiled to bytecode , but then it pioneered(\u5021\u5bfc) just-in-time (JIT) techniques for compiling to machine code at runtime, and now Java is sometimes compiled entirely to machine code, in the C style. This shows just how flimsy the words \u201cinterpreted\u201d and \u201ccompiled\u201d can be. Like most adjectives applied to programming languages, they are thrown around as if they were black-and-white distinctions, but the reality is much subtler and complex. Finally, how your program gets executed isn\u2019t a characteristic of the language at all: it\u2019s about the language implementation . I\u2019ve been talking here about Python, but this has really been a description of CPython, the usual implementation of Python, so-named because it is written in C. PyPy is another implementation, using a JIT compiler to run code much faster than CPython can. So: is Python compiled? Yes. Is Python interpreted? Yes. Sorry, the world is complicated...","title":"Python implementation interpreted or compiled"},{"location":"Python/Language/Developer's-guide/python-implementation-interpreted-or-compiled/#is-python-interpreted-or-compiled-yes","text":"A common question: \u201cIs Python interpreted or compiled?\u201d Usually, the asker has a simple model of the world in mind, and as is typical, the world is more complicated. In the simple model of the world, \u201ccompile\u201d means to convert a program in a high-level language into a binary executable full of machine code (CPU instructions). When you compile a C program, this is what happens. The result is a file that your operating system can run for you. In the simple definition of \u201cinterpreted\u201d, executing a program means reading the source file a line at a time, and doing what it says. This is the way some shells operate. But the real world is not so limited. Making real programming languages useful and powerful involves a wider range of possibilities about how they work. Compiling is a more general idea: take a program in one language (or form), and convert it into another language or form. Usually the source form is a higher-level language than the destination form, such as when converting from C to machine code. But converting from JavaScript 8 to JavaScript 5 is also a kind of compiling. In Python, the source is compiled into a much simpler form called bytecode . These are instructions similar in spirit to CPU instructions, but instead of being executed by the CPU, they are executed by software called a virtual machine. (These are not VM\u2019s that emulate entire operating systems, just a simplified CPU execution environment.) Here\u2019s an example of a short Python function, and its bytecode: >>> import dis >>> def example ( x ): ... for i in range ( x ): ... print ( 2 * i ) ... >>> dis . dis ( example ) 2 0 SETUP_LOOP 28 ( to 30 ) 2 LOAD_GLOBAL 0 ( range ) 4 LOAD_FAST 0 ( x ) 6 CALL_FUNCTION 1 8 GET_ITER >> 10 FOR_ITER 16 ( to 28 ) 12 STORE_FAST 1 ( i ) 3 14 LOAD_GLOBAL 1 ( print ) 16 LOAD_CONST 1 ( 2 ) 18 LOAD_FAST 1 ( i ) 20 BINARY_MULTIPLY 22 CALL_FUNCTION 1 24 POP_TOP 26 JUMP_ABSOLUTE 10 >> 28 POP_BLOCK >> 30 LOAD_CONST 0 ( None ) 32 RETURN_VALUE >>> The dis module in the Python standard library is the disassembler that can show you Python bytecode . It\u2019s also the best (but not great) documentation for the bytecode itself. If you want to know more about how Python\u2019s bytecode works, there are lots of conference talks about bytecode . The software that executes bytecode can be written in any language: byterun is an implementation in Python (!), which is useful only as an educational exercise. An important aspect of Python\u2019s compilation to bytecode is that it\u2019s entirely implicit(\u5b8c\u5168\u662f\u9690\u5f0f\u7684\uff0c\u5373\u7528\u6237\u611f\u77e5\u4e0d\u5230). You never invoke a compiler, you simply run a .py file. The Python implementation compiles the files as needed. This is different than Java, for example, where you have to run the Java compiler to turn Java source into compiled class files. For this reason, Java is often called a compiled language , while Python is called an interpreted language . But both compile to bytecode , and then both execute the bytecode with a software implementation of a virtual machine . Another important Python feature is its interactive prompt. You can type Python statements and have them immediately executed. This interactivity is usually missing in \u201ccompiled\u201d languages, but even at the Python interactive prompt, your Python is compiled to bytecode, and then the bytecode is executed. This immediate execution, and Python\u2019s lack of an explicit compile step, are why people call the Python executable \u201cthe Python interpreter.\u201d By the way, even this is a simplified description of how these languages can work. \u201cCompiled\u201d languages like Java and C can have interactive prompts, but they are not at the center of those worlds in the same way that Python\u2019s is. Java originally always compiled to bytecode , but then it pioneered(\u5021\u5bfc) just-in-time (JIT) techniques for compiling to machine code at runtime, and now Java is sometimes compiled entirely to machine code, in the C style. This shows just how flimsy the words \u201cinterpreted\u201d and \u201ccompiled\u201d can be. Like most adjectives applied to programming languages, they are thrown around as if they were black-and-white distinctions, but the reality is much subtler and complex. Finally, how your program gets executed isn\u2019t a characteristic of the language at all: it\u2019s about the language implementation . I\u2019ve been talking here about Python, but this has really been a description of CPython, the usual implementation of Python, so-named because it is written in C. PyPy is another implementation, using a JIT compiler to run code much faster than CPython can. So: is Python compiled? Yes. Is Python interpreted? Yes. Sorry, the world is complicated...","title":"Is Python interpreted or compiled? Yes."},{"location":"Python/Language/Developer's-guide/1-Getting-Started/1-Getting-Started/","text":"1.8. Directory structure \u00b6 There are several top-level directories in the CPython source tree. Knowing what each one is meant to hold will help you find where a certain piece of functionality is implemented. Do realize, though, there are always exceptions to every rule. Doc The official documentation. This is what https://docs.python.org/ uses. See also Building the documentation . Grammar Contains the EBNF grammar file for Python. Include Contains all interpreter-wide header files. Lib The part of the standard library implemented in pure Python. Mac Mac-specific code (e.g., using IDLE as an OS X application). Misc Things that do not belong elsewhere. Typically this is varying kinds of developer-specific documentation. Modules The part of the standard library (plus some other code) that is implemented in C. Objects Code for all built-in types. PC Windows-specific code. PCbuild Build files for the version of MSVC currently used for the Windows installers provided on python.org. Parser Code related to the parser. The definition of the AST nodes is also kept here. Programs Source code for C executables, including the main function for the CPython interpreter (in versions prior to Python 3.5, these files are in the Modules directory). Python The code that makes up the core CPython runtime. This includes the compiler, eval loop and various built-in modules. Tools Various tools that are (or have been) used to maintain Python.","title":"1 Getting Started"},{"location":"Python/Language/Developer's-guide/1-Getting-Started/1-Getting-Started/#18-directory-structure","text":"There are several top-level directories in the CPython source tree. Knowing what each one is meant to hold will help you find where a certain piece of functionality is implemented. Do realize, though, there are always exceptions to every rule. Doc The official documentation. This is what https://docs.python.org/ uses. See also Building the documentation . Grammar Contains the EBNF grammar file for Python. Include Contains all interpreter-wide header files. Lib The part of the standard library implemented in pure Python. Mac Mac-specific code (e.g., using IDLE as an OS X application). Misc Things that do not belong elsewhere. Typically this is varying kinds of developer-specific documentation. Modules The part of the standard library (plus some other code) that is implemented in C. Objects Code for all built-in types. PC Windows-specific code. PCbuild Build files for the version of MSVC currently used for the Windows installers provided on python.org. Parser Code related to the parser. The definition of the AST nodes is also kept here. Programs Source code for C executables, including the main function for the CPython interpreter (in versions prior to Python 3.5, these files are in the Modules directory). Python The code that makes up the core CPython runtime. This includes the compiler, eval loop and various built-in modules. Tools Various tools that are (or have been) used to maintain Python.","title":"1.8. Directory structure\u00b6"},{"location":"Python/Language/Developer's-guide/23-Exploring-CPython's-Internals/23-Exploring-CPython's-Internals/","text":"23. Exploring CPython\u2019s Internals\u00b6 23.1. CPython Source Code Layout\u00b6 23.2. Additional References\u00b6 23. Exploring CPython\u2019s Internals \u00b6 23.1. CPython Source Code Layout \u00b6 This guide gives an overview of CPython\u2019s code structure. It serves as a summary of file locations for modules and builtins. For Python modules , the typical layout is: Lib/<module>.py Modules/_<module>.c (if there\u2019s also a C accelerator module) Lib/test/test_<module>.py Doc/library/<module>.rst For extension-only modules, the typical layout is: Modules/<module>module.c Lib/test/test_<module>.py Doc/library/<module>.rst For builtin types, the typical layout is: Objects/<builtin>object.c Lib/test/test_<builtin>.py Doc/library/stdtypes.rst For builtin functions, the typical layout is: Python/bltinmodule.c Lib/test/test_builtin.py Doc/library/functions.rst Some exceptions: builtin type int is at Objects/longobject.c builtin type str is at Objects/unicodeobject.c builtin module sys is at Python/sysmodule.c builtin module marshal is at Python/marshal.c Windows-only module winreg is at PC/winreg.c 23.2. Additional References \u00b6 NOTE: \u5728CPython\u7684\u5b98\u65b9\u6587\u6863\u4e2d\u5e76\u6ca1\u6709\u53d1\u73b0\u4e13\u95e8\u5bf9CPython\u7684\u67b6\u6784\u8fdb\u884c\u4e13\u95e8\u4ecb\u7ecd\u7684\uff0c\u4e0b\u9762\u7684\u6587\u7ae0\u867d\u7136\u4e0d\u662f\u5b98\u65b9\u6587\u6863\uff0c\u4f46\u662f\u5185\u5bb9\u975e\u5e38\u597d\uff0c\u8bfb\u5b8c\u540e\uff0c\u57fa\u672c\u53ef\u4ee5\u638c\u63e1CPython\u7684\u67b6\u6784\u3002 For over 20 years the CPython code base has been changing and evolving. Here\u2019s a sample of resources about the architecture of CPython aimed at building your understanding of both the 2.x and 3.x versions of CPython: Current references \u00b6 Title Brief Author Version \u8bc4\u4ef7 A guide from parser to objects, observed using GDB Code walk from Parser, AST, Sym Table and Objects Louie Lu 3.7.a0 Green Tree Snakes The missing Python AST docs Thomas Kluyver 3.6 Yet another guided tour of CPython A guide for how CPython REPL works Guido van Rossum 3.5 \u4e2d\u56fd\u5927\u9646\u65e0\u6cd5\u8bbf\u95ee Python Asynchronous I/O Walkthrough How CPython async I/O, generator and coroutine works Philip Guo 3.5 Coding Patterns for Python Extensions Reliable patterns of coding Python Extensions in C Paul Ross 3.4 Your Guide to the CPython Source Code Your Guide to the CPython Source Code Anthony Shaw 3.8 \u975e\u5e38\u597d\uff0c\u975e\u5e38\u9002\u5408\u4e8e\u5165\u95e8\u3002 \u5982\u4e0b\u662f\u4e00\u4e9b\u8865\u5145\uff1a Guided tour to the CPython source code \u8fd0\u884ccpython Historical references \u00b6 Title Brief Author Version \u8bc4\u4ef7 Python\u2019s Innards Series ceval, objects, pystate and miscellaneous topics Yaniv Aknin 3.1 Eli Bendersky\u2019s Python Internals Objects, Symbol tables and miscellaneous topics Eli Bendersky 3.x A guide from parser to objects, observed using Eclipse Code walk from Parser, AST, Sym Table and Objects Prashanth Raghu 2.7.12 CPython internals: A ten-hour codewalk through the Python interpreter source code Code walk from source code to generators Philip Guo 2.7.8 \u4e3b\u8981\u662f\u89c6\u9891\uff0c\u4f46\u662f\u4e2d\u56fd\u5927\u9646\u65e0\u6cd5\u8bbf\u95ee","title":"23 Exploring CPython's Internals"},{"location":"Python/Language/Developer's-guide/23-Exploring-CPython's-Internals/23-Exploring-CPython's-Internals/#23-exploring-cpythons-internals","text":"","title":"23. Exploring CPython\u2019s Internals\u00b6"},{"location":"Python/Language/Developer's-guide/23-Exploring-CPython's-Internals/23-Exploring-CPython's-Internals/#231-cpython-source-code-layout","text":"This guide gives an overview of CPython\u2019s code structure. It serves as a summary of file locations for modules and builtins. For Python modules , the typical layout is: Lib/<module>.py Modules/_<module>.c (if there\u2019s also a C accelerator module) Lib/test/test_<module>.py Doc/library/<module>.rst For extension-only modules, the typical layout is: Modules/<module>module.c Lib/test/test_<module>.py Doc/library/<module>.rst For builtin types, the typical layout is: Objects/<builtin>object.c Lib/test/test_<builtin>.py Doc/library/stdtypes.rst For builtin functions, the typical layout is: Python/bltinmodule.c Lib/test/test_builtin.py Doc/library/functions.rst Some exceptions: builtin type int is at Objects/longobject.c builtin type str is at Objects/unicodeobject.c builtin module sys is at Python/sysmodule.c builtin module marshal is at Python/marshal.c Windows-only module winreg is at PC/winreg.c","title":"23.1. CPython Source Code Layout\u00b6"},{"location":"Python/Language/Developer's-guide/23-Exploring-CPython's-Internals/23-Exploring-CPython's-Internals/#232-additional-references","text":"NOTE: \u5728CPython\u7684\u5b98\u65b9\u6587\u6863\u4e2d\u5e76\u6ca1\u6709\u53d1\u73b0\u4e13\u95e8\u5bf9CPython\u7684\u67b6\u6784\u8fdb\u884c\u4e13\u95e8\u4ecb\u7ecd\u7684\uff0c\u4e0b\u9762\u7684\u6587\u7ae0\u867d\u7136\u4e0d\u662f\u5b98\u65b9\u6587\u6863\uff0c\u4f46\u662f\u5185\u5bb9\u975e\u5e38\u597d\uff0c\u8bfb\u5b8c\u540e\uff0c\u57fa\u672c\u53ef\u4ee5\u638c\u63e1CPython\u7684\u67b6\u6784\u3002 For over 20 years the CPython code base has been changing and evolving. Here\u2019s a sample of resources about the architecture of CPython aimed at building your understanding of both the 2.x and 3.x versions of CPython: Current references \u00b6 Title Brief Author Version \u8bc4\u4ef7 A guide from parser to objects, observed using GDB Code walk from Parser, AST, Sym Table and Objects Louie Lu 3.7.a0 Green Tree Snakes The missing Python AST docs Thomas Kluyver 3.6 Yet another guided tour of CPython A guide for how CPython REPL works Guido van Rossum 3.5 \u4e2d\u56fd\u5927\u9646\u65e0\u6cd5\u8bbf\u95ee Python Asynchronous I/O Walkthrough How CPython async I/O, generator and coroutine works Philip Guo 3.5 Coding Patterns for Python Extensions Reliable patterns of coding Python Extensions in C Paul Ross 3.4 Your Guide to the CPython Source Code Your Guide to the CPython Source Code Anthony Shaw 3.8 \u975e\u5e38\u597d\uff0c\u975e\u5e38\u9002\u5408\u4e8e\u5165\u95e8\u3002 \u5982\u4e0b\u662f\u4e00\u4e9b\u8865\u5145\uff1a Guided tour to the CPython source code \u8fd0\u884ccpython Historical references \u00b6 Title Brief Author Version \u8bc4\u4ef7 Python\u2019s Innards Series ceval, objects, pystate and miscellaneous topics Yaniv Aknin 3.1 Eli Bendersky\u2019s Python Internals Objects, Symbol tables and miscellaneous topics Eli Bendersky 3.x A guide from parser to objects, observed using Eclipse Code walk from Parser, AST, Sym Table and Objects Prashanth Raghu 2.7.12 CPython internals: A ten-hour codewalk through the Python interpreter source code Code walk from source code to generators Philip Guo 2.7.8 \u4e3b\u8981\u662f\u89c6\u9891\uff0c\u4f46\u662f\u4e2d\u56fd\u5927\u9646\u65e0\u6cd5\u8bbf\u95ee","title":"23.2. Additional References\u00b6"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/25-Design-of-CPython's-Compiler/","text":"25. Design of CPython\u2019s Compiler \u00b6 25.1. Abstract \u00b6 In CPython, the compilation from source code to bytecode involves several steps: Parse source code into a parse tree ( Parser/pgen.c ) Transform parse tree into an Abstract Syntax Tree ( Python/ast.c ) Transform AST into a Control Flow Graph ( Python/compile.c ) Emit bytecode based on the Control Flow Graph ( Python/compile.c ) The purpose of this document is to outline how these steps of the process work. This document does not touch on how parsing works beyond what is needed to explain what is needed for compilation. It is also not exhaustive in terms of the how the entire system works. You will most likely need to read some source to have an exact understanding of all details. 25.2. Parse Trees \u00b6 Python\u2019s parser is an LL(1) parser mostly based off of the implementation laid out in the Dragon Book [ Aho86] . The grammar file for Python can be found in Grammar/Grammar with the numeric value of grammar rules stored in Include/graminit.h . The list of types of tokens (literal tokens, such as : , numbers, etc.) can be found in Grammar/Tokens with the numeric value stored in Include/token.h . The parse tree is made up of node * structs (as defined in Include/node.h ). Querying data from the node structs can be done with the following macros (which are all defined in Include/node.h ): CHILD(node *, int) Returns the nth child of the node using zero-offset indexing RCHILD(node *, int) Returns the nth child of the node from the right side; use negative numbers! NCH(node *) Number of children the node has STR(node *) String representation of the node; e.g., will return : for a COLON token TYPE(node *) The type of node as specified in Include/graminit.h REQ(node *, TYPE) Assert that the node is the type that is expected LINENO(node *) Retrieve the line number of the source code that led to the creation of the parse rule; defined in Python/ast.c For example, consider the rule for \u2018while\u2019: while_stmt ::= \"while\" expression \":\" suite : [\"else\" \":\" suite] The node representing this will have TYPE(node) == while_stmt and the number of children can be 4 or 7 depending on whether there is an \u2018else\u2019 statement. REQ(CHILD(node, 2), COLON) can be used to access what should be the first : and require it be an actual : token. 25.3. Abstract Syntax Trees (AST) \u00b6 The abstract syntax tree (AST) is a high-level representation of the program structure without the necessity of containing the source code; it can be thought of as an abstract representation of the source code. The specification of the AST nodes is specified using the Zephyr Abstract Syntax Definition Language (ASDL) [ Wang97] . Green Tree Snakes See also Green Tree Snakes - the missing Python AST docs by Thomas Kluyver. The definition of the AST nodes for Python is found in the file Parser/Python.asdl . 25.12. References \u00b6 [ Aho86] Alfred V. Aho, Ravi Sethi, Jeffrey D. Ullman. Compilers: Principles, Techniques, and Tools, https://www.amazon.com/exec/obidos/tg/detail/-/0201100886/104-0162389-6419108 [ Wang97] Daniel C. Wang, Andrew W. Appel, Jeff L. Korn, and Chris S. Serra. The Zephyr Abstract Syntax Description Language. In Proceedings of the Conference on Domain-Specific Languages, pp. 213\u2013227, 1997.","title":"25. Design of CPython\u2019s Compiler[\u00b6](https://devguide.python.org/compiler/#design-of-cpython-s-compiler)"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/25-Design-of-CPython's-Compiler/#25-design-of-cpythons-compiler","text":"","title":"25. Design of CPython\u2019s Compiler\u00b6"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/25-Design-of-CPython's-Compiler/#251-abstract","text":"In CPython, the compilation from source code to bytecode involves several steps: Parse source code into a parse tree ( Parser/pgen.c ) Transform parse tree into an Abstract Syntax Tree ( Python/ast.c ) Transform AST into a Control Flow Graph ( Python/compile.c ) Emit bytecode based on the Control Flow Graph ( Python/compile.c ) The purpose of this document is to outline how these steps of the process work. This document does not touch on how parsing works beyond what is needed to explain what is needed for compilation. It is also not exhaustive in terms of the how the entire system works. You will most likely need to read some source to have an exact understanding of all details.","title":"25.1. Abstract\u00b6"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/25-Design-of-CPython's-Compiler/#252-parse-trees","text":"Python\u2019s parser is an LL(1) parser mostly based off of the implementation laid out in the Dragon Book [ Aho86] . The grammar file for Python can be found in Grammar/Grammar with the numeric value of grammar rules stored in Include/graminit.h . The list of types of tokens (literal tokens, such as : , numbers, etc.) can be found in Grammar/Tokens with the numeric value stored in Include/token.h . The parse tree is made up of node * structs (as defined in Include/node.h ). Querying data from the node structs can be done with the following macros (which are all defined in Include/node.h ): CHILD(node *, int) Returns the nth child of the node using zero-offset indexing RCHILD(node *, int) Returns the nth child of the node from the right side; use negative numbers! NCH(node *) Number of children the node has STR(node *) String representation of the node; e.g., will return : for a COLON token TYPE(node *) The type of node as specified in Include/graminit.h REQ(node *, TYPE) Assert that the node is the type that is expected LINENO(node *) Retrieve the line number of the source code that led to the creation of the parse rule; defined in Python/ast.c For example, consider the rule for \u2018while\u2019: while_stmt ::= \"while\" expression \":\" suite : [\"else\" \":\" suite] The node representing this will have TYPE(node) == while_stmt and the number of children can be 4 or 7 depending on whether there is an \u2018else\u2019 statement. REQ(CHILD(node, 2), COLON) can be used to access what should be the first : and require it be an actual : token.","title":"25.2. Parse Trees\u00b6"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/25-Design-of-CPython's-Compiler/#253-abstract-syntax-trees-ast","text":"The abstract syntax tree (AST) is a high-level representation of the program structure without the necessity of containing the source code; it can be thought of as an abstract representation of the source code. The specification of the AST nodes is specified using the Zephyr Abstract Syntax Definition Language (ASDL) [ Wang97] . Green Tree Snakes See also Green Tree Snakes - the missing Python AST docs by Thomas Kluyver. The definition of the AST nodes for Python is found in the file Parser/Python.asdl .","title":"25.3. Abstract Syntax Trees (AST)\u00b6"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/25-Design-of-CPython's-Compiler/#2512-references","text":"[ Aho86] Alfred V. Aho, Ravi Sethi, Jeffrey D. Ullman. Compilers: Principles, Techniques, and Tools, https://www.amazon.com/exec/obidos/tg/detail/-/0201100886/104-0162389-6419108 [ Wang97] Daniel C. Wang, Andrew W. Appel, Jeff L. Korn, and Chris S. Serra. The Zephyr Abstract Syntax Description Language. In Proceedings of the Conference on Domain-Specific Languages, pp. 213\u2013227, 1997.","title":"25.12. References\u00b6"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/CPython-grammar/","text":"python3.8\u4f7f\u7528\u7684\u8bed\u6cd5\u662f Parsing expression grammar \u5982\u4e0b\u662fpython\u4e4b\u7236\u5bf9\u6b64\u7684\u4ecb\u7ecd\uff1a PEG Parsers Python\u4e4b\u7236\u65b0\u53d1\u6587\uff0c\u5c06\u66ff\u6362\u73b0\u6709\u89e3\u6790\u5668","title":"CPython grammar"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/CPython-grammar/#python","text":"","title":"Python\u4e4b\u7236\u65b0\u53d1\u6587\uff0c\u5c06\u66ff\u6362\u73b0\u6709\u89e3\u6790\u5668"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/cpython-symbol-table/","text":"Python internals: Symbol tables, part 1 Symbol table","title":"[Python internals: Symbol tables, part 1](https://eli.thegreenplace.net/2010/09/18/python-internals-symbol-tables-part-1)"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/cpython-symbol-table/#python-internals-symbol-tables-part-1","text":"","title":"Python internals: Symbol tables, part 1"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/cpython-symbol-table/#symbol-table","text":"","title":"Symbol table"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/website-CPython-Compiler-Tools/","text":"","title":"website CPython Compiler Tools"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/","text":"Guido-van-Rossum-PEG-parser-series\u4e2d\u6240\u63cf\u8ff0\u7684\u662fpython\u4e4b\u7236 Guido van Rossum \u5173\u4e8e\u91cd\u5199python parser\u7684\u6587\u7ae0\uff0c\u4ed6\u7684\u8ba1\u5212\u662f\u91c7\u7528PEG ( Parsing Expression Grammars )\u6765\u66ff\u4ee3\u73b0\u5728\u7684python\u8bed\u6cd5\uff0c\u5e76\u4f7f\u7528 PEG parser \u3002 \u76ee\u524dpython\u7684\u6700\u65b0\u7248\u672c\u8fd8\u6ca1\u6709\u91c7\u7eb3 Guido van Rossum \u7684\u4e0a\u8ff0\u8ba1\u5212\uff0c\u76ee\u524dpython\u7684\u8bed\u6cd5\u8fd8\u662f\u4f7f\u7528\u7684\u88ab Guido van Rossum \u79f0\u4e3aEBNF-like grammar \uff0c\u6240\u4f7f\u7528\u7684parser\u8fd8\u662f LL(1) parser \u3002","title":"Home"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/Guido-van-Rossum-PEG-parser-series/01-PEG-Parsers/","text":"PEG Parsers Some years ago someone asked whether it would make sense to switch Python to a PEG parser . (Or a PEG grammar; I don\u2019t recall exactly what was said by whom, or when.) I looked into it a bit and wasn\u2019t sure what to think, so I dropped the subject. Recently I\u2019ve learned more about PEG ( Parsing Expression Grammars ), and I now think it\u2019s an interesting alternative to the home-grown parser generator that I developed 30 years ago when I started working on Python. (That parser generator, dubbed \u201cpgen\u201d, was just about the first piece of code I wrote for Python.) [This is part 1 of my PEG series. See the Series Overview for the rest.] The reason I\u2019m now interested in PEG parsing is that I\u2019ve become somewhat annoyed with pgen\u2019s limitations. It uses a variant of LL(1) parsing that I cooked up myself \u2014 I didn\u2019t like grammar rules that could produce the empty string, so I disallowed that, thereby simplifying the algorithm for producing parsing tables somewhat. I also invented my own EBNF-like grammar notation, which I still like very much. Here are some of the issues with pgen that annoy me. The \u201c1\u201d in the LL(1) moniker implies that it uses only a single token lookahead, and this limits our ability of writing nice grammar rules. For example, a Python statement can be an expression or an assignment (or other things, but those all start with a dedicated keyword like if or def ). We\u2019d like to write this syntax as follows using the pgen notation. (Note that this example describes a toy language that is a tiny subset of Python, as is traditional in writing about language design.) statement: assignment | expr | if_statement expr: expr '+' term | expr '-' term | term term: term '*' atom | term '/' atom | atom atom: NAME | NUMBER | '(' expr ')' assignment: target '=' expr target: NAME if_statement: 'if' expr ':' statement A few words about the notation: NAME and NUMBER are tokens and predefined outside the grammar. Strings in quotes like '+' or 'if' are are also tokens. (I should talk about tokens some other time.) Grammar rules start with a rule name followed by : , followed by one or more alternatives separated by | . The problem is that if you write the grammar like this, the parser does not work, and pgen will complain. One of the issues is that some rules ( expr and term ) are left-recursive , and pgen isn\u2019t smart enough to do the right thing here. This is typically solved by rewriting those rules, for example (leaving the other rules unchanged): expr: term ('+' term | '-' term)* term: atom ('*' atom | '/' atom)* This reveals a few bits of pgen\u2019s EBNF capabilities: you can nest alternatives inside parentheses, and you can create repetitions by placing * after an item, so the rule for expr here means \u201cit\u2019s a term, followed by zero or more repetitions of plus followed by a term or minus followed by a term\u201d. This grammar accepts the same language as the first version, but it doesn\u2019t reflect the intent of the language designer as well \u2014 in particular, it doesn\u2019t show that the operators are left-binding , which is important when you are trying to generate code. But there\u2019s another annoying problem in this toy language (and in Python). Because of the single-token lookahead, the parser cannot determine whether it is looking at the start of an expression or an assignment. At the beginning of a statement, the parser needs to decide what alternative for statement it is seeing from the first token it sees. (Why? This is how pgen\u2019s parsing automation works.) Let\u2019s say our program is this: answer = 42 This program is tokenized into three tokens: NAME (with value answer ), '=' , and NUMBER (with value 42 ). The only lookahead we have at the start of the program is the first token, NAME . The rule we are trying to satisfy at this point is statement (the grammar\u2019s start symbol). This rule has three alternatives: expr , assignment , and if_statement . We can rule out if_statement , because the lookahead token isn\u2019t 'if' . But both expr and assignment (can) start with a NAME token, and because of this pgen rejects our grammar as being ambiguous. (That\u2019s not entirely correct, since technically the grammar isn\u2019t ambiguous per se; but we\u2019ll ignore this because I don\u2019t know if there\u2019s a better word. And how does pgen decide this? It computes something called the FIRST set for each grammar rule, and it complains if the FIRST sets of the choices at any given point overlap.) So couldn\u2019t we solve this annoyance by giving the parser a larger lookahead buffer? For our toy example, a second lookahead token would be enough, since in this grammar the second token of an assignment must be '=' . But in a more realistic language like Python, you may need an unlimited lookahead buffer, since the stuff to the left of the '=' token may be arbitrarily complex, for example: table[index + 1].name.first = 'Steven' That\u2019s already ten tokens before we encounter the '=' token, and I could cook up arbitrary long examples if challenged. What we\u2019ve done to solve this in pgen is to change the grammar to accept some illegal programs, adding an extra check in a later pass that generates a SyntaxError if it finds an invalid left-hand side for an assignment. For our toy language, this comes down to writing the following: statement: assignment_or_expr | if_statement assignment_or_expr: expr ['=' expr] (The square brackets indicate an optional part.) And then in a subsequent compiler pass (say, when generating bytecode) we check whether there\u2019s an '=' or not, and if there is, we check that the left-hand side follows the syntax for target . There\u2019s a similar annoyance around keyword arguments in function calls. We would like to write something like this (again, a simplified version of Python\u2019s call syntax): call: atom '(' arguments ')' arguments: arg (',' arg)* arg: posarg | kwarg posarg: expr kwarg: NAME '=' expr But the single-token lookahead can\u2019t to tell the parser whether a NAME at the start of an argument is the beginning of posarg (since expr may start with NAME ) or the beginning of kwarg . Again, Python\u2019s current parser solves this by essentially stating arg: expr ['=' expr] and then sorting out the cases in a subsequent compiler pass. (We even got this slightly wrong and allowed things like foo((a)=1) , giving it the same meaning as foo(a=1) , until we fixed it in Python 3.8.) So how does a PEG parser solve these annoyances? By using an infinite lookahead buffer ! The typical implementation of a PEG parser uses something called \u201cpackrat parsing\u201d, which not only loads the entire program in memory before parsing it, but also allows the parser to backtrack arbitrarily. While the term PEG primarily refers to the grammar notation, the parsers generated from PEG grammars are typically recursive-descent parsers with unlimited backtracking, and packrat parsing makes this efficient by memoizing the rules already matched for each position. This makes everything easy, but of course there\u2019s a cost: memory. Thirty years ago, I had a good reason to use a parsing technology with a single token lookahead: memory was expensive. LL(1) parsing (and other technologies like LALR(1), made famous by YACC) uses a state machine and a stack (a \u201cpush-down automaton\u201d) to construct a parse tree efficiently. Fortunately the computers on which CPython runs have a lot more memory than 30 years ago, and keeping the entire file in memory really isn\u2019t much of a burden any more. For example, the largest non-test file in the stdlib that I could find is _pydecimal.py , which clocks in at around 223 kilobytes. In a Gigabyte world, that\u2019s essentially nothing. And that\u2019s what led me to have another look at parsing technology. But there\u2019s another thing about CPython\u2019s current parser that bugs me. Compilers are complicated things, and CPython\u2019s is no exception: while the output of the pgen-generated parser is a parse tree , this parse tree is not directly used as the input to the code generator : first it is transformed to an abstract syntax tree (AST), and then that AST is compiled into bytecode . (There\u2019s more to it, but that\u2019s not my focus here.) Why not compile from the parse tree ? That is how it originally worked, but about 15 years ago we found that the compiler was complicated by the structure of the parse tree , and we introduced a separate AST, and a separate translation phase from parse tree to AST. As Python evolves, the AST is more stable than the parse tree , so this reduces the opportunity for bugs in the compiler. The AST is also easier to work with for third-party code that wants to inspect Python code, and is exposed through the popular ast module. This module also lets you construct AST nodes from scratch and modify existing AST nodes, and you can compile the new nodes to bytecode. The latter has enabled an entire cottage industry of language extensions for Python. (The parse tree is also exposed to Python users, via the parser module, but it is much more cumbersome to work with; therefore it has gone out of style in favor of the ast module.) My idea now, putting these things together, is to see if we can create a new parser for CPython that uses PEG and packrat parsing to construct the AST directly during parsing, thereby skipping the intermediate parse tree construction, possibly saving memory despite using an infinite lookahead buffer. I\u2019m not there yet, but I have a prototype that can compile a subset of Python into an AST at about the same speed as CPython\u2019s current parser. It uses more memory, however, and I expect that extending the subset to the full language will slow down the PEG parser. But I also haven\u2019t done anything to optimize it, so I am hopeful. A final advantage of switching to PEG is that it provides more flexibility for future evolution of the language. In the past it\u2019s been said that pgen\u2019s LL(1) restrictions have helped Python\u2019s grammar stay simple. That may well be so, but we have plenty of other processes in place to prevent unchecked growth of the language (mainly the PEP process, aided by very strict backwards compatibility requirements and the new governance structure). So I\u2019m not worried. I have a lot more to write about PEG parsing and my specific implementation, but I\u2019ll write about that in a later post , after I\u2019ve cleaned up the code. License for this article and the code shown: CC BY-NC-SA 4.0","title":"[PEG Parsers](https://medium.com/@gvanrossum_83706/peg-parsers-7ed72462f97c)"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/Guido-van-Rossum-PEG-parser-series/01-PEG-Parsers/#peg-parsers","text":"Some years ago someone asked whether it would make sense to switch Python to a PEG parser . (Or a PEG grammar; I don\u2019t recall exactly what was said by whom, or when.) I looked into it a bit and wasn\u2019t sure what to think, so I dropped the subject. Recently I\u2019ve learned more about PEG ( Parsing Expression Grammars ), and I now think it\u2019s an interesting alternative to the home-grown parser generator that I developed 30 years ago when I started working on Python. (That parser generator, dubbed \u201cpgen\u201d, was just about the first piece of code I wrote for Python.) [This is part 1 of my PEG series. See the Series Overview for the rest.] The reason I\u2019m now interested in PEG parsing is that I\u2019ve become somewhat annoyed with pgen\u2019s limitations. It uses a variant of LL(1) parsing that I cooked up myself \u2014 I didn\u2019t like grammar rules that could produce the empty string, so I disallowed that, thereby simplifying the algorithm for producing parsing tables somewhat. I also invented my own EBNF-like grammar notation, which I still like very much. Here are some of the issues with pgen that annoy me. The \u201c1\u201d in the LL(1) moniker implies that it uses only a single token lookahead, and this limits our ability of writing nice grammar rules. For example, a Python statement can be an expression or an assignment (or other things, but those all start with a dedicated keyword like if or def ). We\u2019d like to write this syntax as follows using the pgen notation. (Note that this example describes a toy language that is a tiny subset of Python, as is traditional in writing about language design.) statement: assignment | expr | if_statement expr: expr '+' term | expr '-' term | term term: term '*' atom | term '/' atom | atom atom: NAME | NUMBER | '(' expr ')' assignment: target '=' expr target: NAME if_statement: 'if' expr ':' statement A few words about the notation: NAME and NUMBER are tokens and predefined outside the grammar. Strings in quotes like '+' or 'if' are are also tokens. (I should talk about tokens some other time.) Grammar rules start with a rule name followed by : , followed by one or more alternatives separated by | . The problem is that if you write the grammar like this, the parser does not work, and pgen will complain. One of the issues is that some rules ( expr and term ) are left-recursive , and pgen isn\u2019t smart enough to do the right thing here. This is typically solved by rewriting those rules, for example (leaving the other rules unchanged): expr: term ('+' term | '-' term)* term: atom ('*' atom | '/' atom)* This reveals a few bits of pgen\u2019s EBNF capabilities: you can nest alternatives inside parentheses, and you can create repetitions by placing * after an item, so the rule for expr here means \u201cit\u2019s a term, followed by zero or more repetitions of plus followed by a term or minus followed by a term\u201d. This grammar accepts the same language as the first version, but it doesn\u2019t reflect the intent of the language designer as well \u2014 in particular, it doesn\u2019t show that the operators are left-binding , which is important when you are trying to generate code. But there\u2019s another annoying problem in this toy language (and in Python). Because of the single-token lookahead, the parser cannot determine whether it is looking at the start of an expression or an assignment. At the beginning of a statement, the parser needs to decide what alternative for statement it is seeing from the first token it sees. (Why? This is how pgen\u2019s parsing automation works.) Let\u2019s say our program is this: answer = 42 This program is tokenized into three tokens: NAME (with value answer ), '=' , and NUMBER (with value 42 ). The only lookahead we have at the start of the program is the first token, NAME . The rule we are trying to satisfy at this point is statement (the grammar\u2019s start symbol). This rule has three alternatives: expr , assignment , and if_statement . We can rule out if_statement , because the lookahead token isn\u2019t 'if' . But both expr and assignment (can) start with a NAME token, and because of this pgen rejects our grammar as being ambiguous. (That\u2019s not entirely correct, since technically the grammar isn\u2019t ambiguous per se; but we\u2019ll ignore this because I don\u2019t know if there\u2019s a better word. And how does pgen decide this? It computes something called the FIRST set for each grammar rule, and it complains if the FIRST sets of the choices at any given point overlap.) So couldn\u2019t we solve this annoyance by giving the parser a larger lookahead buffer? For our toy example, a second lookahead token would be enough, since in this grammar the second token of an assignment must be '=' . But in a more realistic language like Python, you may need an unlimited lookahead buffer, since the stuff to the left of the '=' token may be arbitrarily complex, for example: table[index + 1].name.first = 'Steven' That\u2019s already ten tokens before we encounter the '=' token, and I could cook up arbitrary long examples if challenged. What we\u2019ve done to solve this in pgen is to change the grammar to accept some illegal programs, adding an extra check in a later pass that generates a SyntaxError if it finds an invalid left-hand side for an assignment. For our toy language, this comes down to writing the following: statement: assignment_or_expr | if_statement assignment_or_expr: expr ['=' expr] (The square brackets indicate an optional part.) And then in a subsequent compiler pass (say, when generating bytecode) we check whether there\u2019s an '=' or not, and if there is, we check that the left-hand side follows the syntax for target . There\u2019s a similar annoyance around keyword arguments in function calls. We would like to write something like this (again, a simplified version of Python\u2019s call syntax): call: atom '(' arguments ')' arguments: arg (',' arg)* arg: posarg | kwarg posarg: expr kwarg: NAME '=' expr But the single-token lookahead can\u2019t to tell the parser whether a NAME at the start of an argument is the beginning of posarg (since expr may start with NAME ) or the beginning of kwarg . Again, Python\u2019s current parser solves this by essentially stating arg: expr ['=' expr] and then sorting out the cases in a subsequent compiler pass. (We even got this slightly wrong and allowed things like foo((a)=1) , giving it the same meaning as foo(a=1) , until we fixed it in Python 3.8.) So how does a PEG parser solve these annoyances? By using an infinite lookahead buffer ! The typical implementation of a PEG parser uses something called \u201cpackrat parsing\u201d, which not only loads the entire program in memory before parsing it, but also allows the parser to backtrack arbitrarily. While the term PEG primarily refers to the grammar notation, the parsers generated from PEG grammars are typically recursive-descent parsers with unlimited backtracking, and packrat parsing makes this efficient by memoizing the rules already matched for each position. This makes everything easy, but of course there\u2019s a cost: memory. Thirty years ago, I had a good reason to use a parsing technology with a single token lookahead: memory was expensive. LL(1) parsing (and other technologies like LALR(1), made famous by YACC) uses a state machine and a stack (a \u201cpush-down automaton\u201d) to construct a parse tree efficiently. Fortunately the computers on which CPython runs have a lot more memory than 30 years ago, and keeping the entire file in memory really isn\u2019t much of a burden any more. For example, the largest non-test file in the stdlib that I could find is _pydecimal.py , which clocks in at around 223 kilobytes. In a Gigabyte world, that\u2019s essentially nothing. And that\u2019s what led me to have another look at parsing technology. But there\u2019s another thing about CPython\u2019s current parser that bugs me. Compilers are complicated things, and CPython\u2019s is no exception: while the output of the pgen-generated parser is a parse tree , this parse tree is not directly used as the input to the code generator : first it is transformed to an abstract syntax tree (AST), and then that AST is compiled into bytecode . (There\u2019s more to it, but that\u2019s not my focus here.) Why not compile from the parse tree ? That is how it originally worked, but about 15 years ago we found that the compiler was complicated by the structure of the parse tree , and we introduced a separate AST, and a separate translation phase from parse tree to AST. As Python evolves, the AST is more stable than the parse tree , so this reduces the opportunity for bugs in the compiler. The AST is also easier to work with for third-party code that wants to inspect Python code, and is exposed through the popular ast module. This module also lets you construct AST nodes from scratch and modify existing AST nodes, and you can compile the new nodes to bytecode. The latter has enabled an entire cottage industry of language extensions for Python. (The parse tree is also exposed to Python users, via the parser module, but it is much more cumbersome to work with; therefore it has gone out of style in favor of the ast module.) My idea now, putting these things together, is to see if we can create a new parser for CPython that uses PEG and packrat parsing to construct the AST directly during parsing, thereby skipping the intermediate parse tree construction, possibly saving memory despite using an infinite lookahead buffer. I\u2019m not there yet, but I have a prototype that can compile a subset of Python into an AST at about the same speed as CPython\u2019s current parser. It uses more memory, however, and I expect that extending the subset to the full language will slow down the PEG parser. But I also haven\u2019t done anything to optimize it, so I am hopeful. A final advantage of switching to PEG is that it provides more flexibility for future evolution of the language. In the past it\u2019s been said that pgen\u2019s LL(1) restrictions have helped Python\u2019s grammar stay simple. That may well be so, but we have plenty of other processes in place to prevent unchecked growth of the language (mainly the PEP process, aided by very strict backwards compatibility requirements and the new governance structure). So I\u2019m not worried. I have a lot more to write about PEG parsing and my specific implementation, but I\u2019ll write about that in a later post , after I\u2019ve cleaned up the code. License for this article and the code shown: CC BY-NC-SA 4.0","title":"PEG Parsers"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/Guido-van-Rossum-PEG-parser-series/02-Building-a-PEG-Parser/","text":"Building a PEG Parser Inspired by only a partial understanding of PEG parsing I decided to build one. The result may not be a great general-purpose PEG parser generator \u2014 there are already many of those (e.g. TatSu is written in Python and generates Python code) \u2014 but it was a good way to learn about PEG , and it furthers my goal of replacing CPython\u2019s parser with one built from a PEG grammar. [This is part 2 of my PEG series. See the Series Overview for the rest.] In this section I lay the groundwork for understanding how the generated parser works, by showing a simple hand-written parser . (By the way, as an experiment, I\u2019m not sprinkling links all over my writings. If there\u2019s something you don\u2019t understand, just Google it. :-) The most common way of PEG parsing uses a recursive descent parser with unlimited backtracking . Take the toy grammar from last week\u2019s article: statement: assignment | expr | if_statement expr: expr '+' term | expr '-' term | term term: term '*' atom | term '/' atom | atom atom: NAME | NUMBER | '(' expr ')' assignment: target '=' expr target: NAME if_statement: 'if' expr ':' statement A super-abstract recursive descent parser for this language would define a function for each symbol that tries to call the functions corresponding to the alternatives. For example, for statement we\u2019d have this function: def statement (): if assignment (): return True if expr (): return True if if_statement (): return True return False Of course this is too simplistic: it leaves out essential details about the parser \u2019s input and output. Let\u2019s start with the input side. Classic parsers use a separate tokenizer which breaks the input (a text file or string) into a series of tokens , such as keywords, identifiers (names), numbers and operators. PEG parsers (like other modern parsers such as ANTLR) often unify tokenizing and parsing, but for my project I chose to keep the separate tokenizer . Tokenizing Python is complicated enough that I don\u2019t want to reimplement it using PEG \u2019s formalism. For example, you have to keep track of indentation (this requires a stack inside the tokenizer), and the handling of newlines in Python is interesting (they are significant except inside matching brackets). The many types of string quotes also cause some complexity. In short, I have no beef with Python\u2019s existing tokenizer, so I want to keep it. (Aside: CPython has two tokenizers \u2014an internal one used by the parser , written in C, and the standard library one, which is a faithful reimplementation in pure Python. This is helpful for my project.) Classic tokenizers typically have a simple interface whereby you call a function, e.g. get_token() , which returns the next token in the input, consuming the input a few characters at a time. The tokenize module simplifies this even further: its basic API is a generator which yields one token at a time. Each token is a TypeInfo object which has several fields, the most important ones of which indicate the type of the token (e.g. NAME , NUMBER , STRING ), and its string value, meaning the string of characters comprising the token (e.g. abc , 42 , or \"hello world\" ). There are also additional fields that give the coordinates of the token in the input file, which is useful for error reporting. A special token type is ENDMARKER , which indicates that the end of the input file has been reached. The generator terminates if you ignore this and try to get the next token. But I digress. How do we implement unlimited backtracking ? Backtracking requires you to be able to remember a position in the source code and re-parse from that point. The tokenizer API doesn\u2019t allow us to reset its input pointer, but it\u2019s easy to capture the stream of tokens in an array and replay it from there, so that\u2019s what we do. (You could also do this using itertools.tee() , but based on warnings in the docs that\u2019s probably less efficient in our case.) I suppose you could just first tokenize the entire input into a Python list and then use that as the parser input, but that would mean if there\u2019s an invalid token near the end of the file (such as a string with a missing closing quote) and there\u2019s also a syntax error earlier in the file, you would get an error message about the bad token first. I would find that a poor user experience, since the syntax error could actually be the root cause for the bad string. So my design tokenizes on demand, and the list becomes a lazy list. The basic API is very simple. The Tokenizer object encapsulates the array of tokens and the position in that array. It has three basic methods: get_token() returns the next token, advancing the position in the array (reading another token from the source if we\u2019re at the end of the array); mark() returns the current position in the array; reset(pos) sets the position in the array (the argument must be something you got from mark() ). We add one convenience function, peek_token() which returns the next token without advancing the position. Here, then, is the core of the Tokenizer class: class Tokenizer : def __init__ ( self , tokengen ): \"\"\"Call with tokenize.generate_tokens(...).\"\"\" self . tokengen = tokengen self . tokens = [] self . pos = 0 def mark ( self ): return self . pos def reset ( self , pos ): self . pos = pos def get_token ( self ): token = self . peek_token () self . pos += 1 return token def peek_token ( self ): if self . pos == len ( self . tokens ): self . tokens . append ( next ( self . tokengen )) return self . tokens [ self . pos ] Now, there are various things still missing (and the names of the methods and instance variables should really start with an underscore), but this will do as a sketch of the Tokenizer API. The parser also needs to become a class, so that statement() , expr() and so on can become methods. The tokenizer becomes an instance variable, but we don\u2019t want the parsing methods to call get_token() directly \u2014 instead, we give the **Parser** class an expect() method which can succeed or fail just like a parsing method. The argument to expect() is the expected token \u2014 either a string (like \"+\" ) or a token type (like NAME ). I\u2019ll get to the return type after discussing the parser \u2019s output. In my first sketch of the parser , the parsing functions just returned True or False . That\u2019s fine for theoretical computer science (where the question a parser answers is \u201cis this a valid string in the language?\u201d) but not when you\u2019re building a parser \u2014 instead, we want the parser to create an AST. So let\u2019s just arrange it so that each parsing method returns a Node object on success, or None on failure. The Node class can be super simple: class Node : def __init__ ( self , type , children ): self . type = type self . children = children Here, type indicates what kind of AST node this is (e.g. an \"add\" node or an \"if\" node), and children is a list of nodes and tokens (instances of TokenInfo ). This is enough for a compiler to generate code or do other analysis such as linting or static type checking, although in the future I\u2019d like to change the way we represent the AST. To fit into this scheme, the expect() method returns a TokenInfo object on success, and None on failure. To support backtracking, I wrap the tokenizer\u2019s mark() and reset() methods (no API change here). Here then is the infrastructure for the **Parser** class: class Parser : def __init__ ( self , tokenizer ): self . tokenizer = tokenizer def mark ( self ): return self . tokenizer . mark () def reset ( self , pos ): self . tokenizer . reset ( pos ) def expect ( self , arg ): token = self . tokenizer . peek_token () if token . type == arg or token . string == arg : return self . tokenizer . get_token () return None Again, I\u2019ve left out some details, but this works. At this point I need to introduce an important requirement for parsing methods: a parsing method either returns a Node , positioning the tokenizer after the last token of the grammar rule it recognized; or it returns None , and then it leaves the tokenizer position unchanged . If a parsing method reads several tokens and then decides to fail, it must restore the tokenizer\u2019s position. That\u2019s what mark() and reset() are for. Note that expect() also follows this rule. So here\u2019s a sketch of the actual parser . Note that I am using Python 3.8\u2019s walrus operator ( := ): class ToyParser ( Parser ): def statement ( self ): if a : = self . assignment (): return a if e : = self . expr (): return e if i : = self . if_statement (): return i return None def expr ( self ): if t : = self . term (): pos = self . mark () if op : = self . expect ( \"+\" ): if e : = self . expr (): return Node ( \"add\" , [ t , e ]) self . reset ( pos ) if op : = self . expect ( \"-\" ): if e : = self . expr (): return Node ( \"sub\" , [ t , e ]) self . reset ( pos ) return t return None def term ( self ): # Very similar... def atom ( self ): if token : = self . expect ( NAME ): return token if token : = self . expect ( NUMBER ): return token pos = self . mark () if self . expect ( \"(\" ): if e : = self . expr (): if self . expect ( \")\" ): return e self . reset ( pos ) return None I\u2019ve left some parsing methods as exercises for the reader \u2014 this is really more to give a flavor of what such a parser looks like, and eventually we\u2019ll generate code like this automatically from the grammar. Constants like NAME and NUMBER are imported from the token module in the standard library. (This ties us further to Python tokenization; there are ways around this that we should explore if we want to make a more general PEG parser generator.) Also note that I cheated a bit: expr is left-recursive, but I made the parser *right-*recursive, because recursive-descent parsers don\u2019t work with left-recursive grammar rules. There\u2019s a fix for this, but it\u2019s still the topic of some academic research and I\u2019d like to present it separately. Just realize that this version doesn\u2019t correspond 100% with the toy grammar. The key things I want you to get at this point are: Grammar rules correspond to parser methods, and when a grammar rule references another grammar rule, its parsing method calls the other rule\u2019s parsing method. When multiple items make up an alternative, the parsing method calls the corresponding methods one after the other. When a grammar rule references a token, its parsing method calls expect() . When a parsing method successfully recognizes its grammar rule at the given input position, it returns a corresponding AST node; when it fails to recognize its grammar rule, it returns None . Parsing methods must explicitly reset the tokenizer position when they abandon a parse after having consumed one or more tokens (directly, or indirectly by calling another parsing method that succeeded). This applies when abandoning one alternative to try the next, and also when abandoning the parse altogether. If all parsing methods abide by these rules, it\u2019s not necessary to use mark() and reset() around a single parsing method. You can prove this using induction. As an aside, it\u2019s tempting to try to get rid of the explicit mark() and reset() calls by using a context manager and a with statement, but this doesn\u2019t work: the reset() call shouldn\u2019t be called upon success! As a further fix you could try to use exceptions for control flow, so the context manager knows whether to reset the tokenizer (I think TatSu does something like this). For example, you could arrange for this to work: def statement(self): with self.alt(): return self.assignment() with self.alt(): return self.expr() with self.alt(): return self.if_statement() raise ParsingFailure In particular, the little ladder of if statements in atom() for recognizing a parenthesized expression could become: with self . alt (): self . expect ( \"(\" ) e = self . expr () self . expect ( \")\" ) return e But I find this too \u201cmagical\u201d \u2014 when reading such code you must stay aware that each parsing method (and expect() ) may raise an exception, and that this exception is caught and ignored by the context manager in the with statement. That\u2019s pretty unusual, although definitely supported (by returning true from __exit__ ). Also, my ultimate goal is to generate C, not Python, and in C there\u2019s no with statement to alter the control flow. Anyway, here are some topics for future installments: generating parsing code from the grammar; packrat parsing (memoization); EBNF features like (x | y) , [x y ...] , x* , x+ ; tracing (for debugging the parser or grammar); PEG features like lookahead and \u201ccut\u201d; how to handling left recursive rules; generating C code. License for this article and the code shown: CC BY-NC-SA 4.0","title":"[**Building** a **PEG** **Parser**](https://medium.com/@gvanrossum_83706/building-a-peg-parser-d4869b5958fb)"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/Guido-van-Rossum-PEG-parser-series/02-Building-a-PEG-Parser/#building-a-peg-parser","text":"Inspired by only a partial understanding of PEG parsing I decided to build one. The result may not be a great general-purpose PEG parser generator \u2014 there are already many of those (e.g. TatSu is written in Python and generates Python code) \u2014 but it was a good way to learn about PEG , and it furthers my goal of replacing CPython\u2019s parser with one built from a PEG grammar. [This is part 2 of my PEG series. See the Series Overview for the rest.] In this section I lay the groundwork for understanding how the generated parser works, by showing a simple hand-written parser . (By the way, as an experiment, I\u2019m not sprinkling links all over my writings. If there\u2019s something you don\u2019t understand, just Google it. :-) The most common way of PEG parsing uses a recursive descent parser with unlimited backtracking . Take the toy grammar from last week\u2019s article: statement: assignment | expr | if_statement expr: expr '+' term | expr '-' term | term term: term '*' atom | term '/' atom | atom atom: NAME | NUMBER | '(' expr ')' assignment: target '=' expr target: NAME if_statement: 'if' expr ':' statement A super-abstract recursive descent parser for this language would define a function for each symbol that tries to call the functions corresponding to the alternatives. For example, for statement we\u2019d have this function: def statement (): if assignment (): return True if expr (): return True if if_statement (): return True return False Of course this is too simplistic: it leaves out essential details about the parser \u2019s input and output. Let\u2019s start with the input side. Classic parsers use a separate tokenizer which breaks the input (a text file or string) into a series of tokens , such as keywords, identifiers (names), numbers and operators. PEG parsers (like other modern parsers such as ANTLR) often unify tokenizing and parsing, but for my project I chose to keep the separate tokenizer . Tokenizing Python is complicated enough that I don\u2019t want to reimplement it using PEG \u2019s formalism. For example, you have to keep track of indentation (this requires a stack inside the tokenizer), and the handling of newlines in Python is interesting (they are significant except inside matching brackets). The many types of string quotes also cause some complexity. In short, I have no beef with Python\u2019s existing tokenizer, so I want to keep it. (Aside: CPython has two tokenizers \u2014an internal one used by the parser , written in C, and the standard library one, which is a faithful reimplementation in pure Python. This is helpful for my project.) Classic tokenizers typically have a simple interface whereby you call a function, e.g. get_token() , which returns the next token in the input, consuming the input a few characters at a time. The tokenize module simplifies this even further: its basic API is a generator which yields one token at a time. Each token is a TypeInfo object which has several fields, the most important ones of which indicate the type of the token (e.g. NAME , NUMBER , STRING ), and its string value, meaning the string of characters comprising the token (e.g. abc , 42 , or \"hello world\" ). There are also additional fields that give the coordinates of the token in the input file, which is useful for error reporting. A special token type is ENDMARKER , which indicates that the end of the input file has been reached. The generator terminates if you ignore this and try to get the next token. But I digress. How do we implement unlimited backtracking ? Backtracking requires you to be able to remember a position in the source code and re-parse from that point. The tokenizer API doesn\u2019t allow us to reset its input pointer, but it\u2019s easy to capture the stream of tokens in an array and replay it from there, so that\u2019s what we do. (You could also do this using itertools.tee() , but based on warnings in the docs that\u2019s probably less efficient in our case.) I suppose you could just first tokenize the entire input into a Python list and then use that as the parser input, but that would mean if there\u2019s an invalid token near the end of the file (such as a string with a missing closing quote) and there\u2019s also a syntax error earlier in the file, you would get an error message about the bad token first. I would find that a poor user experience, since the syntax error could actually be the root cause for the bad string. So my design tokenizes on demand, and the list becomes a lazy list. The basic API is very simple. The Tokenizer object encapsulates the array of tokens and the position in that array. It has three basic methods: get_token() returns the next token, advancing the position in the array (reading another token from the source if we\u2019re at the end of the array); mark() returns the current position in the array; reset(pos) sets the position in the array (the argument must be something you got from mark() ). We add one convenience function, peek_token() which returns the next token without advancing the position. Here, then, is the core of the Tokenizer class: class Tokenizer : def __init__ ( self , tokengen ): \"\"\"Call with tokenize.generate_tokens(...).\"\"\" self . tokengen = tokengen self . tokens = [] self . pos = 0 def mark ( self ): return self . pos def reset ( self , pos ): self . pos = pos def get_token ( self ): token = self . peek_token () self . pos += 1 return token def peek_token ( self ): if self . pos == len ( self . tokens ): self . tokens . append ( next ( self . tokengen )) return self . tokens [ self . pos ] Now, there are various things still missing (and the names of the methods and instance variables should really start with an underscore), but this will do as a sketch of the Tokenizer API. The parser also needs to become a class, so that statement() , expr() and so on can become methods. The tokenizer becomes an instance variable, but we don\u2019t want the parsing methods to call get_token() directly \u2014 instead, we give the **Parser** class an expect() method which can succeed or fail just like a parsing method. The argument to expect() is the expected token \u2014 either a string (like \"+\" ) or a token type (like NAME ). I\u2019ll get to the return type after discussing the parser \u2019s output. In my first sketch of the parser , the parsing functions just returned True or False . That\u2019s fine for theoretical computer science (where the question a parser answers is \u201cis this a valid string in the language?\u201d) but not when you\u2019re building a parser \u2014 instead, we want the parser to create an AST. So let\u2019s just arrange it so that each parsing method returns a Node object on success, or None on failure. The Node class can be super simple: class Node : def __init__ ( self , type , children ): self . type = type self . children = children Here, type indicates what kind of AST node this is (e.g. an \"add\" node or an \"if\" node), and children is a list of nodes and tokens (instances of TokenInfo ). This is enough for a compiler to generate code or do other analysis such as linting or static type checking, although in the future I\u2019d like to change the way we represent the AST. To fit into this scheme, the expect() method returns a TokenInfo object on success, and None on failure. To support backtracking, I wrap the tokenizer\u2019s mark() and reset() methods (no API change here). Here then is the infrastructure for the **Parser** class: class Parser : def __init__ ( self , tokenizer ): self . tokenizer = tokenizer def mark ( self ): return self . tokenizer . mark () def reset ( self , pos ): self . tokenizer . reset ( pos ) def expect ( self , arg ): token = self . tokenizer . peek_token () if token . type == arg or token . string == arg : return self . tokenizer . get_token () return None Again, I\u2019ve left out some details, but this works. At this point I need to introduce an important requirement for parsing methods: a parsing method either returns a Node , positioning the tokenizer after the last token of the grammar rule it recognized; or it returns None , and then it leaves the tokenizer position unchanged . If a parsing method reads several tokens and then decides to fail, it must restore the tokenizer\u2019s position. That\u2019s what mark() and reset() are for. Note that expect() also follows this rule. So here\u2019s a sketch of the actual parser . Note that I am using Python 3.8\u2019s walrus operator ( := ): class ToyParser ( Parser ): def statement ( self ): if a : = self . assignment (): return a if e : = self . expr (): return e if i : = self . if_statement (): return i return None def expr ( self ): if t : = self . term (): pos = self . mark () if op : = self . expect ( \"+\" ): if e : = self . expr (): return Node ( \"add\" , [ t , e ]) self . reset ( pos ) if op : = self . expect ( \"-\" ): if e : = self . expr (): return Node ( \"sub\" , [ t , e ]) self . reset ( pos ) return t return None def term ( self ): # Very similar... def atom ( self ): if token : = self . expect ( NAME ): return token if token : = self . expect ( NUMBER ): return token pos = self . mark () if self . expect ( \"(\" ): if e : = self . expr (): if self . expect ( \")\" ): return e self . reset ( pos ) return None I\u2019ve left some parsing methods as exercises for the reader \u2014 this is really more to give a flavor of what such a parser looks like, and eventually we\u2019ll generate code like this automatically from the grammar. Constants like NAME and NUMBER are imported from the token module in the standard library. (This ties us further to Python tokenization; there are ways around this that we should explore if we want to make a more general PEG parser generator.) Also note that I cheated a bit: expr is left-recursive, but I made the parser *right-*recursive, because recursive-descent parsers don\u2019t work with left-recursive grammar rules. There\u2019s a fix for this, but it\u2019s still the topic of some academic research and I\u2019d like to present it separately. Just realize that this version doesn\u2019t correspond 100% with the toy grammar. The key things I want you to get at this point are: Grammar rules correspond to parser methods, and when a grammar rule references another grammar rule, its parsing method calls the other rule\u2019s parsing method. When multiple items make up an alternative, the parsing method calls the corresponding methods one after the other. When a grammar rule references a token, its parsing method calls expect() . When a parsing method successfully recognizes its grammar rule at the given input position, it returns a corresponding AST node; when it fails to recognize its grammar rule, it returns None . Parsing methods must explicitly reset the tokenizer position when they abandon a parse after having consumed one or more tokens (directly, or indirectly by calling another parsing method that succeeded). This applies when abandoning one alternative to try the next, and also when abandoning the parse altogether. If all parsing methods abide by these rules, it\u2019s not necessary to use mark() and reset() around a single parsing method. You can prove this using induction. As an aside, it\u2019s tempting to try to get rid of the explicit mark() and reset() calls by using a context manager and a with statement, but this doesn\u2019t work: the reset() call shouldn\u2019t be called upon success! As a further fix you could try to use exceptions for control flow, so the context manager knows whether to reset the tokenizer (I think TatSu does something like this). For example, you could arrange for this to work: def statement(self): with self.alt(): return self.assignment() with self.alt(): return self.expr() with self.alt(): return self.if_statement() raise ParsingFailure In particular, the little ladder of if statements in atom() for recognizing a parenthesized expression could become: with self . alt (): self . expect ( \"(\" ) e = self . expr () self . expect ( \")\" ) return e But I find this too \u201cmagical\u201d \u2014 when reading such code you must stay aware that each parsing method (and expect() ) may raise an exception, and that this exception is caught and ignored by the context manager in the with statement. That\u2019s pretty unusual, although definitely supported (by returning true from __exit__ ). Also, my ultimate goal is to generate C, not Python, and in C there\u2019s no with statement to alter the control flow. Anyway, here are some topics for future installments: generating parsing code from the grammar; packrat parsing (memoization); EBNF features like (x | y) , [x y ...] , x* , x+ ; tracing (for debugging the parser or grammar); PEG features like lookahead and \u201ccut\u201d; how to handling left recursive rules; generating C code. License for this article and the code shown: CC BY-NC-SA 4.0","title":"Building a PEG Parser"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/Guido-van-Rossum-PEG-parser-series/03-Generating-a-PEG-Parser/","text":"Generating a PEG Parser Now that I\u2019ve sketched the infrastructure for a parser and a simple hand-written parser in part 2 , let\u2019s turn to generating a parser from a grammar, as promised. I\u2019ll also show how to implement packrat parsing using a @memoize decorator. [This is part 3 of my PEG series. See the Series Overview for the rest.] Last time we ended with a hand-written parser . With some limitations to the grammar, it\u2019s easy to generate such parsers automatically from the grammar. (We\u2019ll lift those limitations later.) We need two things: something that reads the grammar, constructing a data structure representing the grammar rules ; and something that takes that data structure and generates the parser . We also need boring glue that I\u2019ll omit. So what we\u2019re creating here is a simple compiler-compiler. I\u2019m simplifying the grammar notation a bit to the point where we just have rules and alternatives; this is actually sufficient for the toy grammar I\u2019ve been using in the previous parts of the series: statement: assignment | expr | if_statement expr: expr '+' term | expr '-' term | term term: term '*' atom | term '/' atom | atom atom: NAME | NUMBER | '(' expr ')' assignment: target '=' expr target: NAME if_statement: 'if' expr ':' statement Using the full notation we can write up the grammar for grammar files:","title":"[Generating a PEG Parser](https://medium.com/@gvanrossum_83706/generating-a-peg-parser-520057d642a9)"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/Guido-van-Rossum-PEG-parser-series/03-Generating-a-PEG-Parser/#generating-a-peg-parser","text":"Now that I\u2019ve sketched the infrastructure for a parser and a simple hand-written parser in part 2 , let\u2019s turn to generating a parser from a grammar, as promised. I\u2019ll also show how to implement packrat parsing using a @memoize decorator. [This is part 3 of my PEG series. See the Series Overview for the rest.] Last time we ended with a hand-written parser . With some limitations to the grammar, it\u2019s easy to generate such parsers automatically from the grammar. (We\u2019ll lift those limitations later.) We need two things: something that reads the grammar, constructing a data structure representing the grammar rules ; and something that takes that data structure and generates the parser . We also need boring glue that I\u2019ll omit. So what we\u2019re creating here is a simple compiler-compiler. I\u2019m simplifying the grammar notation a bit to the point where we just have rules and alternatives; this is actually sufficient for the toy grammar I\u2019ve been using in the previous parts of the series: statement: assignment | expr | if_statement expr: expr '+' term | expr '-' term | term term: term '*' atom | term '/' atom | atom atom: NAME | NUMBER | '(' expr ')' assignment: target '=' expr target: NAME if_statement: 'if' expr ':' statement Using the full notation we can write up the grammar for grammar files:","title":"Generating a PEG Parser"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/Guido-van-Rossum-PEG-parser-series/PEG-Parsing-Series-Overview/","text":"PEG Parsing Series Overview","title":"[PEG Parsing Series Overview](https://medium.com/@gvanrossum_83706/peg-parsing-series-de5d41b2ed60)"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/Guido-van-Rossum-PEG-parser-series/PEG-Parsing-Series-Overview/#peg-parsing-series-overview","text":"","title":"PEG Parsing Series Overview"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/python-3.8-pgen/pgen/","text":"\u9700\u8981\u638c\u63e1\u7684\u7406\u8bba\u77e5\u8bc6 \u7efc\u8ff0 \u5b9e\u73b0\u7ec6\u8282 metaparser.py class GrammarParser parse \u63cf\u8ff0python grammar\u7684grammar: meta-grammar automata.py NFA DFA \u9700\u8981\u638c\u63e1\u7684\u7406\u8bba\u77e5\u8bc6 \u6211\u8ba4\u4e3a\uff0c \u8981\u60f3\u7406\u89e3cpython\u7684 pgen \uff0c\u4f60\u9700\u8981\u638c\u63e1\u4e00\u5b9a\u7684compiler\u7684front end\u7684\u539f\u7406\uff0c\u4ee5dragon book\u6765\u8bf4\u7684\u8bdd\uff0c\u4f60\u81f3\u5c11\u8981\u638c\u63e1\u4e86\u5982\u4e0b\u7ae0\u8282\u7684\u5185\u5bb9\uff1a Chapter 3 Lexical Analysis 3.6 Finite Automata 3.7 From Regular Expressions to Automata Chapter 4 Syntax Analysis 4.2 Context-Free Grammars 4.4 Top-Down Parsing \u7efc\u8ff0 Full Grammar specification of python is here \uff0c\u5b83\u88ab Guido van Rossum \u79f0\u4e3aEBNF-like grammar . EBNF-like grammar\u6240\u6269\u5c55\u7684\u5176\u5b9e\u5c31\u662f\u5bf9regular expression\u4e2d\u7684\u4e00\u4e9b\u6807\u8bb0\u7684\u652f\u6301\uff0c\u6240\u4ee5\u5b83\u7684\u8bed\u6cd5\u770b\u8d77\u6765\u548c\u6b63\u5219\u8868\u8fbe\u5f0f\u6bd4\u8f83\u7c7b\u4f3c\uff0c\u4e0b\u9762\u4f1a\u8fdb\u884c\u8bf4\u660e. Full Grammar specification is a file, which is human-readable, the task of pgen is reading the file, parsing it and constructing predictive parsing table. \u4e0b\u9762\u5c06\u5bf9\u6574\u4e2a pgen \u7684\u5b9e\u73b0\u539f\u7406\u8fdb\u884c\u6982\u62ec\u6027\u7684\u63cf\u8ff0\uff0c\u7136\u540e\u5206\u7ae0\u8282\u5bf9\u5177\u4f53\u7684\u5b9e\u73b0\u7ec6\u8282\u8fdb\u884c\u63cf\u8ff0\u3002 EBNF-like grammar\u7684\u6bcf\u6761\u8bed\u6cd5\u662f\u4ee5 production \u7684\u65b9\u5f0f\u6765\u63cf\u8ff0\u7684\uff0c\u5bf9\u4e8e\u6211\u4eec\u800c\u8a00\uff0c\u9996\u5148\u9700\u8981\u80fd\u591f\u7406\u89e3\u8fd9\u4e9bgrammar\uff0c\u5982\u4e0b\u662fgrammar\u4e2d\u4e2d\u4e00\u4e9b\u7279\u6b8a\u7b26\u53f7\u7684\u542b\u4e49\uff1a [] \u8868\u793a\u53ef\u9009\uff0coptional | \u8868\u793a\u6216\uff0cor + \u8868\u793a\u5927\u4e8e\u7b49\u4e8e1\uff0cmore than 1 * \u8868\u793a\u4efb\u610f\u591a\u4e2a\uff0cany \u5728\u5c06grammar file\u8bfb\u5165\u5185\u5b58\u540e\uff0c pgen \u4f7f\u7528 tokenize \u6a21\u5757\u7684 generate_tokens \u6765\u5c06grammar file\u4e2d\u7684\u5185\u5bb9\u8f6c\u6362\u4e3astream of token\uff0c\u6240\u4ee5\u540e\u7eed\u5bf9grammar file\u7684\u89e3\u6790\u5c31\u662f\u57fa\u4e8e\u8fd9\u4e2astream of token\u7684\u3002\u6b63\u5982\u524d\u9762\u6240\u8bf4\u7684\uff0cpython\u7684EBNF-like grammar\u975e\u5e38\u7c7b\u4f3c\u4e8eregular expression\uff0c\u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u4f7f\u7528regular expression\u6765\u63cf\u8ff0python\u7684\u8bed\u6cd5\uff0c\u4e5f\u5c31\u662f\u8bf4regular expression\u662fpython\u8bed\u6cd5\u7684meta-grammar\u3002\u4e3a\u4ec0\u4e48\u8981\u5f3a\u8c03\u5462\uff1f\u56e0\u4e3a pgen \u8981\u60f3\u5b9e\u73b0parsing grammar\u7684\u4efb\u52a1\uff0c\u5c31\u5fc5\u987b\u77e5\u9053meta-grammar\u3002\u73b0\u5728\u6211\u4eec\u5df2\u7ecf\u77e5\u9053\u4e86meta-grammar\u662fregular expression\uff0c\u6240\u4ee5 pgen \u5c31\u53ef\u4ee5\u6309\u7167regular expression\u7684\u8bed\u6cd5\u6765\u8fdb\u884c\u89e3\u6790\u3002\u901a\u5e38\uff0c\u53ef\u4ee5\u6839\u636eregular expression\u6784\u9020\u51fa\u5bf9\u5e94\u7684DFA\uff0c pgen \u4e2d\u5c31\u662f\u91c7\u53d6\u7684\u8fd9\u79cd\u65b9\u5f0f\uff0c\u7a0b\u5e8f\u5185\u90e8\u4f7f\u7528DFA\u6765\u8868\u793aproduction\u7684body\uff08regular expression\uff09\u3002\u6839\u636eregular expression\u6765\u6784\u5efaDFA\uff0c\u6240\u91c7\u7528\u7684\u662f\u5982\u4e0b\u7b97\u6cd5\uff1a Name Function Chapter in dragon book Thompson's construction algorithm transforming a regular expression into an equivalent nondeterministic finite automaton (NFA) 3.7.4 Construction of an NFA from a Regular Expression subset construction algorithm converting a nondeterministic finite automaton (NFA) into a deterministic finite automaton (DFA) which recognizes the same formal language 3.7.1 Conversion of an NFA to a DFA DFA minimization transforming a given deterministic finite automaton (DFA) into an equivalent DFA that has a minimum number of states. \u5728\u89e3\u6790\u5b8cgrammar\u540e\uff0c pgen \u5c31\u5f97\u5230\u4e86\u4f7f\u7528 DFA \u8868\u793a\u7684\u8bed\u6cd5\u4e86\uff08\u6bcf\u6761\u8bed\u6cd5\u5bf9\u5e94\u4e00\u4e2a DFA \uff09\uff0c\u63a5\u7740 pgen \u5c31\u6839\u636e\u8fd9\u4e9b DFA \u6765\u6784\u9020predictive parsing table\uff0c\u6240\u91c7\u7528\u7684\u662fAlgorithm 4.31 described in chapter 4.4.3 LL(1) Grammars of dragon book \uff0c\u5728\u6b64\u4e0d\u5bf9\u6b64\u7b97\u6cd5\u8fdb\u884c\u8d58\u8ff0\u3002 \u5b9e\u73b0\u7ec6\u8282 metaparser.py \u5b9e\u73b0\u5bf9grammar\u7684parse\u3002 class GrammarParser parse \u4f7f\u7528 Thompson's construction algorithm \u6765\u5c06\u6bcf\u4e2a\u4ea7\u751f\u5f0f\uff08\u4e00\u6761grammar\uff09\u7684body\u8f6c\u6362\u4e3a\u4e00\u4e2aDFA(\u5728 automata.py \u4e2d\u5b9a\u4e49\uff0c\u53c2\u89c1\u4e0b\u4e00\u8282)\uff0c\u6210\u5458\u53d8\u91cf _current_rule_name \u5bf9\u5e94\u7684\u662f\u4ea7\u751f\u5f0f\u7684\u5934\u3002\u5728grammar\u6587\u4ef6\u4e2d\u5b9a\u4e49\u4e86\u591a\u6761grammar\uff0c\u6240\u4ee5 parse \u65b9\u6cd5\u6bcf\u6b21\u5904\u7406\u4e00\u6761grammar\uff0c\u5e76 yield \u8be5grammar\u5bf9\u5e94\u7684DFA\u5bf9\u8c61\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c parse \u65b9\u6cd5\u662f\u4e00\u4e2agenerator\u3002 parse \u91c7\u7528 stream \u5904\u7406\u7684\u65b9\u5f0f\uff1a\u4e00\u6b21\u5904\u7406\u4e00\u4e2atoken\u3002 _parse_rhs \u4e2d rhs \u7684\u542b\u4e49\u662fright hand side\u7684\u542b\u4e49\uff0c\u5bf9\u4e8e\u4e00\u4e2aproduction\u800c\u8a00\uff0c\u5b83\u7684right hand side\u5c31\u662f\u5b83\u7684body\u3002 EBNF-like grammar\u4e2d\u5305\u542b\u6709\u5982\u4e0b\u62ec\u53f7\uff1a [] () \u663e\u7136\uff0c GrammarParser \u7684\u9700\u8981\u5904\u7406\u7684\u4e00\u4e2a\u95ee\u9898\u5c31\u662f\u62ec\u53f7\u7684\u5339\u914d\uff0c\u672c\u7a0b\u5e8f\u4e2d\uff0c\u5b9e\u73b0\u62ec\u53f7\u7684\u5339\u914d\u6240\u4f7f\u7528\u7684\u662f\u9690\u5f0f\u7684 calling stack \uff0c\u800c\u4e0d\u662f\u4f7f\u7528\u4e00\u4e2a\u663e\u5f0f\u7684\u5806\u6808\u3002 \u51e0\u4e2a\u8f85\u52a9\u51fd\u6570\u5982\u4e0b\uff1a _gettoken \u83b7\u53d6\u4e0b\u4e00\u4e2atoken\u4fe1\u606f\uff0c\u5e76\u5c06\u5b83\u4fdd\u5b58\u5728\u6210\u5458\u53d8\u91cf self.type, self.value, self.begin, self.end, self.line \u4e2d _expect \u6bd4\u8f83\u5f53\u524d\u6210\u5458\u53d8\u91cf\u4e0e\u5165\u53c2\u503c\uff0c\u7136\u540e\u8c03\u7528 _gettoken \u63cf\u8ff0python grammar\u7684grammar: meta-grammar \u6b63\u5982\u5728 \u7efc\u8ff0 \u7ae0\u8282\u4e2d\u6240\u63cf\u8ff0\u7684\uff0cpython grammar\u7684meta-grammar\u662fregular expression\uff0c\u6240\u4ee5\u5bf9grammar\u7684\u89e3\u6790\u662f\u6309\u7167\u89e3\u6790regular expression\u7684\u65b9\u5f0f\u6765\u5b9e\u73b0\u7684\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u5c31\u662f\u4f7f\u7528\u7684\u7528 Thompson's construction algorithm \u7b97\u6cd5\u3002 class GrammarParser \u5bf9 Thompson's construction algorithm \u7b97\u6cd5\u7684\u4f7f\u7528\u662f\u975e\u5e38\u6e05\u6670\u7684\uff0c\u5b83\u7ed9\u51fa\u4e86\u8bed\u6cd5\u7684\u901a\u7528\u683c\u5f0f\u5982\u4e0b\uff1a rule->rhs->items->item->atom \u4e0b\u9762\u4f7f\u7528\u7c7b\u4f3c\u4e8e\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u65b9\u5f0f\u5bf9\u4e0a\u8ff0\u7ed3\u6784\u4e2d\u7684\u6bcf\u4e00\u5c42\u8fdb\u884c\u89e3\u91ca\uff1a rule: NAME ':' rhs NEWLINE rhs: items ('|' items)* items: item+ item: '[' rhs ']' | atom ['+' | '*'] atom: '(' rhs ')' | NAME | STRING \u53ef\u4ee5\u770b\u51fa\uff0c\u4e0a\u8bc9\u8bed\u6cd5\u63cf\u8ff0\u51fa\u4e86python grammar\u7684\u7ed3\u6784\uff0c class GrammarParser \u5c31\u662f\u6cbf\u7740\u4e0a\u8bc9hierarchy\u8fdb\u884c\u9010\u5c42\u89e3\u6790\u7684\uff0c\u4e0b\u9762\u7684\u8868\u683c\u662f\u6839\u636e\u4e0a\u8ff0hierarchy\u800c\u753b\u51fa\u7684\uff0c\u6bcf\u4e00\u5217\u5206\u522b\u5bf9\u5e94\u4e00\u5c42\uff0c\u5728\u7b2c\u4e09\u884c\u6dfb\u52a0\u4e86\u89e3\u6790\u8be5\u5c42\u7684\u5bf9\u5e94\u7684\u51fd\u6570\u3002 rule rhs items item atom \u8bed\u6cd5 rule: NAME ':' rhs NEWLINE rhs: items ('|' items)* items: item+ item: '[' rhs ']' | atom ['+' | '*'] atom: '(' rhs ')' \u51fd\u6570 parse _parse_rhs _parse_items _parse_item _parse_atom \u4ece\u4e0a\u8ff0\u8868\u683c\u53ef\u4ee5\u770b\u51fa\uff0c class GrammarParser \u7684\u4ee3\u7801\u7ed3\u6784\u662f\u975e\u5e38\u6e05\u6670\u7684\uff0c\u5b83\u7684\u5b9e\u73b0\u4e5f\u662f\u7b80\u6d01\u6613\u61c2\u7684\u3002 automata.py The implementation of converting the body of the production to a DFA is in automata.py automata\u4e5f\u662f\u56fe\uff0c\u5982\u4f55\u6765\u8868\u793anode\uff08state\uff09\u548cedge\uff08transition\uff09\uff0c\u4e0b\u9762\u662fautomata\u548cgraph\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb graph automata node state edge transition \u5728 automata.py \u4e2d\u5b9a\u4e49\u4e86\u4e24\u79cdautomata\uff1a NFA DFA NFA class NFAArc \u8868\u793a\u56fe\u7684\u8fb9 class NFAState \u8868\u793a\u56fe\u7684\u8282\u70b9 class NFA \u4e00\u4e2aNFA\u5176\u5b9e\u662f\u4e00\u5f20\u6709\u5411\u56fe\uff0c\u6bcf\u4e2aNFA\u6709\u4e00\u4e2a\u8d77\u59cb\u72b6\u6001\u548c\u4e00\u4e2a\u7ec8\u6b62\u72b6\u6001\uff0c\u5206\u522b\u5bf9\u5e94\u4e86\u6210\u5458\u53d8\u91cf start \u548c end \u3002 DFA class DFA \u7c7b\u65b9\u6cd5 from_nfa \u662f\u4e00\u4e2a\u5de5\u5382\u65b9\u6cd5\uff0c\u5b83\u4f7f\u7528 subset construction algorithm \uff0c\u6839\u636e\u4e00\u4e2aNFA\u6784\u9020\u4e00\u4e2aDFA\u3002 class DFAState","title":"Pgen"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/python-3.8-pgen/pgen/#_1","text":"\u6211\u8ba4\u4e3a\uff0c \u8981\u60f3\u7406\u89e3cpython\u7684 pgen \uff0c\u4f60\u9700\u8981\u638c\u63e1\u4e00\u5b9a\u7684compiler\u7684front end\u7684\u539f\u7406\uff0c\u4ee5dragon book\u6765\u8bf4\u7684\u8bdd\uff0c\u4f60\u81f3\u5c11\u8981\u638c\u63e1\u4e86\u5982\u4e0b\u7ae0\u8282\u7684\u5185\u5bb9\uff1a Chapter 3 Lexical Analysis 3.6 Finite Automata 3.7 From Regular Expressions to Automata Chapter 4 Syntax Analysis 4.2 Context-Free Grammars 4.4 Top-Down Parsing","title":"\u9700\u8981\u638c\u63e1\u7684\u7406\u8bba\u77e5\u8bc6"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/python-3.8-pgen/pgen/#_2","text":"Full Grammar specification of python is here \uff0c\u5b83\u88ab Guido van Rossum \u79f0\u4e3aEBNF-like grammar . EBNF-like grammar\u6240\u6269\u5c55\u7684\u5176\u5b9e\u5c31\u662f\u5bf9regular expression\u4e2d\u7684\u4e00\u4e9b\u6807\u8bb0\u7684\u652f\u6301\uff0c\u6240\u4ee5\u5b83\u7684\u8bed\u6cd5\u770b\u8d77\u6765\u548c\u6b63\u5219\u8868\u8fbe\u5f0f\u6bd4\u8f83\u7c7b\u4f3c\uff0c\u4e0b\u9762\u4f1a\u8fdb\u884c\u8bf4\u660e. Full Grammar specification is a file, which is human-readable, the task of pgen is reading the file, parsing it and constructing predictive parsing table. \u4e0b\u9762\u5c06\u5bf9\u6574\u4e2a pgen \u7684\u5b9e\u73b0\u539f\u7406\u8fdb\u884c\u6982\u62ec\u6027\u7684\u63cf\u8ff0\uff0c\u7136\u540e\u5206\u7ae0\u8282\u5bf9\u5177\u4f53\u7684\u5b9e\u73b0\u7ec6\u8282\u8fdb\u884c\u63cf\u8ff0\u3002 EBNF-like grammar\u7684\u6bcf\u6761\u8bed\u6cd5\u662f\u4ee5 production \u7684\u65b9\u5f0f\u6765\u63cf\u8ff0\u7684\uff0c\u5bf9\u4e8e\u6211\u4eec\u800c\u8a00\uff0c\u9996\u5148\u9700\u8981\u80fd\u591f\u7406\u89e3\u8fd9\u4e9bgrammar\uff0c\u5982\u4e0b\u662fgrammar\u4e2d\u4e2d\u4e00\u4e9b\u7279\u6b8a\u7b26\u53f7\u7684\u542b\u4e49\uff1a [] \u8868\u793a\u53ef\u9009\uff0coptional | \u8868\u793a\u6216\uff0cor + \u8868\u793a\u5927\u4e8e\u7b49\u4e8e1\uff0cmore than 1 * \u8868\u793a\u4efb\u610f\u591a\u4e2a\uff0cany \u5728\u5c06grammar file\u8bfb\u5165\u5185\u5b58\u540e\uff0c pgen \u4f7f\u7528 tokenize \u6a21\u5757\u7684 generate_tokens \u6765\u5c06grammar file\u4e2d\u7684\u5185\u5bb9\u8f6c\u6362\u4e3astream of token\uff0c\u6240\u4ee5\u540e\u7eed\u5bf9grammar file\u7684\u89e3\u6790\u5c31\u662f\u57fa\u4e8e\u8fd9\u4e2astream of token\u7684\u3002\u6b63\u5982\u524d\u9762\u6240\u8bf4\u7684\uff0cpython\u7684EBNF-like grammar\u975e\u5e38\u7c7b\u4f3c\u4e8eregular expression\uff0c\u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u4f7f\u7528regular expression\u6765\u63cf\u8ff0python\u7684\u8bed\u6cd5\uff0c\u4e5f\u5c31\u662f\u8bf4regular expression\u662fpython\u8bed\u6cd5\u7684meta-grammar\u3002\u4e3a\u4ec0\u4e48\u8981\u5f3a\u8c03\u5462\uff1f\u56e0\u4e3a pgen \u8981\u60f3\u5b9e\u73b0parsing grammar\u7684\u4efb\u52a1\uff0c\u5c31\u5fc5\u987b\u77e5\u9053meta-grammar\u3002\u73b0\u5728\u6211\u4eec\u5df2\u7ecf\u77e5\u9053\u4e86meta-grammar\u662fregular expression\uff0c\u6240\u4ee5 pgen \u5c31\u53ef\u4ee5\u6309\u7167regular expression\u7684\u8bed\u6cd5\u6765\u8fdb\u884c\u89e3\u6790\u3002\u901a\u5e38\uff0c\u53ef\u4ee5\u6839\u636eregular expression\u6784\u9020\u51fa\u5bf9\u5e94\u7684DFA\uff0c pgen \u4e2d\u5c31\u662f\u91c7\u53d6\u7684\u8fd9\u79cd\u65b9\u5f0f\uff0c\u7a0b\u5e8f\u5185\u90e8\u4f7f\u7528DFA\u6765\u8868\u793aproduction\u7684body\uff08regular expression\uff09\u3002\u6839\u636eregular expression\u6765\u6784\u5efaDFA\uff0c\u6240\u91c7\u7528\u7684\u662f\u5982\u4e0b\u7b97\u6cd5\uff1a Name Function Chapter in dragon book Thompson's construction algorithm transforming a regular expression into an equivalent nondeterministic finite automaton (NFA) 3.7.4 Construction of an NFA from a Regular Expression subset construction algorithm converting a nondeterministic finite automaton (NFA) into a deterministic finite automaton (DFA) which recognizes the same formal language 3.7.1 Conversion of an NFA to a DFA DFA minimization transforming a given deterministic finite automaton (DFA) into an equivalent DFA that has a minimum number of states. \u5728\u89e3\u6790\u5b8cgrammar\u540e\uff0c pgen \u5c31\u5f97\u5230\u4e86\u4f7f\u7528 DFA \u8868\u793a\u7684\u8bed\u6cd5\u4e86\uff08\u6bcf\u6761\u8bed\u6cd5\u5bf9\u5e94\u4e00\u4e2a DFA \uff09\uff0c\u63a5\u7740 pgen \u5c31\u6839\u636e\u8fd9\u4e9b DFA \u6765\u6784\u9020predictive parsing table\uff0c\u6240\u91c7\u7528\u7684\u662fAlgorithm 4.31 described in chapter 4.4.3 LL(1) Grammars of dragon book \uff0c\u5728\u6b64\u4e0d\u5bf9\u6b64\u7b97\u6cd5\u8fdb\u884c\u8d58\u8ff0\u3002","title":"\u7efc\u8ff0"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/python-3.8-pgen/pgen/#_3","text":"","title":"\u5b9e\u73b0\u7ec6\u8282"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/python-3.8-pgen/pgen/#metaparserpy","text":"\u5b9e\u73b0\u5bf9grammar\u7684parse\u3002","title":"metaparser.py"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/python-3.8-pgen/pgen/#class-grammarparser","text":"","title":"class GrammarParser"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/python-3.8-pgen/pgen/#parse","text":"\u4f7f\u7528 Thompson's construction algorithm \u6765\u5c06\u6bcf\u4e2a\u4ea7\u751f\u5f0f\uff08\u4e00\u6761grammar\uff09\u7684body\u8f6c\u6362\u4e3a\u4e00\u4e2aDFA(\u5728 automata.py \u4e2d\u5b9a\u4e49\uff0c\u53c2\u89c1\u4e0b\u4e00\u8282)\uff0c\u6210\u5458\u53d8\u91cf _current_rule_name \u5bf9\u5e94\u7684\u662f\u4ea7\u751f\u5f0f\u7684\u5934\u3002\u5728grammar\u6587\u4ef6\u4e2d\u5b9a\u4e49\u4e86\u591a\u6761grammar\uff0c\u6240\u4ee5 parse \u65b9\u6cd5\u6bcf\u6b21\u5904\u7406\u4e00\u6761grammar\uff0c\u5e76 yield \u8be5grammar\u5bf9\u5e94\u7684DFA\u5bf9\u8c61\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c parse \u65b9\u6cd5\u662f\u4e00\u4e2agenerator\u3002 parse \u91c7\u7528 stream \u5904\u7406\u7684\u65b9\u5f0f\uff1a\u4e00\u6b21\u5904\u7406\u4e00\u4e2atoken\u3002 _parse_rhs \u4e2d rhs \u7684\u542b\u4e49\u662fright hand side\u7684\u542b\u4e49\uff0c\u5bf9\u4e8e\u4e00\u4e2aproduction\u800c\u8a00\uff0c\u5b83\u7684right hand side\u5c31\u662f\u5b83\u7684body\u3002 EBNF-like grammar\u4e2d\u5305\u542b\u6709\u5982\u4e0b\u62ec\u53f7\uff1a [] () \u663e\u7136\uff0c GrammarParser \u7684\u9700\u8981\u5904\u7406\u7684\u4e00\u4e2a\u95ee\u9898\u5c31\u662f\u62ec\u53f7\u7684\u5339\u914d\uff0c\u672c\u7a0b\u5e8f\u4e2d\uff0c\u5b9e\u73b0\u62ec\u53f7\u7684\u5339\u914d\u6240\u4f7f\u7528\u7684\u662f\u9690\u5f0f\u7684 calling stack \uff0c\u800c\u4e0d\u662f\u4f7f\u7528\u4e00\u4e2a\u663e\u5f0f\u7684\u5806\u6808\u3002 \u51e0\u4e2a\u8f85\u52a9\u51fd\u6570\u5982\u4e0b\uff1a _gettoken \u83b7\u53d6\u4e0b\u4e00\u4e2atoken\u4fe1\u606f\uff0c\u5e76\u5c06\u5b83\u4fdd\u5b58\u5728\u6210\u5458\u53d8\u91cf self.type, self.value, self.begin, self.end, self.line \u4e2d _expect \u6bd4\u8f83\u5f53\u524d\u6210\u5458\u53d8\u91cf\u4e0e\u5165\u53c2\u503c\uff0c\u7136\u540e\u8c03\u7528 _gettoken","title":"parse"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/python-3.8-pgen/pgen/#python-grammargrammar-meta-grammar","text":"\u6b63\u5982\u5728 \u7efc\u8ff0 \u7ae0\u8282\u4e2d\u6240\u63cf\u8ff0\u7684\uff0cpython grammar\u7684meta-grammar\u662fregular expression\uff0c\u6240\u4ee5\u5bf9grammar\u7684\u89e3\u6790\u662f\u6309\u7167\u89e3\u6790regular expression\u7684\u65b9\u5f0f\u6765\u5b9e\u73b0\u7684\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u5c31\u662f\u4f7f\u7528\u7684\u7528 Thompson's construction algorithm \u7b97\u6cd5\u3002 class GrammarParser \u5bf9 Thompson's construction algorithm \u7b97\u6cd5\u7684\u4f7f\u7528\u662f\u975e\u5e38\u6e05\u6670\u7684\uff0c\u5b83\u7ed9\u51fa\u4e86\u8bed\u6cd5\u7684\u901a\u7528\u683c\u5f0f\u5982\u4e0b\uff1a rule->rhs->items->item->atom \u4e0b\u9762\u4f7f\u7528\u7c7b\u4f3c\u4e8e\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u65b9\u5f0f\u5bf9\u4e0a\u8ff0\u7ed3\u6784\u4e2d\u7684\u6bcf\u4e00\u5c42\u8fdb\u884c\u89e3\u91ca\uff1a rule: NAME ':' rhs NEWLINE rhs: items ('|' items)* items: item+ item: '[' rhs ']' | atom ['+' | '*'] atom: '(' rhs ')' | NAME | STRING \u53ef\u4ee5\u770b\u51fa\uff0c\u4e0a\u8bc9\u8bed\u6cd5\u63cf\u8ff0\u51fa\u4e86python grammar\u7684\u7ed3\u6784\uff0c class GrammarParser \u5c31\u662f\u6cbf\u7740\u4e0a\u8bc9hierarchy\u8fdb\u884c\u9010\u5c42\u89e3\u6790\u7684\uff0c\u4e0b\u9762\u7684\u8868\u683c\u662f\u6839\u636e\u4e0a\u8ff0hierarchy\u800c\u753b\u51fa\u7684\uff0c\u6bcf\u4e00\u5217\u5206\u522b\u5bf9\u5e94\u4e00\u5c42\uff0c\u5728\u7b2c\u4e09\u884c\u6dfb\u52a0\u4e86\u89e3\u6790\u8be5\u5c42\u7684\u5bf9\u5e94\u7684\u51fd\u6570\u3002 rule rhs items item atom \u8bed\u6cd5 rule: NAME ':' rhs NEWLINE rhs: items ('|' items)* items: item+ item: '[' rhs ']' | atom ['+' | '*'] atom: '(' rhs ')' \u51fd\u6570 parse _parse_rhs _parse_items _parse_item _parse_atom \u4ece\u4e0a\u8ff0\u8868\u683c\u53ef\u4ee5\u770b\u51fa\uff0c class GrammarParser \u7684\u4ee3\u7801\u7ed3\u6784\u662f\u975e\u5e38\u6e05\u6670\u7684\uff0c\u5b83\u7684\u5b9e\u73b0\u4e5f\u662f\u7b80\u6d01\u6613\u61c2\u7684\u3002","title":"\u63cf\u8ff0python grammar\u7684grammar: meta-grammar"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/python-3.8-pgen/pgen/#automatapy","text":"The implementation of converting the body of the production to a DFA is in automata.py automata\u4e5f\u662f\u56fe\uff0c\u5982\u4f55\u6765\u8868\u793anode\uff08state\uff09\u548cedge\uff08transition\uff09\uff0c\u4e0b\u9762\u662fautomata\u548cgraph\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb graph automata node state edge transition \u5728 automata.py \u4e2d\u5b9a\u4e49\u4e86\u4e24\u79cdautomata\uff1a NFA DFA","title":"automata.py"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/python-3.8-pgen/pgen/#nfa","text":"class NFAArc \u8868\u793a\u56fe\u7684\u8fb9 class NFAState \u8868\u793a\u56fe\u7684\u8282\u70b9 class NFA \u4e00\u4e2aNFA\u5176\u5b9e\u662f\u4e00\u5f20\u6709\u5411\u56fe\uff0c\u6bcf\u4e2aNFA\u6709\u4e00\u4e2a\u8d77\u59cb\u72b6\u6001\u548c\u4e00\u4e2a\u7ec8\u6b62\u72b6\u6001\uff0c\u5206\u522b\u5bf9\u5e94\u4e86\u6210\u5458\u53d8\u91cf start \u548c end \u3002","title":"NFA"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/02-cpython-PEG/python-3.8-pgen/pgen/#dfa","text":"class DFA \u7c7b\u65b9\u6cd5 from_nfa \u662f\u4e00\u4e2a\u5de5\u5382\u65b9\u6cd5\uff0c\u5b83\u4f7f\u7528 subset construction algorithm \uff0c\u6839\u636e\u4e00\u4e2aNFA\u6784\u9020\u4e00\u4e2aDFA\u3002 class DFAState","title":"DFA"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/03-cpython-AST/","text":"\u53c2\u8003\u5185\u5bb9\u6709\uff1a Design of CPython\u2019s Compiler \u00b6 Using ASDL to describe ASTs in compilers Green Tree Snakes - the missing Python AST docs The Zephyr Abstract Syntax Description Language","title":"Home"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/03-cpython-AST/blog-Using-ASDL-to-describe-ASTs-in-compilers/","text":"Using ASDL to describe ASTs in compilers ASTs (Abstract Syntax Trees) are an important data structure in compiler front-ends. If you've written a few parsers, you almost definitely ran into the need to describe the result of the parsing in terms of an AST. While the kinds of nodes such ASTs have and their structure is very specific to the source language, many commonalities come up. In other words, coding \"yet another AST\" gets really old after you've done it a few times. Worry not, as you'd expect from the programmer crowd, this problem was \"solved\" by adding another level of abstraction. Yes, an abstraction over Abstract Syntax Trees, oh my! The abstraction here is some textual format (let's call it a DSL to sound smart) that describes what the AST looks like, along with machinery to auto-generate the code that implements this AST. Most solutions in this domain are ad-hoc, but one that I've seen used more than once is ASDL - Abstract Syntax Definition Language. The self-description from the website sounds about right: The Zephyr Abstract Syntax Description Lanuguage (ASDL) is a language designed to describe the tree-like data structures in compilers. Its main goal is to provide a method for compiler components written in different languages to interoperate. ASDL makes it easier for applications written in a variety of programming languages to communicate complex recursive data structures. To given an example, here's a short snippet from an ASDL definition of a simple programming language: program = Program(class* classes) class = Class(identifier name, identifier? parent, feature* features) [...] expression = Assign(identifier name, expression expr) | StaticDispatch(expression expr, identifier type_name, identifier name, expression* actual) | Dispatch(expression expr, identifier name, expression* actual) [...]","title":"[Using ASDL to describe ASTs in compilers](https://eli.thegreenplace.net/2014/06/04/using-asdl-to-describe-asts-in-compilers)"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/03-cpython-AST/blog-Using-ASDL-to-describe-ASTs-in-compilers/#using-asdl-to-describe-asts-in-compilers","text":"ASTs (Abstract Syntax Trees) are an important data structure in compiler front-ends. If you've written a few parsers, you almost definitely ran into the need to describe the result of the parsing in terms of an AST. While the kinds of nodes such ASTs have and their structure is very specific to the source language, many commonalities come up. In other words, coding \"yet another AST\" gets really old after you've done it a few times. Worry not, as you'd expect from the programmer crowd, this problem was \"solved\" by adding another level of abstraction. Yes, an abstraction over Abstract Syntax Trees, oh my! The abstraction here is some textual format (let's call it a DSL to sound smart) that describes what the AST looks like, along with machinery to auto-generate the code that implements this AST. Most solutions in this domain are ad-hoc, but one that I've seen used more than once is ASDL - Abstract Syntax Definition Language. The self-description from the website sounds about right: The Zephyr Abstract Syntax Description Lanuguage (ASDL) is a language designed to describe the tree-like data structures in compilers. Its main goal is to provide a method for compiler components written in different languages to interoperate. ASDL makes it easier for applications written in a variety of programming languages to communicate complex recursive data structures. To given an example, here's a short snippet from an ASDL definition of a simple programming language: program = Program(class* classes) class = Class(identifier name, identifier? parent, feature* features) [...] expression = Assign(identifier name, expression expr) | StaticDispatch(expression expr, identifier type_name, identifier name, expression* actual) | Dispatch(expression expr, identifier name, expression* actual) [...]","title":"Using ASDL to describe ASTs in compilers"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/03-cpython-AST/Zephyr-ASDL/","text":"\u5173\u4e8eASDL\uff0c\u8bfb\u5b8c\u8bba\u6587 The Zephyr Abstract Syntax Description Language \u5c31\u5b8c\u5168\u53ef\u4ee5\u638c\u63e1\u4e86\uff0c\u65e0\u9700\u8865\u5145\u53e6\u5916\u7684\u5185\u5bb9\u3002","title":"Home"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/03-cpython-AST/Zephyr-ASDL/Zephyr-ASDL-Home-Page/","text":"Zephyr ASDL Home Page Introduction The Zephyr Abstract Syntax Description Language (ASDL) is a language designed to describe the tree-like data structures in compilers. Its main goal is to provide a method for compiler components written in different languages to interoperate. ASDL makes it easier for applications written in a variety of programming languages to communicate complex recursive data structures. asdlGen is a tool that takes ASDL descriptions and produces implementations of those descriptions in a variety of popular languages. ASDL and asdlGen together provide the following advantages Concise descriptions of important data structures. Automatic generation of data structure implementations for C, C++ , Java, Standard ML, and Haskell. Automatic generation of functions to read and write the data structures to disk in a machine and language independent way. ASDL descriptions describe the tree-like data structures such as abstract syntax trees (ASTs) and compiler intermediate representations (IRs). Tools such as asdlGen automatically produce the equivalent data structure definitions for C, C++ , Java, Standard ML, OCaml, and Haskell. asdlGen also produces functions for each language that read and write the data structures to and from a platform and language independent sequence of bytes. The sequence of bytes is called a pickle . ASDL pickles can be interactively viewed and edited with a graphical browser , or pretty printed into a simple textual format. The browser provides some advanced features such as display styles and tree based versions of standard unix tools such as diff and grep . ASDL was part of the Zephyr National Compiler Infrastructure project.","title":"[Zephyr ASDL Home Page](http://asdl.sourceforge.net/)"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/03-cpython-AST/Zephyr-ASDL/Zephyr-ASDL-Home-Page/#zephyr-asdl-home-page","text":"","title":"Zephyr ASDL Home Page"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/03-cpython-AST/Zephyr-ASDL/Zephyr-ASDL-Home-Page/#introduction","text":"The Zephyr Abstract Syntax Description Language (ASDL) is a language designed to describe the tree-like data structures in compilers. Its main goal is to provide a method for compiler components written in different languages to interoperate. ASDL makes it easier for applications written in a variety of programming languages to communicate complex recursive data structures. asdlGen is a tool that takes ASDL descriptions and produces implementations of those descriptions in a variety of popular languages. ASDL and asdlGen together provide the following advantages Concise descriptions of important data structures. Automatic generation of data structure implementations for C, C++ , Java, Standard ML, and Haskell. Automatic generation of functions to read and write the data structures to disk in a machine and language independent way. ASDL descriptions describe the tree-like data structures such as abstract syntax trees (ASTs) and compiler intermediate representations (IRs). Tools such as asdlGen automatically produce the equivalent data structure definitions for C, C++ , Java, Standard ML, OCaml, and Haskell. asdlGen also produces functions for each language that read and write the data structures to and from a platform and language independent sequence of bytes. The sequence of bytes is called a pickle . ASDL pickles can be interactively viewed and edited with a graphical browser , or pretty printed into a simple textual format. The browser provides some advanced features such as display styles and tree based versions of standard unix tools such as diff and grep . ASDL was part of the Zephyr National Compiler Infrastructure project.","title":"Introduction"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/03-cpython-AST/Zephyr-ASDL/paper-The-Zephyr-Abstract-Syntax-Description-Language/","text":"The Zephyr Abstract Syntax Description Language","title":"[The Zephyr Abstract Syntax Description Language](https://www.cs.princeton.edu/research/techreps/TR-554-97)"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/03-cpython-AST/Zephyr-ASDL/paper-The-Zephyr-Abstract-Syntax-Description-Language/#the-zephyr-abstract-syntax-description-language","text":"","title":"The Zephyr Abstract Syntax Description Language"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/04-cpython-symbol-table/","text":"\u5728\u9605\u8bfbdragon book\u7684chapter 1.2 The Structure of a Compiler\u7684\u65f6\u5019\uff0c\u6211\u66fe\u6709\u8fc7\u5982\u4e0b\u7684\u60f3\u6cd5\uff1a \u7b26\u53f7\u8868\u4e5f\u662f\u4e00\u95e8\u79d1\u5b66\uff0c\u9700\u8981\u5bf9\u5b83\u4ed4\u7ec6\u7814\u7a76 \u73b0\u5728\u51c6\u5907\u6765\u7814\u7a76\u7814\u7a76python symbol table\u7684\u5b9e\u73b0\u3002 \u4e3b\u8981\u53c2\u8003\u7684\uff1a Python internals: Symbol tables, part 1 Python internals: Symbol tables, part 2 Design of CPython\u2019s Compiler \u00b6","title":"Home"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/05-cpython-bytecode/opensource-An-introduction-to-Python-bytecode/","text":"An introduction to Python bytecode An introduction to Python bytecode","title":"opensource An introduction to Python bytecode"},{"location":"Python/Language/Developer's-guide/25-Design-of-CPython's-Compiler/05-cpython-bytecode/opensource-An-introduction-to-Python-bytecode/#an-introduction-to-python-bytecode","text":"","title":"An introduction to Python bytecode"},{"location":"Python/Language/Developer's-guide/27-Coverity-Scan/27-Coverity-Scan/","text":"27. Coverity Scan \u00b6","title":"27. Coverity Scan[\u00b6](https://devguide.python.org/coverity/#coverity-scan)"},{"location":"Python/Language/Developer's-guide/27-Coverity-Scan/27-Coverity-Scan/#27-coverity-scan","text":"","title":"27. Coverity Scan\u00b6"},{"location":"Python/Language/Developer's-guide/28-Dynamic-Analysis-with-Clang/28-Dynamic-Analysis-with-Clang/","text":"28. Dynamic Analysis with Clang \u00b6","title":"28. Dynamic Analysis with Clang[\u00b6](https://devguide.python.org/clang/#dynamic-analysis-with-clang)"},{"location":"Python/Language/Developer's-guide/28-Dynamic-Analysis-with-Clang/28-Dynamic-Analysis-with-Clang/#28-dynamic-analysis-with-clang","text":"","title":"28. Dynamic Analysis with Clang\u00b6"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-1-Introduction-to-CPython/","text":"Part 1: Introduction to CPython CPython is one of the many Python runtimes , maintained and written by different teams of developers. Some other runtimes you may have heard are PyPy , Cython , and Jython . The unique thing about CPython is that it contains both a runtime and the shared language specification that all Python runtimes use. CPython is the \u201cofficial,\u201d or reference implementation of Python. The Python language specification is the document that the description of the Python language. For example, it says that assert is a reserved keyword, and that [] is used for indexing, slicing, and creating empty lists. Think about what you expect to be inside the Python distribution on your computer: When you type python without a file or module, it gives an interactive prompt. You can import built-in modules from the standard library like json . You can install packages from the internet using pip . You can test your applications using the built-in unittest library. These are all part of the CPython distribution. There\u2019s a lot more than just a compiler . Note: This article is written against version 3.8.0b4 of the CPython source code. What\u2019s in the Source Code? The CPython source distribution comes with a whole range of tools, libraries, and components. We\u2019ll explore those in this article. First we are going to focus on the compiler. Inside of the newly downloaded cpython directory, you will find the following subdirectories: cpython/ \u2502 \u251c\u2500\u2500 Doc \u2190 Source for the documentation \u251c\u2500\u2500 Grammar \u2190 The computer-readable language definition \u251c\u2500\u2500 Include \u2190 The C header files \u251c\u2500\u2500 Lib \u2190 Standard library modules written in Python \u251c\u2500\u2500 Mac \u2190 macOS support files \u251c\u2500\u2500 Misc \u2190 Miscellaneous files \u251c\u2500\u2500 Modules \u2190 Standard Library Modules written in C \u251c\u2500\u2500 Objects \u2190 Core types and the object model \u251c\u2500\u2500 Parser \u2190 The Python parser source code \u251c\u2500\u2500 PC \u2190 Windows build support files \u251c\u2500\u2500 PCbuild \u2190 Windows build support files for older Windows versions \u251c\u2500\u2500 Programs \u2190 Source code for the python executable and other binaries \u251c\u2500\u2500 Python \u2190 The CPython interpreter source code \u2514\u2500\u2500 Tools \u2190 Standalone tools useful for building or extending Python Next, we\u2019ll compile CPython from the source code. This step requires a C compiler, and some build tools, which depend on the operating system you\u2019re using. Compiling CPython (Linux) For Linux, the first step is to download and install make , gcc , configure , and pkgconfig . What Does a Compiler Do? The purpose of a compiler is to convert one language into another. Think of a compiler like a translator. You would hire a translator to listen to you speaking in English and then speak in Japanese: Some compilers will compile into a low-level machine code which can be executed directly on a system. Other compilers will compile into an intermediary language, to be executed by a virtual machine. One important decision to make when choosing a compiler is the system portability requirements. Java and .NET CLR will compile into an Intermediary Language so that the compiled code is portable across multiple systems architectures. C, Go, C++, and Pascal will compile into a low-level executable that will only work on systems similar to the one it was compiled. Because Python applications are typically distributed as source code, the role of the Python runtime is to convert the Python source code and execute it in one step. Internally, the CPython runtime does compile your code. A popular misconception is that Python is an interpreted language. It is actually compiled. Python code is not compiled into machine-code. It is compiled into a special low-level intermediary language called bytecode that only CPython understands. This code is stored in .pyc files in a hidden directory and cached for execution. If you run the same Python application twice without changing the source code, it\u2019ll always be much faster the second time. This is because it loads the compiled bytecode and executes it directly. Why Is CPython Written in C and Not Python? The C in CPython is a reference to the C programming language, implying that this Python distribution is written in the C language. This statement is largely true: the compiler in CPython is written in pure C. However, many of the standard library modules are written in pure Python or a combination of C and Python. So why is CPython written in C and not Python? The answer is located in how compilers work. There are two types of compiler: Self-hosted compilers are compilers written in the language they compile, such as the Go compiler. Source-to-source compilers are compilers written in another language that already have a compiler. If you\u2019re writing a new programming language from scratch, you need an executable application to compile your compiler! You need a compiler to execute anything, so when new languages are developed, they\u2019re often written first in an older, more established language. A good example would be the Go programming language. The first Go compiler was written in C, then once Go could be compiled, the compiler was rewritten in Go. CPython kept its C heritage: many of the standard library modules, like the ssl module or the sockets module, are written in C to access low-level operating system APIs. The APIs in the Windows and Linux kernels for creating network sockets , working with the filesystem or interacting with the display are all written in C. It made sense for Python\u2019s extensibility layer to be focused on the C language. Later in this article, we will cover the Python Standard Library and the C modules. There is a Python compiler written in Python called PyPy . PyPy\u2019s logo is an Ouroboros to represent the self-hosting nature of the compiler. Another example of a cross-compiler for Python is Jython . Jython is written in Java and compiles from Python source code into Java bytecode. In the same way that CPython makes it easy to import C libraries and use them from Python, Jython makes it easy to import and reference Java modules and classes. The Python Language Specification Contained within the CPython source code is the definition of the Python language. This is the reference specification used by all the Python interpreters. The specification is in both human-readable and machine-readable format. Inside the documentation is a detailed explanation of the Python language, what is allowed, and how each statement should behave. Documentation Located inside the Doc/reference directory are reStructuredText explanations of each of the features in the Python language. This forms the official Python reference guide on docs.python.org . Inside the directory are the files you need to understand the whole language, structure, and keywords: cpython/Doc/reference | \u251c\u2500\u2500 compound_stmts.rst \u251c\u2500\u2500 datamodel.rst \u251c\u2500\u2500 executionmodel.rst \u251c\u2500\u2500 expressions.rst \u251c\u2500\u2500 grammar.rst \u251c\u2500\u2500 import.rst \u251c\u2500\u2500 index.rst \u251c\u2500\u2500 introduction.rst \u251c\u2500\u2500 lexical_analysis.rst \u251c\u2500\u2500 simple_stmts.rst \u2514\u2500\u2500 toplevel_components.rst Inside compound_stmts.rst , the documentation for compound statements, you can see a simple example defining the with statement. The with statement can be used in multiple ways in Python, the simplest being the instantiation of a context-manager and a nested block of code: with x (): ... You can assign the result to a variable using the as keyword: with x () as y : ... You can also chain context managers together with a comma: with x () as y , z () as jk : ... Next, we\u2019ll explore the computer-readable documentation of the Python language. Grammar The documentation contains the human-readable specification of the language, and the machine-readable specification is housed in a single file, Grammar/Grammar . The Grammar file is written in a context-notation called Backus-Naur Form (BNF) . BNF is not specific to Python and is often used as the notation for grammars in many other languages. The concept of grammatical structure in a programming language is inspired by Noam Chomsky\u2019s work on Syntactic Structures in the 1950s! Python\u2019s grammar file uses the Extended-BNF (EBNF) specification with regular-expression syntax. So, in the grammar file you can use: \\* for repetition + for at-least-once repetition [] for optional parts | for alternatives () for grouping If you search for the with statement in the grammar file, at around line 80 you\u2019ll see the definitions for the with statement: with_stmt: 'with' with_item (',' with_item)* ':' suite with_item: test ['as' expr] Anything in quotes is a string literal, which is how keywords are defined. So the with_stmt is specified as: Starting with the word with Followed by a with_item , which is a test and (optionally), the word as , and an expression Following one or many items, each separated by a comma Ending with a : Followed by a suite There are references to some other definitions in these two lines: suite refers to a block of code with one or multiple statements test refers to a simple statement that is evaluated expr refers to a simple expression If you want to explore those in detail, the whole of the Python grammar is defined in this single file. If you want to see a recent example of how grammar is used, in PEP 572 the colon equals operator was added to the grammar file in this Git commit . Using pgen The grammar file itself is never used by the Python compiler . Instead, a parser table created by a tool called pgen is used. pgen reads the grammar file and converts it into a parser table . If you make changes to the grammar file, you must regenerate the parser table and recompile Python. Note: The pgen application was rewritten in Python 3.8 from C to pure Python . To see pgen in action, let\u2019s change part of the Python grammar. Around line 51 you will see the definition of a pass statement: pass_stmt: 'pass' Change that line to accept the keyword 'pass' or 'proceed' as keywords: pass_stmt: 'pass' | 'proceed' Now you need to rebuild the grammar files. On macOS and Linux, run make regen-grammar to run pgen over the altered grammar file. For Windows, there is no officially supported way of running pgen . However, you can clone my fork and run build.bat --regen from within the PCBuild directory. You should see an output similar to this, showing that the new Include/graminit.h and Python/graminit.c files have been generated: # Regenerate Doc/library/token-list.inc from Grammar/Tokens # using Tools/scripts/generate_token.py ... python3 ./Tools/scripts/update_file.py ./Include/graminit.h ./Include/graminit.h.new python3 ./Tools/scripts/update_file.py ./Python/graminit.c ./Python/graminit.c.new Note: pgen works by converting the EBNF statements into a Non-deterministic Finite Automaton (NFA) , which is then turned into a Deterministic Finite Automaton (DFA) . The DFAs are used by the parser as parsing tables in a special way that\u2019s unique to CPython. This technique was formed at Stanford University and developed in the 1980s, just before the advent of Python. With the regenerated parser tables, you need to recompile CPython to see the new syntax. Use the same compilation steps you used earlier for your operating system. If the code compiled successfully, you can execute your new CPython binary and start a REPL. In the REPL, you can now try defining a function and instead of using the pass statement, use the proceed keyword alternative that you compiled into the Python grammar: Python 3.8.0b4 (tags/v3.8.0b4:d93605de72, Aug 30 2019, 10:00:03) [Clang 10.0.1 (clang-1001.0.46.4)] on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> def example(): ... proceed ... >>> example() Well done! You\u2019ve changed the CPython syntax and compiled your own version of CPython. Ship it! Next, we\u2019ll explore tokens and their relationship to grammar. Tokens Alongside the grammar file in the Grammar folder is a Tokens file, which contains each of the unique types found as a leaf node in a parse tree . We will cover parser trees in depth later. Each token also has a name and a generated unique ID. The names are used to make it simpler to refer to in the tokenizer . Note: The Tokens file is a new feature in Python 3.8. For example, the left parenthesis is called LPAR , and semicolons are called SEMI . You\u2019ll see these tokens later in the article: LPAR '(' RPAR ')' LSQB '[' RSQB ']' COLON ':' COMMA ',' SEMI ';' As with the Grammar file, if you change the Tokens file, you need to run pgen again. To see tokens in action, you can use the tokenize module in CPython. Create a simple Python script called test_tokens.py : # Hello world! def my_function (): proceed Then pass this file through a module built into the standard library called tokenize . You will see the list of tokens, by line and character. Use the -e flag to output the exact token name: $ ./python.exe -m tokenize -e test_tokens.py 0 ,0-0,0: ENCODING 'utf-8' 1 ,0-1,14: COMMENT '# Hello world!' 1 ,14-1,15: NL '\\n' 2 ,0-2,3: NAME 'def' 2 ,4-2,15: NAME 'my_function' 2 ,15-2,16: LPAR '(' 2 ,16-2,17: RPAR ')' 2 ,17-2,18: COLON ':' 2 ,18-2,19: NEWLINE '\\n' 3 ,0-3,3: INDENT ' ' 3 ,3-3,7: NAME 'proceed' 3 ,7-3,8: NEWLINE '\\n' 4 ,0-4,0: DEDENT '' 4 ,0-4,0: ENDMARKER '' In the output, the first column is the range of the line/column coordinates, the second column is the name of the token, and the final column is the value of the token. In the output, the tokenize module has implied some tokens that were not in the file. The ENCODING token for utf-8 , and a blank line at the end, giving DEDENT to close the function declaration and an ENDMARKER to end the file. It is best practice to have a blank line at the end of your Python source files. If you omit it, CPython adds it for you, with a tiny performance penalty. The tokenize module is written in pure Python and is located in Lib/tokenize.py within the CPython source code. Important: There are two tokenizers in the CPython source code: one written in Python, demonstrated here, and another written in C. The tokenizer written in Python is meant as a utility, and the one written in C is used by the Python compiler. They have identical output and behavior. The version written in C is designed for performance and the module in Python is designed for debugging. NOTE: The tokenizer written in C is in dir Parser . Now that you have an overview of the Python grammar and the relationship between tokens and statements, there is a way to convert the pgen output into an interactive graph. Here is a screenshot of the Python 3.8a2 grammar: The Python package used to generate this graph, instaviz , will be covered in a later chapter. Memory Management in CPython Throughout this article, you will see references to a PyArena object. The arena is one of CPython\u2019s memory management structures. The code is within Python/pyarena.c and contains a wrapper around C\u2019s memory allocation and deallocation functions. In a traditionally written C program, the developer should allocate memory for data structures before writing into that data. This allocation marks the memory as belonging to the process with the operating system. Python takes that responsibility away from the programmer and uses two algorithms: a reference counter and a garbage collector . Whenever an interpreter is instantiated, a PyArena is created and attached one of the fields in the interpreter. During the lifecycle of a CPython interpreter, many arenas could be allocated. They are connected with a linked list. The arena stores a list of pointers to Python Objects as a PyListObject . Whenever a new Python object is created, a pointer to it is added using PyArena_AddPyObject() . This function call stores a pointer in the arena\u2019s list, a_objects . Even though Python doesn\u2019t have pointers, there are some interesting techniques to simulate the behavior of pointers. The PyArena serves a second function, which is to allocate and reference a list of raw memory blocks. For example, a PyList would need extra memory if you added thousands of additional values. The PyList object\u2019s C code does not allocate memory directly. The object gets raw blocks of memory from the PyArena by calling PyArena_Malloc() from the PyObject with the required memory size. This task is completed by another abstraction in Objects/obmalloc.c . In the object allocation module, memory can be allocated, freed, and reallocated for a Python Object. A linked list of allocated blocks is stored inside the arena, so that when an interpreter is stopped, all managed memory blocks can be deallocated in one go using PyArena_Free() . Take the PyListObject example. If you were to .append() an object to the end of a Python list, you don\u2019t need to reallocate the memory used in the existing list beforehand. The .append() method calls list_resize() which handles memory allocation for lists. Each list object keeps a list of the amount of memory allocated. If the item you\u2019re appending will fit inside the existing free memory, it is simply added. If the list needs more memory space, it is expanded. Lists are expanded in length as 0, 4, 8, 16, 25, 35, 46, 58, 72, 88. PyMem_Realloc() is called to expand the memory allocated in a list. PyMem_Realloc() is an API wrapper for pymalloc_realloc() . Python also has a special wrapper for the C call malloc() , which sets the max size of the memory allocation to help prevent buffer overflow errors (See PyMem_RawMalloc() ). In summary: Allocation of raw memory blocks is done via PyMem_RawAlloc() . The pointers to Python objects are stored within the PyArena . PyArena also stores a linked-list of allocated memory blocks. More information on the API is detailed on the CPython documentation . Reference Counting To create a variable in Python, you have to assign a value to a uniquely named variable: my_variable = 180392 Whenever a value is assigned to a variable in Python, the name of the variable is checked within the locals and globals scope to see if it already exists. Because my_variable is not already within the locals() or globals() dictionary, this new object is created, and the value is assigned as being the numeric constant 180392 . There is now one reference to my_variable , so the reference counter for my_variable is incremented by 1. You will see function calls Py_INCREF() and Py_DECREF() throughout the C source code for CPython. These functions increment and decrement the count of references to that object. References to an object are decremented when a variable falls outside of the scope in which it was declared. Scope in Python can refer to a function or method, a comprehension, or a lambda function. These are some of the more literal scopes, but there are many other implicit scopes, like passing variables to a function call. The handling of incrementing and decrementing references based on the language is built into the CPython compiler and the core execution loop, ceval.c , which we will cover in detail later in this article. Whenever Py_DECREF() is called, and the counter becomes 0, the PyObject_Free() function is called. For that object PyArena_Free() is called for all of the memory that was allocated. Garbage Collection How often does your garbage get collected? Weekly, or fortnightly? When you\u2019re finished with something, you discard it and throw it in the trash. But that trash won\u2019t get collected straight away. You need to wait for the garbage trucks to come and pick it up. CPython has the same principle, using a garbage collection algorithm. CPython\u2019s garbage collector is enabled by default, happens in the background and works to deallocate memory that\u2019s been used for objects which are no longer in use. Because the garbage collection algorithm is a lot more complex than the reference counter, it doesn\u2019t happen all the time, otherwise, it would consume a huge amount of CPU resources. It happens periodically, after a set number of operations. CPython\u2019s standard library comes with a Python module to interface with the arena and the garbage collector, the gc module. Here\u2019s how to use the gc module in debug mode: >>> import gc >>> gc.set_debug(gc.DEBUG_STATS) This will print the statistics whenever the garbage collector is run. You can get the threshold after which the garbage collector is run by calling get_threshold() : >>> gc.get_threshold() (700, 10, 10) You can also get the current threshold counts: >>> gc.get_count() (688, 1, 1) Lastly, you can run the collection algorithm manually: >>> gc.collect() 24 This will call collect() inside the Modules/gcmodule.c file which contains the implementation of the garbage collector algorithm. Conclusion In Part 1, you covered the structure of the source code repository, how to compile from source, and the Python language specification. These core concepts will be critical in Part 2 as you dive deeper into the Python interpreter process.","title":"Part 1 Introduction to CPython"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-1-Introduction-to-CPython/#part-1-introduction-to-cpython","text":"CPython is one of the many Python runtimes , maintained and written by different teams of developers. Some other runtimes you may have heard are PyPy , Cython , and Jython . The unique thing about CPython is that it contains both a runtime and the shared language specification that all Python runtimes use. CPython is the \u201cofficial,\u201d or reference implementation of Python. The Python language specification is the document that the description of the Python language. For example, it says that assert is a reserved keyword, and that [] is used for indexing, slicing, and creating empty lists. Think about what you expect to be inside the Python distribution on your computer: When you type python without a file or module, it gives an interactive prompt. You can import built-in modules from the standard library like json . You can install packages from the internet using pip . You can test your applications using the built-in unittest library. These are all part of the CPython distribution. There\u2019s a lot more than just a compiler . Note: This article is written against version 3.8.0b4 of the CPython source code.","title":"Part 1: Introduction to CPython"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-1-Introduction-to-CPython/#whats-in-the-source-code","text":"The CPython source distribution comes with a whole range of tools, libraries, and components. We\u2019ll explore those in this article. First we are going to focus on the compiler. Inside of the newly downloaded cpython directory, you will find the following subdirectories: cpython/ \u2502 \u251c\u2500\u2500 Doc \u2190 Source for the documentation \u251c\u2500\u2500 Grammar \u2190 The computer-readable language definition \u251c\u2500\u2500 Include \u2190 The C header files \u251c\u2500\u2500 Lib \u2190 Standard library modules written in Python \u251c\u2500\u2500 Mac \u2190 macOS support files \u251c\u2500\u2500 Misc \u2190 Miscellaneous files \u251c\u2500\u2500 Modules \u2190 Standard Library Modules written in C \u251c\u2500\u2500 Objects \u2190 Core types and the object model \u251c\u2500\u2500 Parser \u2190 The Python parser source code \u251c\u2500\u2500 PC \u2190 Windows build support files \u251c\u2500\u2500 PCbuild \u2190 Windows build support files for older Windows versions \u251c\u2500\u2500 Programs \u2190 Source code for the python executable and other binaries \u251c\u2500\u2500 Python \u2190 The CPython interpreter source code \u2514\u2500\u2500 Tools \u2190 Standalone tools useful for building or extending Python Next, we\u2019ll compile CPython from the source code. This step requires a C compiler, and some build tools, which depend on the operating system you\u2019re using.","title":"What\u2019s in the Source Code?"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-1-Introduction-to-CPython/#compiling-cpython-linux","text":"For Linux, the first step is to download and install make , gcc , configure , and pkgconfig .","title":"Compiling CPython (Linux)"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-1-Introduction-to-CPython/#what-does-a-compiler-do","text":"The purpose of a compiler is to convert one language into another. Think of a compiler like a translator. You would hire a translator to listen to you speaking in English and then speak in Japanese: Some compilers will compile into a low-level machine code which can be executed directly on a system. Other compilers will compile into an intermediary language, to be executed by a virtual machine. One important decision to make when choosing a compiler is the system portability requirements. Java and .NET CLR will compile into an Intermediary Language so that the compiled code is portable across multiple systems architectures. C, Go, C++, and Pascal will compile into a low-level executable that will only work on systems similar to the one it was compiled. Because Python applications are typically distributed as source code, the role of the Python runtime is to convert the Python source code and execute it in one step. Internally, the CPython runtime does compile your code. A popular misconception is that Python is an interpreted language. It is actually compiled. Python code is not compiled into machine-code. It is compiled into a special low-level intermediary language called bytecode that only CPython understands. This code is stored in .pyc files in a hidden directory and cached for execution. If you run the same Python application twice without changing the source code, it\u2019ll always be much faster the second time. This is because it loads the compiled bytecode and executes it directly.","title":"What Does a Compiler Do?"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-1-Introduction-to-CPython/#why-is-cpython-written-in-c-and-not-python","text":"The C in CPython is a reference to the C programming language, implying that this Python distribution is written in the C language. This statement is largely true: the compiler in CPython is written in pure C. However, many of the standard library modules are written in pure Python or a combination of C and Python. So why is CPython written in C and not Python? The answer is located in how compilers work. There are two types of compiler: Self-hosted compilers are compilers written in the language they compile, such as the Go compiler. Source-to-source compilers are compilers written in another language that already have a compiler. If you\u2019re writing a new programming language from scratch, you need an executable application to compile your compiler! You need a compiler to execute anything, so when new languages are developed, they\u2019re often written first in an older, more established language. A good example would be the Go programming language. The first Go compiler was written in C, then once Go could be compiled, the compiler was rewritten in Go. CPython kept its C heritage: many of the standard library modules, like the ssl module or the sockets module, are written in C to access low-level operating system APIs. The APIs in the Windows and Linux kernels for creating network sockets , working with the filesystem or interacting with the display are all written in C. It made sense for Python\u2019s extensibility layer to be focused on the C language. Later in this article, we will cover the Python Standard Library and the C modules. There is a Python compiler written in Python called PyPy . PyPy\u2019s logo is an Ouroboros to represent the self-hosting nature of the compiler. Another example of a cross-compiler for Python is Jython . Jython is written in Java and compiles from Python source code into Java bytecode. In the same way that CPython makes it easy to import C libraries and use them from Python, Jython makes it easy to import and reference Java modules and classes.","title":"Why Is CPython Written in C and Not Python?"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-1-Introduction-to-CPython/#the-python-language-specification","text":"Contained within the CPython source code is the definition of the Python language. This is the reference specification used by all the Python interpreters. The specification is in both human-readable and machine-readable format. Inside the documentation is a detailed explanation of the Python language, what is allowed, and how each statement should behave.","title":"The Python Language Specification"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-1-Introduction-to-CPython/#documentation","text":"Located inside the Doc/reference directory are reStructuredText explanations of each of the features in the Python language. This forms the official Python reference guide on docs.python.org . Inside the directory are the files you need to understand the whole language, structure, and keywords: cpython/Doc/reference | \u251c\u2500\u2500 compound_stmts.rst \u251c\u2500\u2500 datamodel.rst \u251c\u2500\u2500 executionmodel.rst \u251c\u2500\u2500 expressions.rst \u251c\u2500\u2500 grammar.rst \u251c\u2500\u2500 import.rst \u251c\u2500\u2500 index.rst \u251c\u2500\u2500 introduction.rst \u251c\u2500\u2500 lexical_analysis.rst \u251c\u2500\u2500 simple_stmts.rst \u2514\u2500\u2500 toplevel_components.rst Inside compound_stmts.rst , the documentation for compound statements, you can see a simple example defining the with statement. The with statement can be used in multiple ways in Python, the simplest being the instantiation of a context-manager and a nested block of code: with x (): ... You can assign the result to a variable using the as keyword: with x () as y : ... You can also chain context managers together with a comma: with x () as y , z () as jk : ... Next, we\u2019ll explore the computer-readable documentation of the Python language.","title":"Documentation"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-1-Introduction-to-CPython/#grammar","text":"The documentation contains the human-readable specification of the language, and the machine-readable specification is housed in a single file, Grammar/Grammar . The Grammar file is written in a context-notation called Backus-Naur Form (BNF) . BNF is not specific to Python and is often used as the notation for grammars in many other languages. The concept of grammatical structure in a programming language is inspired by Noam Chomsky\u2019s work on Syntactic Structures in the 1950s! Python\u2019s grammar file uses the Extended-BNF (EBNF) specification with regular-expression syntax. So, in the grammar file you can use: \\* for repetition + for at-least-once repetition [] for optional parts | for alternatives () for grouping If you search for the with statement in the grammar file, at around line 80 you\u2019ll see the definitions for the with statement: with_stmt: 'with' with_item (',' with_item)* ':' suite with_item: test ['as' expr] Anything in quotes is a string literal, which is how keywords are defined. So the with_stmt is specified as: Starting with the word with Followed by a with_item , which is a test and (optionally), the word as , and an expression Following one or many items, each separated by a comma Ending with a : Followed by a suite There are references to some other definitions in these two lines: suite refers to a block of code with one or multiple statements test refers to a simple statement that is evaluated expr refers to a simple expression If you want to explore those in detail, the whole of the Python grammar is defined in this single file. If you want to see a recent example of how grammar is used, in PEP 572 the colon equals operator was added to the grammar file in this Git commit .","title":"Grammar"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-1-Introduction-to-CPython/#using-pgen","text":"The grammar file itself is never used by the Python compiler . Instead, a parser table created by a tool called pgen is used. pgen reads the grammar file and converts it into a parser table . If you make changes to the grammar file, you must regenerate the parser table and recompile Python. Note: The pgen application was rewritten in Python 3.8 from C to pure Python . To see pgen in action, let\u2019s change part of the Python grammar. Around line 51 you will see the definition of a pass statement: pass_stmt: 'pass' Change that line to accept the keyword 'pass' or 'proceed' as keywords: pass_stmt: 'pass' | 'proceed' Now you need to rebuild the grammar files. On macOS and Linux, run make regen-grammar to run pgen over the altered grammar file. For Windows, there is no officially supported way of running pgen . However, you can clone my fork and run build.bat --regen from within the PCBuild directory. You should see an output similar to this, showing that the new Include/graminit.h and Python/graminit.c files have been generated: # Regenerate Doc/library/token-list.inc from Grammar/Tokens # using Tools/scripts/generate_token.py ... python3 ./Tools/scripts/update_file.py ./Include/graminit.h ./Include/graminit.h.new python3 ./Tools/scripts/update_file.py ./Python/graminit.c ./Python/graminit.c.new Note: pgen works by converting the EBNF statements into a Non-deterministic Finite Automaton (NFA) , which is then turned into a Deterministic Finite Automaton (DFA) . The DFAs are used by the parser as parsing tables in a special way that\u2019s unique to CPython. This technique was formed at Stanford University and developed in the 1980s, just before the advent of Python. With the regenerated parser tables, you need to recompile CPython to see the new syntax. Use the same compilation steps you used earlier for your operating system. If the code compiled successfully, you can execute your new CPython binary and start a REPL. In the REPL, you can now try defining a function and instead of using the pass statement, use the proceed keyword alternative that you compiled into the Python grammar: Python 3.8.0b4 (tags/v3.8.0b4:d93605de72, Aug 30 2019, 10:00:03) [Clang 10.0.1 (clang-1001.0.46.4)] on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> def example(): ... proceed ... >>> example() Well done! You\u2019ve changed the CPython syntax and compiled your own version of CPython. Ship it! Next, we\u2019ll explore tokens and their relationship to grammar.","title":"Using pgen"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-1-Introduction-to-CPython/#tokens","text":"Alongside the grammar file in the Grammar folder is a Tokens file, which contains each of the unique types found as a leaf node in a parse tree . We will cover parser trees in depth later. Each token also has a name and a generated unique ID. The names are used to make it simpler to refer to in the tokenizer . Note: The Tokens file is a new feature in Python 3.8. For example, the left parenthesis is called LPAR , and semicolons are called SEMI . You\u2019ll see these tokens later in the article: LPAR '(' RPAR ')' LSQB '[' RSQB ']' COLON ':' COMMA ',' SEMI ';' As with the Grammar file, if you change the Tokens file, you need to run pgen again. To see tokens in action, you can use the tokenize module in CPython. Create a simple Python script called test_tokens.py : # Hello world! def my_function (): proceed Then pass this file through a module built into the standard library called tokenize . You will see the list of tokens, by line and character. Use the -e flag to output the exact token name: $ ./python.exe -m tokenize -e test_tokens.py 0 ,0-0,0: ENCODING 'utf-8' 1 ,0-1,14: COMMENT '# Hello world!' 1 ,14-1,15: NL '\\n' 2 ,0-2,3: NAME 'def' 2 ,4-2,15: NAME 'my_function' 2 ,15-2,16: LPAR '(' 2 ,16-2,17: RPAR ')' 2 ,17-2,18: COLON ':' 2 ,18-2,19: NEWLINE '\\n' 3 ,0-3,3: INDENT ' ' 3 ,3-3,7: NAME 'proceed' 3 ,7-3,8: NEWLINE '\\n' 4 ,0-4,0: DEDENT '' 4 ,0-4,0: ENDMARKER '' In the output, the first column is the range of the line/column coordinates, the second column is the name of the token, and the final column is the value of the token. In the output, the tokenize module has implied some tokens that were not in the file. The ENCODING token for utf-8 , and a blank line at the end, giving DEDENT to close the function declaration and an ENDMARKER to end the file. It is best practice to have a blank line at the end of your Python source files. If you omit it, CPython adds it for you, with a tiny performance penalty. The tokenize module is written in pure Python and is located in Lib/tokenize.py within the CPython source code. Important: There are two tokenizers in the CPython source code: one written in Python, demonstrated here, and another written in C. The tokenizer written in Python is meant as a utility, and the one written in C is used by the Python compiler. They have identical output and behavior. The version written in C is designed for performance and the module in Python is designed for debugging. NOTE: The tokenizer written in C is in dir Parser . Now that you have an overview of the Python grammar and the relationship between tokens and statements, there is a way to convert the pgen output into an interactive graph. Here is a screenshot of the Python 3.8a2 grammar: The Python package used to generate this graph, instaviz , will be covered in a later chapter.","title":"Tokens"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-1-Introduction-to-CPython/#memory-management-in-cpython","text":"Throughout this article, you will see references to a PyArena object. The arena is one of CPython\u2019s memory management structures. The code is within Python/pyarena.c and contains a wrapper around C\u2019s memory allocation and deallocation functions. In a traditionally written C program, the developer should allocate memory for data structures before writing into that data. This allocation marks the memory as belonging to the process with the operating system. Python takes that responsibility away from the programmer and uses two algorithms: a reference counter and a garbage collector . Whenever an interpreter is instantiated, a PyArena is created and attached one of the fields in the interpreter. During the lifecycle of a CPython interpreter, many arenas could be allocated. They are connected with a linked list. The arena stores a list of pointers to Python Objects as a PyListObject . Whenever a new Python object is created, a pointer to it is added using PyArena_AddPyObject() . This function call stores a pointer in the arena\u2019s list, a_objects . Even though Python doesn\u2019t have pointers, there are some interesting techniques to simulate the behavior of pointers. The PyArena serves a second function, which is to allocate and reference a list of raw memory blocks. For example, a PyList would need extra memory if you added thousands of additional values. The PyList object\u2019s C code does not allocate memory directly. The object gets raw blocks of memory from the PyArena by calling PyArena_Malloc() from the PyObject with the required memory size. This task is completed by another abstraction in Objects/obmalloc.c . In the object allocation module, memory can be allocated, freed, and reallocated for a Python Object. A linked list of allocated blocks is stored inside the arena, so that when an interpreter is stopped, all managed memory blocks can be deallocated in one go using PyArena_Free() . Take the PyListObject example. If you were to .append() an object to the end of a Python list, you don\u2019t need to reallocate the memory used in the existing list beforehand. The .append() method calls list_resize() which handles memory allocation for lists. Each list object keeps a list of the amount of memory allocated. If the item you\u2019re appending will fit inside the existing free memory, it is simply added. If the list needs more memory space, it is expanded. Lists are expanded in length as 0, 4, 8, 16, 25, 35, 46, 58, 72, 88. PyMem_Realloc() is called to expand the memory allocated in a list. PyMem_Realloc() is an API wrapper for pymalloc_realloc() . Python also has a special wrapper for the C call malloc() , which sets the max size of the memory allocation to help prevent buffer overflow errors (See PyMem_RawMalloc() ). In summary: Allocation of raw memory blocks is done via PyMem_RawAlloc() . The pointers to Python objects are stored within the PyArena . PyArena also stores a linked-list of allocated memory blocks. More information on the API is detailed on the CPython documentation .","title":"Memory Management in CPython"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-1-Introduction-to-CPython/#reference-counting","text":"To create a variable in Python, you have to assign a value to a uniquely named variable: my_variable = 180392 Whenever a value is assigned to a variable in Python, the name of the variable is checked within the locals and globals scope to see if it already exists. Because my_variable is not already within the locals() or globals() dictionary, this new object is created, and the value is assigned as being the numeric constant 180392 . There is now one reference to my_variable , so the reference counter for my_variable is incremented by 1. You will see function calls Py_INCREF() and Py_DECREF() throughout the C source code for CPython. These functions increment and decrement the count of references to that object. References to an object are decremented when a variable falls outside of the scope in which it was declared. Scope in Python can refer to a function or method, a comprehension, or a lambda function. These are some of the more literal scopes, but there are many other implicit scopes, like passing variables to a function call. The handling of incrementing and decrementing references based on the language is built into the CPython compiler and the core execution loop, ceval.c , which we will cover in detail later in this article. Whenever Py_DECREF() is called, and the counter becomes 0, the PyObject_Free() function is called. For that object PyArena_Free() is called for all of the memory that was allocated.","title":"Reference Counting"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-1-Introduction-to-CPython/#garbage-collection","text":"How often does your garbage get collected? Weekly, or fortnightly? When you\u2019re finished with something, you discard it and throw it in the trash. But that trash won\u2019t get collected straight away. You need to wait for the garbage trucks to come and pick it up. CPython has the same principle, using a garbage collection algorithm. CPython\u2019s garbage collector is enabled by default, happens in the background and works to deallocate memory that\u2019s been used for objects which are no longer in use. Because the garbage collection algorithm is a lot more complex than the reference counter, it doesn\u2019t happen all the time, otherwise, it would consume a huge amount of CPU resources. It happens periodically, after a set number of operations. CPython\u2019s standard library comes with a Python module to interface with the arena and the garbage collector, the gc module. Here\u2019s how to use the gc module in debug mode: >>> import gc >>> gc.set_debug(gc.DEBUG_STATS) This will print the statistics whenever the garbage collector is run. You can get the threshold after which the garbage collector is run by calling get_threshold() : >>> gc.get_threshold() (700, 10, 10) You can also get the current threshold counts: >>> gc.get_count() (688, 1, 1) Lastly, you can run the collection algorithm manually: >>> gc.collect() 24 This will call collect() inside the Modules/gcmodule.c file which contains the implementation of the garbage collector algorithm.","title":"Garbage Collection"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-1-Introduction-to-CPython/#conclusion","text":"In Part 1, you covered the structure of the source code repository, how to compile from source, and the Python language specification. These core concepts will be critical in Part 2 as you dive deeper into the Python interpreter process.","title":"Conclusion"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-2-The-Python-Interpreter-Process/","text":"Part 2: The Python Interpreter Process Now that you\u2019ve seen the Python grammar and memory management, you can follow the process from typing python to the part where your code is executed. There are five ways the python binary can be called: To run a single command with -c and a Python command To start a module with -m and the name of a module To run a file with the filename To run the stdin input using a shell pipe To start the REPL and execute commands one at a time Python has so many ways to execute scripts, it can be a little overwhelming. Darren Jones has put together a great course on running Python scripts if you want to learn more. The three source files you need to inspect to see this process are: Programs/python.c is a simple entry point. Modules/main.c contains the code to bring together the whole process, loading configuration, executing code and clearing up memory. Python/initconfig.c loads the configuration from the system environment and merges it with any command-line flags. This diagram shows how each of those functions is called: The execution mode is determined from the configuration. The CPython source code style: Similar to the PEP8 style guide for Python code , there is an official style guide for the CPython C code, designed originally in 2001 and updated for modern versions. There are some naming standards which help when navigating the source code: Use a Py prefix for public functions, never for static functions. The Py_ prefix is reserved for global service routines like Py_FatalError . Specific groups of routines (like specific object type APIs) use a longer prefix, such as PyString_ for string functions. Public functions and variables use MixedCase with underscores, like this: PyObject_GetAttr , Py_BuildValue , PyExc_TypeError . Occasionally an \u201cinternal\u201d function has to be visible to the loader. We use the _Py prefix for this, for example, _PyObject_Dump . Macros should have a MixedCase prefix and then use upper case, for example PyString_AS_STRING , Py_PRINT_RAW . Establishing Runtime Configuration In the swimlanes, you can see that before any Python code is executed, the runtime first establishes the configuration. The configuration of the runtime is a data structure defined in Include/cpython/initconfig.h named PyConfig . The configuration data structure includes things like: Runtime flags for various modes like debug and optimized mode The execution mode , such as whether a filename was passed, stdin was provided or a module name Extended option , specified by -X Environment variables for runtime settings The configuration data is primarily used by the CPython runtime to enable and disable various features. Python also comes with several Command Line Interface Options . In Python you can enable verbose mode with the -v flag. In verbose mode, Python will print messages to the screen when modules are loaded: python -v -c \"print('hello world')\" You will see a hundred lines or more with all the imports of your user site-packages and anything else in the system environment. You can see the definition of this flag within Include/cpython/initconfig.h inside the struct for PyConfig : /* --- PyConfig ---------------------------------------------- */ typedef struct { int _config_version ; /* Internal configuration version, used for ABI compatibility */ int _config_init ; /* _PyConfigInitEnum value */ ... /* If greater than 0, enable the verbose mode: print a message each time a module is initialized, showing the place (filename or built-in module) from which it is loaded. If greater or equal to 2, print a message for each file that is checked for when searching for a module. Also provides information on module cleanup at exit. Incremented by the -v option. Set by the PYTHONVERBOSE environment variable. If set to -1 (default), inherit Py_VerboseFlag value. */ int verbose ; In Python/initconfig.c , the logic for reading settings from environment variables and runtime command-line flags is established. In the config_read_env_vars function, the environment variables are read and used to assign the values for the configuration settings: static PyStatus config_read_env_vars ( PyConfig * config ) { PyStatus status ; int use_env = config -> use_environment ; /* Get environment variables */ _Py_get_env_flag ( use_env , & config -> parser_debug , \"PYTHONDEBUG\" ); _Py_get_env_flag ( use_env , & config -> verbose , \"PYTHONVERBOSE\" ); _Py_get_env_flag ( use_env , & config -> optimization_level , \"PYTHONOPTIMIZE\" ); _Py_get_env_flag ( use_env , & config -> inspect , \"PYTHONINSPECT\" ); For the verbose setting, you can see that the value of PYTHONVERBOSE is used to set the value of &config->verbose , if PYTHONVERBOSE is found. If the environment variable does not exist, then the default value of -1 will remain. Then in config_parse_cmdline within initconfig.c again, the command-line flag is used to set the value, if provided: static PyStatus config_parse_cmdline ( PyConfig * config , PyWideStringList * warnoptions , Py_ssize_t * opt_index ) { ... switch ( c ) { ... case 'v' : config -> verbose ++ ; break ; ... /* This space reserved for other options */ default : /* unknown argument: parsing failed */ config_usage ( 1 , program ); return _PyStatus_EXIT ( 2 ); } } while ( 1 ); This value is later copied to a global variable Py_VerboseFlag by the _Py_GetGlobalVariablesAsDict function. Within a Python session, you can access the runtime flags, like verbose mode, quiet mode, using the sys.flags named tuple. The -X flags are all available inside the sys._xoptions dictionary: $ ./python.exe -X dev -q >>> import sys >>> sys.flags sys.flags(debug=0, inspect=0, interactive=0, optimize=0, dont_write_bytecode=0, no_user_site=0, no_site=0, ignore_environment=0, verbose=0, bytes_warning=0, quiet=1, hash_randomization=1, isolated=0, dev_mode=True, utf8_mode=0) >>> sys._xoptions {'dev': True} As well as the runtime configuration in initconfig.h , there is also the build configuration , which is located inside pyconfig.h in the root folder. This file is created dynamically in the configure step in the build process, or by Visual Studio for Windows systems. You can see the build configuration by running: $ ./python.exe -m sysconfig Reading Files/Input Once CPython has the runtime configuration and the command-line arguments, it can establish what it needs to execute. This task is handled by the pymain_main function inside Modules/main.c . Depending on the newly created config instance, CPython will now execute code provided via several options. Input via -c The simplest is providing CPython a command with the -c option and a Python program inside quotes. For example: $ ./python.exe -c \"print('hi')\" hi Here is the full flowchart of how this happens: First, the pymain_run_command() function is executed inside Modules/main.c taking the command passed in -c as an argument in the C type wchar_t* . The wchar_t* type is often used as a low-level storage type for Unicode data across CPython as the size of the type can store UTF8 characters. When converting the wchar_t* to a Python string, the Objects/unicodeobject.c file has a helper function PyUnicode_FromWideChar() that returns a PyObject , of type str . The encoding to UTF8 is then done by PyUnicode_AsUTF8String() on the Python str object to convert it to a Python bytes object. Once this is complete, pymain_run_command() will then pass the Python bytes object to PyRun_SimpleStringFlags() for execution, but first converting the bytes to a str type again: static int pymain_run_command ( wchar_t * command , PyCompilerFlags * cf ) { PyObject * unicode , * bytes ; int ret ; unicode = PyUnicode_FromWideChar ( command , - 1 ); if ( unicode == NULL ) { goto error ; } if ( PySys_Audit ( \"cpython.run_command\" , \"O\" , unicode ) < 0 ) { return pymain_exit_err_print (); } bytes = PyUnicode_AsUTF8String ( unicode ); Py_DECREF ( unicode ); if ( bytes == NULL ) { goto error ; } ret = PyRun_SimpleStringFlags ( PyBytes_AsString ( bytes ), cf ); Py_DECREF ( bytes ); return ( ret != 0 ); error : PySys_WriteStderr ( \"Unable to decode the command from the command line: \\n \" ); return pymain_exit_err_print (); } The conversion of wchar_t* to Unicode, bytes, and then a string is roughly equivalent to the following: unicode = str ( command ) bytes_ = bytes ( unicode . encode ( 'utf8' )) # call PyRun_SimpleStringFlags with bytes_ The PyRun_SimpleStringFlags() function is part of Python/pythonrun.c . It\u2019s purpose is to turn this simple command into a Python module and then send it on to be executed. Since a Python module needs to have __main__ to be executed as a standalone module, it creates that automatically: int PyRun_SimpleStringFlags ( const char * command , PyCompilerFlags * flags ) { PyObject * m , * d , * v ; m = PyImport_AddModule ( \"__main__\" ); if ( m == NULL ) return - 1 ; d = PyModule_GetDict ( m ); v = PyRun_StringFlags ( command , Py_file_input , d , d , flags ); if ( v == NULL ) { PyErr_Print (); return - 1 ; } Py_DECREF ( v ); return 0 ; } Once PyRun_SimpleStringFlags() has created a module and a dictionary, it calls PyRun_StringFlags() , which creates a fake filename and then calls the Python parser to create an AST from the string and return a module , mod : PyObject * PyRun_StringFlags ( const char * str , int start , PyObject * globals , PyObject * locals , PyCompilerFlags * flags ) { ... mod = PyParser_ASTFromStringObject ( str , filename , start , flags , arena ); if ( mod != NULL ) ret = run_mod ( mod , filename , globals , locals , flags , arena ); PyArena_Free ( arena ); return ret ; You\u2019ll dive into the AST and Parser code in the next section. NOTE: command string\u2192python module\u2192AST Input via -m Another way to execute Python commands is by using the -m option with the name of a module. A typical example is python -m unittest to run the unittest module in the standard library. Being able to execute modules as scripts were initially proposed in PEP 338 and then the standard for explicit relative imports defined in PEP366 . The use of the -m flag implies that within the module package, you want to execute whatever is inside __main__ . It also implies that you want to search sys.path for the named module. This search mechanism is why you don\u2019t need to remember where the unittest module is stored on your filesystem. Inside Modules/main.c there is a function called when the command-line is run with the -m flag. The name of the module is passed as the modname argument. CPython will then import a standard library module, runpy and execute it using PyObject_Call() . The import is done using the C API function PyImport_ImportModule() , found within the Python/import.c file: static int pymain_run_module ( const wchar_t * modname , int set_argv0 ) { PyObject * module , * runpy , * runmodule , * runargs , * result ; runpy = PyImport_ImportModule ( \"runpy\" ); ... runmodule = PyObject_GetAttrString ( runpy , \"_run_module_as_main\" ); ... module = PyUnicode_FromWideChar ( modname , wcslen ( modname )); ... runargs = Py_BuildValue ( \"(Oi)\" , module , set_argv0 ); ... result = PyObject_Call ( runmodule , runargs , NULL ); ... if ( result == NULL ) { return pymain_exit_err_print (); } Py_DECREF ( result ); return 0 ; } In this function you\u2019ll also see 2 other C API functions: PyObject_Call() and PyObject_GetAttrString() . Because PyImport_ImportModule() returns a PyObject* , the core object type, you need to call special functions to get attributes and to call it. In Python, if you had an object and wanted to get an attribute, then you could call getattr() . In the C API, this call is PyObject_GetAttrString() , which is found in Objects/object.c . If you wanted to run a callable, you would give it parentheses, or you can run the __call__() property on any Python object. The __call__() method is implemented inside Objects/object.c : hi = \"hi!\" hi . upper () == hi . upper . __call__ () # this is the same The runpy module is written in pure Python and located in Lib/runpy.py . Executing python -m is equivalent to running python -m runpy . The runpy module was created to abstract the process of locating and executing modules on an operating system. runpy does a few things to run the target module: Calls __import__() for the module name you provided Sets __name__ (the module name) to a namespace called __main__ Executes the module within the __main__ namespace The runpy module also supports executing directories and zip files. Input via Filename If the first argument to python was a filename, such as python test.py , then CPython will open a file handle, similar to using open() in Python and pass the handle to PyRun_SimpleFileExFlags() inside Python/pythonrun.c . There are 3 paths this function can take: If the file path is a .pyc file, it will call run_pyc_file() . If the file path is a script file ( .py ) it will run PyRun_FileExFlags() . If the filepath is stdin because the user ran command | python then treat stdin as a file handle and run PyRun_FileExFlags() . int PyRun_SimpleFileExFlags ( FILE * fp , const char * filename , int closeit , PyCompilerFlags * flags ) { ... m = PyImport_AddModule ( \"__main__\" ); ... if ( maybe_pyc_file ( fp , filename , ext , closeit )) { ... v = run_pyc_file ( pyc_fp , filename , d , d , flags ); } else { /* When running from stdin, leave __main__.__loader__ alone */ if ( strcmp ( filename , \"<stdin>\" ) != 0 && set_main_loader ( d , filename , \"SourceFileLoader\" ) < 0 ) { fprintf ( stderr , \"python: failed to set __main__.__loader__ \\n \" ); ret = - 1 ; goto done ; } v = PyRun_FileExFlags ( fp , filename , Py_file_input , d , d , closeit , flags ); } ... return ret ; } Input via File With PyRun_FileExFlags() For stdin and basic script files, CPython will pass the file handle to PyRun_FileExFlags() located in the pythonrun.c file. The purpose of PyRun_FileExFlags() is similar to PyRun_SimpleStringFlags() used for the -c input. CPython will load the file handle into PyParser_ASTFromFileObject() . We\u2019ll cover the Parser and AST modules in the next section. Because this is a full script, it doesn\u2019t need the PyImport_AddModule(\"__main__\"); step used by -c : PyObject * PyRun_FileExFlags ( FILE * fp , const char * filename_str , int start , PyObject * globals , PyObject * locals , int closeit , PyCompilerFlags * flags ) { ... mod = PyParser_ASTFromFileObject ( fp , filename , NULL , start , 0 , 0 , flags , NULL , arena ); ... ret = run_mod ( mod , filename , globals , locals , flags , arena ); } Identical to PyRun_SimpleStringFlags() , once PyRun_FileExFlags() has created a Python module from the file, it sent it to run_mod() to be executed. run_mod() is found within Python/pythonrun.c , and sends the module to the AST to be compiled into a code object . Code objects are a format used to store the bytecode operations and the format kept in .pyc files: static PyObject * run_mod ( mod_ty mod , PyObject * filename , PyObject * globals , PyObject * locals , PyCompilerFlags * flags , PyArena * arena ) { PyCodeObject * co ; PyObject * v ; co = PyAST_CompileObject ( mod , filename , flags , - 1 , arena ); if ( co == NULL ) return NULL ; if ( PySys_Audit ( \"exec\" , \"O\" , co ) < 0 ) { Py_DECREF ( co ); return NULL ; } v = run_eval_code_obj ( co , globals , locals ); Py_DECREF ( co ); return v ; } We will cover the CPython compiler and bytecodes in the next section. The call to run_eval_code_obj() is a simple wrapper function that calls PyEval_EvalCode() in the Python/eval.c file. The PyEval_EvalCode() function is the main evaluation loop for CPython, it iterates over each bytecode statement and executes it on your local machine. Input via Compiled Bytecode With run_pyc_file() In the PyRun_SimpleFileExFlags() there was a clause for the user providing a file path to a .pyc file. If the file path ended in .pyc then instead of loading the file as a plain text file and parsing it, it will assume that the .pyc file contains a code object written to disk. The run_pyc_file() function inside Python/pythonrun.c then marshals the code object from the .pyc file by using the file handle. Marshaling is a technical term for copying the contents of a file into memory and converting them to a specific data structure. The code object data structure on the disk is the CPython compiler\u2019s way to caching compiled code so that it doesn\u2019t need to parse it every time the script is called: static PyObject * run_pyc_file ( FILE * fp , const char * filename , PyObject * globals , PyObject * locals , PyCompilerFlags * flags ) { PyCodeObject * co ; PyObject * v ; ... v = PyMarshal_ReadLastObjectFromFile ( fp ); ... if ( v == NULL || ! PyCode_Check ( v )) { Py_XDECREF ( v ); PyErr_SetString ( PyExc_RuntimeError , \"Bad code object in .pyc file\" ); goto error ; } fclose ( fp ); co = ( PyCodeObject * ) v ; v = run_eval_code_obj ( co , globals , locals ); if ( v && flags ) flags -> cf_flags |= ( co -> co_flags & PyCF_MASK ); Py_DECREF ( co ); return v ; } Once the code object has been marshaled to memory, it is sent to run_eval_code_obj() , which calls Python/ceval.c to execute the code. NOTE: Marshalling (computer science) Lexing and Parsing In the exploration of reading and executing Python files, we dived as deep as the parser and AST modules, with function calls to PyParser_ASTFromFileObject() . Sticking within Python/pythonrun.c , the PyParser_ASTFromFileObject() function will take a file handle, compiler flags and a PyArena instance and convert the file object into a node object using PyParser_ParseFileObject() . With the node object , it will then convert that into a module using the AST function PyAST_FromNodeObject() : mod_ty PyParser_ASTFromFileObject ( FILE * fp , PyObject * filename , const char * enc , int start , const char * ps1 , const char * ps2 , PyCompilerFlags * flags , int * errcode , PyArena * arena ) { ... node * n = PyParser_ParseFileObject ( fp , filename , enc , & _PyParser_Grammar , start , ps1 , ps2 , & err , & iflags ); ... if ( n ) { flags -> cf_flags |= iflags & PyCF_MASK ; mod = PyAST_FromNodeObject ( n , flags , filename , arena ); PyNode_Free ( n ); ... return mod ; } For PyParser_ParseFileObject() we switch to Parser/parsetok.c and the parser-tokenizer stage of the CPython interpreter. This function has two important tasks: Instantiate a tokenizer state tok_state using PyTokenizer_FromFile() in Parser/tokenizer.c Convert the tokens into a concrete parse tree (a list of node ) using parsetok() in Parser/parsetok.c node * PyParser_ParseFileObject ( FILE * fp , PyObject * filename , const char * enc , grammar * g , int start , const char * ps1 , const char * ps2 , perrdetail * err_ret , int * flags ) { struct tok_state * tok ; ... if (( tok = PyTokenizer_FromFile ( fp , enc , ps1 , ps2 )) == NULL ) { err_ret -> error = E_NOMEM ; return NULL ; } ... return parsetok ( tok , g , start , err_ret , flags ); } tok_state (defined in Parser/tokenizer.h ) is the data structure to store all temporary data generated by the tokenizer. It is returned to the parser-tokenizer as the data structure is required by parsetok() to develop the concrete syntax tree . Inside parsetok() , it will use the tok_state structure and make calls to tok_get() in a loop until the file is exhausted and no more tokens can be found. tok_get() , defined in Parser/tokenizer.c behaves like an iterator. It will keep returning the next token in the parse tree. tok_get() is one of the most complex functions in the whole CPython codebase. It has over 640 lines and includes decades of heritage with edge cases, new language features, and syntax. One of the simpler examples would be the part that converts a newline break into a NEWLINE token: static int tok_get ( struct tok_state * tok , char ** p_start , char ** p_end ) { ... /* Newline */ if ( c == '\\n' ) { tok -> atbol = 1 ; if ( blankline || tok -> level > 0 ) { goto nextline ; } * p_start = tok -> start ; * p_end = tok -> cur - 1 ; /* Leave '\\n' out of the string */ tok -> cont_line = 0 ; if ( tok -> async_def ) { /* We're somewhere inside an 'async def' function, and we've encountered a NEWLINE after its signature. */ tok -> async_def_nl = 1 ; } return NEWLINE ; } ... } In this case, NEWLINE is a token, with a value defined in Include/token.h . All tokens are constant int values, and the Include/token.h file was generated earlier when we ran make regen-grammar . The node type returned by PyParser_ParseFileObject() is going to be essential for the next stage, converting a parse tree into an Abstract-Syntax-Tree (AST): typedef struct _node { short n_type ; char * n_str ; int n_lineno ; int n_col_offset ; int n_nchildren ; struct _node * n_child ; int n_end_lineno ; int n_end_col_offset ; } node ; Since the CST is a tree of syntax, token IDs, and symbols, it would be difficult for the compiler to make quick decisions based on the Python language. That is why the next stage is to convert the CST into an AST , a much higher-level structure. This task is performed by the Python/ast.c module, which has both a C and Python API. Before you jump into the AST, there is a way to access the output from the parser stage. CPython has a standard library module parser , which exposes the C functions with a Python API. The module is documented as an implementation detail of CPython so that you won\u2019t see it in other Python interpreters. Also the output from the functions is not that easy to read. The output will be in the numeric form, using the token and symbol numbers generated by the make regen-grammar stage, stored in Include/token.h : >>> from pprint import pprint >>> import parser >>> st = parser.expr('a + 1') >>> pprint(parser.st2list(st)) [258, [332, [306, [310, [311, [312, [313, [316, [317, [318, [319, [320, [321, [322, [323, [324, [325, [1, 'a']]]]]], [14, '+'], [321, [322, [323, [324, [325, [2, '1']]]]]]]]]]]]]]]]], [4, ''], [0, '']] To make it easier to understand, you can take all the numbers in the symbol and token modules, put them into a dictionary and recursively replace the values in the output of parser.st2list() with the names: import symbol import token import parser def lex ( expression ): symbols = { v : k for k , v in symbol . __dict__ . items () if isinstance ( v , int )} tokens = { v : k for k , v in token . __dict__ . items () if isinstance ( v , int )} lexicon = { ** symbols , ** tokens } st = parser . expr ( expression ) st_list = parser . st2list ( st ) def replace ( l : list ): r = [] for i in l : if isinstance ( i , list ): r . append ( replace ( i )) else : if i in lexicon : r . append ( lexicon [ i ]) else : r . append ( i ) return r return replace ( st_list ) You can run lex() with a simple expression, like a + 1 to see how this is represented as a parser-tree: >>> from pprint import pprint >>> pprint(lex('a + 1')) ['eval_input', ['testlist', ['test', ['or_test', ['and_test', ['not_test', ['comparison', ['expr', ['xor_expr', ['and_expr', ['shift_expr', ['arith_expr', ['term', ['factor', ['power', ['atom_expr', ['atom', ['NAME', 'a']]]]]], ['PLUS', '+'], ['term', ['factor', ['power', ['atom_expr', ['atom', ['NUMBER', '1']]]]]]]]]]]]]]]]], ['NEWLINE', ''], ['ENDMARKER', '']] In the output, you can see the symbols in lowercase, such as 'test' and the tokens in uppercase, such as 'NUMBER' . Abstract Syntax Trees The next stage in the CPython interpreter is to convert the CST generated by the parser into something more logical that can be executed. The structure is a higher-level representation of the code, called an Abstract Syntax Tree (AST). ASTs are produced inline with the CPython interpreter process, but you can also generate them in both Python using the ast module in the Standard Library as well as through the C API. Before diving into the C implementation of the AST, it would be useful to understand what an AST looks like for a simple piece of Python code. To do this, here\u2019s a simple app called instaviz for this tutorial. It displays the AST and bytecode instructions (which we\u2019ll cover later) in a Web UI. To install instaviz : pip install instaviz Then, open up a REPL by running python at the command line with no arguments: >>> import instaviz >>> def example (): a = 1 b = a + 1 return b >>> instaviz . show ( example ) You\u2019ll see a notification on the command-line that a web server has started on port 8080 . If you were using that port for something else, you can change it by calling instaviz.show(example, port=9090) or another port number. In the web browser, you can see the detailed breakdown of your function: The bottom left graph is the function you declared in REPL, represented as an Abstract Syntax Tree. Each node in the tree is an AST type. They are found in the ast module, and all inherit from _ast.AST . Some of the nodes have properties which link them to child nodes, unlike the CST, which has a generic child node property. For example, if you click on the Assign node in the center, this links to the line b = a + 1 : It has two properties: targets is a list of names to assign. It is a list because you can assign to multiple variables with a single expression using unpacking value is the value to assign, which in this case is a BinOp statement, a + 1 . If you click on the BinOp statement, it shows the properties of relevance: left : the node to the left of the operator op : the operator, in this case, an Add node ( + ) for addition right : the node to the right of the operator Compiling an AST in C is not a straightforward task, so the Python/ast.c module is over 5000 lines of code. There are a few entry points , forming part of the AST\u2019s public API. In the last section on the lexer and parser, you stopped when you\u2019d reached the call to PyAST_FromNodeObject() . By this stage, the Python interpreter process had created a CST in the format of node * tree. Jumping then into PyAST_FromNodeObject() inside Python/ast.c , you can see it receives the node * tree, the filename, compiler flags, and the PyArena . The return type from this function is mod_ty , defined in Include/Python-ast.h . mod_ty is a container structure for one of the 5 module types in Python: Module Interactive Expression FunctionType Suite In Include/Python-ast.h you can see that an Expression type requires a field body , which is an expr_ty type. The expr_ty type is also defined in Include/Python-ast.h : enum _mod_kind { Module_kind = 1 , Interactive_kind = 2 , Expression_kind = 3 , FunctionType_kind = 4 , Suite_kind = 5 }; struct _mod { enum _mod_kind kind ; union { struct { asdl_seq * body ; asdl_seq * type_ignores ; } Module ; struct { asdl_seq * body ; } Interactive ; struct { expr_ty body ; } Expression ; struct { asdl_seq * argtypes ; expr_ty returns ; } FunctionType ; struct { asdl_seq * body ; } Suite ; } v ; }; Conclusion CPython\u2019s versatility and low-level execution API make it the ideal candidate for an embedded scripting engine. You will see CPython used in many UI applications, such as Game Design, 3D graphics and system automation. The interpreter process is flexible and efficient, and now you have an understanding of how it works you\u2019re ready to understand the compiler.","title":"Part 2 The Python Interpreter Process"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-2-The-Python-Interpreter-Process/#part-2-the-python-interpreter-process","text":"Now that you\u2019ve seen the Python grammar and memory management, you can follow the process from typing python to the part where your code is executed. There are five ways the python binary can be called: To run a single command with -c and a Python command To start a module with -m and the name of a module To run a file with the filename To run the stdin input using a shell pipe To start the REPL and execute commands one at a time Python has so many ways to execute scripts, it can be a little overwhelming. Darren Jones has put together a great course on running Python scripts if you want to learn more. The three source files you need to inspect to see this process are: Programs/python.c is a simple entry point. Modules/main.c contains the code to bring together the whole process, loading configuration, executing code and clearing up memory. Python/initconfig.c loads the configuration from the system environment and merges it with any command-line flags. This diagram shows how each of those functions is called: The execution mode is determined from the configuration. The CPython source code style: Similar to the PEP8 style guide for Python code , there is an official style guide for the CPython C code, designed originally in 2001 and updated for modern versions. There are some naming standards which help when navigating the source code: Use a Py prefix for public functions, never for static functions. The Py_ prefix is reserved for global service routines like Py_FatalError . Specific groups of routines (like specific object type APIs) use a longer prefix, such as PyString_ for string functions. Public functions and variables use MixedCase with underscores, like this: PyObject_GetAttr , Py_BuildValue , PyExc_TypeError . Occasionally an \u201cinternal\u201d function has to be visible to the loader. We use the _Py prefix for this, for example, _PyObject_Dump . Macros should have a MixedCase prefix and then use upper case, for example PyString_AS_STRING , Py_PRINT_RAW .","title":"Part 2: The Python Interpreter Process"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-2-The-Python-Interpreter-Process/#establishing-runtime-configuration","text":"In the swimlanes, you can see that before any Python code is executed, the runtime first establishes the configuration. The configuration of the runtime is a data structure defined in Include/cpython/initconfig.h named PyConfig . The configuration data structure includes things like: Runtime flags for various modes like debug and optimized mode The execution mode , such as whether a filename was passed, stdin was provided or a module name Extended option , specified by -X Environment variables for runtime settings The configuration data is primarily used by the CPython runtime to enable and disable various features. Python also comes with several Command Line Interface Options . In Python you can enable verbose mode with the -v flag. In verbose mode, Python will print messages to the screen when modules are loaded: python -v -c \"print('hello world')\" You will see a hundred lines or more with all the imports of your user site-packages and anything else in the system environment. You can see the definition of this flag within Include/cpython/initconfig.h inside the struct for PyConfig : /* --- PyConfig ---------------------------------------------- */ typedef struct { int _config_version ; /* Internal configuration version, used for ABI compatibility */ int _config_init ; /* _PyConfigInitEnum value */ ... /* If greater than 0, enable the verbose mode: print a message each time a module is initialized, showing the place (filename or built-in module) from which it is loaded. If greater or equal to 2, print a message for each file that is checked for when searching for a module. Also provides information on module cleanup at exit. Incremented by the -v option. Set by the PYTHONVERBOSE environment variable. If set to -1 (default), inherit Py_VerboseFlag value. */ int verbose ; In Python/initconfig.c , the logic for reading settings from environment variables and runtime command-line flags is established. In the config_read_env_vars function, the environment variables are read and used to assign the values for the configuration settings: static PyStatus config_read_env_vars ( PyConfig * config ) { PyStatus status ; int use_env = config -> use_environment ; /* Get environment variables */ _Py_get_env_flag ( use_env , & config -> parser_debug , \"PYTHONDEBUG\" ); _Py_get_env_flag ( use_env , & config -> verbose , \"PYTHONVERBOSE\" ); _Py_get_env_flag ( use_env , & config -> optimization_level , \"PYTHONOPTIMIZE\" ); _Py_get_env_flag ( use_env , & config -> inspect , \"PYTHONINSPECT\" ); For the verbose setting, you can see that the value of PYTHONVERBOSE is used to set the value of &config->verbose , if PYTHONVERBOSE is found. If the environment variable does not exist, then the default value of -1 will remain. Then in config_parse_cmdline within initconfig.c again, the command-line flag is used to set the value, if provided: static PyStatus config_parse_cmdline ( PyConfig * config , PyWideStringList * warnoptions , Py_ssize_t * opt_index ) { ... switch ( c ) { ... case 'v' : config -> verbose ++ ; break ; ... /* This space reserved for other options */ default : /* unknown argument: parsing failed */ config_usage ( 1 , program ); return _PyStatus_EXIT ( 2 ); } } while ( 1 ); This value is later copied to a global variable Py_VerboseFlag by the _Py_GetGlobalVariablesAsDict function. Within a Python session, you can access the runtime flags, like verbose mode, quiet mode, using the sys.flags named tuple. The -X flags are all available inside the sys._xoptions dictionary: $ ./python.exe -X dev -q >>> import sys >>> sys.flags sys.flags(debug=0, inspect=0, interactive=0, optimize=0, dont_write_bytecode=0, no_user_site=0, no_site=0, ignore_environment=0, verbose=0, bytes_warning=0, quiet=1, hash_randomization=1, isolated=0, dev_mode=True, utf8_mode=0) >>> sys._xoptions {'dev': True} As well as the runtime configuration in initconfig.h , there is also the build configuration , which is located inside pyconfig.h in the root folder. This file is created dynamically in the configure step in the build process, or by Visual Studio for Windows systems. You can see the build configuration by running: $ ./python.exe -m sysconfig","title":"Establishing Runtime Configuration"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-2-The-Python-Interpreter-Process/#reading-filesinput","text":"Once CPython has the runtime configuration and the command-line arguments, it can establish what it needs to execute. This task is handled by the pymain_main function inside Modules/main.c . Depending on the newly created config instance, CPython will now execute code provided via several options.","title":"Reading Files/Input"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-2-The-Python-Interpreter-Process/#input-via-c","text":"The simplest is providing CPython a command with the -c option and a Python program inside quotes. For example: $ ./python.exe -c \"print('hi')\" hi Here is the full flowchart of how this happens: First, the pymain_run_command() function is executed inside Modules/main.c taking the command passed in -c as an argument in the C type wchar_t* . The wchar_t* type is often used as a low-level storage type for Unicode data across CPython as the size of the type can store UTF8 characters. When converting the wchar_t* to a Python string, the Objects/unicodeobject.c file has a helper function PyUnicode_FromWideChar() that returns a PyObject , of type str . The encoding to UTF8 is then done by PyUnicode_AsUTF8String() on the Python str object to convert it to a Python bytes object. Once this is complete, pymain_run_command() will then pass the Python bytes object to PyRun_SimpleStringFlags() for execution, but first converting the bytes to a str type again: static int pymain_run_command ( wchar_t * command , PyCompilerFlags * cf ) { PyObject * unicode , * bytes ; int ret ; unicode = PyUnicode_FromWideChar ( command , - 1 ); if ( unicode == NULL ) { goto error ; } if ( PySys_Audit ( \"cpython.run_command\" , \"O\" , unicode ) < 0 ) { return pymain_exit_err_print (); } bytes = PyUnicode_AsUTF8String ( unicode ); Py_DECREF ( unicode ); if ( bytes == NULL ) { goto error ; } ret = PyRun_SimpleStringFlags ( PyBytes_AsString ( bytes ), cf ); Py_DECREF ( bytes ); return ( ret != 0 ); error : PySys_WriteStderr ( \"Unable to decode the command from the command line: \\n \" ); return pymain_exit_err_print (); } The conversion of wchar_t* to Unicode, bytes, and then a string is roughly equivalent to the following: unicode = str ( command ) bytes_ = bytes ( unicode . encode ( 'utf8' )) # call PyRun_SimpleStringFlags with bytes_ The PyRun_SimpleStringFlags() function is part of Python/pythonrun.c . It\u2019s purpose is to turn this simple command into a Python module and then send it on to be executed. Since a Python module needs to have __main__ to be executed as a standalone module, it creates that automatically: int PyRun_SimpleStringFlags ( const char * command , PyCompilerFlags * flags ) { PyObject * m , * d , * v ; m = PyImport_AddModule ( \"__main__\" ); if ( m == NULL ) return - 1 ; d = PyModule_GetDict ( m ); v = PyRun_StringFlags ( command , Py_file_input , d , d , flags ); if ( v == NULL ) { PyErr_Print (); return - 1 ; } Py_DECREF ( v ); return 0 ; } Once PyRun_SimpleStringFlags() has created a module and a dictionary, it calls PyRun_StringFlags() , which creates a fake filename and then calls the Python parser to create an AST from the string and return a module , mod : PyObject * PyRun_StringFlags ( const char * str , int start , PyObject * globals , PyObject * locals , PyCompilerFlags * flags ) { ... mod = PyParser_ASTFromStringObject ( str , filename , start , flags , arena ); if ( mod != NULL ) ret = run_mod ( mod , filename , globals , locals , flags , arena ); PyArena_Free ( arena ); return ret ; You\u2019ll dive into the AST and Parser code in the next section. NOTE: command string\u2192python module\u2192AST","title":"Input via -c"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-2-The-Python-Interpreter-Process/#input-via-m","text":"Another way to execute Python commands is by using the -m option with the name of a module. A typical example is python -m unittest to run the unittest module in the standard library. Being able to execute modules as scripts were initially proposed in PEP 338 and then the standard for explicit relative imports defined in PEP366 . The use of the -m flag implies that within the module package, you want to execute whatever is inside __main__ . It also implies that you want to search sys.path for the named module. This search mechanism is why you don\u2019t need to remember where the unittest module is stored on your filesystem. Inside Modules/main.c there is a function called when the command-line is run with the -m flag. The name of the module is passed as the modname argument. CPython will then import a standard library module, runpy and execute it using PyObject_Call() . The import is done using the C API function PyImport_ImportModule() , found within the Python/import.c file: static int pymain_run_module ( const wchar_t * modname , int set_argv0 ) { PyObject * module , * runpy , * runmodule , * runargs , * result ; runpy = PyImport_ImportModule ( \"runpy\" ); ... runmodule = PyObject_GetAttrString ( runpy , \"_run_module_as_main\" ); ... module = PyUnicode_FromWideChar ( modname , wcslen ( modname )); ... runargs = Py_BuildValue ( \"(Oi)\" , module , set_argv0 ); ... result = PyObject_Call ( runmodule , runargs , NULL ); ... if ( result == NULL ) { return pymain_exit_err_print (); } Py_DECREF ( result ); return 0 ; } In this function you\u2019ll also see 2 other C API functions: PyObject_Call() and PyObject_GetAttrString() . Because PyImport_ImportModule() returns a PyObject* , the core object type, you need to call special functions to get attributes and to call it. In Python, if you had an object and wanted to get an attribute, then you could call getattr() . In the C API, this call is PyObject_GetAttrString() , which is found in Objects/object.c . If you wanted to run a callable, you would give it parentheses, or you can run the __call__() property on any Python object. The __call__() method is implemented inside Objects/object.c : hi = \"hi!\" hi . upper () == hi . upper . __call__ () # this is the same The runpy module is written in pure Python and located in Lib/runpy.py . Executing python -m is equivalent to running python -m runpy . The runpy module was created to abstract the process of locating and executing modules on an operating system. runpy does a few things to run the target module: Calls __import__() for the module name you provided Sets __name__ (the module name) to a namespace called __main__ Executes the module within the __main__ namespace The runpy module also supports executing directories and zip files.","title":"Input via -m"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-2-The-Python-Interpreter-Process/#input-via-filename","text":"If the first argument to python was a filename, such as python test.py , then CPython will open a file handle, similar to using open() in Python and pass the handle to PyRun_SimpleFileExFlags() inside Python/pythonrun.c . There are 3 paths this function can take: If the file path is a .pyc file, it will call run_pyc_file() . If the file path is a script file ( .py ) it will run PyRun_FileExFlags() . If the filepath is stdin because the user ran command | python then treat stdin as a file handle and run PyRun_FileExFlags() . int PyRun_SimpleFileExFlags ( FILE * fp , const char * filename , int closeit , PyCompilerFlags * flags ) { ... m = PyImport_AddModule ( \"__main__\" ); ... if ( maybe_pyc_file ( fp , filename , ext , closeit )) { ... v = run_pyc_file ( pyc_fp , filename , d , d , flags ); } else { /* When running from stdin, leave __main__.__loader__ alone */ if ( strcmp ( filename , \"<stdin>\" ) != 0 && set_main_loader ( d , filename , \"SourceFileLoader\" ) < 0 ) { fprintf ( stderr , \"python: failed to set __main__.__loader__ \\n \" ); ret = - 1 ; goto done ; } v = PyRun_FileExFlags ( fp , filename , Py_file_input , d , d , closeit , flags ); } ... return ret ; }","title":"Input via Filename"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-2-The-Python-Interpreter-Process/#input-via-file-with-pyrun_fileexflags","text":"For stdin and basic script files, CPython will pass the file handle to PyRun_FileExFlags() located in the pythonrun.c file. The purpose of PyRun_FileExFlags() is similar to PyRun_SimpleStringFlags() used for the -c input. CPython will load the file handle into PyParser_ASTFromFileObject() . We\u2019ll cover the Parser and AST modules in the next section. Because this is a full script, it doesn\u2019t need the PyImport_AddModule(\"__main__\"); step used by -c : PyObject * PyRun_FileExFlags ( FILE * fp , const char * filename_str , int start , PyObject * globals , PyObject * locals , int closeit , PyCompilerFlags * flags ) { ... mod = PyParser_ASTFromFileObject ( fp , filename , NULL , start , 0 , 0 , flags , NULL , arena ); ... ret = run_mod ( mod , filename , globals , locals , flags , arena ); } Identical to PyRun_SimpleStringFlags() , once PyRun_FileExFlags() has created a Python module from the file, it sent it to run_mod() to be executed. run_mod() is found within Python/pythonrun.c , and sends the module to the AST to be compiled into a code object . Code objects are a format used to store the bytecode operations and the format kept in .pyc files: static PyObject * run_mod ( mod_ty mod , PyObject * filename , PyObject * globals , PyObject * locals , PyCompilerFlags * flags , PyArena * arena ) { PyCodeObject * co ; PyObject * v ; co = PyAST_CompileObject ( mod , filename , flags , - 1 , arena ); if ( co == NULL ) return NULL ; if ( PySys_Audit ( \"exec\" , \"O\" , co ) < 0 ) { Py_DECREF ( co ); return NULL ; } v = run_eval_code_obj ( co , globals , locals ); Py_DECREF ( co ); return v ; } We will cover the CPython compiler and bytecodes in the next section. The call to run_eval_code_obj() is a simple wrapper function that calls PyEval_EvalCode() in the Python/eval.c file. The PyEval_EvalCode() function is the main evaluation loop for CPython, it iterates over each bytecode statement and executes it on your local machine.","title":"Input via File With PyRun_FileExFlags()"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-2-The-Python-Interpreter-Process/#input-via-compiled-bytecode-with-run_pyc_file","text":"In the PyRun_SimpleFileExFlags() there was a clause for the user providing a file path to a .pyc file. If the file path ended in .pyc then instead of loading the file as a plain text file and parsing it, it will assume that the .pyc file contains a code object written to disk. The run_pyc_file() function inside Python/pythonrun.c then marshals the code object from the .pyc file by using the file handle. Marshaling is a technical term for copying the contents of a file into memory and converting them to a specific data structure. The code object data structure on the disk is the CPython compiler\u2019s way to caching compiled code so that it doesn\u2019t need to parse it every time the script is called: static PyObject * run_pyc_file ( FILE * fp , const char * filename , PyObject * globals , PyObject * locals , PyCompilerFlags * flags ) { PyCodeObject * co ; PyObject * v ; ... v = PyMarshal_ReadLastObjectFromFile ( fp ); ... if ( v == NULL || ! PyCode_Check ( v )) { Py_XDECREF ( v ); PyErr_SetString ( PyExc_RuntimeError , \"Bad code object in .pyc file\" ); goto error ; } fclose ( fp ); co = ( PyCodeObject * ) v ; v = run_eval_code_obj ( co , globals , locals ); if ( v && flags ) flags -> cf_flags |= ( co -> co_flags & PyCF_MASK ); Py_DECREF ( co ); return v ; } Once the code object has been marshaled to memory, it is sent to run_eval_code_obj() , which calls Python/ceval.c to execute the code. NOTE: Marshalling (computer science)","title":"Input via Compiled Bytecode With run_pyc_file()"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-2-The-Python-Interpreter-Process/#lexing-and-parsing","text":"In the exploration of reading and executing Python files, we dived as deep as the parser and AST modules, with function calls to PyParser_ASTFromFileObject() . Sticking within Python/pythonrun.c , the PyParser_ASTFromFileObject() function will take a file handle, compiler flags and a PyArena instance and convert the file object into a node object using PyParser_ParseFileObject() . With the node object , it will then convert that into a module using the AST function PyAST_FromNodeObject() : mod_ty PyParser_ASTFromFileObject ( FILE * fp , PyObject * filename , const char * enc , int start , const char * ps1 , const char * ps2 , PyCompilerFlags * flags , int * errcode , PyArena * arena ) { ... node * n = PyParser_ParseFileObject ( fp , filename , enc , & _PyParser_Grammar , start , ps1 , ps2 , & err , & iflags ); ... if ( n ) { flags -> cf_flags |= iflags & PyCF_MASK ; mod = PyAST_FromNodeObject ( n , flags , filename , arena ); PyNode_Free ( n ); ... return mod ; } For PyParser_ParseFileObject() we switch to Parser/parsetok.c and the parser-tokenizer stage of the CPython interpreter. This function has two important tasks: Instantiate a tokenizer state tok_state using PyTokenizer_FromFile() in Parser/tokenizer.c Convert the tokens into a concrete parse tree (a list of node ) using parsetok() in Parser/parsetok.c node * PyParser_ParseFileObject ( FILE * fp , PyObject * filename , const char * enc , grammar * g , int start , const char * ps1 , const char * ps2 , perrdetail * err_ret , int * flags ) { struct tok_state * tok ; ... if (( tok = PyTokenizer_FromFile ( fp , enc , ps1 , ps2 )) == NULL ) { err_ret -> error = E_NOMEM ; return NULL ; } ... return parsetok ( tok , g , start , err_ret , flags ); } tok_state (defined in Parser/tokenizer.h ) is the data structure to store all temporary data generated by the tokenizer. It is returned to the parser-tokenizer as the data structure is required by parsetok() to develop the concrete syntax tree . Inside parsetok() , it will use the tok_state structure and make calls to tok_get() in a loop until the file is exhausted and no more tokens can be found. tok_get() , defined in Parser/tokenizer.c behaves like an iterator. It will keep returning the next token in the parse tree. tok_get() is one of the most complex functions in the whole CPython codebase. It has over 640 lines and includes decades of heritage with edge cases, new language features, and syntax. One of the simpler examples would be the part that converts a newline break into a NEWLINE token: static int tok_get ( struct tok_state * tok , char ** p_start , char ** p_end ) { ... /* Newline */ if ( c == '\\n' ) { tok -> atbol = 1 ; if ( blankline || tok -> level > 0 ) { goto nextline ; } * p_start = tok -> start ; * p_end = tok -> cur - 1 ; /* Leave '\\n' out of the string */ tok -> cont_line = 0 ; if ( tok -> async_def ) { /* We're somewhere inside an 'async def' function, and we've encountered a NEWLINE after its signature. */ tok -> async_def_nl = 1 ; } return NEWLINE ; } ... } In this case, NEWLINE is a token, with a value defined in Include/token.h . All tokens are constant int values, and the Include/token.h file was generated earlier when we ran make regen-grammar . The node type returned by PyParser_ParseFileObject() is going to be essential for the next stage, converting a parse tree into an Abstract-Syntax-Tree (AST): typedef struct _node { short n_type ; char * n_str ; int n_lineno ; int n_col_offset ; int n_nchildren ; struct _node * n_child ; int n_end_lineno ; int n_end_col_offset ; } node ; Since the CST is a tree of syntax, token IDs, and symbols, it would be difficult for the compiler to make quick decisions based on the Python language. That is why the next stage is to convert the CST into an AST , a much higher-level structure. This task is performed by the Python/ast.c module, which has both a C and Python API. Before you jump into the AST, there is a way to access the output from the parser stage. CPython has a standard library module parser , which exposes the C functions with a Python API. The module is documented as an implementation detail of CPython so that you won\u2019t see it in other Python interpreters. Also the output from the functions is not that easy to read. The output will be in the numeric form, using the token and symbol numbers generated by the make regen-grammar stage, stored in Include/token.h : >>> from pprint import pprint >>> import parser >>> st = parser.expr('a + 1') >>> pprint(parser.st2list(st)) [258, [332, [306, [310, [311, [312, [313, [316, [317, [318, [319, [320, [321, [322, [323, [324, [325, [1, 'a']]]]]], [14, '+'], [321, [322, [323, [324, [325, [2, '1']]]]]]]]]]]]]]]]], [4, ''], [0, '']] To make it easier to understand, you can take all the numbers in the symbol and token modules, put them into a dictionary and recursively replace the values in the output of parser.st2list() with the names: import symbol import token import parser def lex ( expression ): symbols = { v : k for k , v in symbol . __dict__ . items () if isinstance ( v , int )} tokens = { v : k for k , v in token . __dict__ . items () if isinstance ( v , int )} lexicon = { ** symbols , ** tokens } st = parser . expr ( expression ) st_list = parser . st2list ( st ) def replace ( l : list ): r = [] for i in l : if isinstance ( i , list ): r . append ( replace ( i )) else : if i in lexicon : r . append ( lexicon [ i ]) else : r . append ( i ) return r return replace ( st_list ) You can run lex() with a simple expression, like a + 1 to see how this is represented as a parser-tree: >>> from pprint import pprint >>> pprint(lex('a + 1')) ['eval_input', ['testlist', ['test', ['or_test', ['and_test', ['not_test', ['comparison', ['expr', ['xor_expr', ['and_expr', ['shift_expr', ['arith_expr', ['term', ['factor', ['power', ['atom_expr', ['atom', ['NAME', 'a']]]]]], ['PLUS', '+'], ['term', ['factor', ['power', ['atom_expr', ['atom', ['NUMBER', '1']]]]]]]]]]]]]]]]], ['NEWLINE', ''], ['ENDMARKER', '']] In the output, you can see the symbols in lowercase, such as 'test' and the tokens in uppercase, such as 'NUMBER' .","title":"Lexing and Parsing"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-2-The-Python-Interpreter-Process/#abstract-syntax-trees","text":"The next stage in the CPython interpreter is to convert the CST generated by the parser into something more logical that can be executed. The structure is a higher-level representation of the code, called an Abstract Syntax Tree (AST). ASTs are produced inline with the CPython interpreter process, but you can also generate them in both Python using the ast module in the Standard Library as well as through the C API. Before diving into the C implementation of the AST, it would be useful to understand what an AST looks like for a simple piece of Python code. To do this, here\u2019s a simple app called instaviz for this tutorial. It displays the AST and bytecode instructions (which we\u2019ll cover later) in a Web UI. To install instaviz : pip install instaviz Then, open up a REPL by running python at the command line with no arguments: >>> import instaviz >>> def example (): a = 1 b = a + 1 return b >>> instaviz . show ( example ) You\u2019ll see a notification on the command-line that a web server has started on port 8080 . If you were using that port for something else, you can change it by calling instaviz.show(example, port=9090) or another port number. In the web browser, you can see the detailed breakdown of your function: The bottom left graph is the function you declared in REPL, represented as an Abstract Syntax Tree. Each node in the tree is an AST type. They are found in the ast module, and all inherit from _ast.AST . Some of the nodes have properties which link them to child nodes, unlike the CST, which has a generic child node property. For example, if you click on the Assign node in the center, this links to the line b = a + 1 : It has two properties: targets is a list of names to assign. It is a list because you can assign to multiple variables with a single expression using unpacking value is the value to assign, which in this case is a BinOp statement, a + 1 . If you click on the BinOp statement, it shows the properties of relevance: left : the node to the left of the operator op : the operator, in this case, an Add node ( + ) for addition right : the node to the right of the operator Compiling an AST in C is not a straightforward task, so the Python/ast.c module is over 5000 lines of code. There are a few entry points , forming part of the AST\u2019s public API. In the last section on the lexer and parser, you stopped when you\u2019d reached the call to PyAST_FromNodeObject() . By this stage, the Python interpreter process had created a CST in the format of node * tree. Jumping then into PyAST_FromNodeObject() inside Python/ast.c , you can see it receives the node * tree, the filename, compiler flags, and the PyArena . The return type from this function is mod_ty , defined in Include/Python-ast.h . mod_ty is a container structure for one of the 5 module types in Python: Module Interactive Expression FunctionType Suite In Include/Python-ast.h you can see that an Expression type requires a field body , which is an expr_ty type. The expr_ty type is also defined in Include/Python-ast.h : enum _mod_kind { Module_kind = 1 , Interactive_kind = 2 , Expression_kind = 3 , FunctionType_kind = 4 , Suite_kind = 5 }; struct _mod { enum _mod_kind kind ; union { struct { asdl_seq * body ; asdl_seq * type_ignores ; } Module ; struct { asdl_seq * body ; } Interactive ; struct { expr_ty body ; } Expression ; struct { asdl_seq * argtypes ; expr_ty returns ; } FunctionType ; struct { asdl_seq * body ; } Suite ; } v ; };","title":"Abstract Syntax Trees"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-2-The-Python-Interpreter-Process/#conclusion","text":"CPython\u2019s versatility and low-level execution API make it the ideal candidate for an embedded scripting engine. You will see CPython used in many UI applications, such as Game Design, 3D graphics and system automation. The interpreter process is flexible and efficient, and now you have an understanding of how it works you\u2019re ready to understand the compiler.","title":"Conclusion"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-3-The-CPython-Compiler-and-Execution-Loop/","text":"Part 3: The CPython Compiler and Execution Loop In Part 2, you saw how the CPython interpreter takes an input, such as a file or string, and converts it into a logical Abstract Syntax Tree . We\u2019re still not at the stage where this code can be executed. Next, we have to go deeper to convert the Abstract Syntax Tree into a set of sequential commands that the CPU can understand. Compiling Now the interpreter has an AST with the properties required for each of the operations, functions, classes, and namespaces. It is the job of the compiler to turn the AST into something the CPU can understand. This compilation task is split into 2 parts: Traverse the tree and create a control-flow-graph , which represents the logical sequence for execution Convert the nodes in the CFG to smaller, executable statements, known as byte-code Earlier, we were looking at how files are executed, and the PyRun_FileExFlags() function in Python/pythonrun.c . Inside this function, we converted the FILE handle into a mod , of type mod_ty . This task was completed by PyParser_ASTFromFileObject() , which in turns calls the tokenizer , parser-tokenizer and then the AST: PyObject * PyRun_FileExFlags ( FILE * fp , const char * filename_str , int start , PyObject * globals , PyObject * locals , int closeit , PyCompilerFlags * flags ) { ... mod = PyParser_ASTFromFileObject ( fp , filename , NULL , start , 0 , 0 , ... ret = run_mod ( mod , filename , globals , locals , flags , arena ); } The resulting module from the call to is sent to run_mod() still in Python/pythonrun.c . This is a small function that gets a PyCodeObject from PyAST_CompileObject() and sends it on to run_eval_code_obj() . You will tackle run_eval_code_obj() in the next section: static PyObject * run_mod ( mod_ty mod , PyObject * filename , PyObject * globals , PyObject * locals , PyCompilerFlags * flags , PyArena * arena ) { PyCodeObject * co ; PyObject * v ; co = PyAST_CompileObject ( mod , filename , flags , - 1 , arena ); if ( co == NULL ) return NULL ; if ( PySys_Audit ( \"exec\" , \"O\" , co ) < 0 ) { Py_DECREF ( co ); return NULL ; } v = run_eval_code_obj ( co , globals , locals ); Py_DECREF ( co ); return v ; } The PyAST_CompileObject() function is the main entry point to the CPython compiler . It takes a Python module as its primary argument, along with the name of the file, the globals, locals, and the PyArena all created earlier in the interpreter process. We\u2019re starting to get into the guts of the CPython compiler now, with decades of development and Computer Science theory behind it. Don\u2019t be put off by the language. Once we break down the compiler into logical steps, it\u2019ll make sense. Before the compiler starts, a global compiler state is created. This type, compiler is defined in Python/compile.c and contains properties used by the compiler to remember the compiler flags, the stack, and the PyArena : struct compiler { PyObject * c_filename ; struct symtable * c_st ; PyFutureFeatures * c_future ; /* pointer to module's __future__ */ PyCompilerFlags * c_flags ; int c_optimize ; /* optimization level */ int c_interactive ; /* true if in interactive mode */ int c_nestlevel ; int c_do_not_emit_bytecode ; /* The compiler won't emit any bytecode if this value is different from zero. This can be used to temporarily visit nodes without emitting bytecode to check only errors. */ PyObject * c_const_cache ; /* Python dict holding all constants, including names tuple */ struct compiler_unit * u ; /* compiler state for current block */ PyObject * c_stack ; /* Python list holding compiler_unit ptrs */ PyArena * c_arena ; /* pointer to memory allocation arena */ }; Inside PyAST_CompileObject() , there are 11 main steps happening: Create an empty __doc__ property to the module if it doesn\u2019t exist. Create an empty __annotations__ property to the module if it doesn\u2019t exist. Set the filename of the global compiler state to the filename argument. Set the memory allocation arena for the compiler to the one used by the interpreter. Copy any __future__ flags in the module to the future flags in the compiler. Merge runtime flags provided by the command-line or environment variables. Enable any __future__ features in the compiler. Set the optimization level to the provided argument, or default. Build a symbol table from the module object. Run the compiler with the compiler state and return the code object . Free any allocated memory by the compiler. PyCodeObject * PyAST_CompileObject ( mod_ty mod , PyObject * filename , PyCompilerFlags * flags , int optimize , PyArena * arena ) { struct compiler c ; PyCodeObject * co = NULL ; PyCompilerFlags local_flags = _PyCompilerFlags_INIT ; int merged ; PyConfig * config = & _PyInterpreterState_GET_UNSAFE () -> config ; if ( ! __doc__ ) { __doc__ = PyUnicode_InternFromString ( \"__doc__\" ); if ( ! __doc__ ) return NULL ; } if ( ! __annotations__ ) { __annotations__ = PyUnicode_InternFromString ( \"__annotations__\" ); if ( ! __annotations__ ) return NULL ; } if ( ! compiler_init ( & c )) return NULL ; Py_INCREF ( filename ); c . c_filename = filename ; c . c_arena = arena ; c . c_future = PyFuture_FromASTObject ( mod , filename ); if ( c . c_future == NULL ) goto finally ; if ( ! flags ) { flags = & local_flags ; } merged = c . c_future -> ff_features | flags -> cf_flags ; c . c_future -> ff_features = merged ; flags -> cf_flags = merged ; c . c_flags = flags ; c . c_optimize = ( optimize == - 1 ) ? config -> optimization_level : optimize ; c . c_nestlevel = 0 ; c . c_do_not_emit_bytecode = 0 ; if ( ! _PyAST_Optimize ( mod , arena , c . c_optimize )) { goto finally ; } c . c_st = PySymtable_BuildObject ( mod , filename , c . c_future ); if ( c . c_st == NULL ) { if ( ! PyErr_Occurred ()) PyErr_SetString ( PyExc_SystemError , \"no symtable\" ); goto finally ; } co = compiler_mod ( & c , mod ); finally : compiler_free ( & c ); assert ( co || PyErr_Occurred ()); return co ; } Future Flags and Compiler Flags Before the compiler runs, there are two types of flags to toggle the features inside the compiler. These come from two places: The interpreter state , which may have been command-line options, set in pyconfig.h or via environment variables The use of __future__ statements inside the actual source code of the module To distinguish the two types of flags, think that the __future__ flags are required because of the syntax or features in that specific module. For example, Python 3.7 introduced delayed evaluation of type hints through the annotations future flag: from __future__ import annotations The code after this statement might use unresolved type hints, so the __future__ statement is required. Otherwise, the module wouldn\u2019t import. It would be unmaintainable to manually request that the person importing the module enable this specific compiler flag. The other compiler flags are specific to the environment, so they might change the way the code executes or the way the compiler runs, but they shouldn\u2019t link to the source in the same way that __future__ statements do. One example of a compiler flag would be the -O flag for optimizing the use of assert statements . This flag disables any assert statements, which may have been put in the code for debugging purposes . It can also be enabled with the PYTHONOPTIMIZE=1 environment variable setting. Symbol Tables In PyAST_CompileObject() there was a reference to a symtable and a call to PySymtable_BuildObject() with the module to be executed. The purpose of the symbol table is to provide a list of namespaces, globals, and locals for the compiler to use for referencing and resolving scopes. NOTE: scope\u5728\u8fd9\u91cc\u7684\u542b\u4e49\u662f\uff1f The symtable structure in Include/symtable.h is well documented, so it\u2019s clear what each of the fields is for. There should be one symtable instance for the compiler, so namespacing becomes essential. NOTE: \u5982\u4f55\u5b9e\u73b0namespace\uff1f If you create a function called resolve_names() in one module and declare another function with the same name in another module, you want to be sure which one is called. The symtable serves this purpose, as well as ensuring that variables declared within a narrow scope don\u2019t automatically become globals (after all, this isn\u2019t JavaScript): struct symtable { PyObject * st_filename ; /* name of file being compiled, decoded from the filesystem encoding */ struct _symtable_entry * st_cur ; /* current symbol table entry */ struct _symtable_entry * st_top ; /* symbol table entry for module */ PyObject * st_blocks ; /* dict: map AST node addresses * to symbol table entries */ PyObject * st_stack ; /* list: stack of namespace info */ PyObject * st_global ; /* borrowed ref to st_top->ste_symbols */ int st_nblocks ; /* number of blocks used. kept for consistency with the corresponding compiler structure */ PyObject * st_private ; /* name of current class or NULL */ PyFutureFeatures * st_future ; /* module's future features that affect the symbol table */ int recursion_depth ; /* current recursion depth */ int recursion_limit ; /* recursion limit */ }; Some of the symbol table API is exposed via the symtable module in the standard library. You can provide an expression or a module and receive a symtable.SymbolTable instance. You can provide a string with a Python expression and the compile_type of \"eval\" , or a module, function or class, and the compile_mode of \"exec\" to get a symbol table . Looping over the elements in the table we can see some of the public and private fields and their types: >>> import symtable >>> s = symtable . symtable ( 'b + 1' , filename = 'test.py' , compile_type = 'eval' ) >>> [ symbol . __dict__ for symbol in s . get_symbols ()] [{ '_Symbol__name' : 'b' , '_Symbol__flags' : 6160 , '_Symbol__scope' : 3 , '_Symbol__namespaces' : ()}] The C code behind this is all within Python/symtable.c and the primary interface is the PySymtable_BuildObject() function. Similar to the top-level AST function we covered earlier, the PySymtable_BuildObject() function switches between the mod_ty possible types (Module, Expression, Interactive, Suite, FunctionType), and visits each of the statements inside them. Remember, mod_ty is an AST instance , so the will now recursively explore the nodes and branches of the tree and add entries to the symtable: struct symtable * PySymtable_BuildObject ( mod_ty mod , PyObject * filename , PyFutureFeatures * future ) { struct symtable * st = symtable_new (); asdl_seq * seq ; int i ; PyThreadState * tstate ; int recursion_limit = Py_GetRecursionLimit (); ... st -> st_top = st -> st_cur ; switch ( mod -> kind ) { case Module_kind : seq = mod -> v . Module . body ; for ( i = 0 ; i < asdl_seq_LEN ( seq ); i ++ ) if ( ! symtable_visit_stmt ( st , ( stmt_ty ) asdl_seq_GET ( seq , i ))) goto error ; break ; case Expression_kind : ... case Interactive_kind : ... case Suite_kind : ... case FunctionType_kind : ... } ... } So for a module, PySymtable_BuildObject() will loop through each statement in the module and call symtable_visit_stmt() . The symtable_visit_stmt() is a huge switch statement with a case for each statement type (defined in Parser/Python.asdl ). For each statement type, there is specific logic to that statement type. For example, a function definition has particular logic for: If the recursion depth is beyond the limit, raise a recursion depth error The name of the function to be added as a local variable The default values for sequential arguments to be resolved The default values for keyword arguments to be resolved Any annotations for the arguments or the return type are resolved Any function decorators are resolved The code block with the contents of the function is visited in symtable_enter_block() The arguments are visited The body of the function is visited Note: If you\u2019ve ever wondered why Python\u2019s default arguments are mutable, the reason is in this function. You can see they are a pointer to the variable in the symtable. No extra work is done to copy any values to an immutable type. static int symtable_visit_stmt ( struct symtable * st , stmt_ty s ) { if ( ++ st -> recursion_depth > st -> recursion_limit ) { // 1. PyErr_SetString ( PyExc_RecursionError , \"maximum recursion depth exceeded during compilation\" ); VISIT_QUIT ( st , 0 ); } switch ( s -> kind ) { case FunctionDef_kind : if ( ! symtable_add_def ( st , s -> v . FunctionDef . name , DEF_LOCAL )) // 2. VISIT_QUIT ( st , 0 ); if ( s -> v . FunctionDef . args -> defaults ) // 3. VISIT_SEQ ( st , expr , s -> v . FunctionDef . args -> defaults ); if ( s -> v . FunctionDef . args -> kw_defaults ) // 4. VISIT_SEQ_WITH_NULL ( st , expr , s -> v . FunctionDef . args -> kw_defaults ); if ( ! symtable_visit_annotations ( st , s , s -> v . FunctionDef . args , // 5. s -> v . FunctionDef . returns )) VISIT_QUIT ( st , 0 ); if ( s -> v . FunctionDef . decorator_list ) // 6. VISIT_SEQ ( st , expr , s -> v . FunctionDef . decorator_list ); if ( ! symtable_enter_block ( st , s -> v . FunctionDef . name , // 7. FunctionBlock , ( void * ) s , s -> lineno , s -> col_offset )) VISIT_QUIT ( st , 0 ); VISIT ( st , arguments , s -> v . FunctionDef . args ); // 8. VISIT_SEQ ( st , stmt , s -> v . FunctionDef . body ); // 9. if ( ! symtable_exit_block ( st , s )) VISIT_QUIT ( st , 0 ); break ; case ClassDef_kind : { ... } case Return_kind : ... case Delete_kind : ... case Assign_kind : ... case AnnAssign_kind : ... Once the resulting symtable has been created, it is sent back to be used for the compiler. Core Compilation Process Now that the PyAST_CompileObject() has a compiler state , a symtable , and a module in the form of the AST, the actual compilation can begin. The purpose of the core compiler is to: Convert the state, symtable, and AST into a Control-Flow-Graph (CFG) Protect the execution stage from runtime exceptions by catching any logic and code errors and raising them here You can call the CPython compiler in Python code by calling the built-in function compile() . It returns a code object instance: >>> co = compile ( 'b+1' , 'test.py' , mode = 'eval' ) < code object < module > at 0x10f222780 , file \"test.py\" , line 1 > The same as with the symtable() function, a simple expression should have a mode of 'eval' and a module, function, or class should have a mode of 'exec' . The compiled code can be found in the co_code property of the code object: >>> co.co_code b'e\\x00d\\x00\\x17\\x00S\\x00' There is also a dis module in the standard library, which disassembles the bytecode instructions and can print them on the screen or give you a list of Instruction instances. If you import dis and give the dis() function the code object\u2019s co_code property it disassembles it and prints the instructions on the REPL: >>> import dis >>> dis . dis ( co . co_code ) 0 LOAD_NAME 0 ( 0 ) 2 LOAD_CONST 0 ( 0 ) 4 BINARY_ADD 6 RETURN_VALUE LOAD_NAME , LOAD_CONST , BINARY_ADD , and RETURN_VALUE are all bytecode instructions. They\u2019re called bytecode because, in binary form, they were a byte long. However, since Python 3.6 the storage format was changed to a word , so now they\u2019re technically wordcode, not bytecode. The full list of bytecode instructions is available for each version of Python, and it does change between versions. For example, in Python 3.7, some new bytecode instructions were introduced to speed up execution of specific method calls. In an earlier section, we explored the instaviz package. This included a visualization of the code object type by running the compiler. It also displays the Bytecode operations inside the code objects. Execute instaviz again to see the code object and bytecode for a function defined on the REPL: >>> import instaviz >>> def example (): a = 1 b = a + 1 return b >>> instaviz . show ( example ) If we now jump into compiler_mod() , a function used to switch to different compiler functions depending on the module type . We\u2019ll assume that mod is a Module . The module is compiled into the compiler state and then assemble() is run to create a PyCodeObject . The new code object is returned back to PyAST_CompileObject() and sent on for execution: static PyCodeObject * compiler_mod ( struct compiler * c , mod_ty mod ) { PyCodeObject * co ; int addNone = 1 ; static PyObject * module ; ... switch ( mod -> kind ) { case Module_kind : if ( ! compiler_body ( c , mod -> v . Module . body )) { compiler_exit_scope ( c ); return 0 ; } break ; case Interactive_kind : ... case Expression_kind : ... case Suite_kind : ... ... co = assemble ( c , addNone ); compiler_exit_scope ( c ); return co ; } The compiler_body() function has some optimization flags and then loops over each statement in the module and visits it, similar to how the symtable functions worked: static int compiler_body ( struct compiler * c , asdl_seq * stmts ) { int i = 0 ; stmt_ty st ; PyObject * docstring ; ... for (; i < asdl_seq_LEN ( stmts ); i ++ ) VISIT ( c , stmt , ( stmt_ty ) asdl_seq_GET ( stmts , i )); return 1 ; } The statement type is determined through a call to the asdl_seq_GET() function, which looks at the AST node\u2019s type. Through some smart macros, VISIT calls a function in Python/compile.c for each statement type: #define VISIT(C, TYPE, V) {\\ if (!compiler_visit_ ## TYPE((C), (V))) \\ return 0; \\ } For a stmt (the category for a statement) the compiler will then drop into compiler_visit_stmt() and switch through all of the potential statement types found in Parser/Python.asdl : static int compiler_visit_stmt ( struct compiler * c , stmt_ty s ) { Py_ssize_t i , n ; /* Always assign a lineno to the next instruction for a stmt. */ c -> u -> u_lineno = s -> lineno ; c -> u -> u_col_offset = s -> col_offset ; c -> u -> u_lineno_set = 0 ; switch ( s -> kind ) { case FunctionDef_kind : return compiler_function ( c , s , 0 ); case ClassDef_kind : return compiler_class ( c , s ); ... case For_kind : return compiler_for ( c , s ); ... } return 1 ; } As an example, let\u2019s focus on the For statement, in Python is the: for i in iterable : # block else : # optional if iterable is False # block If the statement is a For type, it calls compiler_for() . There is an equivalent compiler_*() function for all of the statement and expression types. The more straightforward types create the bytecode instructions inline, some of the more complex statement types call other functions. Many of the statements can have sub-statements . A for loop has a body, but you can also have complex expressions in the assignment and the iterator. The compiler\u2019s compiler_ statements sends blocks to the compiler state . These blocks contain instructions, the instruction data structure in Python/compile.c has the opcode, any arguments, and the target block (if this is a jump instruction), it also contains the line number. For jump statements , they can either be absolute or relative jump statements. Jump statements are used to \u201cjump\u201d from one operation to another. Absolute jump statements specify the exact operation number in the compiled code object, whereas relative jump statements specify the jump target relative to another operation: struct instr { unsigned i_jabs : 1 ; unsigned i_jrel : 1 ; unsigned char i_opcode ; int i_oparg ; struct basicblock_ * i_target ; /* target block (if jump instruction) */ int i_lineno ; }; So a frame block (of type basicblock ), contains the following fields: A b_list pointer, the link to a list of blocks for the compiler state A list of instructions b_instr , with both the allocated list size b_ialloc , and the number used b_iused The next block after this one b_next Whether the block has been \u201cseen\u201d by the assembler when traversing depth-first If this block has a RETURN_VALUE opcode ( b_return ) The depth of the stack when this block was entered ( b_startdepth ) The instruction offset for the assembler typedef struct basicblock_ { /* Each basicblock in a compilation unit is linked via b_list in the reverse order that the block are allocated. b_list points to the next block, not to be confused with b_next, which is next by control flow. */ struct basicblock_ * b_list ; /* number of instructions used */ int b_iused ; /* length of instruction array (b_instr) */ int b_ialloc ; /* pointer to an array of instructions, initially NULL */ struct instr * b_instr ; /* If b_next is non-NULL, it is a pointer to the next block reached by normal control flow. */ struct basicblock_ * b_next ; /* b_seen is used to perform a DFS of basicblocks. */ unsigned b_seen : 1 ; /* b_return is true if a RETURN_VALUE opcode is inserted. */ unsigned b_return : 1 ; /* depth of stack upon entry of block, computed by stackdepth() */ int b_startdepth ; /* instruction offset for block, computed by assemble_jump_offsets() */ int b_offset ; } basicblock ; The For statement is somewhere in the middle in terms of complexity. There are 15 steps in the compilation of a For statement with the for in : syntax: Create a new code block called start , this allocates memory and creates a basicblock pointer Create a new code block called cleanup Create a new code block called end Push a frame block of type FOR_LOOP to the stack with start as the entry block and end as the exit block Visit the iterator expression, which adds any operations for the iterator Add the GET_ITER operation to the compiler state Switch to the start block Call ADDOP_JREL which calls compiler_addop_j() to add the FOR_ITER operation with an argument of the cleanup block Visit the target and add any special code, like tuple unpacking, to the start block Visit each statement in the body of the for loop Call ADDOP_JABS which calls compiler_addop_j() to add the JUMP_ABSOLUTE operation which indicates after the body is executed, jumps back to the start of the loop Move to the cleanup block Pop the FOR_LOOP frame block off the stack Visit the statements inside the else section of the for loop Use the end block Referring back to the basicblock structure. You can see how in the compilation of the for statement, the various blocks are created and pushed into the compiler\u2019s frame block and stack: static int compiler_for ( struct compiler * c , stmt_ty s ) { basicblock * start , * cleanup , * end ; start = compiler_new_block ( c ); // 1. cleanup = compiler_new_block ( c ); // 2. end = compiler_new_block ( c ); // 3. if ( start == NULL || end == NULL || cleanup == NULL ) return 0 ; if ( ! compiler_push_fblock ( c , FOR_LOOP , start , end )) // 4. return 0 ; VISIT ( c , expr , s -> v . For . iter ); // 5. ADDOP ( c , GET_ITER ); // 6. compiler_use_next_block ( c , start ); // 7. ADDOP_JREL ( c , FOR_ITER , cleanup ); // 8. VISIT ( c , expr , s -> v . For . target ); // 9. VISIT_SEQ ( c , stmt , s -> v . For . body ); // 10. ADDOP_JABS ( c , JUMP_ABSOLUTE , start ); // 11. compiler_use_next_block ( c , cleanup ); // 12. compiler_pop_fblock ( c , FOR_LOOP , start ); // 13. VISIT_SEQ ( c , stmt , s -> v . For . orelse ); // 14. compiler_use_next_block ( c , end ); // 15. return 1 ; } Depending on the type of operation, there are different arguments required. For example, we used ADDOP_JABS and ADDOP_JREL here, which refer to \u201c ADD O**peration with **J**ump to a **REL**ative position\u201d and \u201c**ADD **O**peration with **J**ump to an **ABS**olute position\u201d. This is referring to the APPOP_JREL and ADDOP_JABS macros which call compiler_addop_j(struct compiler *c, int opcode, basicblock *b, int absolute) and set the absolute argument to 0 and 1 respectively. There are some other macros, like ADDOP_I calls compiler_addop_i() which add an operation with an integer argument, or ADDOP_O calls compiler_addop_o() which adds an operation with a PyObject argument. Once these stages have completed, the compiler has a list of frame blocks, each containing a list of instructions and a pointer to the next block. Assembly With the compiler state, the assembler performs a \u201cdepth-first-search\u201d of the blocks and merge the instructions into a single bytecode sequence. The assembler state is declared in Python/compile.c : struct assembler { PyObject * a_bytecode ; /* string containing bytecode */ int a_offset ; /* offset into bytecode */ int a_nblocks ; /* number of reachable blocks */ basicblock ** a_postorder ; /* list of blocks in dfs postorder */ PyObject * a_lnotab ; /* string containing lnotab */ int a_lnotab_off ; /* offset into lnotab */ int a_lineno ; /* last lineno of emitted instruction */ int a_lineno_off ; /* bytecode offset of last lineno */ }; The assemble() function has a few tasks: Calculate the number of blocks for memory allocation Ensure that every block that falls off the end returns None , this is why every function returns None , whether or not a return statement exists Resolve any jump statements offsets that were marked as relative Call dfs() to perform a depth-first-search of the blocks Emit all the instructions to the compiler Call makecode() with the compiler state to generate the PyCodeObject static PyCodeObject * assemble ( struct compiler * c , int addNone ) { basicblock * b , * entryblock ; struct assembler a ; int i , j , nblocks ; PyCodeObject * co = NULL ; /* Make sure every block that falls off the end returns None. XXX NEXT_BLOCK() isn't quite right, because if the last block ends with a jump or return b_next shouldn't set. */ if ( ! c -> u -> u_curblock -> b_return ) { NEXT_BLOCK ( c ); if ( addNone ) ADDOP_LOAD_CONST ( c , Py_None ); ADDOP ( c , RETURN_VALUE ); } ... dfs ( c , entryblock , & a , nblocks ); /* Can't modify the bytecode after computing jump offsets. */ assemble_jump_offsets ( & a , c ); /* Emit code in reverse postorder from dfs. */ for ( i = a . a_nblocks - 1 ; i >= 0 ; i -- ) { b = a . a_postorder [ i ]; for ( j = 0 ; j < b -> b_iused ; j ++ ) if ( ! assemble_emit ( & a , & b -> b_instr [ j ])) goto error ; } ... co = makecode ( c , & a ); error : assemble_free ( & a ); return co ; } The depth-first-search is performed by the dfs() function in Python/compile.c , which follows the the b_next pointers in each of the blocks, marks them as seen by toggling b_seen and then adds them to the assemblers **a_postorder list in reverse order. The function loops back over the assembler\u2019s post-order list and for each block, if it has a jump operation, recursively call dfs() for that jump: static void dfs ( struct compiler * c , basicblock * b , struct assembler * a , int end ) { int i , j ; /* Get rid of recursion for normal control flow. Since the number of blocks is limited, unused space in a_postorder (from a_nblocks to end) can be used as a stack for still not ordered blocks. */ for ( j = end ; b && ! b -> b_seen ; b = b -> b_next ) { b -> b_seen = 1 ; assert ( a -> a_nblocks < j ); a -> a_postorder [ -- j ] = b ; } while ( j < end ) { b = a -> a_postorder [ j ++ ]; for ( i = 0 ; i < b -> b_iused ; i ++ ) { struct instr * instr = & b -> b_instr [ i ]; if ( instr -> i_jrel || instr -> i_jabs ) dfs ( c , instr -> i_target , a , j ); } assert ( a -> a_nblocks < j ); a -> a_postorder [ a -> a_nblocks ++ ] = b ; } } Creating a Code Object The task of makecode() is to go through the compiler state, some of the assembler\u2019s properties and to put these into a PyCodeObject by calling PyCode_New() : Execution In Python/pythonrun.c we broke out just before the call to run_eval_code_obj() . This call takes a code object, either fetched from the marshaled .pyc file, or compiled through the AST and compiler stages. run_eval_code_obj() will pass the globals, locals, PyArena , and compiled PyCodeObject to PyEval_EvalCode() in Python/ceval.c . This stage forms the execution component of CPython. Each of the bytecode operations is taken and executed using a \u201cStack Frame\u201d based system . What is a Stack Frame? Stack Frames are a data type used by many runtimes, not just Python, that allows functions to be called and variables to be returned between functions. Stack Frames also contain arguments, local variables, and other state information. Typically, a Stack Frame exists for every function call, and they are stacked in sequence. You can see CPython\u2019s frame stack anytime an exception is unhandled and the stack is printed on the screen.","title":"Part 3 The CPython Compiler and Execution Loop"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-3-The-CPython-Compiler-and-Execution-Loop/#part-3-the-cpython-compiler-and-execution-loop","text":"In Part 2, you saw how the CPython interpreter takes an input, such as a file or string, and converts it into a logical Abstract Syntax Tree . We\u2019re still not at the stage where this code can be executed. Next, we have to go deeper to convert the Abstract Syntax Tree into a set of sequential commands that the CPU can understand.","title":"Part 3: The CPython Compiler and Execution Loop"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-3-The-CPython-Compiler-and-Execution-Loop/#compiling","text":"Now the interpreter has an AST with the properties required for each of the operations, functions, classes, and namespaces. It is the job of the compiler to turn the AST into something the CPU can understand. This compilation task is split into 2 parts: Traverse the tree and create a control-flow-graph , which represents the logical sequence for execution Convert the nodes in the CFG to smaller, executable statements, known as byte-code Earlier, we were looking at how files are executed, and the PyRun_FileExFlags() function in Python/pythonrun.c . Inside this function, we converted the FILE handle into a mod , of type mod_ty . This task was completed by PyParser_ASTFromFileObject() , which in turns calls the tokenizer , parser-tokenizer and then the AST: PyObject * PyRun_FileExFlags ( FILE * fp , const char * filename_str , int start , PyObject * globals , PyObject * locals , int closeit , PyCompilerFlags * flags ) { ... mod = PyParser_ASTFromFileObject ( fp , filename , NULL , start , 0 , 0 , ... ret = run_mod ( mod , filename , globals , locals , flags , arena ); } The resulting module from the call to is sent to run_mod() still in Python/pythonrun.c . This is a small function that gets a PyCodeObject from PyAST_CompileObject() and sends it on to run_eval_code_obj() . You will tackle run_eval_code_obj() in the next section: static PyObject * run_mod ( mod_ty mod , PyObject * filename , PyObject * globals , PyObject * locals , PyCompilerFlags * flags , PyArena * arena ) { PyCodeObject * co ; PyObject * v ; co = PyAST_CompileObject ( mod , filename , flags , - 1 , arena ); if ( co == NULL ) return NULL ; if ( PySys_Audit ( \"exec\" , \"O\" , co ) < 0 ) { Py_DECREF ( co ); return NULL ; } v = run_eval_code_obj ( co , globals , locals ); Py_DECREF ( co ); return v ; } The PyAST_CompileObject() function is the main entry point to the CPython compiler . It takes a Python module as its primary argument, along with the name of the file, the globals, locals, and the PyArena all created earlier in the interpreter process. We\u2019re starting to get into the guts of the CPython compiler now, with decades of development and Computer Science theory behind it. Don\u2019t be put off by the language. Once we break down the compiler into logical steps, it\u2019ll make sense. Before the compiler starts, a global compiler state is created. This type, compiler is defined in Python/compile.c and contains properties used by the compiler to remember the compiler flags, the stack, and the PyArena : struct compiler { PyObject * c_filename ; struct symtable * c_st ; PyFutureFeatures * c_future ; /* pointer to module's __future__ */ PyCompilerFlags * c_flags ; int c_optimize ; /* optimization level */ int c_interactive ; /* true if in interactive mode */ int c_nestlevel ; int c_do_not_emit_bytecode ; /* The compiler won't emit any bytecode if this value is different from zero. This can be used to temporarily visit nodes without emitting bytecode to check only errors. */ PyObject * c_const_cache ; /* Python dict holding all constants, including names tuple */ struct compiler_unit * u ; /* compiler state for current block */ PyObject * c_stack ; /* Python list holding compiler_unit ptrs */ PyArena * c_arena ; /* pointer to memory allocation arena */ }; Inside PyAST_CompileObject() , there are 11 main steps happening: Create an empty __doc__ property to the module if it doesn\u2019t exist. Create an empty __annotations__ property to the module if it doesn\u2019t exist. Set the filename of the global compiler state to the filename argument. Set the memory allocation arena for the compiler to the one used by the interpreter. Copy any __future__ flags in the module to the future flags in the compiler. Merge runtime flags provided by the command-line or environment variables. Enable any __future__ features in the compiler. Set the optimization level to the provided argument, or default. Build a symbol table from the module object. Run the compiler with the compiler state and return the code object . Free any allocated memory by the compiler. PyCodeObject * PyAST_CompileObject ( mod_ty mod , PyObject * filename , PyCompilerFlags * flags , int optimize , PyArena * arena ) { struct compiler c ; PyCodeObject * co = NULL ; PyCompilerFlags local_flags = _PyCompilerFlags_INIT ; int merged ; PyConfig * config = & _PyInterpreterState_GET_UNSAFE () -> config ; if ( ! __doc__ ) { __doc__ = PyUnicode_InternFromString ( \"__doc__\" ); if ( ! __doc__ ) return NULL ; } if ( ! __annotations__ ) { __annotations__ = PyUnicode_InternFromString ( \"__annotations__\" ); if ( ! __annotations__ ) return NULL ; } if ( ! compiler_init ( & c )) return NULL ; Py_INCREF ( filename ); c . c_filename = filename ; c . c_arena = arena ; c . c_future = PyFuture_FromASTObject ( mod , filename ); if ( c . c_future == NULL ) goto finally ; if ( ! flags ) { flags = & local_flags ; } merged = c . c_future -> ff_features | flags -> cf_flags ; c . c_future -> ff_features = merged ; flags -> cf_flags = merged ; c . c_flags = flags ; c . c_optimize = ( optimize == - 1 ) ? config -> optimization_level : optimize ; c . c_nestlevel = 0 ; c . c_do_not_emit_bytecode = 0 ; if ( ! _PyAST_Optimize ( mod , arena , c . c_optimize )) { goto finally ; } c . c_st = PySymtable_BuildObject ( mod , filename , c . c_future ); if ( c . c_st == NULL ) { if ( ! PyErr_Occurred ()) PyErr_SetString ( PyExc_SystemError , \"no symtable\" ); goto finally ; } co = compiler_mod ( & c , mod ); finally : compiler_free ( & c ); assert ( co || PyErr_Occurred ()); return co ; }","title":"Compiling"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-3-The-CPython-Compiler-and-Execution-Loop/#future-flags-and-compiler-flags","text":"Before the compiler runs, there are two types of flags to toggle the features inside the compiler. These come from two places: The interpreter state , which may have been command-line options, set in pyconfig.h or via environment variables The use of __future__ statements inside the actual source code of the module To distinguish the two types of flags, think that the __future__ flags are required because of the syntax or features in that specific module. For example, Python 3.7 introduced delayed evaluation of type hints through the annotations future flag: from __future__ import annotations The code after this statement might use unresolved type hints, so the __future__ statement is required. Otherwise, the module wouldn\u2019t import. It would be unmaintainable to manually request that the person importing the module enable this specific compiler flag. The other compiler flags are specific to the environment, so they might change the way the code executes or the way the compiler runs, but they shouldn\u2019t link to the source in the same way that __future__ statements do. One example of a compiler flag would be the -O flag for optimizing the use of assert statements . This flag disables any assert statements, which may have been put in the code for debugging purposes . It can also be enabled with the PYTHONOPTIMIZE=1 environment variable setting.","title":"Future Flags and Compiler Flags"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-3-The-CPython-Compiler-and-Execution-Loop/#symbol-tables","text":"In PyAST_CompileObject() there was a reference to a symtable and a call to PySymtable_BuildObject() with the module to be executed. The purpose of the symbol table is to provide a list of namespaces, globals, and locals for the compiler to use for referencing and resolving scopes. NOTE: scope\u5728\u8fd9\u91cc\u7684\u542b\u4e49\u662f\uff1f The symtable structure in Include/symtable.h is well documented, so it\u2019s clear what each of the fields is for. There should be one symtable instance for the compiler, so namespacing becomes essential. NOTE: \u5982\u4f55\u5b9e\u73b0namespace\uff1f If you create a function called resolve_names() in one module and declare another function with the same name in another module, you want to be sure which one is called. The symtable serves this purpose, as well as ensuring that variables declared within a narrow scope don\u2019t automatically become globals (after all, this isn\u2019t JavaScript): struct symtable { PyObject * st_filename ; /* name of file being compiled, decoded from the filesystem encoding */ struct _symtable_entry * st_cur ; /* current symbol table entry */ struct _symtable_entry * st_top ; /* symbol table entry for module */ PyObject * st_blocks ; /* dict: map AST node addresses * to symbol table entries */ PyObject * st_stack ; /* list: stack of namespace info */ PyObject * st_global ; /* borrowed ref to st_top->ste_symbols */ int st_nblocks ; /* number of blocks used. kept for consistency with the corresponding compiler structure */ PyObject * st_private ; /* name of current class or NULL */ PyFutureFeatures * st_future ; /* module's future features that affect the symbol table */ int recursion_depth ; /* current recursion depth */ int recursion_limit ; /* recursion limit */ }; Some of the symbol table API is exposed via the symtable module in the standard library. You can provide an expression or a module and receive a symtable.SymbolTable instance. You can provide a string with a Python expression and the compile_type of \"eval\" , or a module, function or class, and the compile_mode of \"exec\" to get a symbol table . Looping over the elements in the table we can see some of the public and private fields and their types: >>> import symtable >>> s = symtable . symtable ( 'b + 1' , filename = 'test.py' , compile_type = 'eval' ) >>> [ symbol . __dict__ for symbol in s . get_symbols ()] [{ '_Symbol__name' : 'b' , '_Symbol__flags' : 6160 , '_Symbol__scope' : 3 , '_Symbol__namespaces' : ()}] The C code behind this is all within Python/symtable.c and the primary interface is the PySymtable_BuildObject() function. Similar to the top-level AST function we covered earlier, the PySymtable_BuildObject() function switches between the mod_ty possible types (Module, Expression, Interactive, Suite, FunctionType), and visits each of the statements inside them. Remember, mod_ty is an AST instance , so the will now recursively explore the nodes and branches of the tree and add entries to the symtable: struct symtable * PySymtable_BuildObject ( mod_ty mod , PyObject * filename , PyFutureFeatures * future ) { struct symtable * st = symtable_new (); asdl_seq * seq ; int i ; PyThreadState * tstate ; int recursion_limit = Py_GetRecursionLimit (); ... st -> st_top = st -> st_cur ; switch ( mod -> kind ) { case Module_kind : seq = mod -> v . Module . body ; for ( i = 0 ; i < asdl_seq_LEN ( seq ); i ++ ) if ( ! symtable_visit_stmt ( st , ( stmt_ty ) asdl_seq_GET ( seq , i ))) goto error ; break ; case Expression_kind : ... case Interactive_kind : ... case Suite_kind : ... case FunctionType_kind : ... } ... } So for a module, PySymtable_BuildObject() will loop through each statement in the module and call symtable_visit_stmt() . The symtable_visit_stmt() is a huge switch statement with a case for each statement type (defined in Parser/Python.asdl ). For each statement type, there is specific logic to that statement type. For example, a function definition has particular logic for: If the recursion depth is beyond the limit, raise a recursion depth error The name of the function to be added as a local variable The default values for sequential arguments to be resolved The default values for keyword arguments to be resolved Any annotations for the arguments or the return type are resolved Any function decorators are resolved The code block with the contents of the function is visited in symtable_enter_block() The arguments are visited The body of the function is visited Note: If you\u2019ve ever wondered why Python\u2019s default arguments are mutable, the reason is in this function. You can see they are a pointer to the variable in the symtable. No extra work is done to copy any values to an immutable type. static int symtable_visit_stmt ( struct symtable * st , stmt_ty s ) { if ( ++ st -> recursion_depth > st -> recursion_limit ) { // 1. PyErr_SetString ( PyExc_RecursionError , \"maximum recursion depth exceeded during compilation\" ); VISIT_QUIT ( st , 0 ); } switch ( s -> kind ) { case FunctionDef_kind : if ( ! symtable_add_def ( st , s -> v . FunctionDef . name , DEF_LOCAL )) // 2. VISIT_QUIT ( st , 0 ); if ( s -> v . FunctionDef . args -> defaults ) // 3. VISIT_SEQ ( st , expr , s -> v . FunctionDef . args -> defaults ); if ( s -> v . FunctionDef . args -> kw_defaults ) // 4. VISIT_SEQ_WITH_NULL ( st , expr , s -> v . FunctionDef . args -> kw_defaults ); if ( ! symtable_visit_annotations ( st , s , s -> v . FunctionDef . args , // 5. s -> v . FunctionDef . returns )) VISIT_QUIT ( st , 0 ); if ( s -> v . FunctionDef . decorator_list ) // 6. VISIT_SEQ ( st , expr , s -> v . FunctionDef . decorator_list ); if ( ! symtable_enter_block ( st , s -> v . FunctionDef . name , // 7. FunctionBlock , ( void * ) s , s -> lineno , s -> col_offset )) VISIT_QUIT ( st , 0 ); VISIT ( st , arguments , s -> v . FunctionDef . args ); // 8. VISIT_SEQ ( st , stmt , s -> v . FunctionDef . body ); // 9. if ( ! symtable_exit_block ( st , s )) VISIT_QUIT ( st , 0 ); break ; case ClassDef_kind : { ... } case Return_kind : ... case Delete_kind : ... case Assign_kind : ... case AnnAssign_kind : ... Once the resulting symtable has been created, it is sent back to be used for the compiler.","title":"Symbol Tables"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-3-The-CPython-Compiler-and-Execution-Loop/#core-compilation-process","text":"Now that the PyAST_CompileObject() has a compiler state , a symtable , and a module in the form of the AST, the actual compilation can begin. The purpose of the core compiler is to: Convert the state, symtable, and AST into a Control-Flow-Graph (CFG) Protect the execution stage from runtime exceptions by catching any logic and code errors and raising them here You can call the CPython compiler in Python code by calling the built-in function compile() . It returns a code object instance: >>> co = compile ( 'b+1' , 'test.py' , mode = 'eval' ) < code object < module > at 0x10f222780 , file \"test.py\" , line 1 > The same as with the symtable() function, a simple expression should have a mode of 'eval' and a module, function, or class should have a mode of 'exec' . The compiled code can be found in the co_code property of the code object: >>> co.co_code b'e\\x00d\\x00\\x17\\x00S\\x00' There is also a dis module in the standard library, which disassembles the bytecode instructions and can print them on the screen or give you a list of Instruction instances. If you import dis and give the dis() function the code object\u2019s co_code property it disassembles it and prints the instructions on the REPL: >>> import dis >>> dis . dis ( co . co_code ) 0 LOAD_NAME 0 ( 0 ) 2 LOAD_CONST 0 ( 0 ) 4 BINARY_ADD 6 RETURN_VALUE LOAD_NAME , LOAD_CONST , BINARY_ADD , and RETURN_VALUE are all bytecode instructions. They\u2019re called bytecode because, in binary form, they were a byte long. However, since Python 3.6 the storage format was changed to a word , so now they\u2019re technically wordcode, not bytecode. The full list of bytecode instructions is available for each version of Python, and it does change between versions. For example, in Python 3.7, some new bytecode instructions were introduced to speed up execution of specific method calls. In an earlier section, we explored the instaviz package. This included a visualization of the code object type by running the compiler. It also displays the Bytecode operations inside the code objects. Execute instaviz again to see the code object and bytecode for a function defined on the REPL: >>> import instaviz >>> def example (): a = 1 b = a + 1 return b >>> instaviz . show ( example ) If we now jump into compiler_mod() , a function used to switch to different compiler functions depending on the module type . We\u2019ll assume that mod is a Module . The module is compiled into the compiler state and then assemble() is run to create a PyCodeObject . The new code object is returned back to PyAST_CompileObject() and sent on for execution: static PyCodeObject * compiler_mod ( struct compiler * c , mod_ty mod ) { PyCodeObject * co ; int addNone = 1 ; static PyObject * module ; ... switch ( mod -> kind ) { case Module_kind : if ( ! compiler_body ( c , mod -> v . Module . body )) { compiler_exit_scope ( c ); return 0 ; } break ; case Interactive_kind : ... case Expression_kind : ... case Suite_kind : ... ... co = assemble ( c , addNone ); compiler_exit_scope ( c ); return co ; } The compiler_body() function has some optimization flags and then loops over each statement in the module and visits it, similar to how the symtable functions worked: static int compiler_body ( struct compiler * c , asdl_seq * stmts ) { int i = 0 ; stmt_ty st ; PyObject * docstring ; ... for (; i < asdl_seq_LEN ( stmts ); i ++ ) VISIT ( c , stmt , ( stmt_ty ) asdl_seq_GET ( stmts , i )); return 1 ; } The statement type is determined through a call to the asdl_seq_GET() function, which looks at the AST node\u2019s type. Through some smart macros, VISIT calls a function in Python/compile.c for each statement type: #define VISIT(C, TYPE, V) {\\ if (!compiler_visit_ ## TYPE((C), (V))) \\ return 0; \\ } For a stmt (the category for a statement) the compiler will then drop into compiler_visit_stmt() and switch through all of the potential statement types found in Parser/Python.asdl : static int compiler_visit_stmt ( struct compiler * c , stmt_ty s ) { Py_ssize_t i , n ; /* Always assign a lineno to the next instruction for a stmt. */ c -> u -> u_lineno = s -> lineno ; c -> u -> u_col_offset = s -> col_offset ; c -> u -> u_lineno_set = 0 ; switch ( s -> kind ) { case FunctionDef_kind : return compiler_function ( c , s , 0 ); case ClassDef_kind : return compiler_class ( c , s ); ... case For_kind : return compiler_for ( c , s ); ... } return 1 ; } As an example, let\u2019s focus on the For statement, in Python is the: for i in iterable : # block else : # optional if iterable is False # block If the statement is a For type, it calls compiler_for() . There is an equivalent compiler_*() function for all of the statement and expression types. The more straightforward types create the bytecode instructions inline, some of the more complex statement types call other functions. Many of the statements can have sub-statements . A for loop has a body, but you can also have complex expressions in the assignment and the iterator. The compiler\u2019s compiler_ statements sends blocks to the compiler state . These blocks contain instructions, the instruction data structure in Python/compile.c has the opcode, any arguments, and the target block (if this is a jump instruction), it also contains the line number. For jump statements , they can either be absolute or relative jump statements. Jump statements are used to \u201cjump\u201d from one operation to another. Absolute jump statements specify the exact operation number in the compiled code object, whereas relative jump statements specify the jump target relative to another operation: struct instr { unsigned i_jabs : 1 ; unsigned i_jrel : 1 ; unsigned char i_opcode ; int i_oparg ; struct basicblock_ * i_target ; /* target block (if jump instruction) */ int i_lineno ; }; So a frame block (of type basicblock ), contains the following fields: A b_list pointer, the link to a list of blocks for the compiler state A list of instructions b_instr , with both the allocated list size b_ialloc , and the number used b_iused The next block after this one b_next Whether the block has been \u201cseen\u201d by the assembler when traversing depth-first If this block has a RETURN_VALUE opcode ( b_return ) The depth of the stack when this block was entered ( b_startdepth ) The instruction offset for the assembler typedef struct basicblock_ { /* Each basicblock in a compilation unit is linked via b_list in the reverse order that the block are allocated. b_list points to the next block, not to be confused with b_next, which is next by control flow. */ struct basicblock_ * b_list ; /* number of instructions used */ int b_iused ; /* length of instruction array (b_instr) */ int b_ialloc ; /* pointer to an array of instructions, initially NULL */ struct instr * b_instr ; /* If b_next is non-NULL, it is a pointer to the next block reached by normal control flow. */ struct basicblock_ * b_next ; /* b_seen is used to perform a DFS of basicblocks. */ unsigned b_seen : 1 ; /* b_return is true if a RETURN_VALUE opcode is inserted. */ unsigned b_return : 1 ; /* depth of stack upon entry of block, computed by stackdepth() */ int b_startdepth ; /* instruction offset for block, computed by assemble_jump_offsets() */ int b_offset ; } basicblock ; The For statement is somewhere in the middle in terms of complexity. There are 15 steps in the compilation of a For statement with the for in : syntax: Create a new code block called start , this allocates memory and creates a basicblock pointer Create a new code block called cleanup Create a new code block called end Push a frame block of type FOR_LOOP to the stack with start as the entry block and end as the exit block Visit the iterator expression, which adds any operations for the iterator Add the GET_ITER operation to the compiler state Switch to the start block Call ADDOP_JREL which calls compiler_addop_j() to add the FOR_ITER operation with an argument of the cleanup block Visit the target and add any special code, like tuple unpacking, to the start block Visit each statement in the body of the for loop Call ADDOP_JABS which calls compiler_addop_j() to add the JUMP_ABSOLUTE operation which indicates after the body is executed, jumps back to the start of the loop Move to the cleanup block Pop the FOR_LOOP frame block off the stack Visit the statements inside the else section of the for loop Use the end block Referring back to the basicblock structure. You can see how in the compilation of the for statement, the various blocks are created and pushed into the compiler\u2019s frame block and stack: static int compiler_for ( struct compiler * c , stmt_ty s ) { basicblock * start , * cleanup , * end ; start = compiler_new_block ( c ); // 1. cleanup = compiler_new_block ( c ); // 2. end = compiler_new_block ( c ); // 3. if ( start == NULL || end == NULL || cleanup == NULL ) return 0 ; if ( ! compiler_push_fblock ( c , FOR_LOOP , start , end )) // 4. return 0 ; VISIT ( c , expr , s -> v . For . iter ); // 5. ADDOP ( c , GET_ITER ); // 6. compiler_use_next_block ( c , start ); // 7. ADDOP_JREL ( c , FOR_ITER , cleanup ); // 8. VISIT ( c , expr , s -> v . For . target ); // 9. VISIT_SEQ ( c , stmt , s -> v . For . body ); // 10. ADDOP_JABS ( c , JUMP_ABSOLUTE , start ); // 11. compiler_use_next_block ( c , cleanup ); // 12. compiler_pop_fblock ( c , FOR_LOOP , start ); // 13. VISIT_SEQ ( c , stmt , s -> v . For . orelse ); // 14. compiler_use_next_block ( c , end ); // 15. return 1 ; } Depending on the type of operation, there are different arguments required. For example, we used ADDOP_JABS and ADDOP_JREL here, which refer to \u201c ADD O**peration with **J**ump to a **REL**ative position\u201d and \u201c**ADD **O**peration with **J**ump to an **ABS**olute position\u201d. This is referring to the APPOP_JREL and ADDOP_JABS macros which call compiler_addop_j(struct compiler *c, int opcode, basicblock *b, int absolute) and set the absolute argument to 0 and 1 respectively. There are some other macros, like ADDOP_I calls compiler_addop_i() which add an operation with an integer argument, or ADDOP_O calls compiler_addop_o() which adds an operation with a PyObject argument. Once these stages have completed, the compiler has a list of frame blocks, each containing a list of instructions and a pointer to the next block.","title":"Core Compilation Process"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-3-The-CPython-Compiler-and-Execution-Loop/#assembly","text":"With the compiler state, the assembler performs a \u201cdepth-first-search\u201d of the blocks and merge the instructions into a single bytecode sequence. The assembler state is declared in Python/compile.c : struct assembler { PyObject * a_bytecode ; /* string containing bytecode */ int a_offset ; /* offset into bytecode */ int a_nblocks ; /* number of reachable blocks */ basicblock ** a_postorder ; /* list of blocks in dfs postorder */ PyObject * a_lnotab ; /* string containing lnotab */ int a_lnotab_off ; /* offset into lnotab */ int a_lineno ; /* last lineno of emitted instruction */ int a_lineno_off ; /* bytecode offset of last lineno */ }; The assemble() function has a few tasks: Calculate the number of blocks for memory allocation Ensure that every block that falls off the end returns None , this is why every function returns None , whether or not a return statement exists Resolve any jump statements offsets that were marked as relative Call dfs() to perform a depth-first-search of the blocks Emit all the instructions to the compiler Call makecode() with the compiler state to generate the PyCodeObject static PyCodeObject * assemble ( struct compiler * c , int addNone ) { basicblock * b , * entryblock ; struct assembler a ; int i , j , nblocks ; PyCodeObject * co = NULL ; /* Make sure every block that falls off the end returns None. XXX NEXT_BLOCK() isn't quite right, because if the last block ends with a jump or return b_next shouldn't set. */ if ( ! c -> u -> u_curblock -> b_return ) { NEXT_BLOCK ( c ); if ( addNone ) ADDOP_LOAD_CONST ( c , Py_None ); ADDOP ( c , RETURN_VALUE ); } ... dfs ( c , entryblock , & a , nblocks ); /* Can't modify the bytecode after computing jump offsets. */ assemble_jump_offsets ( & a , c ); /* Emit code in reverse postorder from dfs. */ for ( i = a . a_nblocks - 1 ; i >= 0 ; i -- ) { b = a . a_postorder [ i ]; for ( j = 0 ; j < b -> b_iused ; j ++ ) if ( ! assemble_emit ( & a , & b -> b_instr [ j ])) goto error ; } ... co = makecode ( c , & a ); error : assemble_free ( & a ); return co ; } The depth-first-search is performed by the dfs() function in Python/compile.c , which follows the the b_next pointers in each of the blocks, marks them as seen by toggling b_seen and then adds them to the assemblers **a_postorder list in reverse order. The function loops back over the assembler\u2019s post-order list and for each block, if it has a jump operation, recursively call dfs() for that jump: static void dfs ( struct compiler * c , basicblock * b , struct assembler * a , int end ) { int i , j ; /* Get rid of recursion for normal control flow. Since the number of blocks is limited, unused space in a_postorder (from a_nblocks to end) can be used as a stack for still not ordered blocks. */ for ( j = end ; b && ! b -> b_seen ; b = b -> b_next ) { b -> b_seen = 1 ; assert ( a -> a_nblocks < j ); a -> a_postorder [ -- j ] = b ; } while ( j < end ) { b = a -> a_postorder [ j ++ ]; for ( i = 0 ; i < b -> b_iused ; i ++ ) { struct instr * instr = & b -> b_instr [ i ]; if ( instr -> i_jrel || instr -> i_jabs ) dfs ( c , instr -> i_target , a , j ); } assert ( a -> a_nblocks < j ); a -> a_postorder [ a -> a_nblocks ++ ] = b ; } }","title":"Assembly"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-3-The-CPython-Compiler-and-Execution-Loop/#creating-a-code-object","text":"The task of makecode() is to go through the compiler state, some of the assembler\u2019s properties and to put these into a PyCodeObject by calling PyCode_New() :","title":"Creating a Code Object"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-3-The-CPython-Compiler-and-Execution-Loop/#execution","text":"In Python/pythonrun.c we broke out just before the call to run_eval_code_obj() . This call takes a code object, either fetched from the marshaled .pyc file, or compiled through the AST and compiler stages. run_eval_code_obj() will pass the globals, locals, PyArena , and compiled PyCodeObject to PyEval_EvalCode() in Python/ceval.c . This stage forms the execution component of CPython. Each of the bytecode operations is taken and executed using a \u201cStack Frame\u201d based system . What is a Stack Frame? Stack Frames are a data type used by many runtimes, not just Python, that allows functions to be called and variables to be returned between functions. Stack Frames also contain arguments, local variables, and other state information. Typically, a Stack Frame exists for every function call, and they are stacked in sequence. You can see CPython\u2019s frame stack anytime an exception is unhandled and the stack is printed on the screen.","title":"Execution"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-4-Objects-in-CPython/","text":"","title":"Part 4 Objects in CPython"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/Part-5-The-CPython-Standard-Library/","text":"","title":"Part 5 The CPython Standard Library"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/note/","text":"\u7f16\u8bd1\u7684\u8fc7\u7a0b\u53ef\u4ee5\u770b\u505a\u662f\u4e0d\u65ad\u5730\u5c06\u6e90\u4ee3\u7801\u4f7f\u7528\u4e0d\u540c\u7684\u4e2d\u95f4\u8868\u793a\uff1a source code\u2192parse tree\u2192AST\u2192CFG\u2192byte code \u663e\u7136\uff0cpython\u7684\u7f16\u8bd1\u5355\u5143\u662fmodule\u3002","title":"Note"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/realpython-Your-Guide-to-the-CPython-Source-Code/","text":"Your Guide to the CPython Source Code Part 4: Objects in CPython Part 5: The CPython Standard Library The CPython Source Code: Conclusion Your Guide to the CPython Source Code Part 4: Objects in CPython CPython comes with a collection of basic types like strings, lists, tuples, dictionaries, and objects. All of these types are built-in. You don\u2019t need to import any libraries, even from the standard library. Also, the instantiation of these built-in types has some handy shortcuts. Part 5: The CPython Standard Library The CPython Source Code: Conclusion","title":"realpython Your Guide to the CPython Source Code"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/realpython-Your-Guide-to-the-CPython-Source-Code/#your-guide-to-the-cpython-source-code","text":"","title":"Your Guide to the CPython Source Code"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/realpython-Your-Guide-to-the-CPython-Source-Code/#part-4-objects-in-cpython","text":"CPython comes with a collection of basic types like strings, lists, tuples, dictionaries, and objects. All of these types are built-in. You don\u2019t need to import any libraries, even from the standard library. Also, the instantiation of these built-in types has some handy shortcuts.","title":"Part 4: Objects in CPython"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/realpython-Your-Guide-to-the-CPython-Source-Code/#part-5-the-cpython-standard-library","text":"","title":"Part 5: The CPython Standard Library"},{"location":"Python/Language/Developer's-guide/Your-Guide-to-the-CPython-Source-Code/realpython-Your-Guide-to-the-CPython-Source-Code/#the-cpython-source-code-conclusion","text":"","title":"The CPython Source Code: Conclusion"},{"location":"Python/Language/Developer's-guide/book-Inside-The-Python-Virtual-Machine/book-Inside-The-Python-Virtual-Machine/","text":"Inside The Python Virtual Machine","title":"[Inside The Python Virtual Machine](https://leanpub.com/insidethepythonvirtualmachine/read)"},{"location":"Python/Language/Developer's-guide/book-Inside-The-Python-Virtual-Machine/book-Inside-The-Python-Virtual-Machine/#inside-the-python-virtual-machine","text":"","title":"Inside The Python Virtual Machine"},{"location":"Python/Language/Language-reference/","text":"\u5173\u4e8e\u672c\u7ae0 grammar \u76f8\u5f53\u4e8ecompiler\u7684\u524d\u7aef \u81ea\u5e95\u5411\u4e0a\u7684\u65b9\u5f0f\u6765\u603b\u7ed3 \u8bcd\u6cd5\uff1a Identifiers and keywords Literals \u8bed\u6cd5\uff1a Expressions statements Simple statements Compound statements \u8bed\u4e49 module package run model data model execution model","title":"Introduction"},{"location":"Python/Language/Language-reference/#_1","text":"","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Python/Language/Language-reference/#grammar","text":"\u76f8\u5f53\u4e8ecompiler\u7684\u524d\u7aef \u81ea\u5e95\u5411\u4e0a\u7684\u65b9\u5f0f\u6765\u603b\u7ed3 \u8bcd\u6cd5\uff1a Identifiers and keywords Literals \u8bed\u6cd5\uff1a Expressions statements Simple statements Compound statements \u8bed\u4e49 module package","title":"grammar"},{"location":"Python/Language/Language-reference/#run-model","text":"data model execution model","title":"run model"},{"location":"Python/Language/Language-reference/Attribute-namepsace-lookcup/","text":"Attribute Attribute references \u00b6 exception AttributeError \u00b6 attribute \u4eceexpression \u5230 attribute \u5230 lookup\uff0c\u4ececompile time \u5230 runtime\u3002 namespace namespace","title":"Attribute namepsace lookcup"},{"location":"Python/Language/Language-reference/Attribute-namepsace-lookcup/#attribute","text":"Attribute references \u00b6 exception AttributeError \u00b6 attribute \u4eceexpression \u5230 attribute \u5230 lookup\uff0c\u4ececompile time \u5230 runtime\u3002","title":"Attribute"},{"location":"Python/Language/Language-reference/Attribute-namepsace-lookcup/#namespace","text":"namespace","title":"namespace"},{"location":"Python/Language/Language-reference/Data-model/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u662f\u9605\u8bfb3. Data model \u00b6 \u7684\u7b14\u8bb0\u3002","title":"Introduction"},{"location":"Python/Language/Language-reference/Data-model/#_1","text":"\u672c\u7ae0\u662f\u9605\u8bfb3. Data model \u00b6 \u7684\u7b14\u8bb0\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Python/Language/Language-reference/Data-model/Coroutines/","text":"","title":"Coroutines"},{"location":"Python/Language/Language-reference/Data-model/Special-attribute-names/","text":"Special Attributes python object\u6709\u4e00\u4e9b\u7279\u6b8a\u7684attribute\uff0c\u5b83\u4eec\u662f\u6211\u4eec\u9700\u8981\u4e86\u89e3\u7684\u3002 Special Attributes \u00b6 instance.__class__ \u00b6 \u5b83\u7684\u7c7b\u578b\u662f Custom classes \u3002 object.__dict__ \u00b6","title":"Special-attribute-names"},{"location":"Python/Language/Language-reference/Data-model/Special-attribute-names/#special-attributes","text":"python object\u6709\u4e00\u4e9b\u7279\u6b8a\u7684attribute\uff0c\u5b83\u4eec\u662f\u6211\u4eec\u9700\u8981\u4e86\u89e3\u7684\u3002","title":"Special Attributes"},{"location":"Python/Language/Language-reference/Data-model/Special-attribute-names/#special-attributes_1","text":"","title":"Special Attributes\u00b6"},{"location":"Python/Language/Language-reference/Data-model/Special-attribute-names/#instance__class__","text":"\u5b83\u7684\u7c7b\u578b\u662f Custom classes \u3002","title":"instance.__class__\u00b6"},{"location":"Python/Language/Language-reference/Data-model/Special-attribute-names/#object__dict__","text":"","title":"object.__dict__\u00b6"},{"location":"Python/Language/Language-reference/Data-model/Special-method-names/","text":"3.3. Special method names \u00b6 \u539f\u6587\u7684\u5185\u5bb9\u6bd4\u8f83\u5197\u957f\uff0c\u68c0\u7d22\u8d77\u6765\u4e0d\u4fbf\uff0c\u672c\u6587\u662f\u5bf9\u5176\u7684\u4e00\u4e2a\u603b\u7ed3\uff0c\u53ef\u4ee5\u4f5c\u4e3ashortcut\u3002 3.3.1. Basic customization \u00b6 \u540d\u79f0 object.__new__(cls[, ...]) \u00b6 object.__init__(self[, ...]) \u00b6 object.__del__(self) \u00b6 object.__repr__(self) \u00b6 object.__str__(self) \u00b6 object.__bytes__(self) \u00b6 object.__format__(self, format_spec) \u00b6 object.__lt__(self, other) \u00b6 object.__le__(self, other) \u00b6 object.__eq__(self, other) \u00b6 object.__ne__(self, other) \u00b6 object.__gt__(self, other) \u00b6 object.__ge__(self, other) \u00b6 object.__hash__(self) \u00b6 object.__bool__(self) \u00b6 3.3.2. Customizing attribute access \u00b6 3.3.3. Customizing class creation \u00b6 3.3.4. Customizing instance and subclass checks \u00b6 3.3.5. Emulating generic types \u00b6 3.3.6. Emulating callable objects \u00b6 3.3.7. Emulating container types \u00b6 \u540d\u79f0 \u7f51\u7edc\u8d44\u6e90 \u4f8b\u5b50 object.__contains__(self, item) \u00b6 Called to implement membership test operators\uff08\u5982 in \uff09. - Functionality of Python in vs. __contains__ - https://www.oreilly.com/library/view/python-in-a/0596001886/re16.html 3.3.8. Emulating numeric types \u00b6 \u8fd9\u662f\u6700\u6700\u7b80\u5355\u7684\u3002 3.3.9. With Statement Context Managers \u00b6","title":"Special-method-names"},{"location":"Python/Language/Language-reference/Data-model/Special-method-names/#33-special-method-names","text":"\u539f\u6587\u7684\u5185\u5bb9\u6bd4\u8f83\u5197\u957f\uff0c\u68c0\u7d22\u8d77\u6765\u4e0d\u4fbf\uff0c\u672c\u6587\u662f\u5bf9\u5176\u7684\u4e00\u4e2a\u603b\u7ed3\uff0c\u53ef\u4ee5\u4f5c\u4e3ashortcut\u3002","title":"3.3. Special method names\u00b6"},{"location":"Python/Language/Language-reference/Data-model/Special-method-names/#331-basic-customization","text":"\u540d\u79f0 object.__new__(cls[, ...]) \u00b6 object.__init__(self[, ...]) \u00b6 object.__del__(self) \u00b6 object.__repr__(self) \u00b6 object.__str__(self) \u00b6 object.__bytes__(self) \u00b6 object.__format__(self, format_spec) \u00b6 object.__lt__(self, other) \u00b6 object.__le__(self, other) \u00b6 object.__eq__(self, other) \u00b6 object.__ne__(self, other) \u00b6 object.__gt__(self, other) \u00b6 object.__ge__(self, other) \u00b6 object.__hash__(self) \u00b6 object.__bool__(self) \u00b6","title":"3.3.1. Basic customization\u00b6"},{"location":"Python/Language/Language-reference/Data-model/Special-method-names/#332-customizing-attribute-access","text":"","title":"3.3.2. Customizing attribute access\u00b6"},{"location":"Python/Language/Language-reference/Data-model/Special-method-names/#333-customizing-class-creation","text":"","title":"3.3.3. Customizing class creation\u00b6"},{"location":"Python/Language/Language-reference/Data-model/Special-method-names/#334-customizing-instance-and-subclass-checks","text":"","title":"3.3.4. Customizing instance and subclass checks\u00b6"},{"location":"Python/Language/Language-reference/Data-model/Special-method-names/#335-emulating-generic-types","text":"","title":"3.3.5. Emulating generic types\u00b6"},{"location":"Python/Language/Language-reference/Data-model/Special-method-names/#336-emulating-callable-objects","text":"","title":"3.3.6. Emulating callable objects\u00b6"},{"location":"Python/Language/Language-reference/Data-model/Special-method-names/#337-emulating-container-types","text":"\u540d\u79f0 \u7f51\u7edc\u8d44\u6e90 \u4f8b\u5b50 object.__contains__(self, item) \u00b6 Called to implement membership test operators\uff08\u5982 in \uff09. - Functionality of Python in vs. __contains__ - https://www.oreilly.com/library/view/python-in-a/0596001886/re16.html","title":"3.3.7. Emulating container types\u00b6"},{"location":"Python/Language/Language-reference/Data-model/Special-method-names/#338-emulating-numeric-types","text":"\u8fd9\u662f\u6700\u6700\u7b80\u5355\u7684\u3002","title":"3.3.8. Emulating numeric types\u00b6"},{"location":"Python/Language/Language-reference/Data-model/Special-method-names/#339-with-statement-context-managers","text":"","title":"3.3.9. With Statement Context Managers\u00b6"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/","text":"3.2. The standard type hierarchy \u00b6 None NotImplemented Ellipsis numbers.Number numbers.Integral Integers ( int ) Booleans ( bool ) numbers.Real ( float ) numbers.Complex ( complex ) Sequences Immutable sequences Strings Tuples Bytes Mutable sequences Lists Byte Arrays Set types Sets Frozen sets Mappings Dictionaries Callable types User-defined functions Instance methods Generator functions Coroutine functions Asynchronous generator functions Built-in functions Built-in methods Classes Class Instances Modules Custom classes Class instances I/O objects (also known as file objects) Internal types Code objects Frame objects Traceback objects Slice objects Static method objects Class method objects","title":"The-standard-type-hierarchy"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#32-the-standard-type-hierarchy","text":"","title":"3.2. The standard type hierarchy\u00b6"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#none","text":"","title":"None"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#notimplemented","text":"","title":"NotImplemented"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#ellipsis","text":"","title":"Ellipsis"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#numbersnumber","text":"","title":"numbers.Number"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#numbersintegral","text":"Integers ( int ) Booleans ( bool )","title":"numbers.Integral"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#numbersreal-float","text":"","title":"numbers.Real (float)"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#numberscomplex-complex","text":"","title":"numbers.Complex (complex)"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#sequences","text":"","title":"Sequences"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#immutable-sequences","text":"","title":"Immutable sequences"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#strings","text":"","title":"Strings"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#tuples","text":"","title":"Tuples"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#bytes","text":"","title":"Bytes"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#mutable-sequences","text":"","title":"Mutable sequences"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#lists","text":"","title":"Lists"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#byte-arrays","text":"","title":"Byte Arrays"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#set-types","text":"","title":"Set types"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#sets","text":"","title":"Sets"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#frozen-sets","text":"","title":"Frozen sets"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#mappings","text":"","title":"Mappings"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#dictionaries","text":"","title":"Dictionaries"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#callable-types","text":"","title":"Callable types"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#user-defined-functions","text":"","title":"User-defined functions"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#instance-methods","text":"","title":"Instance methods"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#generator-functions","text":"","title":"Generator functions"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#coroutine-functions","text":"","title":"Coroutine functions"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#asynchronous-generator-functions","text":"","title":"Asynchronous generator functions"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#built-in-functions","text":"","title":"Built-in functions"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#built-in-methods","text":"","title":"Built-in methods"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#classes","text":"","title":"Classes"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#class-instances","text":"","title":"Class Instances"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#modules","text":"","title":"Modules"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#custom-classes","text":"","title":"Custom classes"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#class-instances_1","text":"","title":"Class instances"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#io-objects-also-known-as-file-objects","text":"","title":"I/O objects (also known as file objects)"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#internal-types","text":"","title":"Internal types"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#code-objects","text":"","title":"Code objects"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#frame-objects","text":"","title":"Frame objects"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#traceback-objects","text":"","title":"Traceback objects"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#slice-objects","text":"","title":"Slice objects"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#static-method-objects","text":"","title":"Static method objects"},{"location":"Python/Language/Language-reference/Data-model/The-standard-type-hierarchy/#class-method-objects","text":"","title":"Class method objects"},{"location":"Python/Language/Language-reference/Execution-model/Execution-model/","text":"Execution model \u00b6 4.1. Structure of a program NOTE: \u8fd9\u624d\u662f\u6838\u5fc3\u6240\u5728\uff0c\u540e\u7eed\u7684\u5f88\u591a\u6982\u5ff5\u90fd\u662f\u57fa\u4e8e\u6b64\u800c\u521b\u5efa\u7684\uff1b A Python program is constructed from code blocks . A block is a piece of Python program text that is executed as a unit \uff08\u5355\u4f4d\uff09. The following are blocks: a module\uff08the top-level code block \uff09 ,a function body and a class definition (\u6267\u884cclass definition\u7684\u7ed3\u679c\u662f\u521b\u5efa\u4e86\u8fd9\u4e2aclass). Each command typed interactively is a block . A script file (a file given as standard input to the interpreter or specified as a command line argument to the interpreter) is a code block . A script command (a command specified on the interpreter command line with the \u2018 -c \u2019 option) is a code block . The string argument passed to the built-in functions eval() and exec() is a code block. A code block is executed in an execution frame . A frame contains some administrative information (used for debugging) and determines where and how execution continues after the code block\u2019s execution has completed. NOTE: python interpreter\u5bf9code block\u7684\u5224\u65ad\u5e94\u8be5\u4f1a\u53d7level of indentation\u7684\u5f71\u54cd\uff0c\u5173\u4e8epython interpreter\u662f\u5982\u4f55\u6765\u5224\u65adlevel of indentation\uff0c\u53c2\u8003 https://docs.python.org/3/reference/lexical_analysis.html#indentation NOTE: \u4e0a\u9762\u8fd9\u6bb5\u4e2d\u63d0\u53ca\u4e86\u5404\u79cd\u5404\u6837\u7684code block\uff0c\u5728python\u4e2d\uff0c\u90fd\u6709\u5bf9\u5e94\u7684standard type\u6765\u63cf\u8ff0\u5b83\u4eec\uff1b\u6bd4\u5982module\u5bf9\u5e94\u7684\u5c31\u662fpython\u7684 standard type hierarchy \u4e2d\u7684Modules NOTE: **execution frame**\u662fpython\u7684 standard type hierarchy \u4e2d\u4e3aInternal types\u4e2d\u7684Frame objects\uff1b\u8fd9\u8ba9\u6211\u60f3\u8d77\u6765 call stack \uff0c stack frame \uff1b\u663e\u7136python\u4e2d\u7684execution frame\u662f\u7531python\u89e3\u91ca\u5668\u6765\u8fdb\u884c\u7ef4\u62a4\uff0c\u5bf9\u4e8e\u7f16\u8bd1\u578b\u8bed\u8a00\uff0c\u5219\u6709OS\u6765\u8fdb\u884c\u7ef4\u62a4\uff1b NOTE: \u9700\u8981\u533a\u5206**code block**\u548c**callable**\uff08\u5728 standard type hierarchy \u7ed9\u51fa\u7684\u5b9a\u4e49\uff09\uff1bcallable\u7684\u5b9a\u4e49\u662f\u6307\uff1a types to which the function call operation (see section Calls ) can be applied\uff1b\u663e\u7136module\u4e0d\u662fcallable\uff0c\u6240\u4ee5code block\u4e0d\u662fcallable\uff1b\u8fd9\u91cc\u6307\u51facode block\u662f\u6307python program\u7684structure\uff0c\u4e5f\u5c31\u662f\u6211\u4eec\u5728\u7f16\u5199python program\u7684\u65f6\u5019\uff0c\u5f80\u5f80\u4f1a\u521b\u5efa\u4e00\u4e2amodule\uff0c\u7136\u540e\u5728module\u4e2d\u5b9a\u4e49function\uff0c\u5b9a\u4e49class\uff1b\u7136\u540e\u6211\u4eec\u4f7f\u7528python interpreter\u6765execute module\uff0c\u8fd9\u624d\u662f\u6700\u540e\u4e00\u6bb5\u8bdd\u4e2dA code block is executed in an *execution frame*\u7684\u542b\u4e49\uff1b\u4e0e\u6b64\u7c7b\u4f3c\u7684\u662f\uff0cpython interpreter\u8fd8\u53ef\u4ee5execute class\uff0cfunction\uff0c\u663e\u7136python interpreter execute class\u7684\u7ed3\u679c\u662f\u5b9a\u4e49\u4e86\u4e00\u4e2aclass\uff1b\u5bf9\u4e00\u4e2aclass\u6267\u884ccall operation\u7684\u7ed3\u679c\u662f\u521b\u5efa\u4e00\u4e2ainstance\uff0c\u5bf9\u4e00\u4e2afunction\u6267\u884ccall operation\u7684\u7ed3\u679c\u662fexecute\u8fd9\u4e2afunction\u7684function body\uff1b TODO: see also : https://docs.python.org/2.0/ref/execframes.html 4.2. Naming and binding 4.2.1. Binding of names Names refer to objects. Names are introduced by name binding operations . NOTE\uff1apython\u4e2d\u4e00\u5207\u7686\u5bf9\u8c61\uff0c\u5e76\u4e14python\u662f\u901a\u8fc7name\u6765access\u5bf9\u8c61\u7684\u3002\u90a3\u8fd9\u6bb5\u4e2d\u7684name\u7684\u542b\u4e49\u5230\u5e95\u662f\u4ec0\u4e48\u5462\uff1fname\u5c31\u662fidentifier\u5417\uff1f\u6839\u636eWikipedia\u4e0a\u7684\u5173\u4e8ename binding\u7684\u89e3\u91ca\uff0c\u53ef\u4ee5\u63a8\u6d4bname\u53ef\u4ee5\u7406\u89e3\u4e3aidentifier\uff1b\u5728youdao 20181030\u4e2d\u6536\u5f55\u4e86name binding\u3002\u5e76\u4e14\u57286.2.1. Identifiers (Names) \u00b6 \u4e2d\u4e5f\u5c06name\u548cidentifier\u89c6\u4e3a\u540c\u4e49\u8bcd\uff1b NOTE\uff1a\u663e\u7136name-binding\u662f\u53d1\u751f\u5728runtime\uff0c\u53ea\u6709\u5f53program runtime\uff0c\u624d\u80fd\u591f\u77e5\u9053name\u5230\u5e95bind\u5230\u54ea\u4e2aobject\u3002 NOTE : \u4e0d\u540c\u7684programming language\u4e2d\u5bf9name\u7684\u5904\u7406\u65b9\u5f0f\u662f\u4e0d\u540c\u7684\uff0c\u663e\u7136python\u4e2dname\u548c c++ \u4e2d\u7684name\u662f\u622a\u7136\u4e0d\u540c\u7684\uff1b The following constructs bind names: formal parameters to functions\uff08\u51fd\u6570\u5f62\u53c2\uff09 import statements class and function definitions (these bind the class or function name in the defining block) targets that are identifiers if occurring in an assignment for loop header after as in a with statement or except clause. The import statement of the form from ... import * binds all names defined in the imported module, except those beginning with an underscore. This form may only be used at the module level\uff08\u5173\u4e8e\u8fd9\u4e00\u70b9\uff0c\u53c2\u8003Reserved classes of identifiers \u00b6 \uff09. NOTE\uff1a\u56e0\u4e3apython\u4e2d\u4e00\u5207\u7686\u5bf9\u8c61\uff0c\u6240\u4ee5programmer\u6240\u5b9a\u4e49\u7684\u7c7b\uff0c\u4e5f\u662f\u7528\u4e00\u4e2a\u5bf9\u8c61\u6765\u8868\u793a\u8be5\u7c7b\u7684\u3002\u663e\u7136\u5728python\u4e2d\uff0c\u53ea\u6709\u901a\u8fc7\u4e0a\u9762\u8fd9\u6bb5\u4e2d\u6240\u63cf\u8ff0\u7684\u65b9\u5f0f\u540e\uff0cprogrammer\u624d\u80fd\u591f\u901a\u8fc7\u7c7b\u540d\u6765reference\u8868\u793a\u8be5\u7c7b\u7684object\u3002\u663e\u7136\u8fd9\u548c\u7f16\u8bd1\u578b\u8bed\u8a00\u662f\u4e0d\u540c\u7684\u3002 NOTE: \u7406\u89e3python\u7684binding of names\u662f\u7406\u89e3python\u7684function pass by sharing\u7684\u524d\u63d0\uff0c\u8fd9\u4e2a\u95ee\u9898\u5728function\u7ae0\u8282\u6709\u4e13\u95e8\u7684\u4ecb\u7ecd\uff1b\u663e\u7136\u5b83\u5c5e\u4e8e\u4e0a\u9762\u6240\u5217\u7684\u7b2c\u4e00\u79cd\u60c5\u51b5\uff1aformal parameters to functions\u3002 A target occurring in a del statement is also considered bound for this purpose (though the actual semantics are to unbind the name). Each assignment or import statement occurs within a block defined by a class or function definition or at the module level (the top-level code block ). SUMMARY :\u5176\u5b9e\u4e3b\u8981\u4e5f\u5c31\u8fd9\u4e09\u79cdcode block\uff1b If a name is bound in a block, it is a local variable of that block, unless declared as nonlocal or global . If a name is bound at the module level, it is a global variable . (The variables of the module code block are local and global.) If a variable is used in a code block but not defined there, it is a free variable . SUMMARY \uff1a\u4e0a\u9762\u8fd9\u6bb5\u4e2d\u7684**bound**\u7684\u542b\u4e49\u662f\u8be5name\u6240\u5bf9\u5e94\u7684object\u5728\u8be5block\u4e2d\u88ab\u521b\u5efa\u7684\u3002 SUMMARY : free variable\u5728Wikipedia\u7684 Closure (computer programming) \u4e2d\u6709\u4ecb\u7ecd\uff0cpython\u4e2d\u51fa\u73b0**free variable**\u7684\u573a\u666fdecorator\uff0c\u5d4c\u5957\u51fd\u6570\u5b9a\u4e49\uff1b SUMMARY \uff1a\u4e0a\u9762\u8fd9\u6bb5\u5173\u4e8efree variable\u7684\u63cf\u8ff0\u662f\u975e\u5e38\u6a21\u7cca\u7684\uff0c\u4e0b\u9762\u8fd9\u6bb5\u662f\u6458\u81eaWikipedia\u4e2d Free variables and bound variables \u4e2d\u5173\u4e8eFree variables\u7684\u89e3\u91ca\uff1a In computer programming , the term free variable refers to variables used in a function that are neither local variables nor parameters of that function. The term non-local variable is often a synonym in this context. A bound variable is a variable that was previously free , but has been bound to a specific value or set of values called domain of discourse or universe . SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u4ecb\u7ecd\u4e86python\u4e2d\u7684\u4e09\u79cdvariable\uff1b\u5176\u5b9e\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e5f\u4f53\u73b0\u4e86python\u4e2d\u7684name\u548cvariable\u4e4b\u95f4\u7684\u5173\u7cfb\uff1aname refer to object\uff0c\u90a3\u4e48\u5bf9\u5e94\u7684object\u5c31\u662fvariable\uff1b Each occurrence of a name in the program text refers to the binding of that name established by the following name resolution rules(\u7a0b\u5e8f\u6587\u672c\u4e2d\u6bcf\u6b21\u51fa\u73b0\u7684\u540d\u79f0\u90fd\u662f\u6307\u7531\u4ee5\u4e0b\u540d\u79f0\u89e3\u6790\u89c4\u5219\u5efa\u7acb\u7684\u540d\u79f0\u7684\u7ed1\u5b9a). SUMMARY : \u9006\u5411\u601d\u7ef4\uff1aname\u5982\u679c\u6ca1\u6709bound\uff0c\u90a3\u4f1a\u53d1\u751f\u4ec0\u4e48\uff1f\u4e0e\u6b64\u76f8\u5173\u7684\u662f UnboundLocalError \u3002 4.2.2. Resolution of names A scope defines the visibility of a name within a block (scope\u5b9a\u4e49\u4e86\u5728\u4e00\u4e2ablock\u4e2d\uff0cname\u7684visibility). If a local variable is defined in a block, its scope includes that block\uff08\u4e5f\u5c31\u662f\u8be5block\u4e2d\u7684\u5176\u4ed6\u5730\u65b9\u662f\u53ef\u4ee5\u770b\u5230\u8be5variable\u7684\uff09. If the definition occurs in a function block , the scope extends to any blocks contained within the defining one, unless a contained block introduces a different binding for the name. SUMMARY \uff1a\u5173\u4e8escope\uff0c\u5728compiler principle\u8fd9\u672c\u4e66\u4e2d\u8fdb\u884c\u4e86\u975e\u5e38\u597d\u7684\u63cf\u8ff0\uff1b SUMMARY \uff1a\u4e0a\u9762\u4ec5\u4ec5\u7ed9\u51fa\u4e86*scope*\u7684\u542b\u4e49\uff0c\u4f46\u662f\u5e76\u6ca1\u6709\u7ed9\u51fa*scope*\u7684\u5177\u4f53\u7684\u754c\u5b9a\u65b9\u6cd5\u3002python\u4e2d\u7684*scope*\u7684\u754c\u5b9a\u65b9\u6cd5\u662f\u4ec0\u4e48\u5462\uff1f\u53c2\u89c1 Python Scopes and Namespaces SUMMARY : \u6ce8\u610f\uff0cfunction\u7684scope\u89c4\u5219\uff0c\u5373the scope extends to any blocks contained within the defining one\uff0c\u975e\u5e38\u6709\u5229\u4e8epython\u4e2d\u5d4c\u5957\u51fd\u6570\u7684\u4f7f\u7528\uff1b When a name is used in a code block, it is resolved using the nearest enclosing scope . The set of all such scopes visible to a code block is called the block\u2019s environment . SUMMARY : every block \u6709\u5bf9\u5e94\u7684environment\uff0cnamespace\uff08\u5bf9\u5e94\u7684\u5c31\u662f __dict__ \uff09\uff1b When a name is not found at all, a NameError exception is raised. If the current scope is a function scope, and the name refers to a local variable that has not yet been bound to a value at the point where the name is used, an UnboundLocalError exception is raised. UnboundLocalError is a subclass of NameError . THINKING : \u4f55\u65f6\u4f1a\u53d1\u751f UnboundLocalError \uff1f\u5728build-in exception\u7ae0\u8282\u6709\u4e13\u95e8\u603b\u7ed3\uff1b If a name binding operation occurs anywhere within a code block, all uses of the name within the block are treated as references to the current block \uff08\u8fd9\u662f\u975e\u5e38\u7b26\u5408\u5e38\u8bc6\u7684\uff09. This can lead to errors when a name is used within a block before it is bound. This rule is subtle. Python lacks declarations and allows name binding operations to occur anywhere within a code block. The local variables of a code block can be determined by scanning the entire text of the block for name binding operations . SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\uff0c\u63d0\u53ca\u5230\u4e86python\u7684\u4e00\u4e2a\u663e\u8457\u7279\u5f81\uff1apython lacks declaration\uff0c\u8fd9\u662fpython\u548c c++ \u7684\u4e00\u4e2a\u663e\u8457\u5dee\u5f02\uff1b If the global statement occurs within a block, all uses of the name specified in the statement refer to the binding of that name in the top-level namespace . Names are resolved in the top-level namespace by searching the global namespace , i.e. the namespace of the module containing the code block, and the builtins namespace, the namespace of the module builtins . The global namespace is searched first. If the name is not found there, the builtins namespace is searched. The global statement must precede all uses of the name. The global statement has the same scope as a name binding operation in the same block. If the nearest enclosing scope for a free variable contains a global statement , the free variable is treated as a global. The nonlocal statement causes corresponding names to refer to previously bound variables in the nearest enclosing function scope. SyntaxError is raised at compile time if the given name does not exist in any enclosing function scope. The namespace for a module is automatically created the first time a module is imported. The main module for a script is always called __main__ . Class definition blocks and arguments to exec() and eval() are special in the context of name resolution. A class definition is an executable statement that may use and define names. These references follow the normal rules for name resolution with an exception that unbound local variables are looked up in the global namespace\uff08\u4e0efunction block\u6709\u5f02\uff09. The namespace of the class definition becomes the attribute dictionary of the class. The scope of names defined in a class block is limited to the class block ; it does not extend to the code blocks of methods \u2013 this includes comprehensions and generator expressions since they are implemented using a function scope \uff08\u4e0efunction block\u6709\u5f02\uff09. This means that the following will fail: class A : a = 42 b = list ( a + i for i in range ( 10 )) SUMMARY : \u6ce8\u610fclass block\u548cfunction block\u4e4b\u95f4\u7684\u5dee\u5f02\u6240\u5728\uff1a SUMMARY : comprehension\u548cgenerator\u57286. Expressions \u00b6 \u4e2d\u6709\u4e13\u95e8\u4ecb\u7ecd\uff1b SUMMARY : resolution of name\u4e3b\u8981\u63cf\u8ff0\u7684\u662f\u5982\u4f55\u627e\u5230name\u6240refer\u7684object\uff1b\u5bf9\u4e8e\u4e00\u4e2a\u5df2\u7ecfbind\u7684name\uff0c\u90a3\u4e48\u5728\u540e\u7eed\u4f7f\u7528\u4e2dpython\u89e3\u91ca\u5668\u5c31\u9700\u8981\u8003\u8651\u7684\u4e00\u4e2a\u95ee\u9898\u662f\u5982\u4f55\u5bf9\u8fd9\u4e2aname\u8fdb\u884cresolve\uff0c\u5373\u627e\u5230\u8fd9\u4e2aname\u6240refer\u7684object\uff1b\u663e\u7136\u8fd9\u5c31\u6d89\u53ca\u5230\u4e86scope\uff0c\u6d89\u53ca\u5230\u4e86namespace\uff0c\u4e3a\u6b64python interpreter\u5b9a\u4e49\u4e86\u4e00\u7cfb\u5217\u7684\u89c4\u5219\uff1b 4.2.3. Builtins and restricted execution CPython implementation detail: Users should not touch __builtins__ ; it is strictly an implementation detail. Users wanting to override values in the builtins namespace should import the builtins module and modify its attributes appropriately. The builtins namespace associated with the execution of a code block is actually found by looking up the name __builtins__ in its global namespace ; this should be a dictionary or a module (in the latter case the module\u2019s dictionary is used). By default, when in the __main__ module, __builtins__ is the built-in module builtins ; when in any other module, __builtins__ is an alias for the dictionary of the builtins module itself. 4.2.4. Interaction with dynamic features Name resolution of free variables occurs at runtime, not at compile time. This means that the following code will print 42: i = 10 def f (): print ( i ) i = 42 f () SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u4ee3\u7801\u7684\u7740\u91cd\u70b9\u662f\u8868\u8fbe\u5f53\u8c03\u7528 f() \u7684\u65f6\u5019\uff0c\u6253\u5370\u7684\u662f\u6700\u540e\u4e00\u6b21 i \u7684\u503c\uff1b SUMMARY : \u5982\u679c\u5c06\u4e0a\u8ff0\u4ee3\u7801\u4fee\u6539\u4e3a\u5982\u4e0b\uff1a def f (): i += 1 print ( i ) \u5219\u4f1a\u629b\u51fa\u5982\u4e0b\u5f02\u5e38\uff1a UnboundLocalError: local variable 'i' referenced before assignment \u4e3a\u4ec0\u4e48\u7b2c\u4e00\u4e2a\u6ca1\u6709\u62a5\u9519\uff1f \u8fd9\u79cd\u65b9\u5f0f\u662f\u6b63\u5e38\u7684\uff1a def f (): global i i += 1 print ( i ) \u663e\u7136\uff0c\u8fd9\u4e2a\u95ee\u9898\u6d89\u53ca\u5230\u4e86python\u4e2d\u7684free variable\uff0c\u8fd8\u6d89\u53ca\u5230\u4e86python\u7684runtime\u548ccompile time\uff1b The eval() and exec() functions do not have access to the full environment for resolving names. Names may be resolved in the local and global namespaces of the caller. Free variables are not resolved in the nearest enclosing namespace, but in the global namespace. [ 1] The exec() and eval() functions have optional arguments to override the global and local namespace. If only one namespace is specified, it is used for both. 4.3. Exceptions Exceptions are a means of breaking out of the normal flow of control of a code block in order to handle errors or other exceptional conditions. An exception is raised at the point where the error is detected; it may be handled by the surrounding code block or by any code block that directly or indirectly invoked the code block where the error occurred. The Python interpreter raises an exception when it detects a run-time error (such as division by zero). A Python program can also explicitly raise an exception with the raise statement. Exception handlers are specified with the try \u2026 except statement. The finally clause of such a statement can be used to specify cleanup code which does not handle the exception, but is executed whether an exception occurred or not in the preceding code. Python uses the \u201ctermination\u201d model of error handling: an exception handler can find out what happened and continue execution at an outer level, but it cannot repair the cause of the error and retry the failing operation (except by re-entering the offending piece of code from the top). When an exception is not handled at all, the interpreter terminates execution of the program, or returns to its interactive main loop. In either case, it prints a stack backtrace , except when the exception is SystemExit . SUMMARY : \u5173\u4e8estack backtrace\uff0c\u5728python\u7684 standard type hierarchy \u4e2d\u4e3aInternal types\u4e2d\u7684Traceback objects\uff1b Exceptions are identified by class instances. The except clause is selected depending on the class of the instance: it must reference the class of the instance or a base class thereof. The instance can be received by the handler and can carry additional information about the exceptional condition. Note :Exception messages are not part of the Python API. Their contents may change from one version of Python to the next without warning and should not be relied on by code which will run under multiple versions of the interpreter. See also the description of the try statement in section The try statement and raise statement in section The raise statement . Footnotes [ 1] This limitation occurs because the code that is executed by these operations is not available at the time the module is compiled.","title":"Execution-model"},{"location":"Python/Language/Language-reference/Execution-model/Execution-model/#execution-model","text":"","title":"Execution model\u00b6"},{"location":"Python/Language/Language-reference/Execution-model/Execution-model/#41-structure-of-a-program","text":"NOTE: \u8fd9\u624d\u662f\u6838\u5fc3\u6240\u5728\uff0c\u540e\u7eed\u7684\u5f88\u591a\u6982\u5ff5\u90fd\u662f\u57fa\u4e8e\u6b64\u800c\u521b\u5efa\u7684\uff1b A Python program is constructed from code blocks . A block is a piece of Python program text that is executed as a unit \uff08\u5355\u4f4d\uff09. The following are blocks: a module\uff08the top-level code block \uff09 ,a function body and a class definition (\u6267\u884cclass definition\u7684\u7ed3\u679c\u662f\u521b\u5efa\u4e86\u8fd9\u4e2aclass). Each command typed interactively is a block . A script file (a file given as standard input to the interpreter or specified as a command line argument to the interpreter) is a code block . A script command (a command specified on the interpreter command line with the \u2018 -c \u2019 option) is a code block . The string argument passed to the built-in functions eval() and exec() is a code block. A code block is executed in an execution frame . A frame contains some administrative information (used for debugging) and determines where and how execution continues after the code block\u2019s execution has completed. NOTE: python interpreter\u5bf9code block\u7684\u5224\u65ad\u5e94\u8be5\u4f1a\u53d7level of indentation\u7684\u5f71\u54cd\uff0c\u5173\u4e8epython interpreter\u662f\u5982\u4f55\u6765\u5224\u65adlevel of indentation\uff0c\u53c2\u8003 https://docs.python.org/3/reference/lexical_analysis.html#indentation NOTE: \u4e0a\u9762\u8fd9\u6bb5\u4e2d\u63d0\u53ca\u4e86\u5404\u79cd\u5404\u6837\u7684code block\uff0c\u5728python\u4e2d\uff0c\u90fd\u6709\u5bf9\u5e94\u7684standard type\u6765\u63cf\u8ff0\u5b83\u4eec\uff1b\u6bd4\u5982module\u5bf9\u5e94\u7684\u5c31\u662fpython\u7684 standard type hierarchy \u4e2d\u7684Modules NOTE: **execution frame**\u662fpython\u7684 standard type hierarchy \u4e2d\u4e3aInternal types\u4e2d\u7684Frame objects\uff1b\u8fd9\u8ba9\u6211\u60f3\u8d77\u6765 call stack \uff0c stack frame \uff1b\u663e\u7136python\u4e2d\u7684execution frame\u662f\u7531python\u89e3\u91ca\u5668\u6765\u8fdb\u884c\u7ef4\u62a4\uff0c\u5bf9\u4e8e\u7f16\u8bd1\u578b\u8bed\u8a00\uff0c\u5219\u6709OS\u6765\u8fdb\u884c\u7ef4\u62a4\uff1b NOTE: \u9700\u8981\u533a\u5206**code block**\u548c**callable**\uff08\u5728 standard type hierarchy \u7ed9\u51fa\u7684\u5b9a\u4e49\uff09\uff1bcallable\u7684\u5b9a\u4e49\u662f\u6307\uff1a types to which the function call operation (see section Calls ) can be applied\uff1b\u663e\u7136module\u4e0d\u662fcallable\uff0c\u6240\u4ee5code block\u4e0d\u662fcallable\uff1b\u8fd9\u91cc\u6307\u51facode block\u662f\u6307python program\u7684structure\uff0c\u4e5f\u5c31\u662f\u6211\u4eec\u5728\u7f16\u5199python program\u7684\u65f6\u5019\uff0c\u5f80\u5f80\u4f1a\u521b\u5efa\u4e00\u4e2amodule\uff0c\u7136\u540e\u5728module\u4e2d\u5b9a\u4e49function\uff0c\u5b9a\u4e49class\uff1b\u7136\u540e\u6211\u4eec\u4f7f\u7528python interpreter\u6765execute module\uff0c\u8fd9\u624d\u662f\u6700\u540e\u4e00\u6bb5\u8bdd\u4e2dA code block is executed in an *execution frame*\u7684\u542b\u4e49\uff1b\u4e0e\u6b64\u7c7b\u4f3c\u7684\u662f\uff0cpython interpreter\u8fd8\u53ef\u4ee5execute class\uff0cfunction\uff0c\u663e\u7136python interpreter execute class\u7684\u7ed3\u679c\u662f\u5b9a\u4e49\u4e86\u4e00\u4e2aclass\uff1b\u5bf9\u4e00\u4e2aclass\u6267\u884ccall operation\u7684\u7ed3\u679c\u662f\u521b\u5efa\u4e00\u4e2ainstance\uff0c\u5bf9\u4e00\u4e2afunction\u6267\u884ccall operation\u7684\u7ed3\u679c\u662fexecute\u8fd9\u4e2afunction\u7684function body\uff1b TODO: see also : https://docs.python.org/2.0/ref/execframes.html","title":"4.1. Structure of a program"},{"location":"Python/Language/Language-reference/Execution-model/Execution-model/#42-naming-and-binding","text":"","title":"4.2. Naming and binding"},{"location":"Python/Language/Language-reference/Execution-model/Execution-model/#421-binding-of-names","text":"Names refer to objects. Names are introduced by name binding operations . NOTE\uff1apython\u4e2d\u4e00\u5207\u7686\u5bf9\u8c61\uff0c\u5e76\u4e14python\u662f\u901a\u8fc7name\u6765access\u5bf9\u8c61\u7684\u3002\u90a3\u8fd9\u6bb5\u4e2d\u7684name\u7684\u542b\u4e49\u5230\u5e95\u662f\u4ec0\u4e48\u5462\uff1fname\u5c31\u662fidentifier\u5417\uff1f\u6839\u636eWikipedia\u4e0a\u7684\u5173\u4e8ename binding\u7684\u89e3\u91ca\uff0c\u53ef\u4ee5\u63a8\u6d4bname\u53ef\u4ee5\u7406\u89e3\u4e3aidentifier\uff1b\u5728youdao 20181030\u4e2d\u6536\u5f55\u4e86name binding\u3002\u5e76\u4e14\u57286.2.1. Identifiers (Names) \u00b6 \u4e2d\u4e5f\u5c06name\u548cidentifier\u89c6\u4e3a\u540c\u4e49\u8bcd\uff1b NOTE\uff1a\u663e\u7136name-binding\u662f\u53d1\u751f\u5728runtime\uff0c\u53ea\u6709\u5f53program runtime\uff0c\u624d\u80fd\u591f\u77e5\u9053name\u5230\u5e95bind\u5230\u54ea\u4e2aobject\u3002 NOTE : \u4e0d\u540c\u7684programming language\u4e2d\u5bf9name\u7684\u5904\u7406\u65b9\u5f0f\u662f\u4e0d\u540c\u7684\uff0c\u663e\u7136python\u4e2dname\u548c c++ \u4e2d\u7684name\u662f\u622a\u7136\u4e0d\u540c\u7684\uff1b The following constructs bind names: formal parameters to functions\uff08\u51fd\u6570\u5f62\u53c2\uff09 import statements class and function definitions (these bind the class or function name in the defining block) targets that are identifiers if occurring in an assignment for loop header after as in a with statement or except clause. The import statement of the form from ... import * binds all names defined in the imported module, except those beginning with an underscore. This form may only be used at the module level\uff08\u5173\u4e8e\u8fd9\u4e00\u70b9\uff0c\u53c2\u8003Reserved classes of identifiers \u00b6 \uff09. NOTE\uff1a\u56e0\u4e3apython\u4e2d\u4e00\u5207\u7686\u5bf9\u8c61\uff0c\u6240\u4ee5programmer\u6240\u5b9a\u4e49\u7684\u7c7b\uff0c\u4e5f\u662f\u7528\u4e00\u4e2a\u5bf9\u8c61\u6765\u8868\u793a\u8be5\u7c7b\u7684\u3002\u663e\u7136\u5728python\u4e2d\uff0c\u53ea\u6709\u901a\u8fc7\u4e0a\u9762\u8fd9\u6bb5\u4e2d\u6240\u63cf\u8ff0\u7684\u65b9\u5f0f\u540e\uff0cprogrammer\u624d\u80fd\u591f\u901a\u8fc7\u7c7b\u540d\u6765reference\u8868\u793a\u8be5\u7c7b\u7684object\u3002\u663e\u7136\u8fd9\u548c\u7f16\u8bd1\u578b\u8bed\u8a00\u662f\u4e0d\u540c\u7684\u3002 NOTE: \u7406\u89e3python\u7684binding of names\u662f\u7406\u89e3python\u7684function pass by sharing\u7684\u524d\u63d0\uff0c\u8fd9\u4e2a\u95ee\u9898\u5728function\u7ae0\u8282\u6709\u4e13\u95e8\u7684\u4ecb\u7ecd\uff1b\u663e\u7136\u5b83\u5c5e\u4e8e\u4e0a\u9762\u6240\u5217\u7684\u7b2c\u4e00\u79cd\u60c5\u51b5\uff1aformal parameters to functions\u3002 A target occurring in a del statement is also considered bound for this purpose (though the actual semantics are to unbind the name). Each assignment or import statement occurs within a block defined by a class or function definition or at the module level (the top-level code block ). SUMMARY :\u5176\u5b9e\u4e3b\u8981\u4e5f\u5c31\u8fd9\u4e09\u79cdcode block\uff1b If a name is bound in a block, it is a local variable of that block, unless declared as nonlocal or global . If a name is bound at the module level, it is a global variable . (The variables of the module code block are local and global.) If a variable is used in a code block but not defined there, it is a free variable . SUMMARY \uff1a\u4e0a\u9762\u8fd9\u6bb5\u4e2d\u7684**bound**\u7684\u542b\u4e49\u662f\u8be5name\u6240\u5bf9\u5e94\u7684object\u5728\u8be5block\u4e2d\u88ab\u521b\u5efa\u7684\u3002 SUMMARY : free variable\u5728Wikipedia\u7684 Closure (computer programming) \u4e2d\u6709\u4ecb\u7ecd\uff0cpython\u4e2d\u51fa\u73b0**free variable**\u7684\u573a\u666fdecorator\uff0c\u5d4c\u5957\u51fd\u6570\u5b9a\u4e49\uff1b SUMMARY \uff1a\u4e0a\u9762\u8fd9\u6bb5\u5173\u4e8efree variable\u7684\u63cf\u8ff0\u662f\u975e\u5e38\u6a21\u7cca\u7684\uff0c\u4e0b\u9762\u8fd9\u6bb5\u662f\u6458\u81eaWikipedia\u4e2d Free variables and bound variables \u4e2d\u5173\u4e8eFree variables\u7684\u89e3\u91ca\uff1a In computer programming , the term free variable refers to variables used in a function that are neither local variables nor parameters of that function. The term non-local variable is often a synonym in this context. A bound variable is a variable that was previously free , but has been bound to a specific value or set of values called domain of discourse or universe . SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u4ecb\u7ecd\u4e86python\u4e2d\u7684\u4e09\u79cdvariable\uff1b\u5176\u5b9e\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e5f\u4f53\u73b0\u4e86python\u4e2d\u7684name\u548cvariable\u4e4b\u95f4\u7684\u5173\u7cfb\uff1aname refer to object\uff0c\u90a3\u4e48\u5bf9\u5e94\u7684object\u5c31\u662fvariable\uff1b Each occurrence of a name in the program text refers to the binding of that name established by the following name resolution rules(\u7a0b\u5e8f\u6587\u672c\u4e2d\u6bcf\u6b21\u51fa\u73b0\u7684\u540d\u79f0\u90fd\u662f\u6307\u7531\u4ee5\u4e0b\u540d\u79f0\u89e3\u6790\u89c4\u5219\u5efa\u7acb\u7684\u540d\u79f0\u7684\u7ed1\u5b9a). SUMMARY : \u9006\u5411\u601d\u7ef4\uff1aname\u5982\u679c\u6ca1\u6709bound\uff0c\u90a3\u4f1a\u53d1\u751f\u4ec0\u4e48\uff1f\u4e0e\u6b64\u76f8\u5173\u7684\u662f UnboundLocalError \u3002","title":"4.2.1. Binding of names"},{"location":"Python/Language/Language-reference/Execution-model/Execution-model/#422-resolution-of-names","text":"A scope defines the visibility of a name within a block (scope\u5b9a\u4e49\u4e86\u5728\u4e00\u4e2ablock\u4e2d\uff0cname\u7684visibility). If a local variable is defined in a block, its scope includes that block\uff08\u4e5f\u5c31\u662f\u8be5block\u4e2d\u7684\u5176\u4ed6\u5730\u65b9\u662f\u53ef\u4ee5\u770b\u5230\u8be5variable\u7684\uff09. If the definition occurs in a function block , the scope extends to any blocks contained within the defining one, unless a contained block introduces a different binding for the name. SUMMARY \uff1a\u5173\u4e8escope\uff0c\u5728compiler principle\u8fd9\u672c\u4e66\u4e2d\u8fdb\u884c\u4e86\u975e\u5e38\u597d\u7684\u63cf\u8ff0\uff1b SUMMARY \uff1a\u4e0a\u9762\u4ec5\u4ec5\u7ed9\u51fa\u4e86*scope*\u7684\u542b\u4e49\uff0c\u4f46\u662f\u5e76\u6ca1\u6709\u7ed9\u51fa*scope*\u7684\u5177\u4f53\u7684\u754c\u5b9a\u65b9\u6cd5\u3002python\u4e2d\u7684*scope*\u7684\u754c\u5b9a\u65b9\u6cd5\u662f\u4ec0\u4e48\u5462\uff1f\u53c2\u89c1 Python Scopes and Namespaces SUMMARY : \u6ce8\u610f\uff0cfunction\u7684scope\u89c4\u5219\uff0c\u5373the scope extends to any blocks contained within the defining one\uff0c\u975e\u5e38\u6709\u5229\u4e8epython\u4e2d\u5d4c\u5957\u51fd\u6570\u7684\u4f7f\u7528\uff1b When a name is used in a code block, it is resolved using the nearest enclosing scope . The set of all such scopes visible to a code block is called the block\u2019s environment . SUMMARY : every block \u6709\u5bf9\u5e94\u7684environment\uff0cnamespace\uff08\u5bf9\u5e94\u7684\u5c31\u662f __dict__ \uff09\uff1b When a name is not found at all, a NameError exception is raised. If the current scope is a function scope, and the name refers to a local variable that has not yet been bound to a value at the point where the name is used, an UnboundLocalError exception is raised. UnboundLocalError is a subclass of NameError . THINKING : \u4f55\u65f6\u4f1a\u53d1\u751f UnboundLocalError \uff1f\u5728build-in exception\u7ae0\u8282\u6709\u4e13\u95e8\u603b\u7ed3\uff1b If a name binding operation occurs anywhere within a code block, all uses of the name within the block are treated as references to the current block \uff08\u8fd9\u662f\u975e\u5e38\u7b26\u5408\u5e38\u8bc6\u7684\uff09. This can lead to errors when a name is used within a block before it is bound. This rule is subtle. Python lacks declarations and allows name binding operations to occur anywhere within a code block. The local variables of a code block can be determined by scanning the entire text of the block for name binding operations . SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\uff0c\u63d0\u53ca\u5230\u4e86python\u7684\u4e00\u4e2a\u663e\u8457\u7279\u5f81\uff1apython lacks declaration\uff0c\u8fd9\u662fpython\u548c c++ \u7684\u4e00\u4e2a\u663e\u8457\u5dee\u5f02\uff1b If the global statement occurs within a block, all uses of the name specified in the statement refer to the binding of that name in the top-level namespace . Names are resolved in the top-level namespace by searching the global namespace , i.e. the namespace of the module containing the code block, and the builtins namespace, the namespace of the module builtins . The global namespace is searched first. If the name is not found there, the builtins namespace is searched. The global statement must precede all uses of the name. The global statement has the same scope as a name binding operation in the same block. If the nearest enclosing scope for a free variable contains a global statement , the free variable is treated as a global. The nonlocal statement causes corresponding names to refer to previously bound variables in the nearest enclosing function scope. SyntaxError is raised at compile time if the given name does not exist in any enclosing function scope. The namespace for a module is automatically created the first time a module is imported. The main module for a script is always called __main__ . Class definition blocks and arguments to exec() and eval() are special in the context of name resolution. A class definition is an executable statement that may use and define names. These references follow the normal rules for name resolution with an exception that unbound local variables are looked up in the global namespace\uff08\u4e0efunction block\u6709\u5f02\uff09. The namespace of the class definition becomes the attribute dictionary of the class. The scope of names defined in a class block is limited to the class block ; it does not extend to the code blocks of methods \u2013 this includes comprehensions and generator expressions since they are implemented using a function scope \uff08\u4e0efunction block\u6709\u5f02\uff09. This means that the following will fail: class A : a = 42 b = list ( a + i for i in range ( 10 )) SUMMARY : \u6ce8\u610fclass block\u548cfunction block\u4e4b\u95f4\u7684\u5dee\u5f02\u6240\u5728\uff1a SUMMARY : comprehension\u548cgenerator\u57286. Expressions \u00b6 \u4e2d\u6709\u4e13\u95e8\u4ecb\u7ecd\uff1b SUMMARY : resolution of name\u4e3b\u8981\u63cf\u8ff0\u7684\u662f\u5982\u4f55\u627e\u5230name\u6240refer\u7684object\uff1b\u5bf9\u4e8e\u4e00\u4e2a\u5df2\u7ecfbind\u7684name\uff0c\u90a3\u4e48\u5728\u540e\u7eed\u4f7f\u7528\u4e2dpython\u89e3\u91ca\u5668\u5c31\u9700\u8981\u8003\u8651\u7684\u4e00\u4e2a\u95ee\u9898\u662f\u5982\u4f55\u5bf9\u8fd9\u4e2aname\u8fdb\u884cresolve\uff0c\u5373\u627e\u5230\u8fd9\u4e2aname\u6240refer\u7684object\uff1b\u663e\u7136\u8fd9\u5c31\u6d89\u53ca\u5230\u4e86scope\uff0c\u6d89\u53ca\u5230\u4e86namespace\uff0c\u4e3a\u6b64python interpreter\u5b9a\u4e49\u4e86\u4e00\u7cfb\u5217\u7684\u89c4\u5219\uff1b","title":"4.2.2. Resolution of names"},{"location":"Python/Language/Language-reference/Execution-model/Execution-model/#423-builtins-and-restricted-execution","text":"CPython implementation detail: Users should not touch __builtins__ ; it is strictly an implementation detail. Users wanting to override values in the builtins namespace should import the builtins module and modify its attributes appropriately. The builtins namespace associated with the execution of a code block is actually found by looking up the name __builtins__ in its global namespace ; this should be a dictionary or a module (in the latter case the module\u2019s dictionary is used). By default, when in the __main__ module, __builtins__ is the built-in module builtins ; when in any other module, __builtins__ is an alias for the dictionary of the builtins module itself.","title":"4.2.3. Builtins and restricted execution"},{"location":"Python/Language/Language-reference/Execution-model/Execution-model/#424-interaction-with-dynamic-features","text":"Name resolution of free variables occurs at runtime, not at compile time. This means that the following code will print 42: i = 10 def f (): print ( i ) i = 42 f () SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u4ee3\u7801\u7684\u7740\u91cd\u70b9\u662f\u8868\u8fbe\u5f53\u8c03\u7528 f() \u7684\u65f6\u5019\uff0c\u6253\u5370\u7684\u662f\u6700\u540e\u4e00\u6b21 i \u7684\u503c\uff1b SUMMARY : \u5982\u679c\u5c06\u4e0a\u8ff0\u4ee3\u7801\u4fee\u6539\u4e3a\u5982\u4e0b\uff1a def f (): i += 1 print ( i ) \u5219\u4f1a\u629b\u51fa\u5982\u4e0b\u5f02\u5e38\uff1a UnboundLocalError: local variable 'i' referenced before assignment \u4e3a\u4ec0\u4e48\u7b2c\u4e00\u4e2a\u6ca1\u6709\u62a5\u9519\uff1f \u8fd9\u79cd\u65b9\u5f0f\u662f\u6b63\u5e38\u7684\uff1a def f (): global i i += 1 print ( i ) \u663e\u7136\uff0c\u8fd9\u4e2a\u95ee\u9898\u6d89\u53ca\u5230\u4e86python\u4e2d\u7684free variable\uff0c\u8fd8\u6d89\u53ca\u5230\u4e86python\u7684runtime\u548ccompile time\uff1b The eval() and exec() functions do not have access to the full environment for resolving names. Names may be resolved in the local and global namespaces of the caller. Free variables are not resolved in the nearest enclosing namespace, but in the global namespace. [ 1] The exec() and eval() functions have optional arguments to override the global and local namespace. If only one namespace is specified, it is used for both.","title":"4.2.4. Interaction with dynamic features"},{"location":"Python/Language/Language-reference/Execution-model/Execution-model/#43-exceptions","text":"Exceptions are a means of breaking out of the normal flow of control of a code block in order to handle errors or other exceptional conditions. An exception is raised at the point where the error is detected; it may be handled by the surrounding code block or by any code block that directly or indirectly invoked the code block where the error occurred. The Python interpreter raises an exception when it detects a run-time error (such as division by zero). A Python program can also explicitly raise an exception with the raise statement. Exception handlers are specified with the try \u2026 except statement. The finally clause of such a statement can be used to specify cleanup code which does not handle the exception, but is executed whether an exception occurred or not in the preceding code. Python uses the \u201ctermination\u201d model of error handling: an exception handler can find out what happened and continue execution at an outer level, but it cannot repair the cause of the error and retry the failing operation (except by re-entering the offending piece of code from the top). When an exception is not handled at all, the interpreter terminates execution of the program, or returns to its interactive main loop. In either case, it prints a stack backtrace , except when the exception is SystemExit . SUMMARY : \u5173\u4e8estack backtrace\uff0c\u5728python\u7684 standard type hierarchy \u4e2d\u4e3aInternal types\u4e2d\u7684Traceback objects\uff1b Exceptions are identified by class instances. The except clause is selected depending on the class of the instance: it must reference the class of the instance or a base class thereof. The instance can be received by the handler and can carry additional information about the exceptional condition. Note :Exception messages are not part of the Python API. Their contents may change from one version of Python to the next without warning and should not be relied on by code which will run under multiple versions of the interpreter. See also the description of the try statement in section The try statement and raise statement in section The raise statement . Footnotes [ 1] This limitation occurs because the code that is executed by these operations is not available at the time the module is compiled.","title":"4.3. Exceptions"},{"location":"Python/Language/Language-reference/Execution-model/Python-GC/","text":"python and java and GC \u4e24\u8005\u90fd\u662f\u5e26GC\u7684\u8bed\u8a00\uff0c\u80fd\u591f\u8fd4\u56de\u5728\u51fd\u6570\u4e2d\u58f0\u660e\u7684\u4e34\u65f6\u53d8\u91cf\uff0c\u51c6\u786e\u6765\u8bf4\uff0c\u5b83\u4e0d\u662f\u4e34\u65f6\u53d8\u91cf\uff0c\u5b83\u5e94\u8be5\u662f\uff1f\uff1f\u6211\u89c9\u5f97\u975e\u5e38\u7c7b\u4f3c\u4e8epointer\uff0c\u5373\u5b83\u6307\u5411\u7684\u662f\u4e00\u4e2a\u4f4d\u4e8eheap\u4e2d\u7684\u5185\u5b58\u533a\u57df\u3002\u800c\u5bf9\u4e8e c++ \u548c c \u800c\u8a00\uff0c\u8fd9\u662f\u4e0d\u53ef\u80fd\u7684\u3002 python name and pointer\uff0c\u6211\u89c9\u5f97python\u4e2didentifier\u975e\u5e38\u7c7b\u4f3c\u4e8e\u6307\u9488\u3002python\u4e2d\u7684 . \uff0c\u6709\u4e9b\u7c7b\u4f3c\u4e8e c \u6216\u8005 c++ \u4e2d\u7684 -> \u3002 \u5728\u8fd0\u884c\u4e00\u4e2apython\u51fd\u6570\u7684\u65f6\u5019\uff0c\u5982\u679c\u5728\u5176\u4e2d\u521b\u5efa\u4e86\u4e00\u4e2a\u5bf9\u8c61\uff0c\u5219\u8fd9\u4e2a\u5bf9\u8c61\u5e94\u8be5\u662f new \u51fa\u6765\u7684\uff0c \u5373\u5b83\u662f\u4f4d\u4e8eheap\u4e0a\u3002 java\u5e94\u8be5\u4e5f\u662f\u5982\u6b64\u3002 python\u7684GC\u5e94\u8be5\u4f5c\u7528\u4e8eheap\u3002","title":"Python-GC"},{"location":"Python/Language/Language-reference/Execution-model/Python-GC/#python-and-java-and-gc","text":"\u4e24\u8005\u90fd\u662f\u5e26GC\u7684\u8bed\u8a00\uff0c\u80fd\u591f\u8fd4\u56de\u5728\u51fd\u6570\u4e2d\u58f0\u660e\u7684\u4e34\u65f6\u53d8\u91cf\uff0c\u51c6\u786e\u6765\u8bf4\uff0c\u5b83\u4e0d\u662f\u4e34\u65f6\u53d8\u91cf\uff0c\u5b83\u5e94\u8be5\u662f\uff1f\uff1f\u6211\u89c9\u5f97\u975e\u5e38\u7c7b\u4f3c\u4e8epointer\uff0c\u5373\u5b83\u6307\u5411\u7684\u662f\u4e00\u4e2a\u4f4d\u4e8eheap\u4e2d\u7684\u5185\u5b58\u533a\u57df\u3002\u800c\u5bf9\u4e8e c++ \u548c c \u800c\u8a00\uff0c\u8fd9\u662f\u4e0d\u53ef\u80fd\u7684\u3002 python name and pointer\uff0c\u6211\u89c9\u5f97python\u4e2didentifier\u975e\u5e38\u7c7b\u4f3c\u4e8e\u6307\u9488\u3002python\u4e2d\u7684 . \uff0c\u6709\u4e9b\u7c7b\u4f3c\u4e8e c \u6216\u8005 c++ \u4e2d\u7684 -> \u3002 \u5728\u8fd0\u884c\u4e00\u4e2apython\u51fd\u6570\u7684\u65f6\u5019\uff0c\u5982\u679c\u5728\u5176\u4e2d\u521b\u5efa\u4e86\u4e00\u4e2a\u5bf9\u8c61\uff0c\u5219\u8fd9\u4e2a\u5bf9\u8c61\u5e94\u8be5\u662f new \u51fa\u6765\u7684\uff0c \u5373\u5b83\u662f\u4f4d\u4e8eheap\u4e0a\u3002 java\u5e94\u8be5\u4e5f\u662f\u5982\u6b64\u3002 python\u7684GC\u5e94\u8be5\u4f5c\u7528\u4e8eheap\u3002","title":"python and java and GC"},{"location":"Python/Language/Language-reference/Execution-model/Python-GIL/","text":"","title":"Python-GIL"},{"location":"Python/Language/Language-reference/Execution-model/Python-interpreter-stack/","text":"Stack machine Stack-oriented programming What does it mean that python is stack based? 4. Execution model \u00b6 traceback \u2014 Print or retrieve a stack traceback \u00b6 inspect \u2014 Inspect live objects \u00b6 What is the difference between a frame and object, and when should I modify one over the other?","title":"Python-interpreter-stack"},{"location":"Python/Language/Language-reference/Execution-model/Python-interpreter-stack/#stack-machine","text":"","title":"Stack machine"},{"location":"Python/Language/Language-reference/Execution-model/Python-interpreter-stack/#stack-oriented-programming","text":"","title":"Stack-oriented programming"},{"location":"Python/Language/Language-reference/Execution-model/Python-interpreter-stack/#what-does-it-mean-that-python-is-stack-based","text":"","title":"What does it mean that python is stack based?"},{"location":"Python/Language/Language-reference/Execution-model/Python-interpreter-stack/#4-execution-model","text":"","title":"4. Execution model\u00b6"},{"location":"Python/Language/Language-reference/Execution-model/Python-interpreter-stack/#traceback-print-or-retrieve-a-stack-traceback","text":"","title":"traceback \u2014 Print or retrieve a stack traceback\u00b6"},{"location":"Python/Language/Language-reference/Execution-model/Python-interpreter-stack/#inspect-inspect-live-objects","text":"","title":"inspect \u2014 Inspect live objects\u00b6"},{"location":"Python/Language/Language-reference/Execution-model/Python-interpreter-stack/#what-is-the-difference-between-a-frame-and-object-and-when-should-i-modify-one-over-the-other","text":"","title":"What is the difference between a frame and object, and when should I modify one over the other?"},{"location":"Python/Language/Language-reference/Type-system/Type-system/","text":"Type system \u672c\u6587\u63cf\u8ff0python\u7684type system\u3002 Duck type duck-typing \u4e3a\u5404\u79cd\u64cd\u4f5c\u90fd\u6307\u5b9aspecial method\u3002 python duck type\u7684\u5b9e\u73b0 \u53c2\u89c13. Data model \u00b6 \u76843.2. The standard type hierarchy \u00b6 \u7684Custom classes\u7ae0\u8282\u3002 duck type and attribute access\u3002 \u663e\u7136\uff0cpython duck type\u7684\u5b9e\u73b0\u662f\u548c\u5b83\u7684run model\u3001data model\u5bc6\u5207\u76f8\u5173\u7684\u3002 typing \u2014 Support for type hints \u00b6 The standard type hierarchy \u00b6","title":"Type-system"},{"location":"Python/Language/Language-reference/Type-system/Type-system/#type-system","text":"\u672c\u6587\u63cf\u8ff0python\u7684type system\u3002","title":"Type system"},{"location":"Python/Language/Language-reference/Type-system/Type-system/#duck-type","text":"duck-typing \u4e3a\u5404\u79cd\u64cd\u4f5c\u90fd\u6307\u5b9aspecial method\u3002","title":"Duck type"},{"location":"Python/Language/Language-reference/Type-system/Type-system/#python-duck-type","text":"\u53c2\u89c13. Data model \u00b6 \u76843.2. The standard type hierarchy \u00b6 \u7684Custom classes\u7ae0\u8282\u3002 duck type and attribute access\u3002 \u663e\u7136\uff0cpython duck type\u7684\u5b9e\u73b0\u662f\u548c\u5b83\u7684run model\u3001data model\u5bc6\u5207\u76f8\u5173\u7684\u3002","title":"python duck type\u7684\u5b9e\u73b0"},{"location":"Python/Language/Language-reference/Type-system/Type-system/#typing-support-for-type-hints","text":"","title":"typing \u2014 Support for type hints\u00b6"},{"location":"Python/Language/Language-reference/Type-system/Type-system/#the-standard-type-hierarchy","text":"","title":"The standard type hierarchy\u00b6"},{"location":"Python/Library/Built-in/","text":"\u5173\u4e8e\u672c\u7ae0 python\u7684build-in\u5305\u62ec\uff1a Built-in Functions Built-in Constants Built-in Types Built-in Exceptions \u8fd9\u4e9b\u90fd\u5b9a\u4e49\u5728 builtins \u2014 Built-in objects \u00b6 \u90a3\u5b83\u4eec\u662f\u5b9a\u4e49\u5728\u54ea\u4e2a\u6587\u4ef6\u4e2d\u5462\uff1f\u6587\u4ef6 builtins.py \u3002","title":"Introduction"},{"location":"Python/Library/Built-in/#_1","text":"python\u7684build-in\u5305\u62ec\uff1a Built-in Functions Built-in Constants Built-in Types Built-in Exceptions \u8fd9\u4e9b\u90fd\u5b9a\u4e49\u5728 builtins \u2014 Built-in objects \u00b6 \u90a3\u5b83\u4eec\u662f\u5b9a\u4e49\u5728\u54ea\u4e2a\u6587\u4ef6\u4e2d\u5462\uff1f\u6587\u4ef6 builtins.py \u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Python/Library/Built-in/Built-in-Constants/","text":"","title":"Introduction"},{"location":"Python/Library/Built-in/Built-in-Exceptions/","text":"","title":"Introduction"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/","text":"Built-in Functions \u00b6 ## \u5206\u7c7b type system\u76f8\u5173 \u7c7b\u578b\u67e5\u8be2\u4e0e\u64cd\u4f5c super() callable() issubclass() isinstance() type() SUMMARY : What are the differences between type() and isinstance()? decorator classmethod() staticmethod() property() \u5c5e\u6027\u64cd\u4f5c setattr() delattr() getattr() hasattr() symbol table globals() locals() dir() vars() \u5185\u7f6e\u6570\u636e\u7c7b\u578b object() \u6309\u71673.2. The standard type hierarchy \u00b6 \u4e2d\u8fdb\u884c\u7ec4\u7ec7 numbers.Number numbers.Integral int() bool() numbers.Real ( float ) float() numbers.Complex ( complex ) complex() Sequences Immutable sequences str() tuple() bytes() Mutable sequences list() bytearray() range() Rather than being a function, range is actually an immutable sequence type, as documented in Ranges and Sequence Types \u2014 list, tuple, range . Set types set() frozenset() Mappings dict() TODO slice() \u6570\u8fdb\u5236 bin() oct() hex() \u5b57\u7b26\u4e32\u4e0e\u6574\u6570 chr() ord() \u8f6c\u6362\u4e3a\u5b57\u7b26\u4e32 ascii() format() repr() \u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236 memoryview() \u7b97\u6cd5 all() any() filter() max() min() sum() sorted() map() next() enumerate() iter() len() reversed() sorted() zip() \u7b97\u672f\u8fd0\u7b97 abs() divmod() hash() pow() round() \u6267\u884c\u6d41\u7a0b\u63a7\u5236 breakpoint() IO input() open() print() python\u89e3\u91ca\u5668\u76f8\u5173 compile() eval() exec() help() id() __import__() Built-in Functions abs() delattr() hash() memoryview() set() all() dict() help() min() setattr() any() dir() hex() next() slice() ascii() divmod() id() object() sorted() bin() enumerate() input() oct() staticmethod() bool() eval() int() open() str() breakpoint() exec() isinstance() ord() sum() bytearray() filter() issubclass() pow() super() bytes() float() iter() print() tuple() callable() format() len() property() type() chr() frozenset() list() range() vars() classmethod() getattr() locals() repr() zip() compile() globals() map() reversed() __import__() complex() hasattr() max() round()","title":"Summary-of-python-build-in-function"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#built-in-functions","text":"## \u5206\u7c7b","title":"Built-in Functions\u00b6"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#type-system","text":"","title":"type system\u76f8\u5173"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#_1","text":"super() callable() issubclass() isinstance() type() SUMMARY : What are the differences between type() and isinstance()?","title":"\u7c7b\u578b\u67e5\u8be2\u4e0e\u64cd\u4f5c"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#decorator","text":"classmethod() staticmethod() property()","title":"decorator"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#_2","text":"setattr() delattr() getattr() hasattr()","title":"\u5c5e\u6027\u64cd\u4f5c"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#symbol-table","text":"globals() locals() dir() vars()","title":"symbol table"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#_3","text":"object() \u6309\u71673.2. The standard type hierarchy \u00b6 \u4e2d\u8fdb\u884c\u7ec4\u7ec7","title":"\u5185\u7f6e\u6570\u636e\u7c7b\u578b"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#numbersnumber","text":"numbers.Integral int() bool() numbers.Real ( float ) float() numbers.Complex ( complex ) complex()","title":"numbers.Number"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#sequences","text":"","title":"Sequences"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#immutable-sequences","text":"str() tuple() bytes()","title":"Immutable sequences"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#mutable-sequences","text":"list() bytearray() range() Rather than being a function, range is actually an immutable sequence type, as documented in Ranges and Sequence Types \u2014 list, tuple, range .","title":"Mutable sequences"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#set-types","text":"set() frozenset()","title":"Set types"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#mappings","text":"dict()","title":"Mappings"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#todo","text":"slice()","title":"TODO"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#_4","text":"bin() oct() hex()","title":"\u6570\u8fdb\u5236"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#_5","text":"chr() ord()","title":"\u5b57\u7b26\u4e32\u4e0e\u6574\u6570"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#_6","text":"ascii() format() repr()","title":"\u8f6c\u6362\u4e3a\u5b57\u7b26\u4e32"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#_7","text":"memoryview()","title":"\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#_8","text":"all() any() filter() max() min() sum() sorted() map() next() enumerate() iter() len() reversed() sorted() zip()","title":"\u7b97\u6cd5"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#_9","text":"abs() divmod() hash() pow() round()","title":"\u7b97\u672f\u8fd0\u7b97"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#_10","text":"breakpoint()","title":"\u6267\u884c\u6d41\u7a0b\u63a7\u5236"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#io","text":"input() open() print()","title":"IO"},{"location":"Python/Library/Built-in/Built-in-Functions/summary-of-python-build-in-function/#python","text":"compile() eval() exec() help() id() __import__() Built-in Functions abs() delattr() hash() memoryview() set() all() dict() help() min() setattr() any() dir() hex() next() slice() ascii() divmod() id() object() sorted() bin() enumerate() input() oct() staticmethod() bool() eval() int() open() str() breakpoint() exec() isinstance() ord() sum() bytearray() filter() issubclass() pow() super() bytes() float() iter() print() tuple() callable() format() len() property() type() chr() frozenset() list() range() vars() classmethod() getattr() locals() repr() zip() compile() globals() map() reversed() __import__() complex() hasattr() max() round()","title":"python\u89e3\u91ca\u5668\u76f8\u5173"},{"location":"Python/Library/Built-in/Built-in-Functions/hash/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u5bf9python\u4e2dhash\u76f8\u5173\u5185\u5bb9\u8fdb\u884c\u603b\u7ed3\u3002","title":"Introduction"},{"location":"Python/Library/Built-in/Built-in-Functions/hash/#_1","text":"\u672c\u7ae0\u5bf9python\u4e2dhash\u76f8\u5173\u5185\u5bb9\u8fdb\u884c\u603b\u7ed3\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Python/Library/Built-in/Built-in-Functions/hash/TODO/","text":"What does \u201chashable\u201d mean in Python? Python hashing tutorial What does hash do in python? What are Hashable Objects Making a python user-defined class sortable, hashable TypeError: unhashable type: 'list' [Tutor] how to understand unhashable type: 'list' Python, TypeError: unhashable type: 'list' hash ( object ) \u00b6 object.__hash__ ( self ) \u00b6 Why does Python's hash of infinity have the digits of \u03c0?","title":"[What does \u201chashable\u201d mean in Python?](https://stackoverflow.com/questions/14535730/what-does-hashable-mean-in-python)"},{"location":"Python/Library/Built-in/Built-in-Functions/hash/TODO/#what-does-hashable-mean-in-python","text":"","title":"What does \u201chashable\u201d mean in Python?"},{"location":"Python/Library/Built-in/Built-in-Functions/hash/TODO/#python-hashing-tutorial","text":"","title":"Python hashing tutorial"},{"location":"Python/Library/Built-in/Built-in-Functions/hash/TODO/#what-does-hash-do-in-python","text":"","title":"What does hash do in python?"},{"location":"Python/Library/Built-in/Built-in-Functions/hash/TODO/#what-are-hashable-objects","text":"","title":"What are Hashable Objects"},{"location":"Python/Library/Built-in/Built-in-Functions/hash/TODO/#making-a-python-user-defined-class-sortable-hashable","text":"","title":"Making a python user-defined class sortable, hashable"},{"location":"Python/Library/Built-in/Built-in-Functions/hash/TODO/#typeerror-unhashable-type-list","text":"","title":"TypeError: unhashable type: 'list'"},{"location":"Python/Library/Built-in/Built-in-Functions/hash/TODO/#tutor-how-to-understand-unhashable-type-list","text":"","title":"[Tutor] how to understand unhashable type: 'list'"},{"location":"Python/Library/Built-in/Built-in-Functions/hash/TODO/#python-typeerror-unhashable-type-list","text":"hash ( object ) \u00b6 object.__hash__ ( self ) \u00b6","title":"Python, TypeError: unhashable type: 'list'"},{"location":"Python/Library/Built-in/Built-in-Functions/hash/TODO/#why-does-pythons-hash-of-infinity-have-the-digits-of","text":"","title":"Why does Python's hash of infinity have the digits of \u03c0?"},{"location":"Python/Library/Built-in/Built-in-Functions/hash/python-hashable/","text":"hashable An object is hashable if it has a hash value which never changes during its lifetime (it needs a __hash__() method), and can be compared to other objects (it needs an __eq__() method). Hashable objects which compare equal must have the same hash value . Hashability makes an object usable as a dictionary key and a set member, because these data structures use the hash value internally. \u603b\u7ed3\uff1a\u663e\u7136Hashability \u662f\u4e00\u4e2aobject\u6210\u4e3adictionary key\u548cset member\u7684\u524d\u63d0\u6761\u4ef6\uff0c\u56e0\u4e3a\u8fd9\u4e9bdata structure\u5728\u5185\u90e8\u4f7f\u7528hash value\u3002 All of Python\u2019s immutable built-in objects are hashable\uff08\u6ce8\u610f\u6b64\u5904\u7684build-in object\u662f\u6307\u7531python interpreter\u6240\u521b\u5efa\u7684\uff09; mutable containers (such as lists or dictionaries) are not. Objects which are instances of user-defined classes are hashable by default. They all compare unequal (except with themselves), and their hash value is derived from their id() . \u603b\u7ed3\uff1a\u663e\u7136hashability\u548cmutability\u4e00\u6837\uff0c\u662fobject\u7684\u4e00\u79cd\u6027\u8d28\u3002 How are Python's Built In Dictionaries Implemented How are dictionaries implemented? Python dictionary implementation How is set() implemented? Internal working of Set in Python","title":"[hashable](https://docs.python.org/3/glossary.html#term-hashable)"},{"location":"Python/Library/Built-in/Built-in-Functions/hash/python-hashable/#hashable","text":"An object is hashable if it has a hash value which never changes during its lifetime (it needs a __hash__() method), and can be compared to other objects (it needs an __eq__() method). Hashable objects which compare equal must have the same hash value . Hashability makes an object usable as a dictionary key and a set member, because these data structures use the hash value internally. \u603b\u7ed3\uff1a\u663e\u7136Hashability \u662f\u4e00\u4e2aobject\u6210\u4e3adictionary key\u548cset member\u7684\u524d\u63d0\u6761\u4ef6\uff0c\u56e0\u4e3a\u8fd9\u4e9bdata structure\u5728\u5185\u90e8\u4f7f\u7528hash value\u3002 All of Python\u2019s immutable built-in objects are hashable\uff08\u6ce8\u610f\u6b64\u5904\u7684build-in object\u662f\u6307\u7531python interpreter\u6240\u521b\u5efa\u7684\uff09; mutable containers (such as lists or dictionaries) are not. Objects which are instances of user-defined classes are hashable by default. They all compare unequal (except with themselves), and their hash value is derived from their id() . \u603b\u7ed3\uff1a\u663e\u7136hashability\u548cmutability\u4e00\u6837\uff0c\u662fobject\u7684\u4e00\u79cd\u6027\u8d28\u3002","title":"hashable"},{"location":"Python/Library/Built-in/Built-in-Functions/hash/python-hashable/#how-are-pythons-built-in-dictionaries-implemented","text":"","title":"How are Python's Built In Dictionaries Implemented"},{"location":"Python/Library/Built-in/Built-in-Functions/hash/python-hashable/#how-are-dictionaries-implemented","text":"","title":"How are dictionaries implemented?"},{"location":"Python/Library/Built-in/Built-in-Functions/hash/python-hashable/#python-dictionary-implementation","text":"","title":"Python dictionary implementation"},{"location":"Python/Library/Built-in/Built-in-Functions/hash/python-hashable/#how-is-set-implemented","text":"","title":"How is set() implemented?"},{"location":"Python/Library/Built-in/Built-in-Functions/hash/python-hashable/#internal-working-of-set-in-python","text":"","title":"Internal working of Set in Python"},{"location":"Python/Library/Built-in/Built-in-Types/","text":"","title":"Introduction"},{"location":"Python/Library/Functional-Programming-Modules/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u5bf9\u5e94\u7684\u662fpython\u6807\u51c6\u5e93\u7684Functional Programming Modules \u00b6 \u3002\u672c\u7ae0\u4e3b\u8981\u5173\u6ce8\u7684\u662f\uff0c\u5982\u4f55\u4f7f\u7528Functional Programming Modules \u00b6 \uff0c\u6765\u5b9e\u73b0\u5e73\u65f6\u7f16\u7a0b\u4e2d\u78b0\u5230\u7684\u4e00\u4e9b\u5c0f\u95ee\u9898\u3002","title":"Introduction"},{"location":"Python/Library/Functional-Programming-Modules/#_1","text":"\u672c\u7ae0\u5bf9\u5e94\u7684\u662fpython\u6807\u51c6\u5e93\u7684Functional Programming Modules \u00b6 \u3002\u672c\u7ae0\u4e3b\u8981\u5173\u6ce8\u7684\u662f\uff0c\u5982\u4f55\u4f7f\u7528Functional Programming Modules \u00b6 \uff0c\u6765\u5b9e\u73b0\u5e73\u65f6\u7f16\u7a0b\u4e2d\u78b0\u5230\u7684\u4e00\u4e9b\u5c0f\u95ee\u9898\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Python/Library/Functional-Programming-Modules/Iterate/","text":"Iterate \u5728python\u4e2d\uff0c\u8fdb\u884citerate\uff08\u904d\u5386\uff09\u662f\u975e\u5e38\u904d\u5386\u7684\uff0c\u672c\u6587\u5bf9python\u4e2d\u4e0e\u904d\u5386\u6709\u5173\u7684\u5185\u5bb9\u8fdb\u884c\u603b\u7ed3\u3002 Python\u8bed\u8a00\u63d0\u4f9b\u7684service Iterator Iterator Types itertools \u2014 Functions creating iterators for efficient looping \u00b6 Application Iterating over every two elements in a list Iterate a list as pair (current, next) in Python answer \u4e2d\u7ed9\u51fa\u4e86\u5982\u4e0b\u4ee3\u7801\uff1a Here's a relevant example from the itertools module docs: import itertools def pairwise ( iterable ): \"s -> (s0,s1), (s1,s2), (s2, s3), ...\" a , b = itertools . tee ( iterable ) next ( b , None ) return zip ( a , b ) For Python 2, you need itertools.izip instead of zip : import itertools def pairwise ( iterable ): \"s -> (s0,s1), (s1,s2), (s2, s3), ...\" a , b = itertools . tee ( iterable ) next ( b , None ) return itertools . izip ( a , b )","title":"Iterate"},{"location":"Python/Library/Functional-Programming-Modules/Iterate/#iterate","text":"\u5728python\u4e2d\uff0c\u8fdb\u884citerate\uff08\u904d\u5386\uff09\u662f\u975e\u5e38\u904d\u5386\u7684\uff0c\u672c\u6587\u5bf9python\u4e2d\u4e0e\u904d\u5386\u6709\u5173\u7684\u5185\u5bb9\u8fdb\u884c\u603b\u7ed3\u3002","title":"Iterate"},{"location":"Python/Library/Functional-Programming-Modules/Iterate/#pythonservice","text":"Iterator Iterator Types itertools \u2014 Functions creating iterators for efficient looping \u00b6","title":"Python\u8bed\u8a00\u63d0\u4f9b\u7684service"},{"location":"Python/Library/Functional-Programming-Modules/Iterate/#application","text":"","title":"Application"},{"location":"Python/Library/Functional-Programming-Modules/Iterate/#iterating-over-every-two-elements-in-a-list","text":"","title":"Iterating over every two elements in a list"},{"location":"Python/Library/Functional-Programming-Modules/Iterate/#iterate-a-list-as-pair-current-next-in-python","text":"answer \u4e2d\u7ed9\u51fa\u4e86\u5982\u4e0b\u4ee3\u7801\uff1a Here's a relevant example from the itertools module docs: import itertools def pairwise ( iterable ): \"s -> (s0,s1), (s1,s2), (s2, s3), ...\" a , b = itertools . tee ( iterable ) next ( b , None ) return zip ( a , b ) For Python 2, you need itertools.izip instead of zip : import itertools def pairwise ( iterable ): \"s -> (s0,s1), (s1,s2), (s2, s3), ...\" a , b = itertools . tee ( iterable ) next ( b , None ) return itertools . izip ( a , b )","title":"Iterate a list as pair (current, next) in Python"},{"location":"Python/Library/Python-Runtime-Services/","text":"","title":"Introduction"},{"location":"Python/Library/Python-Runtime-Services/inspect-Inspect-live-objects/","text":"inspect \u2014 Inspect live objects \u00b6 Application logging How to determine file, function and line number? import inspect def PrintFrame (): callerframerecord = inspect . stack ()[ 1 ] # 0 represents this line # 1 represents line at caller frame = callerframerecord [ 0 ] info = inspect . getframeinfo ( frame ) print ( info . filename ) # __FILE__ -> Test.py print ( info . function ) # __FUNCTION__ -> Main print ( info . lineno ) # __LINE__ -> 13 def Main (): PrintFrame () # for this line Main ()","title":"inspect-Inspect-live-objects"},{"location":"Python/Library/Python-Runtime-Services/inspect-Inspect-live-objects/#inspect-inspect-live-objects","text":"","title":"inspect \u2014 Inspect live objects\u00b6"},{"location":"Python/Library/Python-Runtime-Services/inspect-Inspect-live-objects/#application","text":"","title":"Application"},{"location":"Python/Library/Python-Runtime-Services/inspect-Inspect-live-objects/#logging","text":"","title":"logging"},{"location":"Python/Library/Python-Runtime-Services/inspect-Inspect-live-objects/#how-to-determine-file-function-and-line-number","text":"import inspect def PrintFrame (): callerframerecord = inspect . stack ()[ 1 ] # 0 represents this line # 1 represents line at caller frame = callerframerecord [ 0 ] info = inspect . getframeinfo ( frame ) print ( info . filename ) # __FILE__ -> Test.py print ( info . function ) # __FUNCTION__ -> Main print ( info . lineno ) # __LINE__ -> 13 def Main (): PrintFrame () # for this line Main ()","title":"How to determine file, function and line number?"},{"location":"Python/Paradigm/Functional-programming/","text":"Functional programming python\u4e2d\u8fdb\u884cfunctional programming\u662f\u975e\u5e38\u5bb9\u6613\u7684\uff0c\u56e0\u4e3apython\u4e2dfunctions are first class citizen\u3002 How do I pass a method as a parameter in Python \u770b\u4e86\u8fd9\u4e9b\u56de\u7b54\uff0c\u8fd9\u4e2a\u5177\u6709\u542f\u53d1\u610f\u4e49\uff1a https://stackoverflow.com/a/706744 \uff1b functions (and methods) are first class objects in Python\u3002","title":"Functional-programming"},{"location":"Python/Paradigm/Functional-programming/#functional-programming","text":"python\u4e2d\u8fdb\u884cfunctional programming\u662f\u975e\u5e38\u5bb9\u6613\u7684\uff0c\u56e0\u4e3apython\u4e2dfunctions are first class citizen\u3002","title":"Functional programming"},{"location":"Python/Paradigm/Functional-programming/#how-do-i-pass-a-method-as-a-parameter-in-python","text":"\u770b\u4e86\u8fd9\u4e9b\u56de\u7b54\uff0c\u8fd9\u4e2a\u5177\u6709\u542f\u53d1\u610f\u4e49\uff1a https://stackoverflow.com/a/706744 \uff1b functions (and methods) are first class objects in Python\u3002","title":"How do I pass a method as a parameter in Python"},{"location":"Python/Paradigm/Meta-programming/Reflective/Python-reflection/","text":"Python Programming/Reflection type isinstance issubclass Duck typing callable dir getattr Keywords Built-ins External links Python Programming/Reflection A Python script can find out about the type, class, attributes and methods of an object. This is referred to as reflection or introspection . See also Metaclasses . Reflection-enabling functions include type() , isinstance() , callable() , dir() and getattr() . type The type method enables to find out about the type of an object. The following tests return True: type ( 3 ) is int type ( 3.0 ) is float type ( 10 ** 10 ) is long # Python 2 type ( 1 + 1j ) is complex type ( 'Hello' ) is str type ([ 1 , 2 ]) is list type ([ 1 , [ 2 , 'Hello' ]]) is list type ({ 'city' : 'Paris' }) is dict type (( 1 , 2 )) is tuple type ( set ()) is set type ( frozenset ()) is frozenset type ( 3 ) . __name__ == \"int\" type ( 'Hello' ) . __name__ == \"str\" import types , re , Tkinter # For the following examples type ( re ) is types . ModuleType type ( re . sub ) is types . FunctionType type ( Tkinter . Frame ) is types . ClassType type ( Tkinter . Frame ) . __name__ == \"classobj\" type ( Tkinter . Frame ()) . __name__ == \"instance\" type ( re . compile ( 'myregex' )) . __name__ == \"SRE_Pattern\" type ( type ( 3 )) is types . TypeType The type function disregards(\u5ffd\u89c6) class inheritance: \" type(3) is object \" yields False while \" isinstance(3, object) \" yields True. SUMMARY : \u5173\u4e8e type \u548c isinstance \u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u53c2\u89c1 programming-language-python/python-docs/The Python Standard Library/Built-in Functions Links: 2. Built-in Functions # type , python.org 8.15. types \u2014 Names for built-in types , python.org isinstance Determines whether an object is an instance of a type or class. The following tests return True: isinstance ( 3 , int ) isinstance ([ 1 , 2 ], list ) isinstance ( 3 , object ) isinstance ([ 1 , 2 ], object ) import tkinter ; isinstance ( tkinter . Frame (), tkinter . Frame ) import tkinter ; tkinter . Frame () . __class__ . __name__ == \"Frame\" Note that isinstance provides a weaker condition than a comparison using #Type . Function isinstance and a user-defined class: class Plant : pass # Dummy class class Tree ( Plant ): pass # Dummy class derived from Plant tree = Tree () # A new instance of Tree class print ( isinstance ( tree , Tree )) # True print ( isinstance ( tree , Plant )) # True print ( isinstance ( tree , object ) ) # True print ( type ( tree ) is Tree ) # False print ( type ( tree ) . __name__ == \"instance\" ) # True print ( tree . __class__ . __name__ == \"Tree\" ) # True Links: Built-in Functions # isinstance , python.org isinstance() considered harmful , canonical.org issubclass Determines whether a class is a subclass of another class. Pertains to classes, not their instances. class Plant : pass # Dummy class class Tree ( Plant ): pass # Dummy class derived from Plant tree = Tree () # A new instance of Tree class print ( issubclass ( Tree , Plant ) ) # True print ( issubclass ( Tree , object ) ) # False in Python 2 print ( issubclass ( int , object ) ) # True print ( issubclass ( bool , int ) ) # True print ( issubclass ( int , int )) # True print ( issubclass ( tree , Plant )) # Error - tree is not a class Duck typing Duck typing provides an indirect means of reflection . It is a technique consisting in using an object as if it was of the requested type, while catching exceptions resulting from the object not supporting some of the features of the class or type. Links: Glossary # duck-typing , python.org callable For an object, determines whether it can be called. A class can be made callable by providing a __call__() method. Examples: callable(2) Returns False. Ditto for callable(\"Hello\") and callable([1, 2]). callable([1,2].pop) Returns True, as pop without \"()\" returns a function object. callable([1,2].pop()) Returns False, as [1,2].pop() returns 2 rather than a function object. Links: Built-in Functions # callable , python.org dir Returns the list of names of attributes of an object, which includes methods. Is somewhat heuristic and possibly incomplete, as per python.org. Examples: dir(3) dir(\"Hello\") dir([1, 2]) import re; dir(re) Lists names of functions and other objects available in the re module for regular expressions. Links: Built-in Functions # dir , python.org getattr Returns the value of an attribute of an object, given the attribute name passed as a string. An example: getattr(3, \"imag\") The list of attributes of an object can be obtained using #Dir . Links: Built-in Functions # getattr , python.org Keywords A list of Python keywords can be obtained from Python: import keyword pykeywords = keyword . kwlist print ( keyword . iskeyword ( \"if\" ) ) # True print ( keyword . iskeyword ( \"True\" )) # False Links: 32.6. keyword \u2014 Testing for Python keywords , python.org Built-ins A list of Python built-in objects and functions can be obtained from Python: print ( dir ( __builtins__ ) ) # Output the list print ( type ( __builtins__ . list )) # = <type 'type'> print ( type ( __builtins__ . open ) ) # = <type 'builtin_function_or_method'> print ( list is __builtins__ . list ) # True print ( open is __builtins__ . open ) # True Links: 28.3. __builtin__ \u2014 Built-in objects , python.org Built-in Functions # dir , python.org External links 2. Built-in Functions , docs.python.org How to determine the variable type in Python? , stackoverflow.com Differences between isinstance() and type() in python , stackoverflow.com W:Reflection (computer_programming)#Python , Wikipedia W:Type introspection#Python , Wikipedia","title":"Python-reflection"},{"location":"Python/Paradigm/Meta-programming/Reflective/Python-reflection/#python-programmingreflection","text":"A Python script can find out about the type, class, attributes and methods of an object. This is referred to as reflection or introspection . See also Metaclasses . Reflection-enabling functions include type() , isinstance() , callable() , dir() and getattr() .","title":"Python Programming/Reflection"},{"location":"Python/Paradigm/Meta-programming/Reflective/Python-reflection/#type","text":"The type method enables to find out about the type of an object. The following tests return True: type ( 3 ) is int type ( 3.0 ) is float type ( 10 ** 10 ) is long # Python 2 type ( 1 + 1j ) is complex type ( 'Hello' ) is str type ([ 1 , 2 ]) is list type ([ 1 , [ 2 , 'Hello' ]]) is list type ({ 'city' : 'Paris' }) is dict type (( 1 , 2 )) is tuple type ( set ()) is set type ( frozenset ()) is frozenset type ( 3 ) . __name__ == \"int\" type ( 'Hello' ) . __name__ == \"str\" import types , re , Tkinter # For the following examples type ( re ) is types . ModuleType type ( re . sub ) is types . FunctionType type ( Tkinter . Frame ) is types . ClassType type ( Tkinter . Frame ) . __name__ == \"classobj\" type ( Tkinter . Frame ()) . __name__ == \"instance\" type ( re . compile ( 'myregex' )) . __name__ == \"SRE_Pattern\" type ( type ( 3 )) is types . TypeType The type function disregards(\u5ffd\u89c6) class inheritance: \" type(3) is object \" yields False while \" isinstance(3, object) \" yields True. SUMMARY : \u5173\u4e8e type \u548c isinstance \u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u53c2\u89c1 programming-language-python/python-docs/The Python Standard Library/Built-in Functions Links: 2. Built-in Functions # type , python.org 8.15. types \u2014 Names for built-in types , python.org","title":"type"},{"location":"Python/Paradigm/Meta-programming/Reflective/Python-reflection/#isinstance","text":"Determines whether an object is an instance of a type or class. The following tests return True: isinstance ( 3 , int ) isinstance ([ 1 , 2 ], list ) isinstance ( 3 , object ) isinstance ([ 1 , 2 ], object ) import tkinter ; isinstance ( tkinter . Frame (), tkinter . Frame ) import tkinter ; tkinter . Frame () . __class__ . __name__ == \"Frame\" Note that isinstance provides a weaker condition than a comparison using #Type . Function isinstance and a user-defined class: class Plant : pass # Dummy class class Tree ( Plant ): pass # Dummy class derived from Plant tree = Tree () # A new instance of Tree class print ( isinstance ( tree , Tree )) # True print ( isinstance ( tree , Plant )) # True print ( isinstance ( tree , object ) ) # True print ( type ( tree ) is Tree ) # False print ( type ( tree ) . __name__ == \"instance\" ) # True print ( tree . __class__ . __name__ == \"Tree\" ) # True Links: Built-in Functions # isinstance , python.org isinstance() considered harmful , canonical.org","title":"isinstance"},{"location":"Python/Paradigm/Meta-programming/Reflective/Python-reflection/#issubclass","text":"Determines whether a class is a subclass of another class. Pertains to classes, not their instances. class Plant : pass # Dummy class class Tree ( Plant ): pass # Dummy class derived from Plant tree = Tree () # A new instance of Tree class print ( issubclass ( Tree , Plant ) ) # True print ( issubclass ( Tree , object ) ) # False in Python 2 print ( issubclass ( int , object ) ) # True print ( issubclass ( bool , int ) ) # True print ( issubclass ( int , int )) # True print ( issubclass ( tree , Plant )) # Error - tree is not a class","title":"issubclass"},{"location":"Python/Paradigm/Meta-programming/Reflective/Python-reflection/#duck-typing","text":"Duck typing provides an indirect means of reflection . It is a technique consisting in using an object as if it was of the requested type, while catching exceptions resulting from the object not supporting some of the features of the class or type. Links: Glossary # duck-typing , python.org","title":"Duck typing"},{"location":"Python/Paradigm/Meta-programming/Reflective/Python-reflection/#callable","text":"For an object, determines whether it can be called. A class can be made callable by providing a __call__() method. Examples: callable(2) Returns False. Ditto for callable(\"Hello\") and callable([1, 2]). callable([1,2].pop) Returns True, as pop without \"()\" returns a function object. callable([1,2].pop()) Returns False, as [1,2].pop() returns 2 rather than a function object. Links: Built-in Functions # callable , python.org","title":"callable"},{"location":"Python/Paradigm/Meta-programming/Reflective/Python-reflection/#dir","text":"Returns the list of names of attributes of an object, which includes methods. Is somewhat heuristic and possibly incomplete, as per python.org. Examples: dir(3) dir(\"Hello\") dir([1, 2]) import re; dir(re) Lists names of functions and other objects available in the re module for regular expressions. Links: Built-in Functions # dir , python.org","title":"dir"},{"location":"Python/Paradigm/Meta-programming/Reflective/Python-reflection/#getattr","text":"Returns the value of an attribute of an object, given the attribute name passed as a string. An example: getattr(3, \"imag\") The list of attributes of an object can be obtained using #Dir . Links: Built-in Functions # getattr , python.org","title":"getattr"},{"location":"Python/Paradigm/Meta-programming/Reflective/Python-reflection/#keywords","text":"A list of Python keywords can be obtained from Python: import keyword pykeywords = keyword . kwlist print ( keyword . iskeyword ( \"if\" ) ) # True print ( keyword . iskeyword ( \"True\" )) # False Links: 32.6. keyword \u2014 Testing for Python keywords , python.org","title":"Keywords"},{"location":"Python/Paradigm/Meta-programming/Reflective/Python-reflection/#built-ins","text":"A list of Python built-in objects and functions can be obtained from Python: print ( dir ( __builtins__ ) ) # Output the list print ( type ( __builtins__ . list )) # = <type 'type'> print ( type ( __builtins__ . open ) ) # = <type 'builtin_function_or_method'> print ( list is __builtins__ . list ) # True print ( open is __builtins__ . open ) # True Links: 28.3. __builtin__ \u2014 Built-in objects , python.org Built-in Functions # dir , python.org","title":"Built-ins"},{"location":"Python/Paradigm/Meta-programming/Reflective/Python-reflection/#external-links","text":"2. Built-in Functions , docs.python.org How to determine the variable type in Python? , stackoverflow.com Differences between isinstance() and type() in python , stackoverflow.com W:Reflection (computer_programming)#Python , Wikipedia W:Type introspection#Python , Wikipedia","title":"External links"},{"location":"Python/Pattern/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u5bf9python programming language\u4e2d\u7684\u5e38\u7528\u7684design pattern\u8fdb\u884c\u603b\u7ed3\u3002","title":"Introduction"},{"location":"Python/Pattern/#_1","text":"\u672c\u7ae0\u5bf9python programming language\u4e2d\u7684\u5e38\u7528\u7684design pattern\u8fdb\u884c\u603b\u7ed3\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Python/Philosophy/The-Zen-of-Python/","text":"PEP 20 -- The-Zen-of- Python","title":"The-Zen-of-Python"},{"location":"Python/Programming-tool/Lint/Pylint/","text":"Pylint","title":"Pylint"},{"location":"Python/Programming-tool/Lint/Pylint/#pylint","text":"","title":"Pylint"},{"location":"Python/Programming-tool/Lint/Python-lints/","text":"PyLint, PyChecker or PyFlakes What does '# noqa' mean in Python comments?","title":"Python-lints"},{"location":"Python/Programming-tool/Lint/Python-lints/#pylint-pychecker-or-pyflakes","text":"","title":"PyLint, PyChecker or PyFlakes"},{"location":"Python/Programming-tool/Lint/Python-lints/#what-does-noqa-mean-in-python-comments","text":"","title":"What does '# noqa' mean in Python comments?"},{"location":"Python/Software/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u63cf\u8ff0\u6211\u6709\u4e9b\u7814\u7a76\u7684python package\u3002","title":"Introduction"},{"location":"Python/Software/#_1","text":"\u672c\u7ae0\u63cf\u8ff0\u6211\u6709\u4e9b\u7814\u7a76\u7684python package\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Python/Software/Software-concurrency/Greenlet/Greenlet/","text":"greenlet","title":"Greenlet"},{"location":"Python/Software/Software-concurrency/Greenlet/Greenlet/#greenlet","text":"","title":"greenlet"},{"location":"Python/Software/Software-event-driven-programming/","text":"","title":"Introduciton"},{"location":"Python/Software/Software-event-driven-programming/Eevent/Gevent/","text":"gevent","title":"Gevent"},{"location":"Python/Software/Software-event-driven-programming/Eevent/Gevent/#gevent","text":"","title":"gevent"},{"location":"Python/Software/Software-event-driven-programming/Eventlet/Eventlet/","text":"eventlet","title":"Eventlet"},{"location":"Python/Software/Software-event-driven-programming/Eventlet/Eventlet/#eventlet","text":"","title":"eventlet"},{"location":"Python/Software/software-pallets/flask/Deployment-Options/blog-Serving-Flask-with-Nginx/","text":"Serving Flask with Nginx Serving Flask with Nginx","title":"blog Serving Flask with Nginx"},{"location":"Python/Software/software-pallets/flask/Deployment-Options/blog-Serving-Flask-with-Nginx/#serving-flask-with-nginx","text":"","title":"Serving Flask with Nginx"},{"location":"Python/Software/software-pallets/flask/Deployment-Options/flask-Deployment-Options-Self-hosted options-FastCGI/","text":"FastCGI\u00b6 FastCGI \u00b6 FastCGI is a deployment option on servers like nginx , lighttpd , and cherokee ; see uWSGI and Standalone WSGI Containers for other options. To use your WSGI application with any of them you will need a FastCGI server first. The most popular one is flup which we will use for this guide. Make sure to have it installed to follow along.","title":"flask Deployment Options Self hosted options FastCGI"},{"location":"Python/Software/software-pallets/flask/Deployment-Options/flask-Deployment-Options-Self-hosted options-FastCGI/#fastcgi","text":"FastCGI is a deployment option on servers like nginx , lighttpd , and cherokee ; see uWSGI and Standalone WSGI Containers for other options. To use your WSGI application with any of them you will need a FastCGI server first. The most popular one is flup which we will use for this guide. Make sure to have it installed to follow along.","title":"FastCGI\u00b6"},{"location":"Python/Software/software-pallets/flask/Deployment-Options/flask-Deployment-Options-Self-hosted options-uWSGI/","text":"uWSGI\u00b6 Starting your app with uwsgi\u00b6 Configuring nginx\u00b6 uWSGI \u00b6 uWSGI is a deployment option on servers like nginx , lighttpd , and cherokee ; see FastCGI and Standalone WSGI Containers for other options. To use your WSGI application with uWSGI protocol you will need a uWSGI server first. uWSGI is both a protocol and an application server; the application server can serve uWSGI, FastCGI, and HTTP protocols. The most popular uWSGI server is uwsgi , which we will use for this guide. Make sure to have it installed to follow along. Watch Out Please make sure in advance that any app.run() calls you might have in your application file are inside an if __name__ =='__main__': block or moved to a separate file. Just make sure it\u2019s not called because this will always start a local WSGI server which we do not want if we deploy that application to uWSGI. Starting your app with uwsgi \u00b6 uwsgi is designed to operate on WSGI callables found in python modules. Given a flask application in myapp.py , use the following command: $ uwsgi - s / tmp / yourapplication . sock -- manage - script - name -- mount / yourapplication = myapp : app The --manage-script-name will move the handling of SCRIPT_NAME to uwsgi, since it is smarter about that. It is used together with the --mount directive which will make requests to /yourapplication be directed to myapp:app . If your application is accessible at root level, you can use a single / instead of /yourapplication . myapp refers to the name of the file of your flask application (without extension) or the module which provides app . app is the callable inside of your application (usually the line reads app = Flask(__name__) . If you want to deploy your flask application inside of a virtual environment, you need to also add --virtualenv/path/to/virtual/environment . You might also need to add --plugin python or --plugin python3 depending on which python version you use for your project. Configuring nginx \u00b6 A basic flask nginx configuration looks like this: location = /yourapplication { rewrite ^ /yourapplication/; } location /yourapplication { try_files $uri @yourapplication; } location @yourapplication { include uwsgi_params; uwsgi_pass unix:/tmp/yourapplication.sock; } This configuration binds the application to /yourapplication . If you want to have it in the URL root its a bit simpler: location / { try_files $uri @yourapplication; } location @yourapplication { include uwsgi_params; uwsgi_pass unix:/tmp/yourapplication.sock; }","title":"flask Deployment Options Self hosted options uWSGI"},{"location":"Python/Software/software-pallets/flask/Deployment-Options/flask-Deployment-Options-Self-hosted options-uWSGI/#uwsgi","text":"uWSGI is a deployment option on servers like nginx , lighttpd , and cherokee ; see FastCGI and Standalone WSGI Containers for other options. To use your WSGI application with uWSGI protocol you will need a uWSGI server first. uWSGI is both a protocol and an application server; the application server can serve uWSGI, FastCGI, and HTTP protocols. The most popular uWSGI server is uwsgi , which we will use for this guide. Make sure to have it installed to follow along. Watch Out Please make sure in advance that any app.run() calls you might have in your application file are inside an if __name__ =='__main__': block or moved to a separate file. Just make sure it\u2019s not called because this will always start a local WSGI server which we do not want if we deploy that application to uWSGI.","title":"uWSGI\u00b6"},{"location":"Python/Software/software-pallets/flask/Deployment-Options/flask-Deployment-Options-Self-hosted options-uWSGI/#starting-your-app-with-uwsgi","text":"uwsgi is designed to operate on WSGI callables found in python modules. Given a flask application in myapp.py , use the following command: $ uwsgi - s / tmp / yourapplication . sock -- manage - script - name -- mount / yourapplication = myapp : app The --manage-script-name will move the handling of SCRIPT_NAME to uwsgi, since it is smarter about that. It is used together with the --mount directive which will make requests to /yourapplication be directed to myapp:app . If your application is accessible at root level, you can use a single / instead of /yourapplication . myapp refers to the name of the file of your flask application (without extension) or the module which provides app . app is the callable inside of your application (usually the line reads app = Flask(__name__) . If you want to deploy your flask application inside of a virtual environment, you need to also add --virtualenv/path/to/virtual/environment . You might also need to add --plugin python or --plugin python3 depending on which python version you use for your project.","title":"Starting your app with uwsgi\u00b6"},{"location":"Python/Software/software-pallets/flask/Deployment-Options/flask-Deployment-Options-Self-hosted options-uWSGI/#configuring-nginx","text":"A basic flask nginx configuration looks like this: location = /yourapplication { rewrite ^ /yourapplication/; } location /yourapplication { try_files $uri @yourapplication; } location @yourapplication { include uwsgi_params; uwsgi_pass unix:/tmp/yourapplication.sock; } This configuration binds the application to /yourapplication . If you want to have it in the URL root its a bit simpler: location / { try_files $uri @yourapplication; } location @yourapplication { include uwsgi_params; uwsgi_pass unix:/tmp/yourapplication.sock; }","title":"Configuring nginx\u00b6"},{"location":"Python/Software/software-pallets/flask/Deployment-Options/flask-Deployment-Options-Self-hosted options/","text":"Self-hosted options\u00b6 FastCGI\u00b6 Self-hosted options \u00b6 FastCGI \u00b6","title":"flask Deployment Options Self hosted options"},{"location":"Python/Software/software-pallets/flask/Deployment-Options/flask-Deployment-Options-Self-hosted options/#self-hosted-options","text":"","title":"Self-hosted options\u00b6"},{"location":"Python/Software/software-pallets/flask/Deployment-Options/flask-Deployment-Options-Self-hosted options/#fastcgi","text":"","title":"FastCGI\u00b6"},{"location":"Python/Software/software-pallets/flask/Deployment-Options/flask-Deployment-Options/","text":"Deployment Options\u00b6 Deployment Options \u00b6 While lightweight and easy to use, Flask\u2019s built-in server is not suitable for production as it doesn\u2019t scale well. Some of the options available for properly running Flask in production are documented here. If you want to deploy your Flask application to a WSGI server not listed here, look up the server documentation about how to use a WSGI app with it. Just remember that your Flask application object is the actual WSGI application.","title":"flask-Deployment-Options"},{"location":"Python/Software/software-pallets/flask/Deployment-Options/flask-Deployment-Options/#deployment-options","text":"While lightweight and easy to use, Flask\u2019s built-in server is not suitable for production as it doesn\u2019t scale well. Some of the options available for properly running Flask in production are documented here. If you want to deploy your Flask application to a WSGI server not listed here, look up the server documentation about how to use a WSGI app with it. Just remember that your Flask application object is the actual WSGI application.","title":"Deployment Options\u00b6"},{"location":"Python/Software/software-static-web-generator/static-web-generator/","text":"\u5982\u4e0b\u662f python\u4e16\u754c\u4e2d\u7684\u4e00\u4e9bstatic website generator \uff1a Pelican mkdocs \u4f7f\u7528\u8fd9\u4e9b\u5de5\u5177\u751f\u6210static website\u540e\u9700\u8981\u8003\u8651\u7684\u95ee\u9898\u5c31\u662f\u5982\u4f55\u8fdb\u884c\u90e8\u7f72\uff0c\u5982\u4e0b\u662f\u4e00\u4e9b\u90e8\u7f72\u65b9\u6848\uff1a Nginx GitHub Pages readthedocs","title":"Static-web-generator"},{"location":"Python/Style-guide/Style-Guide-for-Python-Code/","text":"PEP 8 -- Style Guide for Python Code","title":"Style-Guide-for-Python-Code"},{"location":"Python/Style-guide/Style-Guide-for-Python-Code/#pep-8-style-guide-for-python-code","text":"","title":"PEP 8 -- Style Guide for Python Code"},{"location":"Python/TODO/20190924-TODO/","text":"PYTHON SIGNINT\u548cSIGKILL\u4e4b\u95f4\u7684\u5dee\u5f02\uff1aSIGNINT\u4f1a\u89e6\u53d1 __del__ \uff0c\u4f46\u662fSIGKILL\u4e0d\u4f1a\u89e6\u53d1 __del__ \u7684\u6267\u884c\u3002","title":"PYTHON"},{"location":"Python/TODO/20190924-TODO/#python","text":"SIGNINT\u548cSIGKILL\u4e4b\u95f4\u7684\u5dee\u5f02\uff1aSIGNINT\u4f1a\u89e6\u53d1 __del__ \uff0c\u4f46\u662fSIGKILL\u4e0d\u4f1a\u89e6\u53d1 __del__ \u7684\u6267\u884c\u3002","title":"PYTHON"},{"location":"Python/TODO/python-SQLalchemy-TODO/","text":"SQLalchemy\u4e2d\u6d89\u53ca\u5230\u4e86\u5927\u91cf\u7684\u5173\u4e8eDBMS\u7684\u7406\u8bba\u77e5\u8bc6\uff0c\u9700\u8981\u540e\u7eed\u4e86\u89e3\u4e00\u4e0b\uff1a \u5728Overview \u00b6 \u4e2d\uff0c\u8c08\u53ca\u4e86In contrast to the ORM\u2019s domain-centric mode of usage, the expression language provides a schema-centric usage paradigm. \u5176\u4e2d\u6d89\u53ca\u4e86\u4e24\u4e2a\u6982\u5ff5\uff1adomain\u548cschema\uff1b\u663e\u7136\u628a\u63e1\u8fd9\u4e24\u4e2a\u6982\u5ff5\u662f\u7406\u89e3SQLalchemy\u7684\u57fa\u7840\uff1b Database schema Domain-first vs. Schema-first Architecting \u4fee\u6539\u8868\u7ed3\u6784\u540e\u5c06\u4fee\u6539\u540c\u6b65\u5230\u6570\u636e\u5e93\u4e2d","title":"python SQLalchemy TODO"},{"location":"Python/TODO/python-SQLalchemy-TODO/#database-schema","text":"","title":"Database schema"},{"location":"Python/TODO/python-SQLalchemy-TODO/#domain-first-vs-schema-first-architecting","text":"","title":"Domain-first vs. Schema-first Architecting"},{"location":"Python/TODO/python-SQLalchemy-TODO/#_1","text":"","title":"\u4fee\u6539\u8868\u7ed3\u6784\u540e\u5c06\u4fee\u6539\u540c\u6b65\u5230\u6570\u636e\u5e93\u4e2d"},{"location":"Python/TODO/python-TODO/","text":"python \u591a\u7ee7\u627f python lazy-loading module python dir() What is __future__ in Python used for and how/when to use it, and how it works python with \u589e\u5f3a\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027 c++ named requirement and python protocol \u5bf9\u6bd4python\u7684language reference\u548cc++\u7684language reference iterator generator iterable, awaitable python class attribute and instance attribute and attribute reference python exception python \u4e2dyield\u7684\u51c6\u786e\u542b\u4e49\uff0c\u5230\u5e95\u662f**\u4ea7\u751f**\uff0c\u8fd8\u662f**\u8ba9\u6e21** python dict python combine two dict python assign the same value to a dict python use member variable as default argument of member function python cache python \u6784\u9020list\u7684\u65b9\u6cd5\u5bf9\u6bd4 python \u4e2d\u7684\u521b\u5efa\u6587\u4ef6\u7684\u65f6\u5019\u7684\u6743\u9650\u5b57\u6bb5\u4e3a\u4ec0\u4e48\u662f0o\u5373\u516b\u8fdb\u5236\u5462\uff1f getpass.getuser()\u6587\u6863\u4e2d\u7684\u4e00\u4e9b\u5185\u5bb9 os.makedirs automated testing python-determine-the-size-of-object six and 2to3 DEFAULT ARGUMENTS LEGB Understanding UnboundLocalError in Python What are metaclasses in Python? python object \u548c type debug in python python reflection python __builtin__ class\u7684scope Python Programming/Metaclasses python tuple Why should you use namedtuple instead of a tuple? python execution model and variable and scope python setInterval python ajax equivalent ajax and promise python classmethod property \u9759\u6001\u6210\u5458\u53d8\u91cf\u7684\u5bb9\u5668 json.dumps vs flask.jsonify python interpreter\u662f\u5982\u4f55\u4e86\u6765compile function\u7684\uff1f python\u7684dynamic \u4e00\u4e2a\u5c0f\u4f8b\u5b50 rebind argument in function body functools \u2014 Higher-order functions and operations on callable objects\u00b6 Redis in python, how do you close the connection? How to flatten nested python dictionaries? python type system 20190429 python debugger python build_in format input operation with transaction build_in print, repr and special method __str__ and __repr__ list().append(stock_market) python iter and getitem python\u4e2d\u7684\u5e76\u53d1\u65b9\u5f0f How to make a flat list out of list of lists? value type of a dict is list raise error Python: Find in list for\u8bed\u53e5\u7684\u6267\u884c python str to float for and \u4e09\u5143\u8868\u8fbe\u5f0f python iterable and iteration iteration and deletion python min and max of integer python \u591a\u7ee7\u627f \u591a\u7ee7\u627f\u7684\u65f6\u5019\uff0c\u5b50\u7c7b __init__ \u51fd\u6570\u5982\u4f55\u6765\u8c03\u7528\u57fa\u7c7b\u7684 __init__ \u51fd\u6570 python lazy-loading module \u5728GitHub python-in-action\u4e2d\u5df2\u7ecf\u521b\u5efa\u4e86\u6e90\u4ee3\u7801\uff0c\u5728\u672c\u5730\u7684 programming-language-python/pattern/lazy_import/ \u4e2d\uff0c\u8fd8\u6709\u4e00\u4e9b\u7406\u8bba\u77e5\u8bc6\u9700\u8981\u5b66\u4e60\uff1b python dir() https://docs.python.org/3/library/functions.html#dir What is __future__ in Python used for and how/when to use it, and how it works https://stackoverflow.com/questions/7075082/what-is-future-in-python-used-for-and-how-when-to-use-it-and-how-it-works https://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/001386820023084e5263fe54fde4e4e8616597058cc4ba1000 python with python with and scope \u4ee5\u4e0b\u9762\u7684\u4ee3\u7801\u4e3a\u4f8b\uff1a x = tf . constant ([[ 37.0 , - 23.0 ], [ 1.0 , 4.0 ]]) w = tf . Variable ( tf . random_uniform ([ 2 , 2 ])) y = tf . matmul ( x , w ) output = tf . nn . softmax ( y ) init_op = w . initializer with tf . Session () as sess : # Run the initializer on `w`. sess . run ( init_op ) # Evaluate `output`. `sess.run(output)` will return a NumPy array containing # the result of the computation. print ( sess . run ( output )) # Evaluate `y` and `output`. Note that `y` will only be computed once, and its # result used both to return `y_val` and as an input to the `tf.nn.softmax()` # op. Both `y_val` and `output_val` will be NumPy arrays. y_val , output_val = sess . run ([ y , output ]) \u5176\u5b9e\u5728 with \u7684\u5916\u5c42\u662f\u53ef\u4ee5\u8bbf\u95ee\u5728 with \u4e2d\u5b9a\u4e49\u7684\u53d8\u91cf\u7684\uff0c\u4f46\u662f\u5728 c++ \u4e2d\uff0c\u6bd4\u5982\u662f for \uff0c\u5219\u5728 for \u7684\u5916\u5c42\u662f\u65e0\u6cd5\u8bbf\u95ee\u5230\u5728 for \u5185\u90e8\u5b9a\u4e49\u7684\u53d8\u91cf\u7684\uff1b \u589e\u5f3a\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027 tf.register_tensor_conversion_function \u8bb0\u5f97\u5728 py-mysql \u4e2d\u4e5f\u6709\u7c7b\u4f3c\u7684\u51fd\u6570\u3002 c++ named requirement and python protocol \u5bf9\u6bd4python\u7684language reference\u548c c++ \u7684language reference python expression\u548c c++ expression python statement and c++ expression iterator generator iterable, awaitable python class attribute and instance attribute and attribute reference In [11]: class Test: ...: t=1 ...: def __init__(self,t=None): ...: print(self.t) ...: print(id(self.t)) ...: self.t=t if t else self.t ...: print(self.t) ...: print(id(self.t)) ...: ...: In [12]: t=Test(4) 1 139713319475648 4 139713319475744 In [13]: t=Test(4) 1 139713319475648 4 139713319475744 In [9]: t.t Out[9]: 4 In [10]: Test.t Out[10]: 1 \u4e0a\u8ff0\u4f8b\u5b50\u4f53\u73b0\u4e86python\u4e2d\u7684attribute reference \u548c class attribute \u548c instance attribute\u4e4b\u95f4\u7684\u5173\u7cfb\uff1b python exception python \u4e2d yield \u7684\u51c6\u786e\u542b\u4e49\uff0c\u5230\u5e95\u662f**\u4ea7\u751f**\uff0c\u8fd8\u662f**\u8ba9\u6e21** python dict python combine two dict https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression python assign the same value to a dict https://stackoverflow.com/questions/2974022/is-it-possible-to-assign-the-same-value-to-multiple-keys-in-a-dict-object-at-onc python use member variable as default argument of member function https://nikos7am.com/posts/mutable-default-arguments/ python cache python \u6784\u9020list\u7684\u65b9\u6cd5\u5bf9\u6bd4 list(1) \u4f1a\u629b\u51fa\u5f02\u5e38 TypeError: 'int' object is not iterable \uff0c\u4f46\u662f [1] \u5374\u80fd\u591f\u6b63\u5e38\uff1b\u5982\u679c\u6ca1\u6709\u8bb0\u9519\u7684\u8bdd\uff0c\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u53eb\u505adisplay; python \u4e2d\u7684\u521b\u5efa\u6587\u4ef6\u7684\u65f6\u5019\u7684\u6743\u9650\u5b57\u6bb5\u4e3a\u4ec0\u4e48\u662f 0o \u5373\u516b\u8fdb\u5236\u5462\uff1f getpass.getuser()\u6587\u6863\u4e2d\u7684\u4e00\u4e9b\u5185\u5bb9 https://docs.python.org/3/library/getpass.html os.makedirs https://docs.python.org/3/library/os.html#os.makedirs https://stackoverflow.com/questions/5210778/elegant-way-to-make-all-dirs-in-a-path automated testing python\u5982\u4f55\u5b9e\u73b0automated testing python-determine-the-size-of-object https://stackoverflow.com/questions/449560/how-do-i-determine-the-size-of-an-object-in-python keyword-only arguments, chained exceptions, yield from, and enums. six and 2to3 DEFAULT ARGUMENTS SMARTER DEFAULT ARGUMENTS (PYTHON RECIPE) http://code.activestate.com/recipes/577786-smarter-default-arguments/ LEGB Understanding UnboundLocalError in Python https://eli.thegreenplace.net/2011/05/15/understanding-unboundlocalerror-in-python What are metaclasses in Python? python object \u548c type class T: pass T.__bases__ Out[22]: (object,) T.__class__ Out[14]: type i=T() i.__class__ Out[16]: __main__.T debug in python https://stackoverflow.com/questions/16867347/step-by-step-debugging-with-ipython \u672c\u5730\u5df2\u7ecf\u6536\u5f55\u4e86IPython-debug https://github.com/cool-RR/PySnooper python reflection https://www.bnmetrics.com/blog/introspection-reflection-in-python https://www.geeksforgeeks.org/reflection-in-python/ https://docs.python.org/3.7/c-api/reflection.html python __builtin__ \u8fd9\u6d89\u53ca\u5230\u4e86\uff1a python 2\u4e2d\u7684 __builtin__ \u6a21\u5757 dir() \u8fd4\u56de\u7684\u6210\u5458\u4e2d\u5305\u542b\u6709 __builtins__ \u5728\u8fd9\u7bc7\u6587\u7ae0\u4e2d\u7ed9\u51fa\u4e86\u89e3\u7b54 Where is the __builtin__ module in Python3? Why was it renamed? class\u7684scope class PredictionField : PREDICT_TIME = 'predict_time' PREDICT_VALUE = 'predict_value' PREDICT_PROB_RISE = 'predict_prob_rise' PREDICT_PROB_FALL = 'predict_prob_fall' PREDICT_PROB_FLAT = 'predict_prob_flat' ALL_FIELDS = [ getattr ( PredictionField , x ) for x in dir ( PredictionField ) if not x . startswith ( \"__\" )] \u62a5\u9519\u5982\u4e0b\uff1a < ipython - input - 1 - edae3ab18252 > in PredictionField () 1 class PredictionField : 2 PREDICT_TIME = 'predict_time' ----> 3 ALL_FIELDS = tuple ( getattr ( PredictionField , x ) for x in dir ( PredictionField ) if x . startswith ( \"PREDICT\" )) 4 NameError : name 'PredictionField' is not defined Python Programming/Metaclasses https://en.wikibooks.org/wiki/Python_Programming/Metaclasses python tuple tuple ( 1 , 2 , 3 ) --------------------------------------------------------------------------- TypeError Traceback ( most recent call last ) < ipython - input - 24 - 3e233 cfc2777 > in < module > () ----> 1 tuple ( 1 , 2 , 3 ) TypeError : tuple () takes at most 1 argument ( 3 given ) Why should you use namedtuple instead of a tuple? python execution model and variable and scope def outer(): a = 9 def inner(): print(a) inner() print(a) def outer(): a = 9 def inner(): a = 10 print(a) inner() print(a) def outer(): a = 9 def inner(): print(a) a = 10 inner() print(a) def outer(): def inner(): a = 10 print(a) \u601d\u8003\u4e00\u4e2a\u95ee\u9898\uff1apython\u89e3\u91ca\u5668\u5728\u7f16\u8bd1\u51fd\u6570\u7684\u65f6\u5019\uff0c\u662f\u5426\u4f1a\u5c06\u8be5\u51fd\u6570\u7684\u6240\u6709local variable\u90fd\u4fdd\u5b58\u5230\u8be5\u51fd\u6570\u7684namespace\u4e2d\uff1f python setInterval python setinterval equivalent celery\u4e2d\u7684Periodic Tasks \u00b6 \u4e5f\u662f\u4e00\u79cdsetinterval python ajax equivalent ajax\u672c\u8d28\u6765\u8bf4\u662f\u4e00\u79cd\u5f02\u6b65\uff0c\u662f\u4e00\u79cdpromise\uff1bpython\u4e2d\u5e94\u8be5\u6709 ajax and promise python classmethod property \u9759\u6001\u6210\u5458\u53d8\u91cf\u7684\u5bb9\u5668 class PredictionField : PREDICT_TIME = 'predict_time' PREDICT_VALUE = 'predict_value' PREDICT_PROB_RISE = 'predict_prob_rise' PREDICT_PROB_FALL = 'predict_prob_fall' PREDICT_PROB_FLAT = 'predict_prob_flat' ALL_FIELDS = tuple ( getattr ( PredictionField , x ) for x in dir ( PredictionField ) if x . startswith ( \"PREDICT\" )) \u4e0a\u8ff0\u4ee3\u7801\u662f\u5b58\u5728\u9519\u8bef\u7684\uff0c\u4f46\u662f\u6211\u60f3\u8981\u5b9e\u73b0\u7c7b\u4f3c\u4e0a\u8ff0\u7684\u6548\u679c\uff1b \u56de\u5fc6\u8d77\u4e4b\u524d\u4f7f\u7528SQLalchemy\u7684\u7ecf\u9a8c\uff0cSQLalchemy\u4e2d\u5728\u5b9a\u4e49\u8868\u683c\u7684\u65f6\u5019\uff0c\u80af\u5b9a\u4f1a\u6709\u7c7b\u4f3c\u4e8e\u4e0a\u9762\u7684\u9700\u6c42\uff0c\u5373\u83b7\u53d6\u6240\u6709\u7684\u7c7b\u6210\u5458\u53d8\u91cf\uff1b json.dumps vs flask.jsonify https://stackoverflow.com/questions/7907596/json-dumps-vs-flask-jsonify http://flask.pocoo.org/docs/1.0/api/#module-flask.json python interpreter\u662f\u5982\u4f55\u4e86\u6765compile function\u7684\uff1f \u51fd\u6570\u7684local variable\u662f\u5426\u4f1a\u4fdd\u5b58\u5230function\u7684namespace\u4e2d\uff1f python\u7684dynamic \u9700\u8981\u603b\u7ed3python\u7684dynamic\u7279\u6027 google python dynamic https://stackoverflow.com/a/2829588 https://pythonconquerstheuniverse.wordpress.com/2009/10/03/static-vs-dynamic-typing-of-programming-languages/ https://wiki.python.org/moin/Why%20is%20Python%20a%20dynamic%20language%20and%20also%20a%20strongly%20typed%20language \u4e00\u4e2a\u5c0f\u4f8b\u5b50 def test (): def p (): print ( a ) a = 1 p () rebind argument in function body def extract_data ( quote_df , data_window ): if quote_df . shape [ 0 ] > data_window : quote_df = quote_df . tail ( data_window ) return quote_df functools \u2014 Higher-order functions and operations on callable objects \u00b6 Redis in python, how do you close the connection? How to flatten nested python dictionaries? [Aggregate Python lists stored as values in a nested dictionary into one list for arbitrary levels duplicate] python type system duck-typing \u65e2\u7136python\u662fduck-type\uff0c\u90a3\u4e48\u4e3a\u4ec0\u4e48python\u8fd8\u8981\u63d0\u4f9b ABC \u5462\uff1f \u5728 abstract base class \u5df2\u7ecf\u5c06\u8fd9\u4e2a\u95ee\u9898\u8bf4\u6e05\u4e86 https://docs.python.org/3.7/library/collections.abc.html 20190429 python\u7684\u52a8\u6001\u7279\u6027\u6240\u5e26\u6765\u7684\u95ee\u9898\uff1a\u6bd4\u5982\u5728\u7f16\u5199\u4e00\u4e2a\u51fd\u6570\u7684\u65f6\u5019\uff0c\u7531\u4e8epython lack declaration\uff0c\u6240\u4ee5\u6211\u4eec\u538b\u6839\u5c31\u4e0d\u77e5\u9053\u5165\u53c2\u7684\u7c7b\u578b\u662f\u4ec0\u4e48\uff0c\u53ea\u6709\u5230\u8fd0\u884c\u7684\u65f6\u5019\uff0c\u6211\u4eec\u624d\u80fd\u591f\u77e5\u9053\u5165\u53c2\u7684\u51c6\u786e\u7c7b\u578b\uff0c\u624d\u80fd\u591f\u5bf9\u5176\u8fdb\u884c\u51c6\u786e\u7684\u8fd0\u7528\uff0c\u800c\u5728programming\u9636\u6bb5\uff0c\u5bf9\u5176\u5b8c\u5168\u90fd\u662f\u6309\u7167\u5fc3\u4e2d\u7684\u9884\u671f\u8fdb\u884cprogramming\u7684\uff0c\u6240\u4ee5python\u7a0b\u5e8f\u5fc5\u987b\u8981\u8fdb\u884c\u5b8c\u6574\u7684\u6d4b\u8bd5\uff1b \u5e76\u4e14python\u7684\u8fd9\u79cd\u52a8\u6001\u7279\u6027\uff0c\u5e26\u6765\u4e86\u5927\u91cf\u7684\u7c7b\u4f3c\u4e0b\u9762\u8fd9\u6837\u7684\u4ee3\u7801\uff1a @classmethod def read ( cls , redis_conn , ml_model_sub_name , stock_market , reverse = True , fields = None , data_range = None , window = None , predict_time_as_index = True ): \"\"\" :param redis_conn: :param ml_model_sub_name: :param stock_market: :param reverse \u53c2\u89c1`class RedisStructureIOBase` doc :param fields \u53c2\u89c1`class PredictionField` :param data_range \u53c2\u89c1`class RedisStructureIOBase` doc :param window \u53c2\u89c1`class RedisStructureIOBase` doc :param predict_time_as_index:\u5c06predict_time\u5b57\u6bb5\u4f5c\u4e3a\u7d22\u5f15 :return: \"\"\" data_range = cls . convert_data_range ( reverse = reverse , data_range = data_range , window = window ) if fields is None : fields = [ PredictionField . PREDICT_VALUE ] if PredictionField . PREDICT_TIME in fields : fields = list ( fields ) fields . remove ( PredictionField . PREDICT_TIME ) \u91cd\u70b9\u770b\u6700\u540e\u4e24\u884c\uff0c\u6211\u7684\u76ee\u7684\u662f\u5982\u679c fields \u4e2d\u5305\u542b PredictionField.PREDICT_TIME \uff0c\u5219\u5c31\u9700\u8981\u5c06\u5176remove\u6389\uff0c\u4f46\u662f\u5982\u679c\u7528\u6237\u4f20\u5165\u7684\u662f tuple \uff0c\u5219\u5fc5\u987b\u8981\u5148\u5c06\u5176\u8f6c\u6362\u4e3a list \uff0c\u7136\u540e\u624d\u80fd\u591f\u8c03\u7528remove\uff0c\u56e0\u4e3atuple \u662funmutable\u7684\uff0c\u6545\u5176\u6ca1\u6709 remove \u65b9\u6cd5\uff1b \u663e\u7136\uff0c\u5982\u679c\u5728\u9759\u6001\u8bed\u8a00\u7684\u8bdd\uff0c\u5219\u5f53\u6211\u4eec\u5728\u51fd\u6570\u58f0\u660e\u4e2d\uff0c\u6307\u5b9a\u4e86\u5165\u53c2\u7684\u7c7b\u578b\uff0c\u5219\u5c31\u4e0d\u4f1a\u51fa\u73b0\u8fd9\u6837\u7684\u4e8b\u60c5\u4e86\uff1b \u7531\u6b64\u53ef\u89c1\uff0c\u52a8\u6001\u4e5f\u6709\u52a8\u6001\u7684\u5f0a\u7aef\u3002 python debugger pdb \u2014 The Python Debugger \u00b6 How to execute multi-line statements within Python's own debugger (PDB) python build_in format input https://docs.python.org/3/library/functions.html#input operation with transaction \u5728\u5411database\u4e2d\u52a0\u5165\u6279\u91cf\u6570\u636e\u7684\u65f6\u5019\uff0c\u6709\u65f6\u5019\u662f\u9700\u8981\u5b9e\u73b0transaction\u7684\uff0c\u5373\u5982\u679c\u5728\u6dfb\u52a0\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u4e86\u9519\u8bef\uff0c\u5728\u9700\u8981rollback\uff1b\u53ea\u6709\u786e\u4fdd\u65e0\u8bef\u540e\u624d\u80fd\u591fcommit\uff1b build_in print , repr and special method __str__ and __repr__ How to print objects of class using print()? list().append(stock_market) \u4e3a\u4ec0\u4e48\u4e0a\u8ff0\u4ee3\u7801\u6ca1\u6709\u8fd4\u56de\u4e00\u4e2a list \uff1f python iter and getitem \u4eca\u5929\u5728\u4f7f\u7528 to_list \u529f\u80fd\u7684\u65f6\u5019\u78b0\u5230\u4e86\u8fd9\u6837\u7684\u4e00\u4e2a\u95ee\u9898\uff1a In [14]: to_list(QuoteTable.Price) --------------------------------------------------------------------------- NotImplementedError Traceback (most recent call last) <ipython-input-14-b4f3918eec14> in <module>() ----> 1 to_list(QuoteTable.Price) /home/quotepredict/workspace/AIServer/data_util/type_conversion.py in to_list(original) 23 l.append(original) 24 else: ---> 25 l.extend(item for item in original) 26 except TypeError as e: 27 l.append(original) /home/quotepredict/workspace/AIServer/data_util/type_conversion.py in <genexpr>(.0) 23 l.append(original) 24 else: ---> 25 l.extend(item for item in original) 26 except TypeError as e: 27 l.append(original) /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/sql/operators.py in __getitem__(self, index) 409 410 \"\"\" --> 411 return self.operate(getitem, index) 412 413 def __lshift__(self, other): /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/orm/attributes.py in operate(self, op, *other, **kwargs) 178 179 def operate(self, op, *other, **kwargs): --> 180 return op(self.comparator, *other, **kwargs) 181 182 def reverse_operate(self, op, other, **kwargs): /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/sql/operators.py in __getitem__(self, index) 409 410 \"\"\" --> 411 return self.operate(getitem, index) 412 413 def __lshift__(self, other): /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/orm/properties.py in operate(self, op, *other, **kwargs) 268 269 def operate(self, op, *other, **kwargs): --> 270 return op(self.__clause_element__(), *other, **kwargs) 271 272 def reverse_operate(self, op, other, **kwargs): /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/sql/operators.py in __getitem__(self, index) 409 410 \"\"\" --> 411 return self.operate(getitem, index) 412 413 def __lshift__(self, other): /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/sql/elements.py in operate(self, op, *other, **kwargs) 690 691 def operate(self, op, *other, **kwargs): --> 692 return op(self.comparator, *other, **kwargs) 693 694 def reverse_operate(self, op, other, **kwargs): /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/sql/operators.py in __getitem__(self, index) 409 410 \"\"\" --> 411 return self.operate(getitem, index) 412 413 def __lshift__(self, other): <string> in <lambda>(self, op, *other, **kwargs) /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/sql/type_api.py in operate(self, default_comparator, op, *other, **kwargs) 61 def operate(self, default_comparator, op, *other, **kwargs): 62 o = default_comparator.operator_lookup[op.__name__] ---> 63 return o[0](self.expr, op, *(other + o[1:]), **kwargs) 64 65 @util.dependencies('sqlalchemy.sql.default_comparator') /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/sql/default_comparator.py in _getitem_impl(expr, op, other, **kw) 190 return _binary_operate(expr, op, other, **kw) 191 else: --> 192 _unsupported_impl(expr, op, other, **kw) 193 194 /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/sql/default_comparator.py in _unsupported_impl(expr, op, *arg, **kw) 195 def _unsupported_impl(expr, op, *arg, **kw): 196 raise NotImplementedError(\"Operator '%s' is not supported on \" --> 197 \"this expression\" % op.__name__) 198 199 NotImplementedError: Operator 'getitem' is not supported on this expression QuoteTable.Price \u662f\u53ef\u4ee5 iter \u7684\uff0c\u4f46\u662f\u5f53\u5c06\u5176\u7f6e\u4e8e for in \u4e2d\u65f6\uff0c\u5b83\u5c31\u8dd1\u51fa\u6765\u4e0a\u8ff0\u5f02\u5e38\uff1b python\u4e2d\u7684\u5e76\u53d1\u65b9\u5f0f **gunicorn**\u7684\u6587\u6863\u4e2d\u7684\u5e76\u53d1\u65b9\u5f0f\u7684\u603b\u7ed3\u662f\u975e\u5e38\u597d\u7684\uff0c\u5b83\u540c\u6837\u9002\u5408\u4e8ecelery http://docs.gunicorn.org/en/stable/design.html# How to make a flat list out of list of lists? https://stackoverflow.com/questions/952914/how-to-make-a-flat-list-out-of-list-of-lists value type of a dict is list raise error Python: Find in list https://stackoverflow.com/questions/9542738/python-find-in-list for\u8bed\u53e5\u7684\u6267\u884c In [9]: for index, word in enumerate([]): ...: print(index) ...: In [10]: index --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-10-caf7e7bf96a7> in <module>() ----> 1 index NameError: name 'index' is not defined python str to float https://stackoverflow.com/questions/40097590/detect-whether-a-python-string-is-a-number-or-a-letter https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float for and \u4e09\u5143\u8868\u8fbe\u5f0f fen_zi_word_list='abc' similar_words={'a':'1', 'b':'2', 'c':'3'} ''.join(similar_words[word] if word in similar_words else word for word in fen_zi_word_list) Out[9]: '123' python iterable and iteration python\u4e2d\u7684\u652f\u6301\u7b97\u6cd5\u7684build-in function\uff0c\u90fd\u662f\u57fa\u4e8eiterable\u7684\uff0c\u6240\u4ee5\u641e\u6e05\u695a\u5b83\u662f\u975e\u5e38\u4e3b\u8981\u7684\uff1b https://stackoverflow.com/questions/19151/build-a-basic-python-iterator https://www.programiz.com/python-programming/iterator https://docs.python.org/3/reference/datamodel.html#object.__iter __ https://diveintopython3.net/iterators.html iteration and deletion https://thispointer.com/python-different-ways-to-iterate-over-a-list-in-reverse-order/ \u5176\u5b9e\u8fd9\u79cd\u7b97\u6cd5\u5e94\u8be5\u5927\u591a\u6570\u662f\u4e0d\u597d\u7684\uff0c\u4e00\u904d\u904d\u5386\uff0c\u8fd8\u4e00\u8fb9\u8fdb\u884c\u5220\u9664\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u4e00\u5b9a\u7684\u95ee\u9898\uff0c\u5e94\u8be5\u5c3d\u53ef\u80fd\u5730\u5c06\u5faa\u73af\u7684\u5224\u65ad\u6761\u4ef6\u8f6c\u6362\u4e00\u4e0b python min and max of integer https://stackoverflow.com/questions/7604966/maximum-and-minimum-values-for-ints https://stackoverflow.com/questions/7604966/maximum-and-minimum-values-for-ints","title":"python TODO"},{"location":"Python/TODO/python-TODO/#python","text":"\u591a\u7ee7\u627f\u7684\u65f6\u5019\uff0c\u5b50\u7c7b __init__ \u51fd\u6570\u5982\u4f55\u6765\u8c03\u7528\u57fa\u7c7b\u7684 __init__ \u51fd\u6570","title":"python \u591a\u7ee7\u627f"},{"location":"Python/TODO/python-TODO/#python-lazy-loading-module","text":"\u5728GitHub python-in-action\u4e2d\u5df2\u7ecf\u521b\u5efa\u4e86\u6e90\u4ee3\u7801\uff0c\u5728\u672c\u5730\u7684 programming-language-python/pattern/lazy_import/ \u4e2d\uff0c\u8fd8\u6709\u4e00\u4e9b\u7406\u8bba\u77e5\u8bc6\u9700\u8981\u5b66\u4e60\uff1b","title":"python lazy-loading module"},{"location":"Python/TODO/python-TODO/#python-dir","text":"https://docs.python.org/3/library/functions.html#dir","title":"python dir()"},{"location":"Python/TODO/python-TODO/#what-is-__future__-in-python-used-for-and-howwhen-to-use-it-and-how-it-works","text":"https://stackoverflow.com/questions/7075082/what-is-future-in-python-used-for-and-how-when-to-use-it-and-how-it-works https://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/001386820023084e5263fe54fde4e4e8616597058cc4ba1000","title":"What is __future__ in Python used for and how/when to use it, and how it works"},{"location":"Python/TODO/python-TODO/#python-with","text":"python with and scope \u4ee5\u4e0b\u9762\u7684\u4ee3\u7801\u4e3a\u4f8b\uff1a x = tf . constant ([[ 37.0 , - 23.0 ], [ 1.0 , 4.0 ]]) w = tf . Variable ( tf . random_uniform ([ 2 , 2 ])) y = tf . matmul ( x , w ) output = tf . nn . softmax ( y ) init_op = w . initializer with tf . Session () as sess : # Run the initializer on `w`. sess . run ( init_op ) # Evaluate `output`. `sess.run(output)` will return a NumPy array containing # the result of the computation. print ( sess . run ( output )) # Evaluate `y` and `output`. Note that `y` will only be computed once, and its # result used both to return `y_val` and as an input to the `tf.nn.softmax()` # op. Both `y_val` and `output_val` will be NumPy arrays. y_val , output_val = sess . run ([ y , output ]) \u5176\u5b9e\u5728 with \u7684\u5916\u5c42\u662f\u53ef\u4ee5\u8bbf\u95ee\u5728 with \u4e2d\u5b9a\u4e49\u7684\u53d8\u91cf\u7684\uff0c\u4f46\u662f\u5728 c++ \u4e2d\uff0c\u6bd4\u5982\u662f for \uff0c\u5219\u5728 for \u7684\u5916\u5c42\u662f\u65e0\u6cd5\u8bbf\u95ee\u5230\u5728 for \u5185\u90e8\u5b9a\u4e49\u7684\u53d8\u91cf\u7684\uff1b","title":"python with"},{"location":"Python/TODO/python-TODO/#_1","text":"tf.register_tensor_conversion_function \u8bb0\u5f97\u5728 py-mysql \u4e2d\u4e5f\u6709\u7c7b\u4f3c\u7684\u51fd\u6570\u3002","title":"\u589e\u5f3a\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027"},{"location":"Python/TODO/python-TODO/#c-named-requirement-and-python-protocol","text":"","title":"c++ named requirement and python protocol"},{"location":"Python/TODO/python-TODO/#pythonlanguage-referenceclanguage-reference","text":"python expression\u548c c++ expression python statement and c++ expression","title":"\u5bf9\u6bd4python\u7684language reference\u548cc++\u7684language reference"},{"location":"Python/TODO/python-TODO/#iterator-generator","text":"","title":"iterator generator"},{"location":"Python/TODO/python-TODO/#iterable-awaitable","text":"","title":"iterable, awaitable"},{"location":"Python/TODO/python-TODO/#python-class-attribute-and-instance-attribute-and-attribute-reference","text":"In [11]: class Test: ...: t=1 ...: def __init__(self,t=None): ...: print(self.t) ...: print(id(self.t)) ...: self.t=t if t else self.t ...: print(self.t) ...: print(id(self.t)) ...: ...: In [12]: t=Test(4) 1 139713319475648 4 139713319475744 In [13]: t=Test(4) 1 139713319475648 4 139713319475744 In [9]: t.t Out[9]: 4 In [10]: Test.t Out[10]: 1 \u4e0a\u8ff0\u4f8b\u5b50\u4f53\u73b0\u4e86python\u4e2d\u7684attribute reference \u548c class attribute \u548c instance attribute\u4e4b\u95f4\u7684\u5173\u7cfb\uff1b","title":"python class attribute and instance attribute and attribute reference"},{"location":"Python/TODO/python-TODO/#python-exception","text":"","title":"python exception"},{"location":"Python/TODO/python-TODO/#python-yield","text":"","title":"python \u4e2dyield\u7684\u51c6\u786e\u542b\u4e49\uff0c\u5230\u5e95\u662f**\u4ea7\u751f**\uff0c\u8fd8\u662f**\u8ba9\u6e21**"},{"location":"Python/TODO/python-TODO/#python-dict","text":"","title":"python dict"},{"location":"Python/TODO/python-TODO/#python-combine-two-dict","text":"https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression","title":"python combine two dict"},{"location":"Python/TODO/python-TODO/#python-assign-the-same-value-to-a-dict","text":"https://stackoverflow.com/questions/2974022/is-it-possible-to-assign-the-same-value-to-multiple-keys-in-a-dict-object-at-onc","title":"python assign the same value to a dict"},{"location":"Python/TODO/python-TODO/#python-use-member-variable-as-default-argument-of-member-function","text":"https://nikos7am.com/posts/mutable-default-arguments/","title":"python use member variable as default argument of member function"},{"location":"Python/TODO/python-TODO/#python-cache","text":"","title":"python cache"},{"location":"Python/TODO/python-TODO/#python-list","text":"list(1) \u4f1a\u629b\u51fa\u5f02\u5e38 TypeError: 'int' object is not iterable \uff0c\u4f46\u662f [1] \u5374\u80fd\u591f\u6b63\u5e38\uff1b\u5982\u679c\u6ca1\u6709\u8bb0\u9519\u7684\u8bdd\uff0c\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u53eb\u505adisplay;","title":"python \u6784\u9020list\u7684\u65b9\u6cd5\u5bf9\u6bd4"},{"location":"Python/TODO/python-TODO/#python-0o","text":"","title":"python \u4e2d\u7684\u521b\u5efa\u6587\u4ef6\u7684\u65f6\u5019\u7684\u6743\u9650\u5b57\u6bb5\u4e3a\u4ec0\u4e48\u662f0o\u5373\u516b\u8fdb\u5236\u5462\uff1f"},{"location":"Python/TODO/python-TODO/#getpassgetuser","text":"https://docs.python.org/3/library/getpass.html","title":"getpass.getuser()\u6587\u6863\u4e2d\u7684\u4e00\u4e9b\u5185\u5bb9"},{"location":"Python/TODO/python-TODO/#osmakedirs","text":"https://docs.python.org/3/library/os.html#os.makedirs https://stackoverflow.com/questions/5210778/elegant-way-to-make-all-dirs-in-a-path","title":"os.makedirs"},{"location":"Python/TODO/python-TODO/#automated-testing","text":"python\u5982\u4f55\u5b9e\u73b0automated testing","title":"automated testing"},{"location":"Python/TODO/python-TODO/#python-determine-the-size-of-object","text":"https://stackoverflow.com/questions/449560/how-do-i-determine-the-size-of-an-object-in-python","title":"python-determine-the-size-of-object"},{"location":"Python/TODO/python-TODO/#six-and-2to3","text":"","title":"six and 2to3"},{"location":"Python/TODO/python-TODO/#default-arguments","text":"SMARTER DEFAULT ARGUMENTS (PYTHON RECIPE) http://code.activestate.com/recipes/577786-smarter-default-arguments/","title":"DEFAULT ARGUMENTS"},{"location":"Python/TODO/python-TODO/#legb","text":"","title":"LEGB"},{"location":"Python/TODO/python-TODO/#understanding-unboundlocalerror-in-python","text":"https://eli.thegreenplace.net/2011/05/15/understanding-unboundlocalerror-in-python","title":"Understanding UnboundLocalError in Python"},{"location":"Python/TODO/python-TODO/#what-are-metaclasses-in-python","text":"","title":"What are metaclasses in Python?"},{"location":"Python/TODO/python-TODO/#python-object-type","text":"class T: pass T.__bases__ Out[22]: (object,) T.__class__ Out[14]: type i=T() i.__class__ Out[16]: __main__.T","title":"python object \u548c type"},{"location":"Python/TODO/python-TODO/#debug-in-python","text":"https://stackoverflow.com/questions/16867347/step-by-step-debugging-with-ipython \u672c\u5730\u5df2\u7ecf\u6536\u5f55\u4e86IPython-debug https://github.com/cool-RR/PySnooper","title":"debug in python"},{"location":"Python/TODO/python-TODO/#python-reflection","text":"https://www.bnmetrics.com/blog/introspection-reflection-in-python https://www.geeksforgeeks.org/reflection-in-python/ https://docs.python.org/3.7/c-api/reflection.html","title":"python reflection"},{"location":"Python/TODO/python-TODO/#python-__builtin__","text":"\u8fd9\u6d89\u53ca\u5230\u4e86\uff1a python 2\u4e2d\u7684 __builtin__ \u6a21\u5757 dir() \u8fd4\u56de\u7684\u6210\u5458\u4e2d\u5305\u542b\u6709 __builtins__ \u5728\u8fd9\u7bc7\u6587\u7ae0\u4e2d\u7ed9\u51fa\u4e86\u89e3\u7b54 Where is the __builtin__ module in Python3? Why was it renamed?","title":"python __builtin__"},{"location":"Python/TODO/python-TODO/#classscope","text":"class PredictionField : PREDICT_TIME = 'predict_time' PREDICT_VALUE = 'predict_value' PREDICT_PROB_RISE = 'predict_prob_rise' PREDICT_PROB_FALL = 'predict_prob_fall' PREDICT_PROB_FLAT = 'predict_prob_flat' ALL_FIELDS = [ getattr ( PredictionField , x ) for x in dir ( PredictionField ) if not x . startswith ( \"__\" )] \u62a5\u9519\u5982\u4e0b\uff1a < ipython - input - 1 - edae3ab18252 > in PredictionField () 1 class PredictionField : 2 PREDICT_TIME = 'predict_time' ----> 3 ALL_FIELDS = tuple ( getattr ( PredictionField , x ) for x in dir ( PredictionField ) if x . startswith ( \"PREDICT\" )) 4 NameError : name 'PredictionField' is not defined","title":"class\u7684scope"},{"location":"Python/TODO/python-TODO/#python-programmingmetaclasses","text":"https://en.wikibooks.org/wiki/Python_Programming/Metaclasses","title":"Python Programming/Metaclasses"},{"location":"Python/TODO/python-TODO/#python-tuple","text":"tuple ( 1 , 2 , 3 ) --------------------------------------------------------------------------- TypeError Traceback ( most recent call last ) < ipython - input - 24 - 3e233 cfc2777 > in < module > () ----> 1 tuple ( 1 , 2 , 3 ) TypeError : tuple () takes at most 1 argument ( 3 given )","title":"python tuple"},{"location":"Python/TODO/python-TODO/#why-should-you-use-namedtuple-instead-of-a-tuple","text":"","title":"Why should you use namedtuple instead of a tuple?"},{"location":"Python/TODO/python-TODO/#python-execution-model-and-variable-and-scope","text":"def outer(): a = 9 def inner(): print(a) inner() print(a) def outer(): a = 9 def inner(): a = 10 print(a) inner() print(a) def outer(): a = 9 def inner(): print(a) a = 10 inner() print(a) def outer(): def inner(): a = 10 print(a) \u601d\u8003\u4e00\u4e2a\u95ee\u9898\uff1apython\u89e3\u91ca\u5668\u5728\u7f16\u8bd1\u51fd\u6570\u7684\u65f6\u5019\uff0c\u662f\u5426\u4f1a\u5c06\u8be5\u51fd\u6570\u7684\u6240\u6709local variable\u90fd\u4fdd\u5b58\u5230\u8be5\u51fd\u6570\u7684namespace\u4e2d\uff1f","title":"python execution model and variable and scope"},{"location":"Python/TODO/python-TODO/#python-setinterval","text":"python setinterval equivalent celery\u4e2d\u7684Periodic Tasks \u00b6 \u4e5f\u662f\u4e00\u79cdsetinterval","title":"python setInterval"},{"location":"Python/TODO/python-TODO/#python-ajax-equivalent","text":"ajax\u672c\u8d28\u6765\u8bf4\u662f\u4e00\u79cd\u5f02\u6b65\uff0c\u662f\u4e00\u79cdpromise\uff1bpython\u4e2d\u5e94\u8be5\u6709","title":"python ajax equivalent"},{"location":"Python/TODO/python-TODO/#ajax-and-promise","text":"","title":"ajax and promise"},{"location":"Python/TODO/python-TODO/#python-classmethod-property","text":"","title":"python classmethod property"},{"location":"Python/TODO/python-TODO/#_3","text":"class PredictionField : PREDICT_TIME = 'predict_time' PREDICT_VALUE = 'predict_value' PREDICT_PROB_RISE = 'predict_prob_rise' PREDICT_PROB_FALL = 'predict_prob_fall' PREDICT_PROB_FLAT = 'predict_prob_flat' ALL_FIELDS = tuple ( getattr ( PredictionField , x ) for x in dir ( PredictionField ) if x . startswith ( \"PREDICT\" )) \u4e0a\u8ff0\u4ee3\u7801\u662f\u5b58\u5728\u9519\u8bef\u7684\uff0c\u4f46\u662f\u6211\u60f3\u8981\u5b9e\u73b0\u7c7b\u4f3c\u4e0a\u8ff0\u7684\u6548\u679c\uff1b \u56de\u5fc6\u8d77\u4e4b\u524d\u4f7f\u7528SQLalchemy\u7684\u7ecf\u9a8c\uff0cSQLalchemy\u4e2d\u5728\u5b9a\u4e49\u8868\u683c\u7684\u65f6\u5019\uff0c\u80af\u5b9a\u4f1a\u6709\u7c7b\u4f3c\u4e8e\u4e0a\u9762\u7684\u9700\u6c42\uff0c\u5373\u83b7\u53d6\u6240\u6709\u7684\u7c7b\u6210\u5458\u53d8\u91cf\uff1b","title":"\u9759\u6001\u6210\u5458\u53d8\u91cf\u7684\u5bb9\u5668"},{"location":"Python/TODO/python-TODO/#jsondumps-vs-flaskjsonify","text":"https://stackoverflow.com/questions/7907596/json-dumps-vs-flask-jsonify http://flask.pocoo.org/docs/1.0/api/#module-flask.json","title":"json.dumps vs flask.jsonify"},{"location":"Python/TODO/python-TODO/#python-interpretercompile-function","text":"\u51fd\u6570\u7684local variable\u662f\u5426\u4f1a\u4fdd\u5b58\u5230function\u7684namespace\u4e2d\uff1f","title":"python interpreter\u662f\u5982\u4f55\u4e86\u6765compile function\u7684\uff1f"},{"location":"Python/TODO/python-TODO/#pythondynamic","text":"\u9700\u8981\u603b\u7ed3python\u7684dynamic\u7279\u6027 google python dynamic https://stackoverflow.com/a/2829588 https://pythonconquerstheuniverse.wordpress.com/2009/10/03/static-vs-dynamic-typing-of-programming-languages/ https://wiki.python.org/moin/Why%20is%20Python%20a%20dynamic%20language%20and%20also%20a%20strongly%20typed%20language","title":"python\u7684dynamic"},{"location":"Python/TODO/python-TODO/#_4","text":"def test (): def p (): print ( a ) a = 1 p ()","title":"\u4e00\u4e2a\u5c0f\u4f8b\u5b50"},{"location":"Python/TODO/python-TODO/#rebind-argument-in-function-body","text":"def extract_data ( quote_df , data_window ): if quote_df . shape [ 0 ] > data_window : quote_df = quote_df . tail ( data_window ) return quote_df","title":"rebind argument in function body"},{"location":"Python/TODO/python-TODO/#functools-higher-order-functions-and-operations-on-callable-objects","text":"","title":"functools \u2014 Higher-order functions and operations on callable objects\u00b6"},{"location":"Python/TODO/python-TODO/#redis-in-python-how-do-you-close-the-connection","text":"","title":"Redis in python, how do you close the connection?"},{"location":"Python/TODO/python-TODO/#how-to-flatten-nested-python-dictionaries","text":"[Aggregate Python lists stored as values in a nested dictionary into one list for arbitrary levels duplicate]","title":"How to flatten nested python dictionaries?"},{"location":"Python/TODO/python-TODO/#python-type-system","text":"duck-typing \u65e2\u7136python\u662fduck-type\uff0c\u90a3\u4e48\u4e3a\u4ec0\u4e48python\u8fd8\u8981\u63d0\u4f9b ABC \u5462\uff1f \u5728 abstract base class \u5df2\u7ecf\u5c06\u8fd9\u4e2a\u95ee\u9898\u8bf4\u6e05\u4e86 https://docs.python.org/3.7/library/collections.abc.html","title":"python type system"},{"location":"Python/TODO/python-TODO/#20190429","text":"python\u7684\u52a8\u6001\u7279\u6027\u6240\u5e26\u6765\u7684\u95ee\u9898\uff1a\u6bd4\u5982\u5728\u7f16\u5199\u4e00\u4e2a\u51fd\u6570\u7684\u65f6\u5019\uff0c\u7531\u4e8epython lack declaration\uff0c\u6240\u4ee5\u6211\u4eec\u538b\u6839\u5c31\u4e0d\u77e5\u9053\u5165\u53c2\u7684\u7c7b\u578b\u662f\u4ec0\u4e48\uff0c\u53ea\u6709\u5230\u8fd0\u884c\u7684\u65f6\u5019\uff0c\u6211\u4eec\u624d\u80fd\u591f\u77e5\u9053\u5165\u53c2\u7684\u51c6\u786e\u7c7b\u578b\uff0c\u624d\u80fd\u591f\u5bf9\u5176\u8fdb\u884c\u51c6\u786e\u7684\u8fd0\u7528\uff0c\u800c\u5728programming\u9636\u6bb5\uff0c\u5bf9\u5176\u5b8c\u5168\u90fd\u662f\u6309\u7167\u5fc3\u4e2d\u7684\u9884\u671f\u8fdb\u884cprogramming\u7684\uff0c\u6240\u4ee5python\u7a0b\u5e8f\u5fc5\u987b\u8981\u8fdb\u884c\u5b8c\u6574\u7684\u6d4b\u8bd5\uff1b \u5e76\u4e14python\u7684\u8fd9\u79cd\u52a8\u6001\u7279\u6027\uff0c\u5e26\u6765\u4e86\u5927\u91cf\u7684\u7c7b\u4f3c\u4e0b\u9762\u8fd9\u6837\u7684\u4ee3\u7801\uff1a @classmethod def read ( cls , redis_conn , ml_model_sub_name , stock_market , reverse = True , fields = None , data_range = None , window = None , predict_time_as_index = True ): \"\"\" :param redis_conn: :param ml_model_sub_name: :param stock_market: :param reverse \u53c2\u89c1`class RedisStructureIOBase` doc :param fields \u53c2\u89c1`class PredictionField` :param data_range \u53c2\u89c1`class RedisStructureIOBase` doc :param window \u53c2\u89c1`class RedisStructureIOBase` doc :param predict_time_as_index:\u5c06predict_time\u5b57\u6bb5\u4f5c\u4e3a\u7d22\u5f15 :return: \"\"\" data_range = cls . convert_data_range ( reverse = reverse , data_range = data_range , window = window ) if fields is None : fields = [ PredictionField . PREDICT_VALUE ] if PredictionField . PREDICT_TIME in fields : fields = list ( fields ) fields . remove ( PredictionField . PREDICT_TIME ) \u91cd\u70b9\u770b\u6700\u540e\u4e24\u884c\uff0c\u6211\u7684\u76ee\u7684\u662f\u5982\u679c fields \u4e2d\u5305\u542b PredictionField.PREDICT_TIME \uff0c\u5219\u5c31\u9700\u8981\u5c06\u5176remove\u6389\uff0c\u4f46\u662f\u5982\u679c\u7528\u6237\u4f20\u5165\u7684\u662f tuple \uff0c\u5219\u5fc5\u987b\u8981\u5148\u5c06\u5176\u8f6c\u6362\u4e3a list \uff0c\u7136\u540e\u624d\u80fd\u591f\u8c03\u7528remove\uff0c\u56e0\u4e3atuple \u662funmutable\u7684\uff0c\u6545\u5176\u6ca1\u6709 remove \u65b9\u6cd5\uff1b \u663e\u7136\uff0c\u5982\u679c\u5728\u9759\u6001\u8bed\u8a00\u7684\u8bdd\uff0c\u5219\u5f53\u6211\u4eec\u5728\u51fd\u6570\u58f0\u660e\u4e2d\uff0c\u6307\u5b9a\u4e86\u5165\u53c2\u7684\u7c7b\u578b\uff0c\u5219\u5c31\u4e0d\u4f1a\u51fa\u73b0\u8fd9\u6837\u7684\u4e8b\u60c5\u4e86\uff1b \u7531\u6b64\u53ef\u89c1\uff0c\u52a8\u6001\u4e5f\u6709\u52a8\u6001\u7684\u5f0a\u7aef\u3002","title":"20190429"},{"location":"Python/TODO/python-TODO/#python-debugger","text":"pdb \u2014 The Python Debugger \u00b6 How to execute multi-line statements within Python's own debugger (PDB)","title":"python debugger"},{"location":"Python/TODO/python-TODO/#python-build_in-format-input","text":"https://docs.python.org/3/library/functions.html#input","title":"python build_in format input"},{"location":"Python/TODO/python-TODO/#operation-with-transaction","text":"\u5728\u5411database\u4e2d\u52a0\u5165\u6279\u91cf\u6570\u636e\u7684\u65f6\u5019\uff0c\u6709\u65f6\u5019\u662f\u9700\u8981\u5b9e\u73b0transaction\u7684\uff0c\u5373\u5982\u679c\u5728\u6dfb\u52a0\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u4e86\u9519\u8bef\uff0c\u5728\u9700\u8981rollback\uff1b\u53ea\u6709\u786e\u4fdd\u65e0\u8bef\u540e\u624d\u80fd\u591fcommit\uff1b","title":"operation with transaction"},{"location":"Python/TODO/python-TODO/#build_in-print-repr-and-special-method-__str__-and-__repr__","text":"How to print objects of class using print()?","title":"build_in print, repr and special method __str__ and __repr__"},{"location":"Python/TODO/python-TODO/#listappendstock_market","text":"\u4e3a\u4ec0\u4e48\u4e0a\u8ff0\u4ee3\u7801\u6ca1\u6709\u8fd4\u56de\u4e00\u4e2a list \uff1f","title":"list().append(stock_market)"},{"location":"Python/TODO/python-TODO/#python-iter-and-getitem","text":"\u4eca\u5929\u5728\u4f7f\u7528 to_list \u529f\u80fd\u7684\u65f6\u5019\u78b0\u5230\u4e86\u8fd9\u6837\u7684\u4e00\u4e2a\u95ee\u9898\uff1a In [14]: to_list(QuoteTable.Price) --------------------------------------------------------------------------- NotImplementedError Traceback (most recent call last) <ipython-input-14-b4f3918eec14> in <module>() ----> 1 to_list(QuoteTable.Price) /home/quotepredict/workspace/AIServer/data_util/type_conversion.py in to_list(original) 23 l.append(original) 24 else: ---> 25 l.extend(item for item in original) 26 except TypeError as e: 27 l.append(original) /home/quotepredict/workspace/AIServer/data_util/type_conversion.py in <genexpr>(.0) 23 l.append(original) 24 else: ---> 25 l.extend(item for item in original) 26 except TypeError as e: 27 l.append(original) /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/sql/operators.py in __getitem__(self, index) 409 410 \"\"\" --> 411 return self.operate(getitem, index) 412 413 def __lshift__(self, other): /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/orm/attributes.py in operate(self, op, *other, **kwargs) 178 179 def operate(self, op, *other, **kwargs): --> 180 return op(self.comparator, *other, **kwargs) 181 182 def reverse_operate(self, op, other, **kwargs): /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/sql/operators.py in __getitem__(self, index) 409 410 \"\"\" --> 411 return self.operate(getitem, index) 412 413 def __lshift__(self, other): /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/orm/properties.py in operate(self, op, *other, **kwargs) 268 269 def operate(self, op, *other, **kwargs): --> 270 return op(self.__clause_element__(), *other, **kwargs) 271 272 def reverse_operate(self, op, other, **kwargs): /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/sql/operators.py in __getitem__(self, index) 409 410 \"\"\" --> 411 return self.operate(getitem, index) 412 413 def __lshift__(self, other): /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/sql/elements.py in operate(self, op, *other, **kwargs) 690 691 def operate(self, op, *other, **kwargs): --> 692 return op(self.comparator, *other, **kwargs) 693 694 def reverse_operate(self, op, other, **kwargs): /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/sql/operators.py in __getitem__(self, index) 409 410 \"\"\" --> 411 return self.operate(getitem, index) 412 413 def __lshift__(self, other): <string> in <lambda>(self, op, *other, **kwargs) /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/sql/type_api.py in operate(self, default_comparator, op, *other, **kwargs) 61 def operate(self, default_comparator, op, *other, **kwargs): 62 o = default_comparator.operator_lookup[op.__name__] ---> 63 return o[0](self.expr, op, *(other + o[1:]), **kwargs) 64 65 @util.dependencies('sqlalchemy.sql.default_comparator') /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/sql/default_comparator.py in _getitem_impl(expr, op, other, **kw) 190 return _binary_operate(expr, op, other, **kw) 191 else: --> 192 _unsupported_impl(expr, op, other, **kw) 193 194 /usr/anaconda3/lib/python3.6/site-packages/sqlalchemy/sql/default_comparator.py in _unsupported_impl(expr, op, *arg, **kw) 195 def _unsupported_impl(expr, op, *arg, **kw): 196 raise NotImplementedError(\"Operator '%s' is not supported on \" --> 197 \"this expression\" % op.__name__) 198 199 NotImplementedError: Operator 'getitem' is not supported on this expression QuoteTable.Price \u662f\u53ef\u4ee5 iter \u7684\uff0c\u4f46\u662f\u5f53\u5c06\u5176\u7f6e\u4e8e for in \u4e2d\u65f6\uff0c\u5b83\u5c31\u8dd1\u51fa\u6765\u4e0a\u8ff0\u5f02\u5e38\uff1b","title":"python iter and getitem"},{"location":"Python/TODO/python-TODO/#python_1","text":"**gunicorn**\u7684\u6587\u6863\u4e2d\u7684\u5e76\u53d1\u65b9\u5f0f\u7684\u603b\u7ed3\u662f\u975e\u5e38\u597d\u7684\uff0c\u5b83\u540c\u6837\u9002\u5408\u4e8ecelery http://docs.gunicorn.org/en/stable/design.html#","title":"python\u4e2d\u7684\u5e76\u53d1\u65b9\u5f0f"},{"location":"Python/TODO/python-TODO/#how-to-make-a-flat-list-out-of-list-of-lists","text":"https://stackoverflow.com/questions/952914/how-to-make-a-flat-list-out-of-list-of-lists","title":"How to make a flat list out of list of lists?"},{"location":"Python/TODO/python-TODO/#value-type-of-a-dict-is-list-raise-error","text":"","title":"value type of a dict is list raise error"},{"location":"Python/TODO/python-TODO/#python-find-in-list","text":"https://stackoverflow.com/questions/9542738/python-find-in-list","title":"Python: Find in list"},{"location":"Python/TODO/python-TODO/#for","text":"In [9]: for index, word in enumerate([]): ...: print(index) ...: In [10]: index --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-10-caf7e7bf96a7> in <module>() ----> 1 index NameError: name 'index' is not defined","title":"for\u8bed\u53e5\u7684\u6267\u884c"},{"location":"Python/TODO/python-TODO/#python-str-to-float","text":"https://stackoverflow.com/questions/40097590/detect-whether-a-python-string-is-a-number-or-a-letter https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float","title":"python str to float"},{"location":"Python/TODO/python-TODO/#for-and","text":"fen_zi_word_list='abc' similar_words={'a':'1', 'b':'2', 'c':'3'} ''.join(similar_words[word] if word in similar_words else word for word in fen_zi_word_list) Out[9]: '123'","title":"for and \u4e09\u5143\u8868\u8fbe\u5f0f"},{"location":"Python/TODO/python-TODO/#python-iterable-and-iteration","text":"python\u4e2d\u7684\u652f\u6301\u7b97\u6cd5\u7684build-in function\uff0c\u90fd\u662f\u57fa\u4e8eiterable\u7684\uff0c\u6240\u4ee5\u641e\u6e05\u695a\u5b83\u662f\u975e\u5e38\u4e3b\u8981\u7684\uff1b https://stackoverflow.com/questions/19151/build-a-basic-python-iterator https://www.programiz.com/python-programming/iterator https://docs.python.org/3/reference/datamodel.html#object.__iter __ https://diveintopython3.net/iterators.html","title":"python iterable and iteration"},{"location":"Python/TODO/python-TODO/#iteration-and-deletion","text":"https://thispointer.com/python-different-ways-to-iterate-over-a-list-in-reverse-order/ \u5176\u5b9e\u8fd9\u79cd\u7b97\u6cd5\u5e94\u8be5\u5927\u591a\u6570\u662f\u4e0d\u597d\u7684\uff0c\u4e00\u904d\u904d\u5386\uff0c\u8fd8\u4e00\u8fb9\u8fdb\u884c\u5220\u9664\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u4e00\u5b9a\u7684\u95ee\u9898\uff0c\u5e94\u8be5\u5c3d\u53ef\u80fd\u5730\u5c06\u5faa\u73af\u7684\u5224\u65ad\u6761\u4ef6\u8f6c\u6362\u4e00\u4e0b","title":"iteration and deletion"},{"location":"Python/TODO/python-TODO/#python-min-and-max-of-integer","text":"https://stackoverflow.com/questions/7604966/maximum-and-minimum-values-for-ints https://stackoverflow.com/questions/7604966/maximum-and-minimum-values-for-ints","title":"python min and max of integer"},{"location":"Python/TODO/python-celery-TODO/","text":"Monitoring and Management Guide \u00b6 \u4fee\u6539\u5185\u5bb9\uff1a how to get the queue in which a task was run - celery Retrieve list of tasks in a queue in Celery How to send periodic tasks to specific queue in Celery https://stackoverflow.com/questions/16962449/how-to-send-periodic-tasks-to-specific-queue-in-celery https://stackoverflow.com/questions/29306337/how-to-stop-celery-worker-process https://serverfault.com/questions/695787/is-there-a-more-convenient-way-to-stop-or-restart-a-detached-celery-beat-proce celery multiple queues \u6709\u51e0\u4e2a\u6a21\u578b\u5c31\u9700\u8981\u6784\u5efa\u51e0\u4e2aapplication/worker\uff0c\u6bcf\u4e2aapplication/worker\u6839\u636e model_name \uff0c model_sub_name \u5c31\u53ef\u4ee5\u786e\u5b9aapplication/workername\uff0capplication/workerqueue name\uff1b \u663e\u7136\u6211\u7684\u6240\u6709\u7684worker\u7684\u6a21\u5f0f\u5b8c\u5168\u76f8\u540c\uff0c\u6240\u4e0d\u540c\u7684\u662f\u8fd9\u4e9bworker\u6240\u8fd0\u884c\u7684machine learning model\u4e0d\u540c\uff1b\u90a3\u4e48\u6211\u8981\u5982\u4f55\u6765\u5feb\u901f\u5730\u4e3a\u6bcf\u4e2amodel\u751f\u6210\u4e00\u4e2aworker\u5462\uff1f \u6211\u76ee\u524d\u7684\u601d\u8def\u662f\uff1a\u751f\u6210\u5404\u4e2aapplication\u7684\u4ee3\u7801\uff0c\u7136\u540e\u9010\u4e2a\u542f\u52a8\uff1b \u7b2c\u4e8c\u79cd\u601d\u8def\u662f\uff1a for model_name , model_sub_name in models : app = create_app ( model_name , model_sub_name ) def create_app ( model_name , model_sub_name ) : app = Celery ( application_name , broker = ' redis : //{}/0'.format(config.REDIS_URL), backend = ' redis : //{}/1'.format(config.REDIS_URL), include = [ ' proj_HS300_1_0 . task_predict ' ] ) app . conf [ ' model_name ' ] = model_name app . conf [ ' model_sub_name ' ] = model_sub_name app . conf [ ' queue_name ' ] = RedisCeleryQueueKeys . get_celery_app_queue_key ( model_name , model_sub_name ) \u5982\u4f55\u6765\u542f\u52a8\u5404\u4e2aworker\uff1f AIServerCtr.py from ml_model import MLModelBuilder import config ml_model_builder = MLModelBuilder ( config . ML_MODEL_DIR ) ml_model_builder . restore_ml_model ( load = False ) \u5982\u4f55\u5c06 model_name , model_sub_name \u4f20\u9012\u5230\u5404\u4e2a\u5b50\u8fdb\u7a0b\u4e2d\uff1f\u76ee\u524d\u60f3\u5230\u4e86\u5982\u4e0b\u7684\u65b9\u6cd5\uff1a \u901a\u8fc7Environment Variables \u901a\u8fc7Command-Line Arguments \u7ecf\u8fc7\u8003\u8651\uff0c\u6700\u7ec8\u7684\u601d\u8def\u5982\u4e0b\uff1a celery -A proj_HS300_1_0 worker -l info -c 1 -Q CeleryQueue:HS300_1:0 DuplicateNodenameWarning with no obvious reason https://docs.celeryproject.org/en/latest/userguide/workers.html https://docs.celeryproject.org/en/latest/faq.html","title":"Monitoring and Management Guide[\u00b6](https://docs.celeryproject.org/en/latest/userguide/monitoring.html#monitoring-and-management-guide)"},{"location":"Python/TODO/python-celery-TODO/#monitoring-and-management-guide","text":"\u4fee\u6539\u5185\u5bb9\uff1a how to get the queue in which a task was run - celery Retrieve list of tasks in a queue in Celery","title":"Monitoring and Management Guide\u00b6"},{"location":"Python/TODO/python-celery-TODO/#how-to-send-periodic-tasks-to-specific-queue-in-celery","text":"https://stackoverflow.com/questions/16962449/how-to-send-periodic-tasks-to-specific-queue-in-celery https://stackoverflow.com/questions/29306337/how-to-stop-celery-worker-process https://serverfault.com/questions/695787/is-there-a-more-convenient-way-to-stop-or-restart-a-detached-celery-beat-proce","title":"How to send periodic tasks to specific queue in Celery"},{"location":"Python/TODO/python-celery-TODO/#celery-multiple-queues","text":"\u6709\u51e0\u4e2a\u6a21\u578b\u5c31\u9700\u8981\u6784\u5efa\u51e0\u4e2aapplication/worker\uff0c\u6bcf\u4e2aapplication/worker\u6839\u636e model_name \uff0c model_sub_name \u5c31\u53ef\u4ee5\u786e\u5b9aapplication/workername\uff0capplication/workerqueue name\uff1b \u663e\u7136\u6211\u7684\u6240\u6709\u7684worker\u7684\u6a21\u5f0f\u5b8c\u5168\u76f8\u540c\uff0c\u6240\u4e0d\u540c\u7684\u662f\u8fd9\u4e9bworker\u6240\u8fd0\u884c\u7684machine learning model\u4e0d\u540c\uff1b\u90a3\u4e48\u6211\u8981\u5982\u4f55\u6765\u5feb\u901f\u5730\u4e3a\u6bcf\u4e2amodel\u751f\u6210\u4e00\u4e2aworker\u5462\uff1f \u6211\u76ee\u524d\u7684\u601d\u8def\u662f\uff1a\u751f\u6210\u5404\u4e2aapplication\u7684\u4ee3\u7801\uff0c\u7136\u540e\u9010\u4e2a\u542f\u52a8\uff1b \u7b2c\u4e8c\u79cd\u601d\u8def\u662f\uff1a for model_name , model_sub_name in models : app = create_app ( model_name , model_sub_name ) def create_app ( model_name , model_sub_name ) : app = Celery ( application_name , broker = ' redis : //{}/0'.format(config.REDIS_URL), backend = ' redis : //{}/1'.format(config.REDIS_URL), include = [ ' proj_HS300_1_0 . task_predict ' ] ) app . conf [ ' model_name ' ] = model_name app . conf [ ' model_sub_name ' ] = model_sub_name app . conf [ ' queue_name ' ] = RedisCeleryQueueKeys . get_celery_app_queue_key ( model_name , model_sub_name ) \u5982\u4f55\u6765\u542f\u52a8\u5404\u4e2aworker\uff1f AIServerCtr.py from ml_model import MLModelBuilder import config ml_model_builder = MLModelBuilder ( config . ML_MODEL_DIR ) ml_model_builder . restore_ml_model ( load = False ) \u5982\u4f55\u5c06 model_name , model_sub_name \u4f20\u9012\u5230\u5404\u4e2a\u5b50\u8fdb\u7a0b\u4e2d\uff1f\u76ee\u524d\u60f3\u5230\u4e86\u5982\u4e0b\u7684\u65b9\u6cd5\uff1a \u901a\u8fc7Environment Variables \u901a\u8fc7Command-Line Arguments \u7ecf\u8fc7\u8003\u8651\uff0c\u6700\u7ec8\u7684\u601d\u8def\u5982\u4e0b\uff1a celery -A proj_HS300_1_0 worker -l info -c 1 -Q CeleryQueue:HS300_1:0","title":"celery multiple queues"},{"location":"Python/TODO/python-celery-TODO/#duplicatenodenamewarning-with-no-obvious-reason","text":"https://docs.celeryproject.org/en/latest/userguide/workers.html https://docs.celeryproject.org/en/latest/faq.html","title":"DuplicateNodenameWarning with no obvious reason"},{"location":"Python/TODO/python-customization-TODO/","text":"\u524d\u8a00 customize class creation customize module load \u524d\u8a00 \u60f3\u8981\u628apython\u73a9\u5f97\u9ad8\u7ea7\uff0c\u9700\u8981\u80fd\u591f\u5bf9python\u8fdb\u884c\u9ad8\u5ea6\u7684customization\uff0c\u4e3b\u8981\u5305\u62ec\u5982\u4e0b\u65b9\u9762 customize class creation python\u4e2d\u7c7b\u5b9a\u4e49\u8bed\u53e5\u662f\u4e00\u4e2a\u53ef\u6267\u884c\u8bed\u53e5\uff0c\u6240\u4ee5\u5f53\u5bfc\u5165\u4e00\u4e2a\u5305\u542b\u4e86\u6709\u7c7b\u5b9a\u4e49\u7684\u8bed\u53e5\u7684module\u7684\u65f6\u5019\uff0c\u5c31\u4f1a\u89e6\u53d1python\u89e3\u91ca\u5668\u6765\u6267\u884c\u8fd9\u4e2a\u7c7b\u7684\u5b9a\u4e49\uff0c\u6240\u4ee5\u6b64\u65f6\u5c31\u4f1a\u89e6\u53d1\u4e00\u4e9b\u4e0e\u7c7b\u521b\u5efa\u6709\u5173\u7684hook\u65b9\u6cd5\u7684\u6267\u884c\uff0c\u5173\u4e8e\u8fd9\u4e9b\u65b9\u6cd5\uff0c\u5728\u4e0b\u9762\u7684\u6587\u7ae0\u4e2d\u6709\u975e\u5e38\u597d\u7684\u89e3\u91ca\uff1a Customizing class creation in Python \u5728python doc\u7684 3.3.3. Customizing class creation \u4e2d\u63cf\u8ff0\u4e86\u81ea\u5b9a\u4e49\u7c7b\u7684\u521b\u5efa\uff1b\u5176\u4e2d\u63d0\u53ca\uff1a By default, classes are constructed using type() . The class body is executed in a new namespace and the class name is bound locally to the result of type(name, bases, namespace). \u8fd9\u5c31\u89e6\u53d1\u4e86\u6211\u7684\u4e00\u4e2a\u60f3\u6cd5\u662f\uff0c\u6211\u662f\u5426\u81ea\u5df1\u6765\u63a7\u5236\u4f55\u65f6\u4f7f\u7528 type \u6765\u521b\u5efa\u7c7b\uff0c\u5e76\u4e14\u4f20\u5165\u4e00\u4e2a\u53c2\u6570\u503c\uff1b customize module load \u8fd9\u662f\u6211\u5728\u9605\u8bfbcelery\u7684\u6e90\u4ee3\u7801\u7684\u65f6\u5019\u53d1\u73b0\u7684\uff0ccelery\u7684 find_app \u51fd\u6570\u4e2d\u5c31\u6709\u4e00\u4e2a\u5206\u652f\u662f\u81ea\u5df1\u6765\u52a0\u8f7d\u5b9a\u4e49\u6709 app \u7684python\u6587\u4ef6 \uff1b","title":"python customization TODO"},{"location":"Python/TODO/python-customization-TODO/#_1","text":"\u60f3\u8981\u628apython\u73a9\u5f97\u9ad8\u7ea7\uff0c\u9700\u8981\u80fd\u591f\u5bf9python\u8fdb\u884c\u9ad8\u5ea6\u7684customization\uff0c\u4e3b\u8981\u5305\u62ec\u5982\u4e0b\u65b9\u9762","title":"\u524d\u8a00"},{"location":"Python/TODO/python-customization-TODO/#customize-class-creation","text":"python\u4e2d\u7c7b\u5b9a\u4e49\u8bed\u53e5\u662f\u4e00\u4e2a\u53ef\u6267\u884c\u8bed\u53e5\uff0c\u6240\u4ee5\u5f53\u5bfc\u5165\u4e00\u4e2a\u5305\u542b\u4e86\u6709\u7c7b\u5b9a\u4e49\u7684\u8bed\u53e5\u7684module\u7684\u65f6\u5019\uff0c\u5c31\u4f1a\u89e6\u53d1python\u89e3\u91ca\u5668\u6765\u6267\u884c\u8fd9\u4e2a\u7c7b\u7684\u5b9a\u4e49\uff0c\u6240\u4ee5\u6b64\u65f6\u5c31\u4f1a\u89e6\u53d1\u4e00\u4e9b\u4e0e\u7c7b\u521b\u5efa\u6709\u5173\u7684hook\u65b9\u6cd5\u7684\u6267\u884c\uff0c\u5173\u4e8e\u8fd9\u4e9b\u65b9\u6cd5\uff0c\u5728\u4e0b\u9762\u7684\u6587\u7ae0\u4e2d\u6709\u975e\u5e38\u597d\u7684\u89e3\u91ca\uff1a Customizing class creation in Python \u5728python doc\u7684 3.3.3. Customizing class creation \u4e2d\u63cf\u8ff0\u4e86\u81ea\u5b9a\u4e49\u7c7b\u7684\u521b\u5efa\uff1b\u5176\u4e2d\u63d0\u53ca\uff1a By default, classes are constructed using type() . The class body is executed in a new namespace and the class name is bound locally to the result of type(name, bases, namespace). \u8fd9\u5c31\u89e6\u53d1\u4e86\u6211\u7684\u4e00\u4e2a\u60f3\u6cd5\u662f\uff0c\u6211\u662f\u5426\u81ea\u5df1\u6765\u63a7\u5236\u4f55\u65f6\u4f7f\u7528 type \u6765\u521b\u5efa\u7c7b\uff0c\u5e76\u4e14\u4f20\u5165\u4e00\u4e2a\u53c2\u6570\u503c\uff1b","title":"customize class creation"},{"location":"Python/TODO/python-customization-TODO/#customize-module-load","text":"\u8fd9\u662f\u6211\u5728\u9605\u8bfbcelery\u7684\u6e90\u4ee3\u7801\u7684\u65f6\u5019\u53d1\u73b0\u7684\uff0ccelery\u7684 find_app \u51fd\u6570\u4e2d\u5c31\u6709\u4e00\u4e2a\u5206\u652f\u662f\u81ea\u5df1\u6765\u52a0\u8f7d\u5b9a\u4e49\u6709 app \u7684python\u6587\u4ef6 \uff1b","title":"customize module load"},{"location":"Python/TODO/python-pandas-TODO/","text":"How To Add a New Column Using a Dictionary in Pandas Data Frame ? http://cmdlinetips.com/2018/01/how-to-add-a-new-column-to-using-a-dictionary-in-pandas-data-frame/ https://www.geeksforgeeks.org/add-a-new-column-in-pandas-data-frame-using-a-dictionary/ https://stackoverflow.com/questions/20250771/remap-values-in-pandas-column-with-a-dict","title":"How To Add a New Column Using a Dictionary in Pandas Data Frame ?"},{"location":"Python/TODO/python-pandas-TODO/#how-to-add-a-new-column-using-a-dictionary-in-pandas-data-frame","text":"http://cmdlinetips.com/2018/01/how-to-add-a-new-column-to-using-a-dictionary-in-pandas-data-frame/ https://www.geeksforgeeks.org/add-a-new-column-in-pandas-data-frame-using-a-dictionary/ https://stackoverflow.com/questions/20250771/remap-values-in-pandas-column-with-a-dict","title":"How To Add a New Column Using a Dictionary in Pandas Data Frame ?"},{"location":"Theory/","text":"\u5173\u4e8e\u672c\u7ae0 \u4f5c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u5e08\uff0c\u6211\u4eec\u5df2\u7ecf\u5bf9programming language\u4e60\u4ee5\u4e3a\u5e38\uff0c\u5176\u5b9eprogramming language\u4e5f\u6d89\u53ca\u4e86\u4e00\u4e9b\u7406\u8bba\u77e5\u8bc6\u7684\uff0c\u672c\u7ae0\u5c31\u5bf9programming language theory\u8fdb\u884c\u68b3\u7406\u3002 \u53c2\u89c1\u7ef4\u57fa\u767e\u79d1 Programming language theory \u3002","title":"Introduction"},{"location":"Theory/#_1","text":"\u4f5c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u5e08\uff0c\u6211\u4eec\u5df2\u7ecf\u5bf9programming language\u4e60\u4ee5\u4e3a\u5e38\uff0c\u5176\u5b9eprogramming language\u4e5f\u6d89\u53ca\u4e86\u4e00\u4e9b\u7406\u8bba\u77e5\u8bc6\u7684\uff0c\u672c\u7ae0\u5c31\u5bf9programming language theory\u8fdb\u884c\u68b3\u7406\u3002 \u53c2\u89c1\u7ef4\u57fa\u767e\u79d1 Programming language theory \u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Theory/First-class-citizen/","text":"First-class citizen Concept Description Languages first-class function closures and anonymous functions Scheme , ML , Haskell , F# , Scala , Swift , PHP , Perl 6 , JavaScript , Delphi first-class control continuations Scheme , ML , F# first-class type Coq , Idris first-class data type Generic Haskell . C++11 first-class polymorphism impredicative polymorphism first-class message dynamic messages (method calls) Smalltalk ,[ 8] Objective-C [ 8] first-class class metaclass Smalltalk , Objective-C , Ruby , Python , Delphi proof object [ 9] Coq , Agda","title":"First-class-citizen"},{"location":"Theory/First-class-citizen/#first-class-citizen","text":"Concept Description Languages first-class function closures and anonymous functions Scheme , ML , Haskell , F# , Scala , Swift , PHP , Perl 6 , JavaScript , Delphi first-class control continuations Scheme , ML , F# first-class type Coq , Idris first-class data type Generic Haskell . C++11 first-class polymorphism impredicative polymorphism first-class message dynamic messages (method calls) Smalltalk ,[ 8] Objective-C [ 8] first-class class metaclass Smalltalk , Objective-C , Ruby , Python , Delphi proof object [ 9] Coq , Agda","title":"First-class citizen"},{"location":"Theory/Runtime/","text":"Runtime \u201cruntime\u201d\u8fd9\u4e2a\u8bcd\u8bed\uff0c\u7ecf\u5e38\u78b0\u5230\uff0c\u5176\u5b9e\u5b83\u6709\u4e24\u4e2a\u542b\u4e49\uff1a Runtime system Runtime (program lifecycle phase) \u7ef4\u57fa\u767e\u79d1 Runtime (program lifecycle phase) In computer science, runtime , run time or execution time is the time when the CPU is executing the machine code . This stage in the program lifecycle phases is the last step in the lifecycle process . \u5b83\u662f\u76f8\u5bf9\u4e8ecompile-time\u800c\u8a00\u7684\uff0c\u66f4\u591a\u5173\u4e8e\u5b83\u7684\u5185\u5bb9\uff0c\u53c2\u89c1\u5de5\u7a0b compile-principle \u7684\u6587\u7ae0 Compile-time and run-time \u3002 \u672c\u6587\u4e3b\u8981\u8ba8\u8bba Runtime system \uff0c\u5b83\u8868\u793a\u8bed\u8a00\u7684\u8fd0\u884c\u65f6\u73af\u5883\uff0c\u6bd4\u5982node.js\u662fJavaScript\u7684runtime\u3002 Common Language Runtime \u662f Microsoft .NET framework \u7684\u8fd0\u884c\u65f6\u3002 \u7ef4\u57fa\u767e\u79d1 Runtime system \u7ef4\u57fa\u767e\u79d1Notable runtimes Android Runtime (ART) Common Language Runtime (CLR) & Mono crt0 HHVM Java virtual machine (JVM) Objective-C V8 Node.js PyPy Zend Engine","title":"Runtime"},{"location":"Theory/Runtime/#runtime","text":"\u201cruntime\u201d\u8fd9\u4e2a\u8bcd\u8bed\uff0c\u7ecf\u5e38\u78b0\u5230\uff0c\u5176\u5b9e\u5b83\u6709\u4e24\u4e2a\u542b\u4e49\uff1a Runtime system Runtime (program lifecycle phase) \u7ef4\u57fa\u767e\u79d1 Runtime (program lifecycle phase) In computer science, runtime , run time or execution time is the time when the CPU is executing the machine code . This stage in the program lifecycle phases is the last step in the lifecycle process . \u5b83\u662f\u76f8\u5bf9\u4e8ecompile-time\u800c\u8a00\u7684\uff0c\u66f4\u591a\u5173\u4e8e\u5b83\u7684\u5185\u5bb9\uff0c\u53c2\u89c1\u5de5\u7a0b compile-principle \u7684\u6587\u7ae0 Compile-time and run-time \u3002 \u672c\u6587\u4e3b\u8981\u8ba8\u8bba Runtime system \uff0c\u5b83\u8868\u793a\u8bed\u8a00\u7684\u8fd0\u884c\u65f6\u73af\u5883\uff0c\u6bd4\u5982node.js\u662fJavaScript\u7684runtime\u3002 Common Language Runtime \u662f Microsoft .NET framework \u7684\u8fd0\u884c\u65f6\u3002","title":"Runtime"},{"location":"Theory/Runtime/#runtime-system","text":"","title":"\u7ef4\u57fa\u767e\u79d1Runtime system"},{"location":"Theory/Runtime/#notable-runtimes","text":"Android Runtime (ART) Common Language Runtime (CLR) & Mono crt0 HHVM Java virtual machine (JVM) Objective-C V8 Node.js PyPy Zend Engine","title":"\u7ef4\u57fa\u767e\u79d1Notable runtimes"},{"location":"Theory/Aliase/Aliasing(computing)/","text":"Aliasing \u201caliasing\u201d\u5373\u201c\u522b\u540d\u201d\uff0c\u5176\u5b9e\u5c31\u662f\u591a\u4e2aname\u90fd\u6307\u5411\u540c\u4e00\u4e2aobject\uff0caliasing\u5728programming language\u4e2d\u5e7f\u6cdb\u5b58\u5728\uff0c\u6700\u6700\u5178\u578b\u7684\u5c31\u662fc\u4e2d\u7684pointer\u3001c++\u4e2d\u7684reference\uff0c\u5728python\u4e2d\uff0c\u540c\u4e00\u4e2aobject\u53ef\u4ee5bind\u5230\u591a\u4e2aname\uff0c\u8fd9\u4e5f\u662f\u4e00\u79cdaliasing\u3002 \u7ef4\u57fa\u767e\u79d1 Aliasing (computing) In computing , aliasing describes a situation in which a data location in memory can be accessed through different symbolic names in the program. Thus, modifying the data through one name implicitly modifies the values associated with all aliased names , which may not be expected by the programmer. As a result, aliasing makes it particularly difficult to understand, analyze and optimize programs. Aliasing analysers intend to make and compute useful information for understanding aliasing in programs. NOTE: \u5178\u578b\u7684\u60c5\u51b5\u5c31\u662f\uff1a\u4e24\u4e2a\u6307\u5411\u540c\u4e00\u4e2amemory\u7684pointer\uff1b Examples Buffer overflow For example, most implementations of the C programming language do not perform array bounds checking . One can then exploit the implementation of the programming language by the compiler and the computer architecture's assembly language conventions, to achieve aliasing effects by writing outside of the array (a type of buffer overflow ). This invokes undefined behaviour according to the C language specification; however many implementations of C will show the aliasing effects described here. If an array is created on the stack , with a variable laid out in memory directly beside that array , one could index outside the array and directly change the variable by changing the relevant array element. For example, if we have an int array of size 2 (for this example's sake, calling it arr ), next to another int variable (call it i ), arr[2] (i.e. the 3 rd element) would be aliased to i if they are adjacent in memory. # include <stdio.h> int main () { int arr [ 2 ] = { 1 , 2 }; int i = 10 ; /* Write beyond the end of arr. Undefined behaviour in standard C, will write to i in some implementations. */ arr [ 2 ] = 20 ; printf ( \"element 0: %d \\t \" , arr [ 0 ]); // outputs 1 printf ( \"element 1: %d \\t \" , arr [ 1 ]); // outputs 2 printf ( \"element 2: %d \\t \" , arr [ 2 ]); // outputs 20, if aliasing occurred printf ( \"i: %d \\t\\t \" , i ); // might also output 20, not 10, because of aliasing, but the compiler might have i stored in a register and print 10 /* arr size is still 2. */ printf ( \"arr size: %d \\n \" , ( sizeof ( arr ) / sizeof ( int ))); } This is possible in some implementations of C because an array is a block of contiguous memory, and array elements are merely referenced by offsets off the address of the beginning of that block multiplied by the size of a single element. Since C has no bounds checking, indexing and addressing outside of the array is possible. Note that the aforementioned aliasing behaviour is undefined behaviour . Some implementations may leave space between arrays and variables on the stack, for instance, to align variables to memory locations that are a multiple of the architecture's native word size . The C standard does not generally specify how data is to be laid out in memory. (ISO/IEC 9899:1999, section 6.2.6.1). It is not erroneous for a compiler to omit aliasing effects for accesses that fall outside the bounds of an array. \u7f16\u8bd1\u5668\u4e3a\u8d85\u51fa\u6570\u7ec4\u8303\u56f4\u7684\u8bbf\u95ee\u7701\u7565\u522b\u540d\u6548\u5e94\u5e76\u4e0d\u662f\u9519\u8bef\u7684\u3002 Aliased pointers See also: Pointer aliasing Another variety of aliasing can occur in any language that can refer to one location in memory with more than one name (for example, with pointers ). See the C example of the xor swap algorithm that is a function; it assumes the two pointers passed to it are distinct, but if they are in fact equal (or aliases of each other), the function fails. This is a common problem with functions that accept pointer arguments, and their tolerance (or the lack thereof) for aliasing must be carefully documented, particularly for functions that perform complex manipulations on memory areas passed to them. Specified aliasing Controlled aliasing behaviour may be desirable in some cases (that is, aliasing behaviour that is specified, unlike that enabled by memory layout in C). It is common practice in Fortran . The Perl programming language specifies, in some constructs, aliasing behaviour, such as in foreach loops. This allows certain data structures to be modified directly with less code. For example, my @array = (1, 2, 3); foreach my $element (@array) { # Increment $element, thus automatically # modifying @array, since $element is ''aliased'' # to each of @array's elements in turn. $element++; } print \"@array \\n\"; will print out \"2 3 4\" as a result. If one wanted to bypass aliasing effects, one could copy the contents of the index variable into another and change the copy. SUMMARY : \u770b\u4e86\u4e0a\u9762\u8fd9\u6bb5\u8bdd\uff0c\u6211\u53d1\u73b0\uff1ac++\u8fd9\u7684reference\u548calias\u975e\u5e38\u7c7b\u4f3c Conflicts with optimization Optimizers often have to make conservative assumptions about variables in the presence of pointers. For example, knowing the value of a variable (such as x is 5) normally allows certain optimizations (such as constant propagation ). However, the compiler cannot use this information after an assignment to another variable (for example, in C, *y = 10 ) because it could be that *y is an alias of x . This could be the case after an assignment like y = &x . As an effect of this assignment to *y , the value of x would be changed as well, so propagating the information that x is 5 to the statements following *y = 10 would be potentially wrong (if *y is indeed an alias of x ). However, if we have information about pointers, the constant propagation process could make a query like: can x be an alias of *y ? Then, if the answer is no, x = 5 can be propagated safely. Another optimization impacted by aliasing is code reordering. If the compiler decides that x is not aliased by *y , then code that uses or changes the value of x can be moved before the assignment *y = 10 , if this would improve scheduling or enable more loop optimizations to be carried out. To enable such optimizations in a predictable manner, the ISO standard for the C programming language (including its newer C99 edition, see section 6.5, paragraph 7) specifies that it is illegal (with some exceptions) to access the same memory location using pointers of different types. A compiler may therefore assume that such pointers do not alias. This rule, known as the strict aliasing rule , sometimes allows for impressive increases in performance,[ 1] but has been known to break some otherwise valid code. Several software projects intentionally violate this portion of the C99 standard. For example, Python 2.x did so to implement reference counting,[ 2] and required changes to the basic object structs in Python 3 to enable this optimization. The Linux kernel does this because strict aliasing causes problems with optimization of inlined code.[ 3] In such cases, when compiled with gcc , the option -fno-strict-aliasing is invoked to prevent unwanted optimizations that could yield unexpected code. Hardware aliasing The term aliasing is also used to describe the situation where, due to either a hardware design choice or a hardware failure, one or more of the available address bits is not used in the memory selection process.[ 4] This may be a design decision if there are more address bits available than are necessary to support the installed memory device(s). In a failure, one or more address bits may be shorted together, or may be forced to ground (logic 0) or the supply voltage (logic 1). Example For this example, we assume a memory design with 8 locations, requiring only 3 address lines (or bits ) since 23 = 8). Address bits (named A2 through A0) are decoded to select unique memory locations as follows, in standard binary counter fashion: A2 A1 A0 Memory location 0 0 0 0 0 0 1 1 0 1 0 2 0 1 1 3 1 0 0 4 1 0 1 5 1 1 0 6 1 1 1 7 In the table above, each of the 8 unique combinations of address bits selects a different memory location. However, if one address bit (say A2) were to be shorted to ground, the table would be modified as follows: A2 A1 A0 Memory location 0 0 0 0 0 0 1 1 0 1 0 2 0 1 1 3 0 0 0 0 0 0 1 1 0 1 0 2 0 1 1 3 In this case, with A2 always being zero, the first four memory locations are duplicated and appear again as the second four. Memory locations 4 through 7 have become inaccessible. If this change occurred to a different address bit, the decoding results would be different, but in general the effect would be the same: the loss of a single address bit cuts the available memory space in half, with resulting duplication (aliasing) of the remaining space. See also Aliasing for uses of the word when applied to signal processing, including computer graphics Pointer alias References Mike Acton (2006-06-01). \"Understanding Strict Aliasing\" . ^ Neil Schemenauer (2003-07-17). \"ANSI strict aliasing and Python\" . ^ Linus Torvalds (2003-02-26). \"Re: Invalid compilation without -fno-strict-aliasing\" . ^ Michael Barr (2012-07-27). \"Software Based Memory Testing\" . External links Understanding Strict Aliasing \u2013 article by Mike Acton Aliasing, pointer casts and gcc 3.3 \u2013 informational article on NetBSD mailing list Type-based alias analysis in C++ \u2013 Informational article on type-based alias analysis in C++ Understand C/C++ Strict Aliasing \u2013 article on strict aliasing originally from the boost developer's wiki","title":"Aliasing(computing)"},{"location":"Theory/Aliase/Aliasing(computing)/#aliasing","text":"\u201caliasing\u201d\u5373\u201c\u522b\u540d\u201d\uff0c\u5176\u5b9e\u5c31\u662f\u591a\u4e2aname\u90fd\u6307\u5411\u540c\u4e00\u4e2aobject\uff0caliasing\u5728programming language\u4e2d\u5e7f\u6cdb\u5b58\u5728\uff0c\u6700\u6700\u5178\u578b\u7684\u5c31\u662fc\u4e2d\u7684pointer\u3001c++\u4e2d\u7684reference\uff0c\u5728python\u4e2d\uff0c\u540c\u4e00\u4e2aobject\u53ef\u4ee5bind\u5230\u591a\u4e2aname\uff0c\u8fd9\u4e5f\u662f\u4e00\u79cdaliasing\u3002","title":"Aliasing"},{"location":"Theory/Aliase/Aliasing(computing)/#aliasing-computing","text":"In computing , aliasing describes a situation in which a data location in memory can be accessed through different symbolic names in the program. Thus, modifying the data through one name implicitly modifies the values associated with all aliased names , which may not be expected by the programmer. As a result, aliasing makes it particularly difficult to understand, analyze and optimize programs. Aliasing analysers intend to make and compute useful information for understanding aliasing in programs. NOTE: \u5178\u578b\u7684\u60c5\u51b5\u5c31\u662f\uff1a\u4e24\u4e2a\u6307\u5411\u540c\u4e00\u4e2amemory\u7684pointer\uff1b","title":"\u7ef4\u57fa\u767e\u79d1Aliasing (computing)"},{"location":"Theory/Aliase/Aliasing(computing)/#examples","text":"","title":"Examples"},{"location":"Theory/Aliase/Aliasing(computing)/#buffer-overflow","text":"For example, most implementations of the C programming language do not perform array bounds checking . One can then exploit the implementation of the programming language by the compiler and the computer architecture's assembly language conventions, to achieve aliasing effects by writing outside of the array (a type of buffer overflow ). This invokes undefined behaviour according to the C language specification; however many implementations of C will show the aliasing effects described here. If an array is created on the stack , with a variable laid out in memory directly beside that array , one could index outside the array and directly change the variable by changing the relevant array element. For example, if we have an int array of size 2 (for this example's sake, calling it arr ), next to another int variable (call it i ), arr[2] (i.e. the 3 rd element) would be aliased to i if they are adjacent in memory. # include <stdio.h> int main () { int arr [ 2 ] = { 1 , 2 }; int i = 10 ; /* Write beyond the end of arr. Undefined behaviour in standard C, will write to i in some implementations. */ arr [ 2 ] = 20 ; printf ( \"element 0: %d \\t \" , arr [ 0 ]); // outputs 1 printf ( \"element 1: %d \\t \" , arr [ 1 ]); // outputs 2 printf ( \"element 2: %d \\t \" , arr [ 2 ]); // outputs 20, if aliasing occurred printf ( \"i: %d \\t\\t \" , i ); // might also output 20, not 10, because of aliasing, but the compiler might have i stored in a register and print 10 /* arr size is still 2. */ printf ( \"arr size: %d \\n \" , ( sizeof ( arr ) / sizeof ( int ))); } This is possible in some implementations of C because an array is a block of contiguous memory, and array elements are merely referenced by offsets off the address of the beginning of that block multiplied by the size of a single element. Since C has no bounds checking, indexing and addressing outside of the array is possible. Note that the aforementioned aliasing behaviour is undefined behaviour . Some implementations may leave space between arrays and variables on the stack, for instance, to align variables to memory locations that are a multiple of the architecture's native word size . The C standard does not generally specify how data is to be laid out in memory. (ISO/IEC 9899:1999, section 6.2.6.1). It is not erroneous for a compiler to omit aliasing effects for accesses that fall outside the bounds of an array. \u7f16\u8bd1\u5668\u4e3a\u8d85\u51fa\u6570\u7ec4\u8303\u56f4\u7684\u8bbf\u95ee\u7701\u7565\u522b\u540d\u6548\u5e94\u5e76\u4e0d\u662f\u9519\u8bef\u7684\u3002","title":"Buffer overflow"},{"location":"Theory/Aliase/Aliasing(computing)/#aliased-pointers","text":"See also: Pointer aliasing Another variety of aliasing can occur in any language that can refer to one location in memory with more than one name (for example, with pointers ). See the C example of the xor swap algorithm that is a function; it assumes the two pointers passed to it are distinct, but if they are in fact equal (or aliases of each other), the function fails. This is a common problem with functions that accept pointer arguments, and their tolerance (or the lack thereof) for aliasing must be carefully documented, particularly for functions that perform complex manipulations on memory areas passed to them.","title":"Aliased pointers"},{"location":"Theory/Aliase/Aliasing(computing)/#specified-aliasing","text":"Controlled aliasing behaviour may be desirable in some cases (that is, aliasing behaviour that is specified, unlike that enabled by memory layout in C). It is common practice in Fortran . The Perl programming language specifies, in some constructs, aliasing behaviour, such as in foreach loops. This allows certain data structures to be modified directly with less code. For example, my @array = (1, 2, 3); foreach my $element (@array) { # Increment $element, thus automatically # modifying @array, since $element is ''aliased'' # to each of @array's elements in turn. $element++; } print \"@array \\n\"; will print out \"2 3 4\" as a result. If one wanted to bypass aliasing effects, one could copy the contents of the index variable into another and change the copy. SUMMARY : \u770b\u4e86\u4e0a\u9762\u8fd9\u6bb5\u8bdd\uff0c\u6211\u53d1\u73b0\uff1ac++\u8fd9\u7684reference\u548calias\u975e\u5e38\u7c7b\u4f3c","title":"Specified aliasing"},{"location":"Theory/Aliase/Aliasing(computing)/#conflicts-with-optimization","text":"Optimizers often have to make conservative assumptions about variables in the presence of pointers. For example, knowing the value of a variable (such as x is 5) normally allows certain optimizations (such as constant propagation ). However, the compiler cannot use this information after an assignment to another variable (for example, in C, *y = 10 ) because it could be that *y is an alias of x . This could be the case after an assignment like y = &x . As an effect of this assignment to *y , the value of x would be changed as well, so propagating the information that x is 5 to the statements following *y = 10 would be potentially wrong (if *y is indeed an alias of x ). However, if we have information about pointers, the constant propagation process could make a query like: can x be an alias of *y ? Then, if the answer is no, x = 5 can be propagated safely. Another optimization impacted by aliasing is code reordering. If the compiler decides that x is not aliased by *y , then code that uses or changes the value of x can be moved before the assignment *y = 10 , if this would improve scheduling or enable more loop optimizations to be carried out. To enable such optimizations in a predictable manner, the ISO standard for the C programming language (including its newer C99 edition, see section 6.5, paragraph 7) specifies that it is illegal (with some exceptions) to access the same memory location using pointers of different types. A compiler may therefore assume that such pointers do not alias. This rule, known as the strict aliasing rule , sometimes allows for impressive increases in performance,[ 1] but has been known to break some otherwise valid code. Several software projects intentionally violate this portion of the C99 standard. For example, Python 2.x did so to implement reference counting,[ 2] and required changes to the basic object structs in Python 3 to enable this optimization. The Linux kernel does this because strict aliasing causes problems with optimization of inlined code.[ 3] In such cases, when compiled with gcc , the option -fno-strict-aliasing is invoked to prevent unwanted optimizations that could yield unexpected code.","title":"Conflicts with optimization"},{"location":"Theory/Aliase/Aliasing(computing)/#hardware-aliasing","text":"The term aliasing is also used to describe the situation where, due to either a hardware design choice or a hardware failure, one or more of the available address bits is not used in the memory selection process.[ 4] This may be a design decision if there are more address bits available than are necessary to support the installed memory device(s). In a failure, one or more address bits may be shorted together, or may be forced to ground (logic 0) or the supply voltage (logic 1). Example For this example, we assume a memory design with 8 locations, requiring only 3 address lines (or bits ) since 23 = 8). Address bits (named A2 through A0) are decoded to select unique memory locations as follows, in standard binary counter fashion: A2 A1 A0 Memory location 0 0 0 0 0 0 1 1 0 1 0 2 0 1 1 3 1 0 0 4 1 0 1 5 1 1 0 6 1 1 1 7 In the table above, each of the 8 unique combinations of address bits selects a different memory location. However, if one address bit (say A2) were to be shorted to ground, the table would be modified as follows: A2 A1 A0 Memory location 0 0 0 0 0 0 1 1 0 1 0 2 0 1 1 3 0 0 0 0 0 0 1 1 0 1 0 2 0 1 1 3 In this case, with A2 always being zero, the first four memory locations are duplicated and appear again as the second four. Memory locations 4 through 7 have become inaccessible. If this change occurred to a different address bit, the decoding results would be different, but in general the effect would be the same: the loss of a single address bit cuts the available memory space in half, with resulting duplication (aliasing) of the remaining space.","title":"Hardware aliasing"},{"location":"Theory/Aliase/Aliasing(computing)/#see-also","text":"Aliasing for uses of the word when applied to signal processing, including computer graphics Pointer alias","title":"See also"},{"location":"Theory/Aliase/Aliasing(computing)/#references","text":"Mike Acton (2006-06-01). \"Understanding Strict Aliasing\" . ^ Neil Schemenauer (2003-07-17). \"ANSI strict aliasing and Python\" . ^ Linus Torvalds (2003-02-26). \"Re: Invalid compilation without -fno-strict-aliasing\" . ^ Michael Barr (2012-07-27). \"Software Based Memory Testing\" .","title":"References"},{"location":"Theory/Aliase/Aliasing(computing)/#external-links","text":"Understanding Strict Aliasing \u2013 article by Mike Acton Aliasing, pointer casts and gcc 3.3 \u2013 informational article on NetBSD mailing list Type-based alias analysis in C++ \u2013 Informational article on type-based alias analysis in C++ Understand C/C++ Strict Aliasing \u2013 article on strict aliasing originally from the boost developer's wiki","title":"External links"},{"location":"Theory/Basic-Language-construct/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u8bb2\u8ff0programming language\u6700\u6700\u57fa\u672c\u7684construct\uff1a operator\u3001expression\u3001statement\uff0c\u5173\u4e8estatement\uff0c\u5728\u6587\u7ae0 Unit \u4e2d\u5df2\u7ecf\u63d0\u53ca\u8fc7\u5b83\u3002","title":"Introduction"},{"location":"Theory/Basic-Language-construct/#_1","text":"\u672c\u7ae0\u8bb2\u8ff0programming language\u6700\u6700\u57fa\u672c\u7684construct\uff1a operator\u3001expression\u3001statement\uff0c\u5173\u4e8estatement\uff0c\u5728\u6587\u7ae0 Unit \u4e2d\u5df2\u7ecf\u63d0\u53ca\u8fc7\u5b83\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Theory/Basic-Language-construct/Operator-expression-statement/","text":"Operator expression and statement \u5927\u591a\u6570programming language\u90fd\u4f1a\u6d89\u53ca\u5230\u8fd9\u4e09\u4e2a\u6982\u5ff5\uff0c\u672c\u6587\u5bf9\u5b83\u4eec\u8fdb\u884c\u5206\u6790\uff0c\u6211\u89c9\u5f97\u4eceexpression\u4f5c\u4e3a\u5207\u5165\u70b9\u662f\u6700\u597d\u7684\uff0c\u4e00\u662f\u56e0\u4e3a\u5b83\u662f\u6211\u4eec\u6700\u6700\u719f\u6089\u7684\uff08\u6211\u4eec\u4ece\u5c0f\u5c31\u5b66\u4e60\u6570\u5b66\uff0c\u6570\u5b66\u8868\u8fbe\u5f0f\u7684\u6982\u5ff5\u6211\u4eec\u65e9\u5df2\u6839\u6df1\u8482\u56fa\u4e86\uff09\uff0c\u4e8c\u662f\u56e0\u4e3aexpression\u7531operator\u6784\u6210\uff0c\u4e14expression\u4e5f\u53ef\u4ee5\u6784\u6210statement\u3002 Expression and operator cppreference\u4e2d\u5bf9c++\u8bed\u8a00\u7684 Expressions \u7684\u4ecb\u7ecd\u5982\u4e0b\uff1a An expression is a sequence of operators and their operands , that specifies a computation. Expression evaluation may produce a result (e.g., evaluation of 2+2 produces the result 4) and may generate side-effects (e.g. evaluation of std::printf(\"%d\",4) prints the character '4' on the standard output). std::printf(\"%d\",4) \u6d89\u53ca\u5230\u7684*operators*\u662f () \uff0c\u5728 c++ \u4e2d\uff0c\u5b83\u8868\u793a\u7684\u662f\u51fd\u6570\u8c03\u7528\uff1b \u663e\u7136expression\u662f\u6d89\u53ca\u5230***operators***\uff0c\u63d0\u53ca***operators***\uff0c\u6211\u4eec\u7684\u7b2c\u4e00\u53cd\u5e94\u5c31\u662f\u6570\u5b66\u4e2d\u7684\u4e00\u4e9b\u5e38\u89c1\u7684operator\uff0c +-*/ \uff0c\u5b83\u4eec\u662f\u4e00\u95e8programming language\u4e2d\u6700\u6700\u57fa\u7840\u7684*operator*\uff1b\u5176\u5b9e\u8fd9\u4e5f\u63ed\u793a\u4e86programming language\u5176\u5b9e\u662f\u6df1\u6df1\u7684\u624e\u6839\u4e8emath\u7684\uff0cprogramming language\u4e2d\u7684\u5f88\u591aexpression\u5c31\u662f\u76f4\u63a5\u7684 math expression \uff0cprogramming language\u4e2d\u7684expression\u9075\u5faa\u7740 math expression \u7cfb\u7edf\u7684\u89c4\u5f8b\uff0c\u8fd9\u662f\u56e0\u4e3aprogramming language\u662f\u8d77\u6e90\u81eamath\uff0c\u6216\u8005\u6309\u7167\u5728\u6587\u7ae0 Language \u4e2d\u6240\u8ff0\u7684\u89c2\u70b9\uff1a\u4f7f\u7528programming language\u6765\u63cf\u8ff0\u8ba1\u7b97\u3002 \u4f46\u662fprogramming language\u6bd5\u7adf\u4e0d\u662fmath\uff0c\u5b83\u8fd8\u6709\u5f88\u591a\u5176\u4ed6\u7684\u9700\u6c42\uff0c\u56e0\u6b64\uff0cprogramming language\u6269\u5c55\u51fa\u4e86\u975e\u5e38\u591a\u7684***operator***\uff0c\u5982\u5728 c \u548c c++ \u4e2d\u975e\u5e38\u5e38\u89c1\u7684 type conversion \uff0c\u5982\u6240\u6709\u7684programming language\u4e2d\u90fd\u662f\u652f\u6301\u7684function call\uff08 c++ function call \uff0c python function call \uff09\uff0c\u5982class member\u7684access\uff08 python Attribute references , c++ member access \uff09\u7b49\uff1b \u5176\u5b9e\uff0cprogramming language\u548cmath\u90fd\u662f\u5728\u4f7f\u7528***operator***\uff0c***operator***\u5f80\u5f80\u90fd\u662f\u4e00\u4e9b\u7b26\u53f7\uff0cprogramming language\u7684\u80fd\u591f\u4f7f\u7528\u7684\u7b26\u53f7\u4ec5\u4ec5\u5c40\u9650\u4e8eASCII\u7b26\u53f7\uff0c\u800cmath\u4e2d\u80fd\u591f\u4f7f\u7528\u7684\u7b26\u53f7\u5219\u662f\u975e\u5e38\u5e7f\u6cdb\u7684\uff0c\u5b83\u4e0d\u4ec5\u4ec5\u5c40\u9650\u4e8eASCII\uff1b\u6240\u6709programming language\u4e3a\u4e86\u6446\u8131\u8fd9\u4e2a\u9650\u5236\uff0c\u53ea\u80fd\u591f\u4f7f\u7528\u4e00\u4e9b\u5b57\u6bcd\u7ec4\u5408\u6765\u8868\u793a\u4e00\u4e9boperator\uff0c\u6bd4\u5982 c++ new \uff0c python await \uff0c\u8fd9\u4e9b\u8868\u793aoperator\u7684\u5b57\u6bcd\u7ec4\u5408\u5f80\u5f80\u88abprogramming language\u4f5c\u4e3akey word\u6765\u4f7f\u7528\u3002\u5bf9\u4e8e\u8fd9\u4e9b\u4f7f\u7528\u5b57\u6bcd\u7ec4\u5408\u6765\u8868\u793a\u7684operator\uff0c\u662fprogrammer\u975e\u5e38\u4efb\u610f\u5ffd\u89c6\u7684\uff1b NOTE: c++ new \u662f\u4e00\u4e2aoperator\uff0c\u4f46\u662f c malloc \u662f\u4e00\u4e2afunction\uff1b \u63d0\u53ca*operators*\uff0c\u5c31\u6d89\u53ca\u5230Operator precedence\uff0c Wikipedia Order of operations \uff0c c++ operator precedence \uff0c python precedence \u3002 \u548c math expression \u4e00\u6837\uff0cprogramming language\u4e2d\u7684expression\u4e5f\u662f\u53ef\u4ee5\u8fdb\u884cevaluation\uff0c\u8fd9\u4e00\u70b9\u5728 Expression (computer science) \u4e2d\u8fdb\u884c\u4e86\u4ecb\u7ecd\uff1b\u5982\u7b2c\u4e00\u6bb5\u6240\u5c5e\uff0c Expression evaluation may produce a result and may generate side-effects\u3002 \u63d0\u53caoperator\uff0c\u5c31\u4f1a\u6d89\u53ca\u5230operator overloading\uff0c c++ operator overloading \uff0c python Emulating numeric types \u7b49\uff1b \u603b\u7684\u6765\u8bf4\uff0cprogramming language\u7684expression\u5176\u5b9e\u975e\u5e38\u7c7b\u4f3c\u4e8emath expression\uff0cprogrammer\u4f7f\u7528\u5b83\u4eec\u6765\u8868\u8fbe\u5982\u4f55\u8fdb\u884c\u8fd0\u7b97\uff1b \u5173\u4e8eexpression\uff0c\u65e0\u8bba\u662fc\uff0c c++ \u8fd8\u662fpython\uff0c\u672c\u8d28\u4e0a\u90fd\u9075\u5faa\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u6240\u603b\u7ed3\u7684\uff1b \u53c2\u89c1 \u7ef4\u57fa\u767e\u79d1 Expression (computer science) Statements \u7ef4\u57fa\u767e\u79d1 Statement (computer science) \u7684\u4ecb\u7ecd\u662f\u6bd4\u8f83\u597d\u7684\uff1a In computer programming , a statement is a syntactic unit of an imperative programming language that expresses some action to be carried out. A program written in such a language is formed by a sequence of one or more statements. A statement may have internal components (e.g., expressions ). \u663e\u7136\uff0c\u4e0a\u8ff0\u89c2\u70b9\u548c\u6211\u5728\u6587\u7ae0 Unit \u4e2d\u6240\u603b\u7ed3\u7684\uff1a \u663e\u7136\uff0c\u5982\u679c\u5c06\u6211\u4eec\u7684program\u6bd4\u4f5c\u662f\u4e00\u7bc7\u6587\u7ae0\u7684\u8bdd\uff0cstatement\u5c31\u76f8\u5f53\u4e8e\u201c\u53e5\u5b50\u201d\u3002 syntax \u5728\u7ef4\u57fa\u767e\u79d1 Statement (computer science) \u7684 Syntax \u6bb5\u4ecb\u7ecd\u4e86\u63cf\u8ff0\uff08\u5b9a\u4e49\uff09statement\u7684\u8bed\u6cd5\uff0c\u6bd4\u5982python\u4e2d\u4f7f\u7528indentation\uff0cc\u548c c++ \u4e2d\u4f7f\u7528 ; \u3002 Classification \u5728\u7ef4\u57fa\u767e\u79d1 Statement (computer science) \u7684 Kinds of statements \u6bb5\u4ecb\u7ecd\u4e86\u63cf\u8ff0\uff08\u5b9a\u4e49\uff09statement\u7684\u5206\u7c7b\uff0c\u5927\u591a\u6570programming language\u90fd\u5c06statement\u5206\u4e3a\uff1a Simple statements Compound statements python statement \u5728python\u4e2d\u5c06***statement***\u5206\u4e3a simple statement \u548c Compound statements \u3002 python\u4e2d\u5bf9 simple statement \u7684\u5b9a\u4e49\u5982\u4e0b\uff1a A simple statement is comprised within a single logical line . Several simple statements may occur on a single line separated by semicolons. python\u4e2d\u5bf9 Compound statements \u7684\u5b9a\u4e49\u5982\u4e0b\uff1a Compound statements contain (groups of) other statements; they affect or control the execution of those other statements in some way. In general, compound statements span multiple lines, although in simple incarnations a whole compound statement may be contained in one line. \u5176\u5b9epython\u4e2d\u7684 simple statement \u548c Compound statements \u7684\u754c\u5b9a\u662f\u975e\u5e38\u7b80\u5355\u7684\uff0c \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u4e0a\u9762\u6211\u5bf9statement\u7684\u7406\u89e3\u662f\uff1a***statement***\u63a7\u5236\u7740\u7a0b\u5e8f\u6267\u884c\u7684**\u6d41\u7a0b**\uff0c\u5176\u5b9e\u8fd9\u662f\u4e0d\u5b8c\u5907\u7684\uff0c\u5982 python Function definitions \u548c python Class definitions \u90fd\u662fstatement\uff0c\u6240\u4ee5\u5728python\u4e2dstatement\u8fd8\u5177\u5907**\u5b9a\u4e49**\u7684\u529f\u80fd\u3002 \u90a3\u5e94\u8be5\u5982\u4f55\u7406\u89e3python\u4e2d\u7684**\u51fd\u6570\u5b9a\u4e49\u8bed\u53e5**\u5462\uff1f\u5728python\u4e2d\uff0c\u5e76\u6ca1\u6709declaration\uff0c\u51fd\u6570\u5b9a\u4e49\u8bed\u53e5\u5728python\u4e2d\u662fname bind\u53c2\u770b python Function definitions \uff0c\u5176\u4e2d\u7684\u89e3\u91ca\u662f\u975e\u5e38\u6e05\u695a\u7684\uff1a A function definition is an executable statement . Its execution binds the function name in the current local namespace to a function object (a wrapper around the executable code for the function). This function object contains a reference to the current global namespace as the global namespace to be used when the function is called. \u4e24\u8005\u4e4b\u95f4\u7684\u672c\u8d28\u5dee\u522b\u5728\u4e8epython program\u6700\u7ec8\u662f\u7531python interpreter\u6765\u89e3\u91ca\u6267\u884c\u7684\uff0c\u5e76\u4e14python\u4e2deverything is an object\uff1b\u800cc++ program\u5219\u9700\u8981\u7531compiler\u8fdb\u884ccompile\uff0c\u5b83\u7684declaration\u90fd\u662f\u5411compiler\u8fdb\u884cdeclare\uff1b TODO \uff1a \u5173\u4e8epython lack declaration\uff0c\u9700\u8981\u518d\u53bb\u67e5\u9605\u67e5\u9605\u8d44\u6599\uff0c\u4ee5\u4e0b\u662f\u4e00\u4e9b\u91cd\u8981\u8d44\u6599\uff1a Python variable declaration python lacks declaration c++ statement \u5728 c++ statement \u7684\u5206\u7c7b\u4e0e\u754c\u5b9a\u6bd4python\u8981\u590d\u6742\u5730\u591a\uff0c\u5982\u4e0b\u662f c++ \u4e2d\u7684statement\u7684\u5206\u7c7b \uff1a C++ includes the following types of statements: 1) expression statements; 2) compound statements; 3) selection statements; 4) iteration statements; 5) jump statements; 6) declaration statements; 7) try blocks; 8) atomic and synchronized blocks (TM TS). \u5728 c++ \u4e2d\u6709 declaration statements \uff0c\u5982 int n = 1;// declaration statement \uff0c\u800cpython\u4e2d\u5374\u6ca1\u6709\uff0c python lack declaration \uff0c\u6211\u89c9\u5f97python\u4e2d\u7684declaration statement\u5176\u5b9e\u5bf9\u5e94\u8fd9python\u4e2d\u7684name bind\uff1b\u663e\u7136\u8fd9\u662fpython\u548c c++ \u7684\u663e\u8457\u5dee\u522b\uff1b \u603b\u7684\u6765\u8bf4\uff1astatement\u6709\u7740\u5982\u4e0b\u7684\u529f\u80fd\uff1a ***statement***\u63a7\u5236\u7740\u7a0b\u5e8f\u6267\u884c\u7684**\u6d41\u7a0b**\uff08\u663e\u7136expression\u5e76\u4e0d\u5177\u5907\u8fd9\u6837\u7684\u529f\u80fd\uff09\uff0c\u5982\u987a\u5e8f\u6267\u884c\uff0c\u5faa\u73af\u6267\u884c\uff08 for \uff0c while \uff09\uff0c return \uff0c\u6761\u4ef6\u5206\u652f\u6267\u884c\uff08 if-else \uff09\uff1b \u5b9a\u4e49\u4e0e\u58f0\u660e \u4ece = \u6765\u770b\u5f85expression\u548cstatement\u4e4b\u95f4\u7684\u5dee\u5f02 \u5728 Operator associativity \u4e2d\u6709\u8fd9\u6837\u7684\u63cf\u8ff0\uff1a In many imperative programming languages , the assignment operator is defined to be right-associative, and assignment is defined to be an expression (with a value ), not just a statement . This allows chained assignment by using the value of one assignment expression as the input (right operand) of the next. For example, in C , the assignment a = b is an expression that returns a value (namely, b converted to the type of a ) with the side effect of setting a to this value. An assignment can be performed in the middle of an expression. The right-associativity of the = operator allows expressions such as a = b = c to be interpreted as a = (b = c) , thereby setting both a and b to the value of c . In C, the alternative (a = b) = c does not make sense because a = b is not an l-Value , just an r-value. However, in C++ an assignment a = b returns a value referring to the left term in the assignment. Therefore, (a = b) = c can be interpreted as a = b; a = c; .","title":"Operator-expression-statement"},{"location":"Theory/Basic-Language-construct/Operator-expression-statement/#operator-expression-and-statement","text":"\u5927\u591a\u6570programming language\u90fd\u4f1a\u6d89\u53ca\u5230\u8fd9\u4e09\u4e2a\u6982\u5ff5\uff0c\u672c\u6587\u5bf9\u5b83\u4eec\u8fdb\u884c\u5206\u6790\uff0c\u6211\u89c9\u5f97\u4eceexpression\u4f5c\u4e3a\u5207\u5165\u70b9\u662f\u6700\u597d\u7684\uff0c\u4e00\u662f\u56e0\u4e3a\u5b83\u662f\u6211\u4eec\u6700\u6700\u719f\u6089\u7684\uff08\u6211\u4eec\u4ece\u5c0f\u5c31\u5b66\u4e60\u6570\u5b66\uff0c\u6570\u5b66\u8868\u8fbe\u5f0f\u7684\u6982\u5ff5\u6211\u4eec\u65e9\u5df2\u6839\u6df1\u8482\u56fa\u4e86\uff09\uff0c\u4e8c\u662f\u56e0\u4e3aexpression\u7531operator\u6784\u6210\uff0c\u4e14expression\u4e5f\u53ef\u4ee5\u6784\u6210statement\u3002","title":"Operator expression and statement"},{"location":"Theory/Basic-Language-construct/Operator-expression-statement/#expression-and-operator","text":"cppreference\u4e2d\u5bf9c++\u8bed\u8a00\u7684 Expressions \u7684\u4ecb\u7ecd\u5982\u4e0b\uff1a An expression is a sequence of operators and their operands , that specifies a computation. Expression evaluation may produce a result (e.g., evaluation of 2+2 produces the result 4) and may generate side-effects (e.g. evaluation of std::printf(\"%d\",4) prints the character '4' on the standard output). std::printf(\"%d\",4) \u6d89\u53ca\u5230\u7684*operators*\u662f () \uff0c\u5728 c++ \u4e2d\uff0c\u5b83\u8868\u793a\u7684\u662f\u51fd\u6570\u8c03\u7528\uff1b \u663e\u7136expression\u662f\u6d89\u53ca\u5230***operators***\uff0c\u63d0\u53ca***operators***\uff0c\u6211\u4eec\u7684\u7b2c\u4e00\u53cd\u5e94\u5c31\u662f\u6570\u5b66\u4e2d\u7684\u4e00\u4e9b\u5e38\u89c1\u7684operator\uff0c +-*/ \uff0c\u5b83\u4eec\u662f\u4e00\u95e8programming language\u4e2d\u6700\u6700\u57fa\u7840\u7684*operator*\uff1b\u5176\u5b9e\u8fd9\u4e5f\u63ed\u793a\u4e86programming language\u5176\u5b9e\u662f\u6df1\u6df1\u7684\u624e\u6839\u4e8emath\u7684\uff0cprogramming language\u4e2d\u7684\u5f88\u591aexpression\u5c31\u662f\u76f4\u63a5\u7684 math expression \uff0cprogramming language\u4e2d\u7684expression\u9075\u5faa\u7740 math expression \u7cfb\u7edf\u7684\u89c4\u5f8b\uff0c\u8fd9\u662f\u56e0\u4e3aprogramming language\u662f\u8d77\u6e90\u81eamath\uff0c\u6216\u8005\u6309\u7167\u5728\u6587\u7ae0 Language \u4e2d\u6240\u8ff0\u7684\u89c2\u70b9\uff1a\u4f7f\u7528programming language\u6765\u63cf\u8ff0\u8ba1\u7b97\u3002 \u4f46\u662fprogramming language\u6bd5\u7adf\u4e0d\u662fmath\uff0c\u5b83\u8fd8\u6709\u5f88\u591a\u5176\u4ed6\u7684\u9700\u6c42\uff0c\u56e0\u6b64\uff0cprogramming language\u6269\u5c55\u51fa\u4e86\u975e\u5e38\u591a\u7684***operator***\uff0c\u5982\u5728 c \u548c c++ \u4e2d\u975e\u5e38\u5e38\u89c1\u7684 type conversion \uff0c\u5982\u6240\u6709\u7684programming language\u4e2d\u90fd\u662f\u652f\u6301\u7684function call\uff08 c++ function call \uff0c python function call \uff09\uff0c\u5982class member\u7684access\uff08 python Attribute references , c++ member access \uff09\u7b49\uff1b \u5176\u5b9e\uff0cprogramming language\u548cmath\u90fd\u662f\u5728\u4f7f\u7528***operator***\uff0c***operator***\u5f80\u5f80\u90fd\u662f\u4e00\u4e9b\u7b26\u53f7\uff0cprogramming language\u7684\u80fd\u591f\u4f7f\u7528\u7684\u7b26\u53f7\u4ec5\u4ec5\u5c40\u9650\u4e8eASCII\u7b26\u53f7\uff0c\u800cmath\u4e2d\u80fd\u591f\u4f7f\u7528\u7684\u7b26\u53f7\u5219\u662f\u975e\u5e38\u5e7f\u6cdb\u7684\uff0c\u5b83\u4e0d\u4ec5\u4ec5\u5c40\u9650\u4e8eASCII\uff1b\u6240\u6709programming language\u4e3a\u4e86\u6446\u8131\u8fd9\u4e2a\u9650\u5236\uff0c\u53ea\u80fd\u591f\u4f7f\u7528\u4e00\u4e9b\u5b57\u6bcd\u7ec4\u5408\u6765\u8868\u793a\u4e00\u4e9boperator\uff0c\u6bd4\u5982 c++ new \uff0c python await \uff0c\u8fd9\u4e9b\u8868\u793aoperator\u7684\u5b57\u6bcd\u7ec4\u5408\u5f80\u5f80\u88abprogramming language\u4f5c\u4e3akey word\u6765\u4f7f\u7528\u3002\u5bf9\u4e8e\u8fd9\u4e9b\u4f7f\u7528\u5b57\u6bcd\u7ec4\u5408\u6765\u8868\u793a\u7684operator\uff0c\u662fprogrammer\u975e\u5e38\u4efb\u610f\u5ffd\u89c6\u7684\uff1b NOTE: c++ new \u662f\u4e00\u4e2aoperator\uff0c\u4f46\u662f c malloc \u662f\u4e00\u4e2afunction\uff1b \u63d0\u53ca*operators*\uff0c\u5c31\u6d89\u53ca\u5230Operator precedence\uff0c Wikipedia Order of operations \uff0c c++ operator precedence \uff0c python precedence \u3002 \u548c math expression \u4e00\u6837\uff0cprogramming language\u4e2d\u7684expression\u4e5f\u662f\u53ef\u4ee5\u8fdb\u884cevaluation\uff0c\u8fd9\u4e00\u70b9\u5728 Expression (computer science) \u4e2d\u8fdb\u884c\u4e86\u4ecb\u7ecd\uff1b\u5982\u7b2c\u4e00\u6bb5\u6240\u5c5e\uff0c Expression evaluation may produce a result and may generate side-effects\u3002 \u63d0\u53caoperator\uff0c\u5c31\u4f1a\u6d89\u53ca\u5230operator overloading\uff0c c++ operator overloading \uff0c python Emulating numeric types \u7b49\uff1b \u603b\u7684\u6765\u8bf4\uff0cprogramming language\u7684expression\u5176\u5b9e\u975e\u5e38\u7c7b\u4f3c\u4e8emath expression\uff0cprogrammer\u4f7f\u7528\u5b83\u4eec\u6765\u8868\u8fbe\u5982\u4f55\u8fdb\u884c\u8fd0\u7b97\uff1b \u5173\u4e8eexpression\uff0c\u65e0\u8bba\u662fc\uff0c c++ \u8fd8\u662fpython\uff0c\u672c\u8d28\u4e0a\u90fd\u9075\u5faa\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u6240\u603b\u7ed3\u7684\uff1b","title":"Expression and operator"},{"location":"Theory/Basic-Language-construct/Operator-expression-statement/#_1","text":"\u7ef4\u57fa\u767e\u79d1 Expression (computer science)","title":"\u53c2\u89c1"},{"location":"Theory/Basic-Language-construct/Operator-expression-statement/#statements","text":"\u7ef4\u57fa\u767e\u79d1 Statement (computer science) \u7684\u4ecb\u7ecd\u662f\u6bd4\u8f83\u597d\u7684\uff1a In computer programming , a statement is a syntactic unit of an imperative programming language that expresses some action to be carried out. A program written in such a language is formed by a sequence of one or more statements. A statement may have internal components (e.g., expressions ). \u663e\u7136\uff0c\u4e0a\u8ff0\u89c2\u70b9\u548c\u6211\u5728\u6587\u7ae0 Unit \u4e2d\u6240\u603b\u7ed3\u7684\uff1a \u663e\u7136\uff0c\u5982\u679c\u5c06\u6211\u4eec\u7684program\u6bd4\u4f5c\u662f\u4e00\u7bc7\u6587\u7ae0\u7684\u8bdd\uff0cstatement\u5c31\u76f8\u5f53\u4e8e\u201c\u53e5\u5b50\u201d\u3002","title":"Statements"},{"location":"Theory/Basic-Language-construct/Operator-expression-statement/#syntax","text":"\u5728\u7ef4\u57fa\u767e\u79d1 Statement (computer science) \u7684 Syntax \u6bb5\u4ecb\u7ecd\u4e86\u63cf\u8ff0\uff08\u5b9a\u4e49\uff09statement\u7684\u8bed\u6cd5\uff0c\u6bd4\u5982python\u4e2d\u4f7f\u7528indentation\uff0cc\u548c c++ \u4e2d\u4f7f\u7528 ; \u3002","title":"syntax"},{"location":"Theory/Basic-Language-construct/Operator-expression-statement/#classification","text":"\u5728\u7ef4\u57fa\u767e\u79d1 Statement (computer science) \u7684 Kinds of statements \u6bb5\u4ecb\u7ecd\u4e86\u63cf\u8ff0\uff08\u5b9a\u4e49\uff09statement\u7684\u5206\u7c7b\uff0c\u5927\u591a\u6570programming language\u90fd\u5c06statement\u5206\u4e3a\uff1a Simple statements Compound statements","title":"Classification"},{"location":"Theory/Basic-Language-construct/Operator-expression-statement/#python-statement","text":"\u5728python\u4e2d\u5c06***statement***\u5206\u4e3a simple statement \u548c Compound statements \u3002 python\u4e2d\u5bf9 simple statement \u7684\u5b9a\u4e49\u5982\u4e0b\uff1a A simple statement is comprised within a single logical line . Several simple statements may occur on a single line separated by semicolons. python\u4e2d\u5bf9 Compound statements \u7684\u5b9a\u4e49\u5982\u4e0b\uff1a Compound statements contain (groups of) other statements; they affect or control the execution of those other statements in some way. In general, compound statements span multiple lines, although in simple incarnations a whole compound statement may be contained in one line. \u5176\u5b9epython\u4e2d\u7684 simple statement \u548c Compound statements \u7684\u754c\u5b9a\u662f\u975e\u5e38\u7b80\u5355\u7684\uff0c \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u4e0a\u9762\u6211\u5bf9statement\u7684\u7406\u89e3\u662f\uff1a***statement***\u63a7\u5236\u7740\u7a0b\u5e8f\u6267\u884c\u7684**\u6d41\u7a0b**\uff0c\u5176\u5b9e\u8fd9\u662f\u4e0d\u5b8c\u5907\u7684\uff0c\u5982 python Function definitions \u548c python Class definitions \u90fd\u662fstatement\uff0c\u6240\u4ee5\u5728python\u4e2dstatement\u8fd8\u5177\u5907**\u5b9a\u4e49**\u7684\u529f\u80fd\u3002 \u90a3\u5e94\u8be5\u5982\u4f55\u7406\u89e3python\u4e2d\u7684**\u51fd\u6570\u5b9a\u4e49\u8bed\u53e5**\u5462\uff1f\u5728python\u4e2d\uff0c\u5e76\u6ca1\u6709declaration\uff0c\u51fd\u6570\u5b9a\u4e49\u8bed\u53e5\u5728python\u4e2d\u662fname bind\u53c2\u770b python Function definitions \uff0c\u5176\u4e2d\u7684\u89e3\u91ca\u662f\u975e\u5e38\u6e05\u695a\u7684\uff1a A function definition is an executable statement . Its execution binds the function name in the current local namespace to a function object (a wrapper around the executable code for the function). This function object contains a reference to the current global namespace as the global namespace to be used when the function is called. \u4e24\u8005\u4e4b\u95f4\u7684\u672c\u8d28\u5dee\u522b\u5728\u4e8epython program\u6700\u7ec8\u662f\u7531python interpreter\u6765\u89e3\u91ca\u6267\u884c\u7684\uff0c\u5e76\u4e14python\u4e2deverything is an object\uff1b\u800cc++ program\u5219\u9700\u8981\u7531compiler\u8fdb\u884ccompile\uff0c\u5b83\u7684declaration\u90fd\u662f\u5411compiler\u8fdb\u884cdeclare\uff1b TODO \uff1a \u5173\u4e8epython lack declaration\uff0c\u9700\u8981\u518d\u53bb\u67e5\u9605\u67e5\u9605\u8d44\u6599\uff0c\u4ee5\u4e0b\u662f\u4e00\u4e9b\u91cd\u8981\u8d44\u6599\uff1a Python variable declaration python lacks declaration","title":"python statement"},{"location":"Theory/Basic-Language-construct/Operator-expression-statement/#c-statement","text":"\u5728 c++ statement \u7684\u5206\u7c7b\u4e0e\u754c\u5b9a\u6bd4python\u8981\u590d\u6742\u5730\u591a\uff0c\u5982\u4e0b\u662f c++ \u4e2d\u7684statement\u7684\u5206\u7c7b \uff1a C++ includes the following types of statements: 1) expression statements; 2) compound statements; 3) selection statements; 4) iteration statements; 5) jump statements; 6) declaration statements; 7) try blocks; 8) atomic and synchronized blocks (TM TS). \u5728 c++ \u4e2d\u6709 declaration statements \uff0c\u5982 int n = 1;// declaration statement \uff0c\u800cpython\u4e2d\u5374\u6ca1\u6709\uff0c python lack declaration \uff0c\u6211\u89c9\u5f97python\u4e2d\u7684declaration statement\u5176\u5b9e\u5bf9\u5e94\u8fd9python\u4e2d\u7684name bind\uff1b\u663e\u7136\u8fd9\u662fpython\u548c c++ \u7684\u663e\u8457\u5dee\u522b\uff1b \u603b\u7684\u6765\u8bf4\uff1astatement\u6709\u7740\u5982\u4e0b\u7684\u529f\u80fd\uff1a ***statement***\u63a7\u5236\u7740\u7a0b\u5e8f\u6267\u884c\u7684**\u6d41\u7a0b**\uff08\u663e\u7136expression\u5e76\u4e0d\u5177\u5907\u8fd9\u6837\u7684\u529f\u80fd\uff09\uff0c\u5982\u987a\u5e8f\u6267\u884c\uff0c\u5faa\u73af\u6267\u884c\uff08 for \uff0c while \uff09\uff0c return \uff0c\u6761\u4ef6\u5206\u652f\u6267\u884c\uff08 if-else \uff09\uff1b \u5b9a\u4e49\u4e0e\u58f0\u660e","title":"c++ statement"},{"location":"Theory/Basic-Language-construct/Operator-expression-statement/#expressionstatement","text":"\u5728 Operator associativity \u4e2d\u6709\u8fd9\u6837\u7684\u63cf\u8ff0\uff1a In many imperative programming languages , the assignment operator is defined to be right-associative, and assignment is defined to be an expression (with a value ), not just a statement . This allows chained assignment by using the value of one assignment expression as the input (right operand) of the next. For example, in C , the assignment a = b is an expression that returns a value (namely, b converted to the type of a ) with the side effect of setting a to this value. An assignment can be performed in the middle of an expression. The right-associativity of the = operator allows expressions such as a = b = c to be interpreted as a = (b = c) , thereby setting both a and b to the value of c . In C, the alternative (a = b) = c does not make sense because a = b is not an l-Value , just an r-value. However, in C++ an assignment a = b returns a value referring to the left term in the assignment. Therefore, (a = b) = c can be interpreted as a = b; a = c; .","title":"\u4ece=\u6765\u770b\u5f85expression\u548cstatement\u4e4b\u95f4\u7684\u5dee\u5f02"},{"location":"Theory/Basic-Language-construct/Operator/Operator-associativity/","text":"Operator associativity In programming languages , the associativity of an operator is a property that determines how operators of the same precedence are grouped in the absence of parentheses . If an operand is both preceded and followed by operators (for example, ^ 3 ^ ), and those operators have equal precedence, then the operand may be used as input to two different operations (i.e. the two operations indicated by the two operators). The choice of which operations to apply the operand to, is determined by the \" associativity \" of the operators. Operators may be associative (meaning the operations can be grouped arbitrarily\uff08\u4efb\u610f\u7684\uff09), left-associative (meaning the operations are grouped from the left), right-associative (meaning the operations are grouped from the right) or non-associative (meaning operations cannot be chained, often because the output type is incompatible with the input types). The associativity and precedence of an operator is a part of the definition of the programming language; different programming languages may have different associativity and precedence for the same type of operator. \u5728\u7f16\u7a0b\u8bed\u8a00\u4e2d\uff0c\u8fd0\u7b97\u7b26\u7684\u5173\u8054\u6027\u662f\u4e00\u79cd\u5c5e\u6027\uff0c\u5b83\u786e\u5b9a\u5728\u6ca1\u6709\u62ec\u53f7\u7684\u60c5\u51b5\u4e0b\u5982\u4f55\u5bf9\u5177\u6709\u76f8\u540c\u4f18\u5148\u7ea7\u7684\u8fd0\u7b97\u7b26\u8fdb\u884c\u5206\u7ec4\u3002\u5982\u679c\u64cd\u4f5c\u6570\u5728\u8fd0\u7b97\u7b26\u4e4b\u524d\u548c\u4e4b\u540e\uff08\u4f8b\u5982^ 3 ^\uff09\uff0c\u5e76\u4e14\u90a3\u4e9b\u8fd0\u7b97\u7b26\u5177\u6709\u76f8\u540c\u7684\u4f18\u5148\u7ea7\uff0c\u5219\u8be5\u64cd\u4f5c\u6570\u53ef\u4ee5\u7528\u4f5c\u4e24\u4e2a\u4e0d\u540c\u64cd\u4f5c\uff08\u5373\u4e24\u4e2a\u8fd0\u7b97\u7b26\u6307\u793a\u7684\u4e24\u4e2a\u64cd\u4f5c\uff09\u7684\u8f93\u5165\u3002\u5c06\u64cd\u4f5c\u6570\u5e94\u7528\u4e8e\u54ea\u4e2a\u8fd0\u7b97\u7684\u9009\u62e9\uff0c\u53d6\u51b3\u4e8e\u8fd0\u7b97\u7b26\u7684\u201c\u5173\u8054\u6027\u201d\u3002\u8fd0\u7b97\u7b26\u53ef\u4ee5\u662f\u5173\u8054\u7684\uff08\u8868\u793a\u64cd\u4f5c\u53ef\u4ee5\u4efb\u610f\u5206\u7ec4\uff09\uff0c\u5de6\u5173\u8054\u7684\uff08\u8868\u793a\u64cd\u4f5c\u4ece\u5de6\u5f00\u59cb\u5206\u7ec4\uff09\uff0c\u53f3\u5173\u8054\u7684\uff08\u8868\u793a\u64cd\u4f5c\u4ece\u53f3\u5f00\u59cb\u5206\u7ec4\uff09\u6216\u975e\u5173\u8054\u7684\uff08\u8868\u793a\u64cd\u4f5c\u4e0d\u80fd\u94fe\u63a5\uff0c\u901a\u5e38\u662f\u56e0\u4e3a\u8f93\u51fa\u7c7b\u578b\u4e0e\u8f93\u5165\u7c7b\u578b\u4e0d\u517c\u5bb9\uff09\u3002\u8fd0\u7b97\u7b26\u7684\u5173\u8054\u6027\u548c\u4f18\u5148\u7ea7\u662f\u7f16\u7a0b\u8bed\u8a00\u5b9a\u4e49\u7684\u4e00\u90e8\u5206\uff1b\u5bf9\u4e8e\u76f8\u540c\u7c7b\u578b\u7684\u8fd0\u7b97\u7b26\uff0c\u4e0d\u540c\u7684\u7f16\u7a0b\u8bed\u8a00\u53ef\u80fd\u5177\u6709\u4e0d\u540c\u7684\u5173\u8054\u6027\u548c\u4f18\u5148\u7ea7\u3002 Consider the expression a ~ b ~ c . If the operator ~ has left associativity, this expression would be interpreted as (a ~ b) ~ c . If the operator has right associativity, the expression would be interpreted as a ~ (b ~ c) . If the operator is non-associative, the expression might be a syntax error , or it might have some special meaning. Some mathematical operators have inherent\uff08\u56fa\u6709\u7684\uff09 associativity . For example, subtraction and division, as used in conventional math notation, are inherently left-associative . Addition and multiplication, by contrast, are both left and right associative. (e.g. (a * b) * c = a * (b * c) ). Many programming language manuals provide a table of operator precedence and associativity; see, for example, the table for C and C++ . The concept of notational associativity described here is related to, but different from the mathematical associativity . An operation that is mathematically associative, by definition requires no notational associativity. (For example, addition has the associative property, therefore it does not have to be either left associative or right associative.) An operation that is not mathematically associative, however, must be notationally left-, right-, or non-associative. (For example, subtraction does not have the associative property, therefore it must have notational associativity.) Examples Associativity is only needed when the operators in an expression have the same precedence . Usually + and - have the same precedence. Consider the expression 7 \u2212 4 + 2 . The result could be either (7 \u2212 4) + 2 = 5 or 7 \u2212 (4 + 2) = 1 . The former result corresponds to the case when + and \u2212 are left-associative, the latter to when + and - are right-associative. In order to reflect normal usage, addition , subtraction , multiplication , and division operators are usually left-associative ,[ 1] [ 2] [ 3] [ 4] [ 5] while for an exponentiation operator (if present)[ 6] and Knuth's up-arrow operators there is no general agreement. Any assignment operators are typically right-associative . To prevent cases where operands would be associated with two operators, or no operator at all, operators with the same precedence must have the same associativity. A detailed example Consider the expression 5^4^3^2 , in which ^ is taken to be a right-associative exponentiation operator. A parser reading the tokens from left to right would apply the associativity rule to a branch, because of the right-associativity of ^ , in the following way: Term 5 is read. Nonterminal ^ is read. Node: \" 5^ \". Term 4 is read. Node: \" 5^4 \". Nonterminal ^ is read, triggering the right-associativity rule . Associativity decides node: \" 5^(4^ \". Term 3 is read. Node: \" 5^(4^3 \". Nonterminal ^ is read, triggering the re-application of the right-associativity rule. Node \" 5^(4^(3^ \". Term 2 is read. Node \" 5^(4^(3^2 \". No tokens to read. Apply associativity to produce parse tree \" 5^(4^(3^2)) \". This can then be evaluated depth-first, starting at the top node (the first ^ ): The evaluator walks down the tree, from the first, over the second, to the third ^ expression. It evaluates as: 3^2 = 9 3^2 = 9 . The result replaces the expression branch as the second operand of the second ^ . Evaluation continues one level up the parse tree as: 4^9 = 262144 4^9 = 262144 . Again, the result replaces the expression branch as the second operand of the first ^ . Again, the evaluator steps up the tree to the root expression and evaluates as: 5^262144 \u2248 6.2060699 \u00d7 10183230 5^262144 \u2248 6.2060699 \u00d7 10183230 . The last remaining branch collapses and the result becomes the overall result, therefore completing overall evaluation. A left-associative evaluation would have resulted in the parse tree ((5^4)^3)^2 and the completely different results 625, 244140625 and finally ~5.9604645 \u00d7 1016. Right-associativity of assignment operators In many imperative programming languages , the assignment operator is defined to be right-associative, and assignment is defined to be an expression (with a value), not just a statement . This allows chained assignment by using the value of one assignment expression as the input (right operand) of the next. SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u5c31\u8868\u8fbe\u4e86expression\u548cstatement\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u9700\u8981\u5c06\u5b83\u6dfb\u52a0\u5230\u300a expression-statement-declaration.md \u300b\u4e2d For example, in C , the assignment a = b is an expression that returns a value (namely, b converted to the type of a ) with the side effect of setting a to this value.[ a] An assignment can be performed in the middle of an expression. The right-associativity of the = operator allows expressions such as a = b = c to be interpreted as a = (b = c) , thereby setting both a and b to the value of c . In C, the alternative (a = b) = c does not make sense because a = b is not an l-Value , just an r-value. However, in C++ an assignment a = b returns a value referring to the left term in the assignment. Therefore, (a = b) = c can be interpreted as a = b; a = c; . Non-associative operators Non-associative operators are operators that have no defined behavior when used in sequence in an expression. In Prolog the infix operator :- is non-associative because constructs such as \" a :- b :- c \" constitute syntax errors. Another possibility is that sequences of certain operators are interpreted in some other way, which cannot be expressed as associativity. This generally means that syntactically, there is a special rule for sequences of these operations, and semantically the behavior is different. A good example is in Python , which has several such constructs.[ 7] Since assignments are statements, not operations, the assignment operator does not have a value and is not associative. Chained assignment is instead implemented by having a grammar rule for sequences of assignments a = b = c , which are then assigned left-to-right. Further, combinations of assignment and augmented assignment, like a = b += c are not legal in Python, though they are legal C. Another example are comparison operators, such as > , == , and <= . A chained comparison like a < b < c is interpreted as (a < b) and (b < c) , not equivalent to either (a < b) < c or a < (b < c) .[ 8]","title":"Operator-associativity"},{"location":"Theory/Basic-Language-construct/Operator/Operator-associativity/#operator-associativity","text":"In programming languages , the associativity of an operator is a property that determines how operators of the same precedence are grouped in the absence of parentheses . If an operand is both preceded and followed by operators (for example, ^ 3 ^ ), and those operators have equal precedence, then the operand may be used as input to two different operations (i.e. the two operations indicated by the two operators). The choice of which operations to apply the operand to, is determined by the \" associativity \" of the operators. Operators may be associative (meaning the operations can be grouped arbitrarily\uff08\u4efb\u610f\u7684\uff09), left-associative (meaning the operations are grouped from the left), right-associative (meaning the operations are grouped from the right) or non-associative (meaning operations cannot be chained, often because the output type is incompatible with the input types). The associativity and precedence of an operator is a part of the definition of the programming language; different programming languages may have different associativity and precedence for the same type of operator. \u5728\u7f16\u7a0b\u8bed\u8a00\u4e2d\uff0c\u8fd0\u7b97\u7b26\u7684\u5173\u8054\u6027\u662f\u4e00\u79cd\u5c5e\u6027\uff0c\u5b83\u786e\u5b9a\u5728\u6ca1\u6709\u62ec\u53f7\u7684\u60c5\u51b5\u4e0b\u5982\u4f55\u5bf9\u5177\u6709\u76f8\u540c\u4f18\u5148\u7ea7\u7684\u8fd0\u7b97\u7b26\u8fdb\u884c\u5206\u7ec4\u3002\u5982\u679c\u64cd\u4f5c\u6570\u5728\u8fd0\u7b97\u7b26\u4e4b\u524d\u548c\u4e4b\u540e\uff08\u4f8b\u5982^ 3 ^\uff09\uff0c\u5e76\u4e14\u90a3\u4e9b\u8fd0\u7b97\u7b26\u5177\u6709\u76f8\u540c\u7684\u4f18\u5148\u7ea7\uff0c\u5219\u8be5\u64cd\u4f5c\u6570\u53ef\u4ee5\u7528\u4f5c\u4e24\u4e2a\u4e0d\u540c\u64cd\u4f5c\uff08\u5373\u4e24\u4e2a\u8fd0\u7b97\u7b26\u6307\u793a\u7684\u4e24\u4e2a\u64cd\u4f5c\uff09\u7684\u8f93\u5165\u3002\u5c06\u64cd\u4f5c\u6570\u5e94\u7528\u4e8e\u54ea\u4e2a\u8fd0\u7b97\u7684\u9009\u62e9\uff0c\u53d6\u51b3\u4e8e\u8fd0\u7b97\u7b26\u7684\u201c\u5173\u8054\u6027\u201d\u3002\u8fd0\u7b97\u7b26\u53ef\u4ee5\u662f\u5173\u8054\u7684\uff08\u8868\u793a\u64cd\u4f5c\u53ef\u4ee5\u4efb\u610f\u5206\u7ec4\uff09\uff0c\u5de6\u5173\u8054\u7684\uff08\u8868\u793a\u64cd\u4f5c\u4ece\u5de6\u5f00\u59cb\u5206\u7ec4\uff09\uff0c\u53f3\u5173\u8054\u7684\uff08\u8868\u793a\u64cd\u4f5c\u4ece\u53f3\u5f00\u59cb\u5206\u7ec4\uff09\u6216\u975e\u5173\u8054\u7684\uff08\u8868\u793a\u64cd\u4f5c\u4e0d\u80fd\u94fe\u63a5\uff0c\u901a\u5e38\u662f\u56e0\u4e3a\u8f93\u51fa\u7c7b\u578b\u4e0e\u8f93\u5165\u7c7b\u578b\u4e0d\u517c\u5bb9\uff09\u3002\u8fd0\u7b97\u7b26\u7684\u5173\u8054\u6027\u548c\u4f18\u5148\u7ea7\u662f\u7f16\u7a0b\u8bed\u8a00\u5b9a\u4e49\u7684\u4e00\u90e8\u5206\uff1b\u5bf9\u4e8e\u76f8\u540c\u7c7b\u578b\u7684\u8fd0\u7b97\u7b26\uff0c\u4e0d\u540c\u7684\u7f16\u7a0b\u8bed\u8a00\u53ef\u80fd\u5177\u6709\u4e0d\u540c\u7684\u5173\u8054\u6027\u548c\u4f18\u5148\u7ea7\u3002 Consider the expression a ~ b ~ c . If the operator ~ has left associativity, this expression would be interpreted as (a ~ b) ~ c . If the operator has right associativity, the expression would be interpreted as a ~ (b ~ c) . If the operator is non-associative, the expression might be a syntax error , or it might have some special meaning. Some mathematical operators have inherent\uff08\u56fa\u6709\u7684\uff09 associativity . For example, subtraction and division, as used in conventional math notation, are inherently left-associative . Addition and multiplication, by contrast, are both left and right associative. (e.g. (a * b) * c = a * (b * c) ). Many programming language manuals provide a table of operator precedence and associativity; see, for example, the table for C and C++ . The concept of notational associativity described here is related to, but different from the mathematical associativity . An operation that is mathematically associative, by definition requires no notational associativity. (For example, addition has the associative property, therefore it does not have to be either left associative or right associative.) An operation that is not mathematically associative, however, must be notationally left-, right-, or non-associative. (For example, subtraction does not have the associative property, therefore it must have notational associativity.)","title":"Operator associativity"},{"location":"Theory/Basic-Language-construct/Operator/Operator-associativity/#examples","text":"Associativity is only needed when the operators in an expression have the same precedence . Usually + and - have the same precedence. Consider the expression 7 \u2212 4 + 2 . The result could be either (7 \u2212 4) + 2 = 5 or 7 \u2212 (4 + 2) = 1 . The former result corresponds to the case when + and \u2212 are left-associative, the latter to when + and - are right-associative. In order to reflect normal usage, addition , subtraction , multiplication , and division operators are usually left-associative ,[ 1] [ 2] [ 3] [ 4] [ 5] while for an exponentiation operator (if present)[ 6] and Knuth's up-arrow operators there is no general agreement. Any assignment operators are typically right-associative . To prevent cases where operands would be associated with two operators, or no operator at all, operators with the same precedence must have the same associativity.","title":"Examples"},{"location":"Theory/Basic-Language-construct/Operator/Operator-associativity/#a-detailed-example","text":"Consider the expression 5^4^3^2 , in which ^ is taken to be a right-associative exponentiation operator. A parser reading the tokens from left to right would apply the associativity rule to a branch, because of the right-associativity of ^ , in the following way: Term 5 is read. Nonterminal ^ is read. Node: \" 5^ \". Term 4 is read. Node: \" 5^4 \". Nonterminal ^ is read, triggering the right-associativity rule . Associativity decides node: \" 5^(4^ \". Term 3 is read. Node: \" 5^(4^3 \". Nonterminal ^ is read, triggering the re-application of the right-associativity rule. Node \" 5^(4^(3^ \". Term 2 is read. Node \" 5^(4^(3^2 \". No tokens to read. Apply associativity to produce parse tree \" 5^(4^(3^2)) \". This can then be evaluated depth-first, starting at the top node (the first ^ ): The evaluator walks down the tree, from the first, over the second, to the third ^ expression. It evaluates as: 3^2 = 9 3^2 = 9 . The result replaces the expression branch as the second operand of the second ^ . Evaluation continues one level up the parse tree as: 4^9 = 262144 4^9 = 262144 . Again, the result replaces the expression branch as the second operand of the first ^ . Again, the evaluator steps up the tree to the root expression and evaluates as: 5^262144 \u2248 6.2060699 \u00d7 10183230 5^262144 \u2248 6.2060699 \u00d7 10183230 . The last remaining branch collapses and the result becomes the overall result, therefore completing overall evaluation. A left-associative evaluation would have resulted in the parse tree ((5^4)^3)^2 and the completely different results 625, 244140625 and finally ~5.9604645 \u00d7 1016.","title":"A detailed example"},{"location":"Theory/Basic-Language-construct/Operator/Operator-associativity/#right-associativity-of-assignment-operators","text":"In many imperative programming languages , the assignment operator is defined to be right-associative, and assignment is defined to be an expression (with a value), not just a statement . This allows chained assignment by using the value of one assignment expression as the input (right operand) of the next. SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u5c31\u8868\u8fbe\u4e86expression\u548cstatement\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u9700\u8981\u5c06\u5b83\u6dfb\u52a0\u5230\u300a expression-statement-declaration.md \u300b\u4e2d For example, in C , the assignment a = b is an expression that returns a value (namely, b converted to the type of a ) with the side effect of setting a to this value.[ a] An assignment can be performed in the middle of an expression. The right-associativity of the = operator allows expressions such as a = b = c to be interpreted as a = (b = c) , thereby setting both a and b to the value of c . In C, the alternative (a = b) = c does not make sense because a = b is not an l-Value , just an r-value. However, in C++ an assignment a = b returns a value referring to the left term in the assignment. Therefore, (a = b) = c can be interpreted as a = b; a = c; .","title":"Right-associativity of assignment operators"},{"location":"Theory/Basic-Language-construct/Operator/Operator-associativity/#non-associative-operators","text":"Non-associative operators are operators that have no defined behavior when used in sequence in an expression. In Prolog the infix operator :- is non-associative because constructs such as \" a :- b :- c \" constitute syntax errors. Another possibility is that sequences of certain operators are interpreted in some other way, which cannot be expressed as associativity. This generally means that syntactically, there is a special rule for sequences of these operations, and semantically the behavior is different. A good example is in Python , which has several such constructs.[ 7] Since assignments are statements, not operations, the assignment operator does not have a value and is not associative. Chained assignment is instead implemented by having a grammar rule for sequences of assignments a = b = c , which are then assigned left-to-right. Further, combinations of assignment and augmented assignment, like a = b += c are not legal in Python, though they are legal C. Another example are comparison operators, such as > , == , and <= . A chained comparison like a < b < c is interpreted as (a < b) and (b < c) , not equivalent to either (a < b) < c or a < (b < c) .[ 8]","title":"Non-associative operators"},{"location":"Theory/Basic-Language-construct/Operator/Operator-precedence/","text":"Order of operations In mathematics and computer programming , the order of operations (or operator precedence ) is a collection of rules that reflect conventions about which procedures to perform first in order to evaluate a given mathematical expression . For example, in mathematics and most computer languages, multiplication is granted a higher precedence than addition, and it has been this way since the introduction of modern algebraic notation.[ 1] [ 2] Thus, the expression 2 + 3 \u00d7 4 2 + 3 \u00d7 4 is interpreted to have the value 2 + (3 \u00d7 4) = 14 2 + (3 \u00d7 4) = 14 , not (2 + 3) \u00d7 4 = 20. (2 + 3) \u00d7 4 = 20. With the introduction of exponents in the 16 th and 17 th centuries, they were given precedence over both addition and multiplication and could be placed only as a superscript to the right of their base.[ 1] Thus $3 + 5^2 = 28 $and 3 \u00d7 5^2 = 75 3 \u00d7 5^2 = 75 . These conventions exist to eliminate ambiguity while allowing notation to be as brief as possible. Where it is desired to override the precedence conventions, or even simply to emphasize them, parentheses ( ) (sometimes replaced by brackets [ ] or braces { } for readability) can indicate an alternate order or reinforce the default order to avoid confusion. For example, (2 + 3) \u00d7 4 = 20 (2 + 3) \u00d7 4 = 20 forces addition to precede multiplication, and (3 + 5)^2 = 64 (3 + 5)^2 = 64 forces addition to precede exponentiation.","title":"Operator-precedence"},{"location":"Theory/Basic-Language-construct/Operator/Operator-precedence/#order-of-operations","text":"In mathematics and computer programming , the order of operations (or operator precedence ) is a collection of rules that reflect conventions about which procedures to perform first in order to evaluate a given mathematical expression . For example, in mathematics and most computer languages, multiplication is granted a higher precedence than addition, and it has been this way since the introduction of modern algebraic notation.[ 1] [ 2] Thus, the expression 2 + 3 \u00d7 4 2 + 3 \u00d7 4 is interpreted to have the value 2 + (3 \u00d7 4) = 14 2 + (3 \u00d7 4) = 14 , not (2 + 3) \u00d7 4 = 20. (2 + 3) \u00d7 4 = 20. With the introduction of exponents in the 16 th and 17 th centuries, they were given precedence over both addition and multiplication and could be placed only as a superscript to the right of their base.[ 1] Thus $3 + 5^2 = 28 $and 3 \u00d7 5^2 = 75 3 \u00d7 5^2 = 75 . These conventions exist to eliminate ambiguity while allowing notation to be as brief as possible. Where it is desired to override the precedence conventions, or even simply to emphasize them, parentheses ( ) (sometimes replaced by brackets [ ] or braces { } for readability) can indicate an alternate order or reinforce the default order to avoid confusion. For example, (2 + 3) \u00d7 4 = 20 (2 + 3) \u00d7 4 = 20 forces addition to precede multiplication, and (3 + 5)^2 = 64 (3 + 5)^2 = 64 forces addition to precede exponentiation.","title":"Order of operations"},{"location":"Theory/Code-refactoring/","text":"\u5173\u4e8e\u672c\u7ae0 \u201cCode refactoring\u201d\u5373\u201c\u4ee3\u7801\u91cd\u6784\u201d\uff0c\u672c\u7ae0\u7684\u5185\u5bb9\u4e3b\u8981\u53c2\u8003\uff1a \u7ef4\u57fa\u767e\u79d1 Code refactoring \u7f51\u7ad9 Refactoring","title":"Introduction"},{"location":"Theory/Code-refactoring/#_1","text":"\u201cCode refactoring\u201d\u5373\u201c\u4ee3\u7801\u91cd\u6784\u201d\uff0c\u672c\u7ae0\u7684\u5185\u5bb9\u4e3b\u8981\u53c2\u8003\uff1a \u7ef4\u57fa\u767e\u79d1 Code refactoring \u7f51\u7ad9 Refactoring","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Theory/Coroutine/Coroutine/","text":"Coroutine \u8d8a\u6765\u8d8a\u591a\u7684language\u652f\u6301Coroutine\u3002 \u7ef4\u57fa\u767e\u79d1 Coroutine Coroutines are computer program components that generalize subroutines for non-preemptive multitasking , by allowing execution to be suspended and resumed. Coroutines are well-suited for implementing familiar program components such as cooperative tasks , exceptions , event loops , iterators , infinite lists and pipes . According to Donald Knuth , Melvin Conway coined the term coroutine in 1958 when he applied it to construction of an assembly program . The first published explanation of the coroutine appeared later, in 1963. Comparison with subroutines Subroutines are special cases of coroutines . When subroutines are invoked, execution begins at the start, and once a subroutine exits, it is finished; an instance of a subroutine only returns once, and does not hold state between invocations. By contrast, coroutines can exit by calling other coroutines, which may later return to the point where they were invoked in the original coroutine; from the coroutine's point of view, it is not exiting but calling another coroutine. Thus, a coroutine instance holds state, and varies between invocations; there can be multiple instances of a given coroutine at once. The difference between calling another coroutine by means of \"yielding\" to it and simply calling another routine (which then, also, would return to the original point), is that the relationship between two coroutines which yield to each other is not that of caller-callee, but instead symmetric. NOTE: \u6700\u540e\u4e00\u6bb5\u8bdd\u975e\u5e38\u91cd\u8981\uff0c\u5b83\u7684\u610f\u601d\u662f\uff1a\u901a\u8fc7 \"yielding\" \u6765\u8c03\u7528\u53e6\u5916\u4e00\u4e2acoroutine\u548c\u7b80\u5355\u8c03\u7528\u53e6\u5916\u4e00\u4e2aroutine\u4e4b\u95f4\u7684\u5dee\u5f02\u662f\u4e24\u8005\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u901a\u8fc7yield\u7684coroutine\u4e4b\u95f4\u7684\u5173\u7cfb\u4e0d\u662fcaller-callee\uff0c\u800c\u662f\u5bf9\u79f0\u7684\uff1b\u7406\u89e3\u8fd9\u6bb5\u8bdd\u7684\u5173\u952e\u662f\u5bf9 \"yielding\" \u7406\u89e3\uff0cyield\u5373\u8ba9\u6e21\uff0c\u505c\u6b62\u5f53\u524dcoroutine\u5e76\u8ba9\u53e6\u5916\u4e00\u4e2acoroutine\u5f00\u59cb\u6267\u884c\u3002 Any subroutine can be translated to a coroutine which does not call yield . Here is a simple example of how coroutines can be useful. Suppose you have a consumer-producer relationship where one routine creates items and adds them to a queue and another removes items from the queue and uses them. For reasons of efficiency, you want to add and remove several items at once. The code might look like this: var q := new queue coroutine produce loop while q is not full create some new items add the items to q yield to consume coroutine consume loop while q is not empty remove some items from q use the items yield to produce The queue is then completely filled or emptied before yielding control to the other coroutine using the yield command. The further coroutines calls are starting right after the yield , in the outer coroutine loop. Although this example is often used as an introduction to multithreading , two threads are not needed for this: the yield statement can be implemented by a jump directly from one routine into the other. Comparison with threads Coroutines are very similar to threads . However, coroutines are cooperatively multitasked, whereas threads are typically preemptively multitasked . This means that coroutines provide concurrency but not parallelism . The advantages of coroutines over threads are that they may be used in a hard-realtime context ( switching between coroutines need not involve any system calls or any blocking calls whatsoever), there is no need for synchronisation primitives such as mutexes , semaphores, etc. in order to guard critical sections , and there is no need for support from the operating system. It is possible to implement coroutines using preemptively-scheduled threads, in a way that will be transparent to the calling code, but some of the advantages (particularly the suitability for hard-realtime operation and relative cheapness of switching between them) will be lost. Comparison with generators Generators , also known as semicoroutines ,[ 5] are a subset of coroutines. Specifically, while both can yield multiple times, suspending their execution and allowing re-entry at multiple entry points, they differ in coroutines ' ability to control where execution continues immediately after they yield, while generators cannot, instead transferring control back to the generator's caller.[ 6] That is, since generators are primarily used to simplify the writing of iterators , the yield statement in a generator does not specify a coroutine to jump to, but rather passes a value back to a parent routine. However, it is still possible to implement coroutines on top of a generator facility, with the aid of a top-level dispatcher routine (a trampoline , essentially) that passes control explicitly to child generators identified by tokens passed back from the generators: var q := new queue generator produce loop while q is not full create some new items add the items to q yield consume generator consume loop while q is not empty remove some items from q use the items yield produce subroutine dispatcher var d := new dictionary(generator \u2192 iterator) d[produce] := start produce d[consume] := start consume var current := produce loop current := next d[current] A number of implementations of coroutines for languages with generator support but no native coroutines (e.g. Python[ 7] before 2.5) use this or a similar model. Comparison with mutual recursion Further information: Mutual recursion Using coroutines for state machines or concurrency is similar to using mutual recursion with tail calls , as in both cases the control changes to a different one of a set of routines. However, coroutines are more flexible and generally more efficient. Since coroutines yield rather than return, and then resume execution rather than restarting from the beginning, they are able to hold state, both variables (as in a closure) and execution point, and yields are not limited to being in tail position; mutually recursive subroutines must either use shared variables or pass state as parameters. Further, each mutually recursive call of a subroutine requires a new stack frame (unless tail call elimination is implemented), while passing control between coroutines uses the existing contexts and can be implemented simply by a jump. Common uses Coroutines are useful to implement the following: State machines within a single subroutine, where the state is determined by the current entry/exit point of the procedure; this can result in more readable code compared to use of goto , and may also be implemented via mutual recursion with tail calls . Actor model of concurrency, for instance in video games . Each actor has its own procedures (this again logically separates the code), but they voluntarily give up control to central scheduler, which executes them sequentially (this is a form of cooperative multitasking ). Generators , and these are useful for streams \u2013 particularly input/output \u2013 and for generic traversal of data structures. Communicating sequential processes where each sub-process is a coroutine. Channel inputs/outputs and blocking operations yield coroutines and a scheduler unblocks them on completion events. Alternatively, each sub-process may be the parent of the one following it in the data pipeline (or preceding it, in which case the pattern can be expressed as nested generators). Reverse communication, commonly used in mathematical software, wherein a procedure such as a solver, integral evaluator, ... needs the using process to make a computation, such as evaluating an equation or integrand. Implementations As of 2003, many of the most popular programming languages, including C and its derivatives, do not have direct support for coroutines within the language or their standard libraries. (This is, in large part, due to the limitations of stack-based subroutine implementation.) An exception is the C++ library Boost.Context , part of boost libraries , which supports context swapping on ARM, MIPS, PowerPC, SPARC and x86 on POSIX, Mac OS X and Windows. Coroutines can be built upon Boost.Context. In situations where a coroutine would be the natural implementation of a mechanism, but is not available, the typical response is to use a closure \u2013 a subroutine with state variables ( static variables , often boolean flags) to maintain an internal state between calls, and to transfer control to the correct point. Conditionals within the code result in the execution of different code paths on successive calls, based on the values of the state variables. Another typical response is to implement an explicit state machine in the form of a large and complex switch statement or via a goto statement, particularly a computed goto . Such implementations are considered difficult to understand and maintain, and a motivation for coroutine support. Threads , and to a lesser extent fibers , are an alternative to coroutines in mainstream programming environments today. Threads provide facilities for managing the realtime cooperative interaction of simultaneously executing pieces of code. Threads are widely available in environments that support C (and are supported natively in many other modern languages), are familiar to many programmers, and are usually well-implemented, well-documented and well-supported. However, as they solve a large and difficult problem they include many powerful and complex facilities and have a correspondingly difficult learning curve. As such, when a coroutine is all that is needed, using a thread can be overkill. One important difference between threads and coroutines is that threads are typically preemptively scheduled while coroutines are not. Because threads can be rescheduled at any instant and can execute concurrently, programs using threads must be careful about locking . In contrast, because coroutines can only be rescheduled at specific points in the program and do not execute concurrently, programs using coroutines can often avoid locking entirely. (This property is also cited as a benefit of event-driven or asynchronous programming.) Since fibers are cooperatively scheduled, they provide an ideal base for implementing coroutines above.[ 20] However, system support for fibers is often lacking compared to that for threads.","title":"Coroutine"},{"location":"Theory/Coroutine/Coroutine/#coroutine","text":"\u8d8a\u6765\u8d8a\u591a\u7684language\u652f\u6301Coroutine\u3002","title":"Coroutine"},{"location":"Theory/Coroutine/Coroutine/#coroutine_1","text":"Coroutines are computer program components that generalize subroutines for non-preemptive multitasking , by allowing execution to be suspended and resumed. Coroutines are well-suited for implementing familiar program components such as cooperative tasks , exceptions , event loops , iterators , infinite lists and pipes . According to Donald Knuth , Melvin Conway coined the term coroutine in 1958 when he applied it to construction of an assembly program . The first published explanation of the coroutine appeared later, in 1963.","title":"\u7ef4\u57fa\u767e\u79d1Coroutine"},{"location":"Theory/Coroutine/Coroutine/#comparison-with-subroutines","text":"Subroutines are special cases of coroutines . When subroutines are invoked, execution begins at the start, and once a subroutine exits, it is finished; an instance of a subroutine only returns once, and does not hold state between invocations. By contrast, coroutines can exit by calling other coroutines, which may later return to the point where they were invoked in the original coroutine; from the coroutine's point of view, it is not exiting but calling another coroutine. Thus, a coroutine instance holds state, and varies between invocations; there can be multiple instances of a given coroutine at once. The difference between calling another coroutine by means of \"yielding\" to it and simply calling another routine (which then, also, would return to the original point), is that the relationship between two coroutines which yield to each other is not that of caller-callee, but instead symmetric. NOTE: \u6700\u540e\u4e00\u6bb5\u8bdd\u975e\u5e38\u91cd\u8981\uff0c\u5b83\u7684\u610f\u601d\u662f\uff1a\u901a\u8fc7 \"yielding\" \u6765\u8c03\u7528\u53e6\u5916\u4e00\u4e2acoroutine\u548c\u7b80\u5355\u8c03\u7528\u53e6\u5916\u4e00\u4e2aroutine\u4e4b\u95f4\u7684\u5dee\u5f02\u662f\u4e24\u8005\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u901a\u8fc7yield\u7684coroutine\u4e4b\u95f4\u7684\u5173\u7cfb\u4e0d\u662fcaller-callee\uff0c\u800c\u662f\u5bf9\u79f0\u7684\uff1b\u7406\u89e3\u8fd9\u6bb5\u8bdd\u7684\u5173\u952e\u662f\u5bf9 \"yielding\" \u7406\u89e3\uff0cyield\u5373\u8ba9\u6e21\uff0c\u505c\u6b62\u5f53\u524dcoroutine\u5e76\u8ba9\u53e6\u5916\u4e00\u4e2acoroutine\u5f00\u59cb\u6267\u884c\u3002 Any subroutine can be translated to a coroutine which does not call yield . Here is a simple example of how coroutines can be useful. Suppose you have a consumer-producer relationship where one routine creates items and adds them to a queue and another removes items from the queue and uses them. For reasons of efficiency, you want to add and remove several items at once. The code might look like this: var q := new queue coroutine produce loop while q is not full create some new items add the items to q yield to consume coroutine consume loop while q is not empty remove some items from q use the items yield to produce The queue is then completely filled or emptied before yielding control to the other coroutine using the yield command. The further coroutines calls are starting right after the yield , in the outer coroutine loop. Although this example is often used as an introduction to multithreading , two threads are not needed for this: the yield statement can be implemented by a jump directly from one routine into the other.","title":"Comparison with subroutines"},{"location":"Theory/Coroutine/Coroutine/#comparison-with-threads","text":"Coroutines are very similar to threads . However, coroutines are cooperatively multitasked, whereas threads are typically preemptively multitasked . This means that coroutines provide concurrency but not parallelism . The advantages of coroutines over threads are that they may be used in a hard-realtime context ( switching between coroutines need not involve any system calls or any blocking calls whatsoever), there is no need for synchronisation primitives such as mutexes , semaphores, etc. in order to guard critical sections , and there is no need for support from the operating system. It is possible to implement coroutines using preemptively-scheduled threads, in a way that will be transparent to the calling code, but some of the advantages (particularly the suitability for hard-realtime operation and relative cheapness of switching between them) will be lost.","title":"Comparison with threads"},{"location":"Theory/Coroutine/Coroutine/#comparison-with-generators","text":"Generators , also known as semicoroutines ,[ 5] are a subset of coroutines. Specifically, while both can yield multiple times, suspending their execution and allowing re-entry at multiple entry points, they differ in coroutines ' ability to control where execution continues immediately after they yield, while generators cannot, instead transferring control back to the generator's caller.[ 6] That is, since generators are primarily used to simplify the writing of iterators , the yield statement in a generator does not specify a coroutine to jump to, but rather passes a value back to a parent routine. However, it is still possible to implement coroutines on top of a generator facility, with the aid of a top-level dispatcher routine (a trampoline , essentially) that passes control explicitly to child generators identified by tokens passed back from the generators: var q := new queue generator produce loop while q is not full create some new items add the items to q yield consume generator consume loop while q is not empty remove some items from q use the items yield produce subroutine dispatcher var d := new dictionary(generator \u2192 iterator) d[produce] := start produce d[consume] := start consume var current := produce loop current := next d[current] A number of implementations of coroutines for languages with generator support but no native coroutines (e.g. Python[ 7] before 2.5) use this or a similar model.","title":"Comparison with generators"},{"location":"Theory/Coroutine/Coroutine/#comparison-with-mutual-recursion","text":"Further information: Mutual recursion Using coroutines for state machines or concurrency is similar to using mutual recursion with tail calls , as in both cases the control changes to a different one of a set of routines. However, coroutines are more flexible and generally more efficient. Since coroutines yield rather than return, and then resume execution rather than restarting from the beginning, they are able to hold state, both variables (as in a closure) and execution point, and yields are not limited to being in tail position; mutually recursive subroutines must either use shared variables or pass state as parameters. Further, each mutually recursive call of a subroutine requires a new stack frame (unless tail call elimination is implemented), while passing control between coroutines uses the existing contexts and can be implemented simply by a jump.","title":"Comparison with mutual recursion"},{"location":"Theory/Coroutine/Coroutine/#common-uses","text":"Coroutines are useful to implement the following: State machines within a single subroutine, where the state is determined by the current entry/exit point of the procedure; this can result in more readable code compared to use of goto , and may also be implemented via mutual recursion with tail calls . Actor model of concurrency, for instance in video games . Each actor has its own procedures (this again logically separates the code), but they voluntarily give up control to central scheduler, which executes them sequentially (this is a form of cooperative multitasking ). Generators , and these are useful for streams \u2013 particularly input/output \u2013 and for generic traversal of data structures. Communicating sequential processes where each sub-process is a coroutine. Channel inputs/outputs and blocking operations yield coroutines and a scheduler unblocks them on completion events. Alternatively, each sub-process may be the parent of the one following it in the data pipeline (or preceding it, in which case the pattern can be expressed as nested generators). Reverse communication, commonly used in mathematical software, wherein a procedure such as a solver, integral evaluator, ... needs the using process to make a computation, such as evaluating an equation or integrand.","title":"Common uses"},{"location":"Theory/Coroutine/Coroutine/#implementations","text":"As of 2003, many of the most popular programming languages, including C and its derivatives, do not have direct support for coroutines within the language or their standard libraries. (This is, in large part, due to the limitations of stack-based subroutine implementation.) An exception is the C++ library Boost.Context , part of boost libraries , which supports context swapping on ARM, MIPS, PowerPC, SPARC and x86 on POSIX, Mac OS X and Windows. Coroutines can be built upon Boost.Context. In situations where a coroutine would be the natural implementation of a mechanism, but is not available, the typical response is to use a closure \u2013 a subroutine with state variables ( static variables , often boolean flags) to maintain an internal state between calls, and to transfer control to the correct point. Conditionals within the code result in the execution of different code paths on successive calls, based on the values of the state variables. Another typical response is to implement an explicit state machine in the form of a large and complex switch statement or via a goto statement, particularly a computed goto . Such implementations are considered difficult to understand and maintain, and a motivation for coroutine support. Threads , and to a lesser extent fibers , are an alternative to coroutines in mainstream programming environments today. Threads provide facilities for managing the realtime cooperative interaction of simultaneously executing pieces of code. Threads are widely available in environments that support C (and are supported natively in many other modern languages), are familiar to many programmers, and are usually well-implemented, well-documented and well-supported. However, as they solve a large and difficult problem they include many powerful and complex facilities and have a correspondingly difficult learning curve. As such, when a coroutine is all that is needed, using a thread can be overkill. One important difference between threads and coroutines is that threads are typically preemptively scheduled while coroutines are not. Because threads can be rescheduled at any instant and can execute concurrently, programs using threads must be careful about locking . In contrast, because coroutines can only be rescheduled at specific points in the program and do not execute concurrently, programs using coroutines can often avoid locking entirely. (This property is also cited as a benefit of event-driven or asynchronous programming.) Since fibers are cooperatively scheduled, they provide an ideal base for implementing coroutines above.[ 20] However, system support for fibers is often lacking compared to that for threads.","title":"Implementations"},{"location":"Theory/Declaration-and-definition/Declaration-and-definition/","text":"","title":"Declaration-and-definition"},{"location":"Theory/Declaration-and-definition/Declaration/","text":"Declaration (computer programming) In computer programming , a declaration is a language construct that specifies properties of an identifier : it declares what a word (identifier) \"means\". Declarations are most commonly used for functions , variables , constants , and classes , but can also be used for other entities such as enumerations and type definitions. Beyond the name (the identifier itself) and the kind of entity (function, variable, etc.), declarations typically specify the data type (for variables and constants), or the type signature (for functions); types may also include dimensions, such as for arrays. A declaration is used to announce the existence of the entity to the compiler ; this is important in those strongly typed languages that require functions, variables, and constants, and their types to be specified with a declaration before use, and is used in forward declaration . The term \"declaration\" is frequently contrasted with the term \"definition\", but meaning and usage varies significantly between languages; see below. Declarations are particularly prominent in languages in the ALGOL tradition, including the BCPL family, most prominently C and C++ , and also Pascal . Java uses the term \"declaration\", though Java does not have separate declarations and definitions.","title":"Declaration"},{"location":"Theory/Declaration-and-definition/Declaration/#declaration-computer-programming","text":"In computer programming , a declaration is a language construct that specifies properties of an identifier : it declares what a word (identifier) \"means\". Declarations are most commonly used for functions , variables , constants , and classes , but can also be used for other entities such as enumerations and type definitions. Beyond the name (the identifier itself) and the kind of entity (function, variable, etc.), declarations typically specify the data type (for variables and constants), or the type signature (for functions); types may also include dimensions, such as for arrays. A declaration is used to announce the existence of the entity to the compiler ; this is important in those strongly typed languages that require functions, variables, and constants, and their types to be specified with a declaration before use, and is used in forward declaration . The term \"declaration\" is frequently contrasted with the term \"definition\", but meaning and usage varies significantly between languages; see below. Declarations are particularly prominent in languages in the ALGOL tradition, including the BCPL family, most prominently C and C++ , and also Pascal . Java uses the term \"declaration\", though Java does not have separate declarations and definitions.","title":"Declaration (computer programming)"},{"location":"Theory/Declaration-and-definition/Forward-declaration/","text":"Forward declaration In computer programming , a forward declaration is a declaration of an identifier (denoting an entity such as a type, a variable, a constant, or a function) for which the programmer has not yet given a complete definition . It is required for a compiler to know certain properties of an identifier (size for memory allocation , data type for type checking, such as type signature of functions), but not other details, like the particular value it holds (in case of variables or constants) or definition (in the case of functions). This is particularly useful for one-pass compilers and separate compilation . Forward declaration is used in languages that require declaration before use; it is necessary for mutual recursion in such languages, as it is impossible to define such functions (or data structures) without a forward reference in one definition: one of the functions (respectively, data structures) must be defined first. It is also useful to allow flexible code organization, for example if one wishes to place the main body at the top, and called functions below it. In other languages forward declarations are not necessary, which generally requires instead a multi-pass compiler and for some compilation to be deferred to link time . In these cases identifiers must be defined (variables initialized, functions defined) before they are used in execution, but do not need to be defined before they are used in source code for compilation or interpretation: identifiers do not need to be immediately resolved to an existing entity. SUMMARY : \u663e\u7136forward declaration\u662fcompiler\u9700\u8981\u7684\uff0c\u800clinker\u662f\u4e0d\u9700\u8981\u7684","title":"Forward-declaration"},{"location":"Theory/Declaration-and-definition/Forward-declaration/#forward-declaration","text":"In computer programming , a forward declaration is a declaration of an identifier (denoting an entity such as a type, a variable, a constant, or a function) for which the programmer has not yet given a complete definition . It is required for a compiler to know certain properties of an identifier (size for memory allocation , data type for type checking, such as type signature of functions), but not other details, like the particular value it holds (in case of variables or constants) or definition (in the case of functions). This is particularly useful for one-pass compilers and separate compilation . Forward declaration is used in languages that require declaration before use; it is necessary for mutual recursion in such languages, as it is impossible to define such functions (or data structures) without a forward reference in one definition: one of the functions (respectively, data structures) must be defined first. It is also useful to allow flexible code organization, for example if one wishes to place the main body at the top, and called functions below it. In other languages forward declarations are not necessary, which generally requires instead a multi-pass compiler and for some compilation to be deferred to link time . In these cases identifiers must be defined (variables initialized, functions defined) before they are used in execution, but do not need to be defined before they are used in source code for compilation or interpretation: identifiers do not need to be immediately resolved to an existing entity. SUMMARY : \u663e\u7136forward declaration\u662fcompiler\u9700\u8981\u7684\uff0c\u800clinker\u662f\u4e0d\u9700\u8981\u7684","title":"Forward declaration"},{"location":"Theory/Declaration-and-definition/What-declaration-and-definition-mean-for-compiler/","text":"20180318 \u6709\u4ee3\u7801\u5982\u4e0b\uff1a a.c void test_a()//\u5b9a\u4e49\u51fd\u6570test_a { return; } b.c void test_a(); void test_b() { test_a(); // \u7531\u4e8e\u4e0a\u9762\u5df2\u7ecf\u58f0\u660e\u4e86\uff0c\u6240\u4ee5\u53ef\u4ee5\u4f7f\u7528 } void main() { test_b(); } \u7f16\u8bd1\u547d\u4ee4\u5982\u4e0b gcc a.c b.c -o b \u6309\u7167\u8fd9\u79cd\u5199\u6cd5\u662f\u53ef\u4ee5\u6b63\u786e\u7f16\u8bd1\u51fa\u53ef\u6267\u884c\u6587\u4ef6b\u7684\u3002 \u5982\u679c\u6211\u5c06\u7f16\u8bd1\u547d\u4ee4\u4fee\u6539\u4e3a\u5982\u4e0b\u5f62\u5f0f\uff1a gcc b.c -o b \u5219\u7f16\u8bd1\u5668\u4f1a\u62a5\u5982\u4e0b\u9519\u8bef\uff1a /tmp/cc91umxf.o\uff1a\u5728\u51fd\u6570\u2018test_b\u2019\u4e2d\uff1a b.c:(.text+0xa)\uff1a\u5bf9\u2018test_a\u2019\u672a\u5b9a\u4e49\u7684\u5f15\u7528 collect2: \u9519\u8bef\uff1ald \u8fd4\u56de 1 \u4e5f\u5c31\u662f\u627e\u4e0d\u5230\u51fd\u6570test_a\u7684\u5b9a\u4e49\u3002 \u8fd9\u4e2a\u95ee\u9898\u5f15\u53d1\u4e86\u6211\u8fd9\u6837\u7684\u601d\u8003\uff1a\u5bf9\u4e8e\u7f16\u8bd1\u5668\u800c\u8a00\uff0c\u58f0\u660e\u548c\u5b9a\u4e49\u5206\u522b\u610f\u5473\u7740\u4ec0\u4e48\uff1f\u7f16\u8bd1\u5668\u5bf9\u51fd\u6570\u58f0\u660e\uff0c\u51fd\u6570\u5b9a\u4e49\u7684\u5904\u7406\u548c\u5bf9\u53d8\u91cf\u58f0\u660e\uff0c\u53d8\u91cf\u5b9a\u4e49\u7684\u5904\u7406\u662f\u76f8\u540c\u7684\u5417\uff1f \u663e\u7136\u662f\u4e0d\u76f8\u540c\u7684\u3002 \u51fd\u6570\u58f0\u660e\u5bf9\u4e8e\u7f16\u8bd1\u5668\u610f\u5473\u7740\u4ec0\u4e48 \u5982\u679c\u5728b.c\u4e2d\u5c06\u51fd\u6570test_a\u7684\u58f0\u660e\u53bb\u9664\u6389\u7684\u8bdd\uff0c\u518d\u8fdb\u884c\u7f16\u8bd1\uff0c\u6211\u53d1\u73b0\u51fd\u6570\u4e5f\u80fd\u591f\u7f16\u8bd1\u901a\u8fc7\uff0c\u5e76\u4e14\u80fd\u591f\u6b63\u786e\u6267\u884c\u3002","title":"What-declaration-and-definition-mean-for-compiler"},{"location":"Theory/Declaration-and-definition/What-declaration-and-definition-mean-for-compiler/#20180318","text":"\u6709\u4ee3\u7801\u5982\u4e0b\uff1a a.c void test_a()//\u5b9a\u4e49\u51fd\u6570test_a { return; } b.c void test_a(); void test_b() { test_a(); // \u7531\u4e8e\u4e0a\u9762\u5df2\u7ecf\u58f0\u660e\u4e86\uff0c\u6240\u4ee5\u53ef\u4ee5\u4f7f\u7528 } void main() { test_b(); } \u7f16\u8bd1\u547d\u4ee4\u5982\u4e0b gcc a.c b.c -o b \u6309\u7167\u8fd9\u79cd\u5199\u6cd5\u662f\u53ef\u4ee5\u6b63\u786e\u7f16\u8bd1\u51fa\u53ef\u6267\u884c\u6587\u4ef6b\u7684\u3002 \u5982\u679c\u6211\u5c06\u7f16\u8bd1\u547d\u4ee4\u4fee\u6539\u4e3a\u5982\u4e0b\u5f62\u5f0f\uff1a gcc b.c -o b \u5219\u7f16\u8bd1\u5668\u4f1a\u62a5\u5982\u4e0b\u9519\u8bef\uff1a /tmp/cc91umxf.o\uff1a\u5728\u51fd\u6570\u2018test_b\u2019\u4e2d\uff1a b.c:(.text+0xa)\uff1a\u5bf9\u2018test_a\u2019\u672a\u5b9a\u4e49\u7684\u5f15\u7528 collect2: \u9519\u8bef\uff1ald \u8fd4\u56de 1 \u4e5f\u5c31\u662f\u627e\u4e0d\u5230\u51fd\u6570test_a\u7684\u5b9a\u4e49\u3002 \u8fd9\u4e2a\u95ee\u9898\u5f15\u53d1\u4e86\u6211\u8fd9\u6837\u7684\u601d\u8003\uff1a\u5bf9\u4e8e\u7f16\u8bd1\u5668\u800c\u8a00\uff0c\u58f0\u660e\u548c\u5b9a\u4e49\u5206\u522b\u610f\u5473\u7740\u4ec0\u4e48\uff1f\u7f16\u8bd1\u5668\u5bf9\u51fd\u6570\u58f0\u660e\uff0c\u51fd\u6570\u5b9a\u4e49\u7684\u5904\u7406\u548c\u5bf9\u53d8\u91cf\u58f0\u660e\uff0c\u53d8\u91cf\u5b9a\u4e49\u7684\u5904\u7406\u662f\u76f8\u540c\u7684\u5417\uff1f \u663e\u7136\u662f\u4e0d\u76f8\u540c\u7684\u3002","title":"20180318"},{"location":"Theory/Declaration-and-definition/What-declaration-and-definition-mean-for-compiler/#_1","text":"\u5982\u679c\u5728b.c\u4e2d\u5c06\u51fd\u6570test_a\u7684\u58f0\u660e\u53bb\u9664\u6389\u7684\u8bdd\uff0c\u518d\u8fdb\u884c\u7f16\u8bd1\uff0c\u6211\u53d1\u73b0\u51fd\u6570\u4e5f\u80fd\u591f\u7f16\u8bd1\u901a\u8fc7\uff0c\u5e76\u4e14\u80fd\u591f\u6b63\u786e\u6267\u884c\u3002","title":"\u51fd\u6570\u58f0\u660e\u5bf9\u4e8e\u7f16\u8bd1\u5668\u610f\u5473\u7740\u4ec0\u4e48"},{"location":"Theory/Design-pattern/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u4e3b\u8981\u603b\u7ed3design pattern\uff0c\u672c\u7ae0\u7684\u5185\u5bb9\u4e3b\u8981\u53c2\u8003\u81ea\uff1a \u7ef4\u57fa\u767e\u79d1 Software design patterns w3sdesign Refactoring.Guru","title":"Introduction"},{"location":"Theory/Design-pattern/#_1","text":"\u672c\u7ae0\u4e3b\u8981\u603b\u7ed3design pattern\uff0c\u672c\u7ae0\u7684\u5185\u5bb9\u4e3b\u8981\u53c2\u8003\u81ea\uff1a \u7ef4\u57fa\u767e\u79d1 Software design patterns w3sdesign Refactoring.Guru","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Theory/Design-pattern/Software-design-pattern/","text":"Software design pattern \u201csoftware \u7684sing pattern\u201d\u5373\u8f6f\u4ef6\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u662f\u524d\u4eba\u603b\u7ed3\u7684\u89e3\u51b3\u7279\u5b9a\u95ee\u9898\u7684\u6700\u4f73\u5b9e\u8df5\uff08 best practice \uff09\u3002\u6211\u4eec\u5e73\u65f6\u63d0\u53cadesign pattern\u7684\u65f6\u5019\uff0c\u5f80\u5f80\u7b2c\u4e00\u53cd\u5e94\u662f Object-oriented design pattern\uff0c\u5176\u5b9edesign pattern\u4e0d\u4ec5\u9650\u4e8e Object-oriented programming\uff0c\u5728\u5404\u4e2a\u9886\u57df\u4e2d\uff0c\u90fd\u80fd\u591f\u603b\u7ed3\u51fa domain-specific patterns \u3002 \u7ef4\u57fa\u767e\u79d1 Software design pattern In software engineering , a software design pattern is a general, reusable solution to a commonly occurring problem within a given context in software design . It is not a finished design that can be transformed directly into source or machine code . It is a description or template for how to solve a problem that can be used in many different situations. Design patterns are formalized best practices that the programmer can use to solve common problems when designing an application or system. Object-oriented design patterns typically show relationships and interactions between classes or objects , without specifying the final application classes or objects that are involved. Patterns that imply mutable\uff08\u53ef\u53d8\u7684\uff09 state may be unsuited for functional programming languages, some patterns can be rendered unnecessary in languages that have built-in support for solving the problem they are trying to solve, and object-oriented patterns are not necessarily suitable for non-object-oriented languages. Practice Design patterns can speed up the development process by providing tested, proven development paradigms. Effective software design requires considering issues that may not become visible until later in the implementation. Freshly written code can often have hidden subtle issues that take time to be detected, issues that sometimes can cause major problems down the road. Reusing design patterns helps to prevent such subtle issues , and it also improves code readability for coders and architects who are familiar with the patterns. NOTE: \u4f7f\u7528design pattern\u7684\u4f18\u52bf\u3002 software design\u548c \u57ce\u5e02\u89c4\u5212 \u6709\u70b9\u7c7b\u4f3c\uff0c\u90fd\u9700\u8981\u4ee5\u53d1\u5c55\u7684\u773c\u5149\u6765\u8fdb\u884c\u89c4\u5212\u3002 In order to achieve flexibility, design patterns usually introduce additional levels of indirection , which in some cases may complicate the resulting designs and hurt application performance. NOTE: \u53c2\u89c1\u6587\u7ae0 \u5206\u5c42 \u3002 By definition, a pattern must be programmed anew\uff08\u91cd\u65b0\uff0c\u518d\u6b21\uff09 into each application that uses it. Since some authors see this as a step backward from software reuse as provided by components , researchers have worked to turn patterns into components. Meyer and Arnout were able to provide full or partial componentization of two-thirds of the patterns they attempted. Software design techniques are difficult to apply to a broader range of problems. Design patterns provide general solutions, documented in a format that does not require specifics tied to a particular problem. Classification and list Design patterns were originally grouped into the categories: creational patterns , structural patterns , and behavioral patterns , and described using the concepts of delegation , aggregation , and consultation . For further background on object-oriented design, see coupling and cohesion , inheritance , interface , and polymorphism . Another classification has also introduced the notion of architectural design pattern that may be applied at the architecture level of the software such as the Model\u2013View\u2013Controller pattern. Creational patterns Name Description In Design Patterns In Code Complete Other Abstract factory Provide an interface for creating families of related or dependent objects without specifying their concrete classes. Yes Yes N/A Builder Separate the construction of a complex object from its representation, allowing the same construction process to create various representations. Yes No N/A Dependency Injection A class accepts the objects it requires from an injector instead of creating the objects directly. No No N/A Factory method Define an interface for creating a single object, but let subclasses decide which class to instantiate. Factory Method lets a class defer instantiation to subclasses. Yes Yes N/A Lazy initialization Tactic of delaying the creation of an object, the calculation of a value, or some other expensive process until the first time it is needed. This pattern appears in the GoF catalog as \"virtual proxy\", an implementation strategy for the Proxy pattern. No No PoEAA Multiton Ensure a class has only named instances, and provide a global point of access to them. No No N/A Object pool Avoid expensive acquisition and release of resources by recycling objects that are no longer in use. Can be considered a generalisation of connection pool and thread pool patterns. No No N/A Prototype Specify the kinds of objects to create using a prototypical instance, and create new objects from the 'skeleton' of an existing object, thus boosting performance and keeping memory footprints to a minimum. Yes No N/A Resource acquisition is initialization (RAII) Ensure that resources are properly released by tying them to the lifespan of suitable objects. No No N/A Singleton Ensure a class has only one instance, and provide a global point of access to it. Yes Yes N/A Concurrency patterns Name Description In POSA2 Other Active Object Decouples method execution from method invocation that reside in their own thread of control. The goal is to introduce concurrency, by using asynchronous method invocation and a scheduler for handling requests. Yes N/A","title":"Software-design-pattern"},{"location":"Theory/Design-pattern/Software-design-pattern/#software-design-pattern","text":"\u201csoftware \u7684sing pattern\u201d\u5373\u8f6f\u4ef6\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u662f\u524d\u4eba\u603b\u7ed3\u7684\u89e3\u51b3\u7279\u5b9a\u95ee\u9898\u7684\u6700\u4f73\u5b9e\u8df5\uff08 best practice \uff09\u3002\u6211\u4eec\u5e73\u65f6\u63d0\u53cadesign pattern\u7684\u65f6\u5019\uff0c\u5f80\u5f80\u7b2c\u4e00\u53cd\u5e94\u662f Object-oriented design pattern\uff0c\u5176\u5b9edesign pattern\u4e0d\u4ec5\u9650\u4e8e Object-oriented programming\uff0c\u5728\u5404\u4e2a\u9886\u57df\u4e2d\uff0c\u90fd\u80fd\u591f\u603b\u7ed3\u51fa domain-specific patterns \u3002","title":"Software design pattern"},{"location":"Theory/Design-pattern/Software-design-pattern/#software-design-pattern_1","text":"In software engineering , a software design pattern is a general, reusable solution to a commonly occurring problem within a given context in software design . It is not a finished design that can be transformed directly into source or machine code . It is a description or template for how to solve a problem that can be used in many different situations. Design patterns are formalized best practices that the programmer can use to solve common problems when designing an application or system. Object-oriented design patterns typically show relationships and interactions between classes or objects , without specifying the final application classes or objects that are involved. Patterns that imply mutable\uff08\u53ef\u53d8\u7684\uff09 state may be unsuited for functional programming languages, some patterns can be rendered unnecessary in languages that have built-in support for solving the problem they are trying to solve, and object-oriented patterns are not necessarily suitable for non-object-oriented languages.","title":"\u7ef4\u57fa\u767e\u79d1Software design pattern"},{"location":"Theory/Design-pattern/Software-design-pattern/#practice","text":"Design patterns can speed up the development process by providing tested, proven development paradigms. Effective software design requires considering issues that may not become visible until later in the implementation. Freshly written code can often have hidden subtle issues that take time to be detected, issues that sometimes can cause major problems down the road. Reusing design patterns helps to prevent such subtle issues , and it also improves code readability for coders and architects who are familiar with the patterns. NOTE: \u4f7f\u7528design pattern\u7684\u4f18\u52bf\u3002 software design\u548c \u57ce\u5e02\u89c4\u5212 \u6709\u70b9\u7c7b\u4f3c\uff0c\u90fd\u9700\u8981\u4ee5\u53d1\u5c55\u7684\u773c\u5149\u6765\u8fdb\u884c\u89c4\u5212\u3002 In order to achieve flexibility, design patterns usually introduce additional levels of indirection , which in some cases may complicate the resulting designs and hurt application performance. NOTE: \u53c2\u89c1\u6587\u7ae0 \u5206\u5c42 \u3002 By definition, a pattern must be programmed anew\uff08\u91cd\u65b0\uff0c\u518d\u6b21\uff09 into each application that uses it. Since some authors see this as a step backward from software reuse as provided by components , researchers have worked to turn patterns into components. Meyer and Arnout were able to provide full or partial componentization of two-thirds of the patterns they attempted. Software design techniques are difficult to apply to a broader range of problems. Design patterns provide general solutions, documented in a format that does not require specifics tied to a particular problem.","title":"Practice"},{"location":"Theory/Design-pattern/Software-design-pattern/#classification-and-list","text":"Design patterns were originally grouped into the categories: creational patterns , structural patterns , and behavioral patterns , and described using the concepts of delegation , aggregation , and consultation . For further background on object-oriented design, see coupling and cohesion , inheritance , interface , and polymorphism . Another classification has also introduced the notion of architectural design pattern that may be applied at the architecture level of the software such as the Model\u2013View\u2013Controller pattern.","title":"Classification and list"},{"location":"Theory/Design-pattern/Software-design-pattern/#creational-patterns","text":"Name Description In Design Patterns In Code Complete Other Abstract factory Provide an interface for creating families of related or dependent objects without specifying their concrete classes. Yes Yes N/A Builder Separate the construction of a complex object from its representation, allowing the same construction process to create various representations. Yes No N/A Dependency Injection A class accepts the objects it requires from an injector instead of creating the objects directly. No No N/A Factory method Define an interface for creating a single object, but let subclasses decide which class to instantiate. Factory Method lets a class defer instantiation to subclasses. Yes Yes N/A Lazy initialization Tactic of delaying the creation of an object, the calculation of a value, or some other expensive process until the first time it is needed. This pattern appears in the GoF catalog as \"virtual proxy\", an implementation strategy for the Proxy pattern. No No PoEAA Multiton Ensure a class has only named instances, and provide a global point of access to them. No No N/A Object pool Avoid expensive acquisition and release of resources by recycling objects that are no longer in use. Can be considered a generalisation of connection pool and thread pool patterns. No No N/A Prototype Specify the kinds of objects to create using a prototypical instance, and create new objects from the 'skeleton' of an existing object, thus boosting performance and keeping memory footprints to a minimum. Yes No N/A Resource acquisition is initialization (RAII) Ensure that resources are properly released by tying them to the lifespan of suitable objects. No No N/A Singleton Ensure a class has only one instance, and provide a global point of access to it. Yes Yes N/A","title":"Creational patterns"},{"location":"Theory/Design-pattern/Software-design-pattern/#concurrency-patterns","text":"Name Description In POSA2 Other Active Object Decouples method execution from method invocation that reside in their own thread of control. The goal is to introduce concurrency, by using asynchronous method invocation and a scheduler for handling requests. Yes N/A","title":"Concurrency patterns"},{"location":"Theory/Design-pattern/OOP-design-pattern/Books/","text":"Book Patterns of Enterprise Application Architecture","title":"Books"},{"location":"Theory/Design-pattern/OOP-design-pattern/Books/#book","text":"","title":"Book"},{"location":"Theory/Design-pattern/OOP-design-pattern/Books/#patterns-of-enterprise-application-architecture","text":"","title":"Patterns of Enterprise Application Architecture"},{"location":"Theory/Design-pattern/OOP-design-pattern/Object-oriented-design/","text":"Design \u5728\u8fdb\u5165\u5177\u4f53\u7684design pattern\u4e4b\u524d\uff0c\u6709\u5fc5\u8981\u5bf9oop\u4e2d\u7684\u8bbe\u8ba1\u601d\u60f3\u8fdb\u884c\u9610\u8ff0\uff0c\u56e0\u4e3a\u5404\u79cd\u7684design pattern\u5176\u5b9e\u90fd\u662f\u8d2f\u5f7b\u7740\u8fd9\u4e9b\u601d\u60f3\u7684\u3002 Design by contract and Interface-based programming \u4e24\u8005\u5176\u5b9e\u672c\u8d28\u4e0a\u90fd\u5728\u63cf\u8ff0\u76f8\u540c\u7684\u5185\u5bb9\uff0c\u9762\u5411\u62bd\u8c61\uff0c\u800c\u4e0d\u662f\u9762\u5411\u5177\u4f53\u3002\u62bd\u8c61\u662f\u79d1\u5b66\u7684\u601d\u8003\u65b9\u5f0f\uff0c\u5176\u5b9e\uff0c\u8fd9\u4e00\u6bb5\u7684\u63cf\u8ff0\uff0c\u9700\u8981\u4ece\u5bf9\u62bd\u8c61\u7684\u63cf\u8ff0\u5f00\u59cb\uff1a\u89e3\u51b3\u95ee\u9898\uff0c\u6211\u4eec\u5f80\u5f80\u662f\u5148\u5efa\u7acb\u8d77\u62bd\u8c61\u6a21\u578b\uff0c\u8fd9\u4e2a\u62bd\u8c61\u6a21\u578b\u6765\u89e3\u51b3\u5177\u4f53\u7684\u95ee\u9898\u3002 dynamic dispatch\u662f\u8fde\u63a5\u62bd\u8c61\u4e0e\u5177\u4f53\u7684\u6865\u6881\u3002 Object-oriented design","title":"Object-oriented-design"},{"location":"Theory/Design-pattern/OOP-design-pattern/Object-oriented-design/#design","text":"\u5728\u8fdb\u5165\u5177\u4f53\u7684design pattern\u4e4b\u524d\uff0c\u6709\u5fc5\u8981\u5bf9oop\u4e2d\u7684\u8bbe\u8ba1\u601d\u60f3\u8fdb\u884c\u9610\u8ff0\uff0c\u56e0\u4e3a\u5404\u79cd\u7684design pattern\u5176\u5b9e\u90fd\u662f\u8d2f\u5f7b\u7740\u8fd9\u4e9b\u601d\u60f3\u7684\u3002","title":"Design"},{"location":"Theory/Design-pattern/OOP-design-pattern/Object-oriented-design/#design-by-contract-and-interface-based-programming","text":"\u4e24\u8005\u5176\u5b9e\u672c\u8d28\u4e0a\u90fd\u5728\u63cf\u8ff0\u76f8\u540c\u7684\u5185\u5bb9\uff0c\u9762\u5411\u62bd\u8c61\uff0c\u800c\u4e0d\u662f\u9762\u5411\u5177\u4f53\u3002\u62bd\u8c61\u662f\u79d1\u5b66\u7684\u601d\u8003\u65b9\u5f0f\uff0c\u5176\u5b9e\uff0c\u8fd9\u4e00\u6bb5\u7684\u63cf\u8ff0\uff0c\u9700\u8981\u4ece\u5bf9\u62bd\u8c61\u7684\u63cf\u8ff0\u5f00\u59cb\uff1a\u89e3\u51b3\u95ee\u9898\uff0c\u6211\u4eec\u5f80\u5f80\u662f\u5148\u5efa\u7acb\u8d77\u62bd\u8c61\u6a21\u578b\uff0c\u8fd9\u4e2a\u62bd\u8c61\u6a21\u578b\u6765\u89e3\u51b3\u5177\u4f53\u7684\u95ee\u9898\u3002 dynamic dispatch\u662f\u8fde\u63a5\u62bd\u8c61\u4e0e\u5177\u4f53\u7684\u6865\u6881\u3002","title":"Design by contract and Interface-based programming"},{"location":"Theory/Design-pattern/OOP-design-pattern/Object-oriented-design/#object-oriented-design","text":"","title":"Object-oriented design"},{"location":"Theory/Design-pattern/OOP-design-pattern/Separation-of-container-and-algorithm/","text":"Separation of container and algorithm \u5c06\u5bb9\u5668\u4e0e\u7b97\u6cd5\u8fdb\u884c\u5206\u79bb\u3002 \u5728\u7ef4\u57fa\u767e\u79d1 Visitor pattern \u4e2d\u6709\u5982\u4e0b\u63cf\u8ff0\uff1a In object-oriented programming and software engineering , the visitor design pattern is a way of separating an algorithm from an object structure on which it operates. A practical result of this separation is the ability to add new operations to existing object structures without modifying the structures. \u5728\u7ef4\u57fa\u767e\u79d1 Iterator pattern \u4e2d\u6709\u5982\u4e0b\u63cf\u8ff0\uff1a The iterator pattern decouples algorithms from containers; in some cases, algorithms are necessarily container-specific and thus cannot be decoupled.","title":"Separation-of-container-and-algorithm"},{"location":"Theory/Design-pattern/OOP-design-pattern/Separation-of-container-and-algorithm/#separation-of-container-and-algorithm","text":"\u5c06\u5bb9\u5668\u4e0e\u7b97\u6cd5\u8fdb\u884c\u5206\u79bb\u3002 \u5728\u7ef4\u57fa\u767e\u79d1 Visitor pattern \u4e2d\u6709\u5982\u4e0b\u63cf\u8ff0\uff1a In object-oriented programming and software engineering , the visitor design pattern is a way of separating an algorithm from an object structure on which it operates. A practical result of this separation is the ability to add new operations to existing object structures without modifying the structures. \u5728\u7ef4\u57fa\u767e\u79d1 Iterator pattern \u4e2d\u6709\u5982\u4e0b\u63cf\u8ff0\uff1a The iterator pattern decouples algorithms from containers; in some cases, algorithms are necessarily container-specific and thus cannot be decoupled.","title":"Separation of container and algorithm"},{"location":"Theory/Design-pattern/OOP-design-pattern/Summary-of-design-pattern/","text":"Summary of design pattern Iterator pattern VS visitor pattern Iterator pattern\u662f\u6307\u521b\u5efaiterator\u4ee5\u4fbf\u4e8e\u904d\u5386container\uff0cvisitor pattern\u5219\u662f\u6307\u4e3a\u4e0d\u540c\u7c7b\u578b\u7684\u5143\u7d20\u4f7f\u7528\u4e0d\u540c\u7684\u7b97\u6cd5\u3002 \u6b63\u5982\u5728 refactoring Iterator \u4e2d\u6240\u603b\u7ed3\u7684\uff1a You can use Visitor along with Iterator to traverse a complex data structure and execute some operation over its elements, even if they all have different classes. Visitor Pattern VS Iterator Pattern: visiting across hierarchy class? A First, you should know what these patterns are for. The Iterator Pattern is used to access an aggregate sequentially without exposing its underlying representation. So you could Hide a List or array or similar aggregates behind an Iterator. Visitor Pattern is used to perform an action on a structure of elements without changing the implementation of the elements themselves. So you use the patterns in two different situations and not as alternatives to each other. In the Visitor Pattern you implement an Interface IAcceptor in each element you want to visit. So the Visitor Pattern doesn't rely on a superclass but on Interfaces public interface IAcceptor { public void Accept ( IVisitor visitor ); } So if you have a List of objects you can iterate over it and visit the objects implementing IAcceptor public VisitorExample () { MyVisitorImplementation visitor = new MyVisitorImplementation (); List < object > objects = GetList (); foreach ( IAcceptor item in objects ) item . Accept ( visitor ); } public interface IVisitor { public void Visit ( MyAcceptorImplementation item ); public void Visit ( AnotherAcceptorImplementation item ); } public class MyAcceptorImplementation : IAcceptor { //Some Code ... public void Accept ( IVisitor visitor ) { visitor . Visit ( this ); } } To complete the code here is Visitor to write to Console if it visits my or another implementation of an acceptor. public class MyVisitorImplementation : IVisitor { public void Visit ( MyAcceptorImplementation item ) { Console . WriteLine ( \"Mine\" ); } public void Visit ( AnotherAcceptorImplementation item ) { Console . WriteLine ( \"Another\" ); } } For more useful examples and better explanation have a look at Visitor Pattern and Iterator Pattern EDIT: Here an example using both, the visitor and Iterator. The iterator is just the logic how to move through your aggregate. It would make more sense with a hierarchical structure. public VisitorExample2 () { MyVisitorImplementation visitor = new MyVisitorImplementation (); List < object > myListToHide = GetList (); //Here you hide that the aggregate is a List<object> ConcreteIterator i = new ConcreteIterator ( myListToHide ); IAcceptor item = i . First (); while ( item != null ) { item . Accept ( visitor ); item = i . Next (); } //... do something with the result } A There are two good examples I know of where visitor is clearly preferable to iterator. The first is interacting with some unknown set of class members, in particular in C++. For example, here's a visitor that prints out all the members of other classes. Imagine you're the author of Printer and someone you're unacquainted with is the author of Heterogeneous3Tuple . #include <iostream> template < class ElemType1 , class ElemType2 , class ElemType3 > class Heterogeneous3Tuple { public : Heterogeneous3Tuple ( ElemType1 elem1 , ElemType2 elem2 , ElemType3 elem3 ) : elem1_ ( std :: move ( elem1 )), elem2_ ( std :: move ( elem2 )), elem3_ ( std :: move ( elem3 )) {} template < class Visitor > void accept ( const Visitor & visitor ) { visitor ( elem1_ ); visitor ( elem2_ ); visitor ( elem3_ ); } private : ElemType1 elem1_ ; ElemType2 elem2_ ; ElemType3 elem3_ ; }; class Printer { public : template < class VisitedElemType > void operator ()( const VisitedElemType & visitee ) const { std :: cout << visitee << std :: endl ; } private : }; int main () { Heterogeneous3Tuple < char , int , double > h3t ( 'a' , 0 , 3.14 ); Printer p ; h3t . accept ( p ); } a 0 3.14 coliru There's no sensible way to get an iterator to work here. Without even knowing what types our Printer class might interact with this works so long as the visitor is accept() ed and the elements all interact in a similar way with operator << and a stream. The other good example I know of shows up in abstract syntax tree manipulations. CPython and LLVM both use visitors. Using a visitor here prevents code that manipulates certain AST nodes from needing to know how to iterate over all the various AST nodes that might branch in complicated ways. The LLVM source code goes into more detail. Here's the highlight: /// Instruction visitors are used when you want to perform different actions /// for different kinds of instructions without having to use lots of casts /// and a big switch statement (in your code, that is). /// /// To define your own visitor, inherit from this class, specifying your /// new type for the 'SubClass' template parameter, and \"override\" visitXXX /// functions in your class. I say \"override\" because this class is defined /// in terms of statically resolved overloading, not virtual functions. /// /// For example, here is a visitor that counts the number of malloc /// instructions processed: /// /// /// Declare the class. Note that we derive from InstVisitor instantiated /// /// with _our new subclasses_ type. /// /// /// struct CountAllocaVisitor : public InstVisitor<CountAllocaVisitor> { /// unsigned Count; /// CountAllocaVisitor() : Count(0) {} /// /// void visitAllocaInst(AllocaInst &AI) { ++Count; } /// }; /// /// And this class would be used like this: /// CountAllocaVisitor CAV; /// CAV.visit(function); /// NumAllocas = CAV.Count; TO READ Visitor Pattern VS Iterator Pattern: visiting across hierarchy class? - iterator Combination of visitor and iterator pattern Iterator vs Visitor Design Pattern and How Observer pattern and visitor pattern Observer pattern + Visitor pattern for message system https://stackoverflow.com/questions/32079697/observer-pattern-visitor-pattern-for-message-system Design pattern\u8ba9\u6211\u4eec\u907f\u514d\u4f7f\u7528if-else\u5206\u652f \u201cDesign pattern\u8ba9\u6211\u4eec\u907f\u514d\u4f7f\u7528if-else\u5206\u652f\u201d\uff0c\u8fd9\u662f\u6211\u5b66\u4e60\u4e86\u5404\u79cd\u5404\u6837\u7684\u8bbe\u8ba1\u6a21\u5f0f\u540e\uff0c\u4ea7\u751f\u7684\u4e00\u79cd\u60f3\u6cd5\uff0c\u5728\u4e0b\u9762\u6587\u7ae0\u4e2d\uff0c\u90fd\u8c08\u5230\u4e86\u8fd9\u4e00\u70b9\uff1a Java\u8bbe\u8ba1\u6a21\u5f0f\u2014\u2014\u72b6\u6001\u6a21\u5f0f\uff08STATE PATTERN\uff09 Refactoring.Guru \u7684 Visitor \u8fd9\u8ba9\u6211\u53cd\u601d\uff0c\u4f7f\u7528if-else\u7684\u574f\u5904\uff1a \u5982\u679c\u60c5\u51b5\u5c11\uff0c\u8fd8\u6bd4\u8f83\u597d\u5904\u7406\uff0c\u4e00\u65e6\u60c5\u51b5\u975e\u5e38\u591a\uff0c\u90a3\u4e48\u65e0\u8bba\u662f\u7f16\u7a0b\u3001\u8fd8\u662f\u7ef4\u62a4\u90fd\u975e\u5e38\u96be \u4f7f\u7528if\u662f\u4e0d\u597d\u6269\u5c55\u7684 \u6027\u80fd\uff08\u8fd9\u4e00\u70b9\u9700\u8981\u8bc1\u660e\uff09\uff0c\u4f7f\u7528if\u6761\u4ef6\u5224\u65ad\uff0c\u662f\u5426\u6709dynamic dispatch\u6216\u8005static dispatch\u6027\u80fd\u597d\u5462\uff1f design pattern\u5145\u5206\u5229\u7528dynamic dispatch\u548cstatic dispatch\uff0c\u4e3b\u8981\u6211\u4eec\u9075\u5faadesign-by-context\uff0c\u90a3\u4e48\u5c31\u53ef\u4ee5\u5728\u4e0d\u4fee\u6539\u7684design\uff08\u62bd\u8c61\u6a21\u578b\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u8fdb\u884c\u6269\u5c55\uff0c\u6216\u8005\u6240\uff0cdispatch\u662f\u5efa\u7acb\u62bd\u8c61\u4e0e\u5177\u4f53\u7684\u6865\u6881\u3002","title":"Summary-of-design-pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Summary-of-design-pattern/#summary-of-design-pattern","text":"","title":"Summary of design pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Summary-of-design-pattern/#iterator-pattern-vs-visitor-pattern","text":"Iterator pattern\u662f\u6307\u521b\u5efaiterator\u4ee5\u4fbf\u4e8e\u904d\u5386container\uff0cvisitor pattern\u5219\u662f\u6307\u4e3a\u4e0d\u540c\u7c7b\u578b\u7684\u5143\u7d20\u4f7f\u7528\u4e0d\u540c\u7684\u7b97\u6cd5\u3002 \u6b63\u5982\u5728 refactoring Iterator \u4e2d\u6240\u603b\u7ed3\u7684\uff1a You can use Visitor along with Iterator to traverse a complex data structure and execute some operation over its elements, even if they all have different classes.","title":"Iterator pattern VS visitor pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Summary-of-design-pattern/#visitor-pattern-vs-iterator-pattern-visiting-across-hierarchy-class","text":"","title":"Visitor Pattern VS Iterator Pattern: visiting across hierarchy class?"},{"location":"Theory/Design-pattern/OOP-design-pattern/Summary-of-design-pattern/#a","text":"First, you should know what these patterns are for. The Iterator Pattern is used to access an aggregate sequentially without exposing its underlying representation. So you could Hide a List or array or similar aggregates behind an Iterator. Visitor Pattern is used to perform an action on a structure of elements without changing the implementation of the elements themselves. So you use the patterns in two different situations and not as alternatives to each other. In the Visitor Pattern you implement an Interface IAcceptor in each element you want to visit. So the Visitor Pattern doesn't rely on a superclass but on Interfaces public interface IAcceptor { public void Accept ( IVisitor visitor ); } So if you have a List of objects you can iterate over it and visit the objects implementing IAcceptor public VisitorExample () { MyVisitorImplementation visitor = new MyVisitorImplementation (); List < object > objects = GetList (); foreach ( IAcceptor item in objects ) item . Accept ( visitor ); } public interface IVisitor { public void Visit ( MyAcceptorImplementation item ); public void Visit ( AnotherAcceptorImplementation item ); } public class MyAcceptorImplementation : IAcceptor { //Some Code ... public void Accept ( IVisitor visitor ) { visitor . Visit ( this ); } } To complete the code here is Visitor to write to Console if it visits my or another implementation of an acceptor. public class MyVisitorImplementation : IVisitor { public void Visit ( MyAcceptorImplementation item ) { Console . WriteLine ( \"Mine\" ); } public void Visit ( AnotherAcceptorImplementation item ) { Console . WriteLine ( \"Another\" ); } } For more useful examples and better explanation have a look at Visitor Pattern and Iterator Pattern EDIT: Here an example using both, the visitor and Iterator. The iterator is just the logic how to move through your aggregate. It would make more sense with a hierarchical structure. public VisitorExample2 () { MyVisitorImplementation visitor = new MyVisitorImplementation (); List < object > myListToHide = GetList (); //Here you hide that the aggregate is a List<object> ConcreteIterator i = new ConcreteIterator ( myListToHide ); IAcceptor item = i . First (); while ( item != null ) { item . Accept ( visitor ); item = i . Next (); } //... do something with the result }","title":"A"},{"location":"Theory/Design-pattern/OOP-design-pattern/Summary-of-design-pattern/#a_1","text":"There are two good examples I know of where visitor is clearly preferable to iterator. The first is interacting with some unknown set of class members, in particular in C++. For example, here's a visitor that prints out all the members of other classes. Imagine you're the author of Printer and someone you're unacquainted with is the author of Heterogeneous3Tuple . #include <iostream> template < class ElemType1 , class ElemType2 , class ElemType3 > class Heterogeneous3Tuple { public : Heterogeneous3Tuple ( ElemType1 elem1 , ElemType2 elem2 , ElemType3 elem3 ) : elem1_ ( std :: move ( elem1 )), elem2_ ( std :: move ( elem2 )), elem3_ ( std :: move ( elem3 )) {} template < class Visitor > void accept ( const Visitor & visitor ) { visitor ( elem1_ ); visitor ( elem2_ ); visitor ( elem3_ ); } private : ElemType1 elem1_ ; ElemType2 elem2_ ; ElemType3 elem3_ ; }; class Printer { public : template < class VisitedElemType > void operator ()( const VisitedElemType & visitee ) const { std :: cout << visitee << std :: endl ; } private : }; int main () { Heterogeneous3Tuple < char , int , double > h3t ( 'a' , 0 , 3.14 ); Printer p ; h3t . accept ( p ); } a 0 3.14 coliru There's no sensible way to get an iterator to work here. Without even knowing what types our Printer class might interact with this works so long as the visitor is accept() ed and the elements all interact in a similar way with operator << and a stream. The other good example I know of shows up in abstract syntax tree manipulations. CPython and LLVM both use visitors. Using a visitor here prevents code that manipulates certain AST nodes from needing to know how to iterate over all the various AST nodes that might branch in complicated ways. The LLVM source code goes into more detail. Here's the highlight: /// Instruction visitors are used when you want to perform different actions /// for different kinds of instructions without having to use lots of casts /// and a big switch statement (in your code, that is). /// /// To define your own visitor, inherit from this class, specifying your /// new type for the 'SubClass' template parameter, and \"override\" visitXXX /// functions in your class. I say \"override\" because this class is defined /// in terms of statically resolved overloading, not virtual functions. /// /// For example, here is a visitor that counts the number of malloc /// instructions processed: /// /// /// Declare the class. Note that we derive from InstVisitor instantiated /// /// with _our new subclasses_ type. /// /// /// struct CountAllocaVisitor : public InstVisitor<CountAllocaVisitor> { /// unsigned Count; /// CountAllocaVisitor() : Count(0) {} /// /// void visitAllocaInst(AllocaInst &AI) { ++Count; } /// }; /// /// And this class would be used like this: /// CountAllocaVisitor CAV; /// CAV.visit(function); /// NumAllocas = CAV.Count;","title":"A"},{"location":"Theory/Design-pattern/OOP-design-pattern/Summary-of-design-pattern/#to-read","text":"Visitor Pattern VS Iterator Pattern: visiting across hierarchy class? - iterator Combination of visitor and iterator pattern Iterator vs Visitor Design Pattern and How","title":"TO READ"},{"location":"Theory/Design-pattern/OOP-design-pattern/Summary-of-design-pattern/#observer-pattern-and-visitor-pattern","text":"","title":"Observer pattern and visitor pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Summary-of-design-pattern/#observer-pattern-visitor-pattern-for-message-system","text":"https://stackoverflow.com/questions/32079697/observer-pattern-visitor-pattern-for-message-system","title":"Observer pattern + Visitor pattern for message system"},{"location":"Theory/Design-pattern/OOP-design-pattern/Summary-of-design-pattern/#design-patternif-else","text":"\u201cDesign pattern\u8ba9\u6211\u4eec\u907f\u514d\u4f7f\u7528if-else\u5206\u652f\u201d\uff0c\u8fd9\u662f\u6211\u5b66\u4e60\u4e86\u5404\u79cd\u5404\u6837\u7684\u8bbe\u8ba1\u6a21\u5f0f\u540e\uff0c\u4ea7\u751f\u7684\u4e00\u79cd\u60f3\u6cd5\uff0c\u5728\u4e0b\u9762\u6587\u7ae0\u4e2d\uff0c\u90fd\u8c08\u5230\u4e86\u8fd9\u4e00\u70b9\uff1a Java\u8bbe\u8ba1\u6a21\u5f0f\u2014\u2014\u72b6\u6001\u6a21\u5f0f\uff08STATE PATTERN\uff09 Refactoring.Guru \u7684 Visitor \u8fd9\u8ba9\u6211\u53cd\u601d\uff0c\u4f7f\u7528if-else\u7684\u574f\u5904\uff1a \u5982\u679c\u60c5\u51b5\u5c11\uff0c\u8fd8\u6bd4\u8f83\u597d\u5904\u7406\uff0c\u4e00\u65e6\u60c5\u51b5\u975e\u5e38\u591a\uff0c\u90a3\u4e48\u65e0\u8bba\u662f\u7f16\u7a0b\u3001\u8fd8\u662f\u7ef4\u62a4\u90fd\u975e\u5e38\u96be \u4f7f\u7528if\u662f\u4e0d\u597d\u6269\u5c55\u7684 \u6027\u80fd\uff08\u8fd9\u4e00\u70b9\u9700\u8981\u8bc1\u660e\uff09\uff0c\u4f7f\u7528if\u6761\u4ef6\u5224\u65ad\uff0c\u662f\u5426\u6709dynamic dispatch\u6216\u8005static dispatch\u6027\u80fd\u597d\u5462\uff1f design pattern\u5145\u5206\u5229\u7528dynamic dispatch\u548cstatic dispatch\uff0c\u4e3b\u8981\u6211\u4eec\u9075\u5faadesign-by-context\uff0c\u90a3\u4e48\u5c31\u53ef\u4ee5\u5728\u4e0d\u4fee\u6539\u7684design\uff08\u62bd\u8c61\u6a21\u578b\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u8fdb\u884c\u6269\u5c55\uff0c\u6216\u8005\u6240\uff0cdispatch\u662f\u5efa\u7acb\u62bd\u8c61\u4e0e\u5177\u4f53\u7684\u6865\u6881\u3002","title":"Design pattern\u8ba9\u6211\u4eec\u907f\u514d\u4f7f\u7528if-else\u5206\u652f"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Iterator-pattern/Iterator-pattern/","text":"Iterator pattern Iteration\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u4e2d\u662f \u7ef4\u57fa\u767e\u79d1 Iterator pattern In object-oriented programming , the iterator pattern is a design pattern in which an iterator is used to traverse a container and access the container's elements. The iterator pattern decouples algorithms from containers; in some cases, algorithms are necessarily container-specific and thus cannot be decoupled. w3sdesign iterator pattern","title":"Iterator-pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Iterator-pattern/Iterator-pattern/#iterator-pattern","text":"Iteration\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u4e2d\u662f","title":"Iterator pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Iterator-pattern/Iterator-pattern/#iterator-pattern_1","text":"In object-oriented programming , the iterator pattern is a design pattern in which an iterator is used to traverse a container and access the container's elements. The iterator pattern decouples algorithms from containers; in some cases, algorithms are necessarily container-specific and thus cannot be decoupled.","title":"\u7ef4\u57fa\u767e\u79d1Iterator pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Iterator-pattern/Iterator-pattern/#w3sdesign-iterator-pattern","text":"","title":"w3sdesign iterator pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Observer-pattern/","text":"Observer pattern Observer pattern\u4f7f\u7528OOP\u7684\u8bed\u8a00\u6765\u63cf\u8ff0event-driven model\u3002 \u7ef4\u57fa\u767e\u79d1 Observer pattern The observer pattern is a software design pattern in which an object , called the subject , maintains a list of its dependents, called observers , and notifies them automatically of any state changes, usually by calling one of their methods . NOTE: subject\u5bf9\u5e94\u7684\u662fevent-driven model\u7684monitor\u7684\u89d2\u8272\uff0cobserver\u5bf9\u5e94\u7684\u662fevent-driven model\u7684executor\u89d2\u8272\u3002 w3sdesign Observer design pattern Intent The Observer design pattern solves problems like: How can a one-to-many dependency between objects be defined without making the objects tightly coupled? How can an object notify an open-ended-number of other objects? NOTE: \u201copen-ended-number of other objects\u201d\u610f\u5473\u7740\uff0c\u5728runtime\uff0c\u53ef\u4ee5\u589e\u52a0observer\uff0c\u4e5f\u53ef\u4ee5\u5220\u9664observer\u3002 The Observer pattern describes how to solve such problems: Define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically. The key idea in this pattern is to establish a flexible notification-registration mechanism that notifies all registered objects automatically when an event of interest occurs. NOTE: notification-registration mechanism\u662fobserver pattern\u7684\u6838\u5fc3\u601d\u60f3\uff0c\u51ed\u501f\u5b83\uff0cobserver pattern\u89e3\u51b3\u4e86\u524d\u9762\u63d0\u51fa\u7684\u95ee\u9898\u3002*notification-registration*\u4e5f\u53eb\u505apublish-subscribe\u3002 NOTE: \u5728\u539f\u6587\u7684intent\u8282\u7ed9\u51fa\u7684sample class diagram\u548csample sequence diagram\u5176\u5b9e\u5c31\u5df2\u7ecf\u5c55\u793a\u51fa\u4e86observer design pattern\u7684\u5b9e\u73b0\u4e86\u3002 Problem NOTE: \u5728\u539f\u6587\u7684\u8fd9\u4e00\u8282\u7ed9\u51fa\u4e86\u4e00\u4e2a\u53cd\u4f8b\uff0c\u6211\u4eec\u4e5f\u5e94\u8be5\u8981\u6ce8\u610f\u53cd\u4f8b\u3002\u5728\u539f\u6587\u7684motivation\u7ae0\u8282\uff0c\u7ed9\u51fa\u4e86\u66f4\u52a0\u8be6\u7ec6\u7684\u5bf9\u6bd4\u3002 Implementation NOTE: \u539f\u6587\u7684\u8fd9\u4e00\u8282\u7ed9\u51fa\u7684**Push Data**\u3001**Pull Data**\u5b9e\u73b0\u65b9\u5f0f Sample code NOTE: \u539f\u6587\u7ed9\u51fa\u7684sample code\u975e\u5e38\u597d\u3002 microsoft Observer Design Pattern Events and routed events overview Handling and raising events oodesign Observer Pattern refactoring Observer NOTE: \u524d\u9762\u7ed9\u51fa\u7684\u793a\u4f8b\u90fd\u6ca1\u6709\u51c6\u786e\u63cf\u8ff0\u5bf9\u4e0d\u540c\u7c7b\u578b\u7684\u4e8b\u4ef6\uff0c\u6267\u884c\u4e0d\u540c\u7684\u51fd\u6570\uff0c\u800c\u672c\u6587\u7684\u793a\u4f8b\u5219\u5c55\u793a\u4e86\u8fd9\u4e00\u70b9\u3002\u5b83\u7684\u4ee3\u7801\u4e5f\u662f\u503c\u5f97\u9605\u8bfb\u7684https://refactoring.guru/design-patterns cpppatterns Observer TODO observer pattern VS publish subscribe pattern https://hackernoon.com/observer-vs-pub-sub-pattern-50d3b27f838c","title":"Observer-pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Observer-pattern/#observer-pattern","text":"Observer pattern\u4f7f\u7528OOP\u7684\u8bed\u8a00\u6765\u63cf\u8ff0event-driven model\u3002","title":"Observer pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Observer-pattern/#observer-pattern_1","text":"The observer pattern is a software design pattern in which an object , called the subject , maintains a list of its dependents, called observers , and notifies them automatically of any state changes, usually by calling one of their methods . NOTE: subject\u5bf9\u5e94\u7684\u662fevent-driven model\u7684monitor\u7684\u89d2\u8272\uff0cobserver\u5bf9\u5e94\u7684\u662fevent-driven model\u7684executor\u89d2\u8272\u3002","title":"\u7ef4\u57fa\u767e\u79d1Observer pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Observer-pattern/#w3sdesign-observer-design-pattern","text":"","title":"w3sdesign Observer design pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Observer-pattern/#intent","text":"The Observer design pattern solves problems like: How can a one-to-many dependency between objects be defined without making the objects tightly coupled? How can an object notify an open-ended-number of other objects? NOTE: \u201copen-ended-number of other objects\u201d\u610f\u5473\u7740\uff0c\u5728runtime\uff0c\u53ef\u4ee5\u589e\u52a0observer\uff0c\u4e5f\u53ef\u4ee5\u5220\u9664observer\u3002 The Observer pattern describes how to solve such problems: Define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically. The key idea in this pattern is to establish a flexible notification-registration mechanism that notifies all registered objects automatically when an event of interest occurs. NOTE: notification-registration mechanism\u662fobserver pattern\u7684\u6838\u5fc3\u601d\u60f3\uff0c\u51ed\u501f\u5b83\uff0cobserver pattern\u89e3\u51b3\u4e86\u524d\u9762\u63d0\u51fa\u7684\u95ee\u9898\u3002*notification-registration*\u4e5f\u53eb\u505apublish-subscribe\u3002 NOTE: \u5728\u539f\u6587\u7684intent\u8282\u7ed9\u51fa\u7684sample class diagram\u548csample sequence diagram\u5176\u5b9e\u5c31\u5df2\u7ecf\u5c55\u793a\u51fa\u4e86observer design pattern\u7684\u5b9e\u73b0\u4e86\u3002","title":"Intent"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Observer-pattern/#problem","text":"NOTE: \u5728\u539f\u6587\u7684\u8fd9\u4e00\u8282\u7ed9\u51fa\u4e86\u4e00\u4e2a\u53cd\u4f8b\uff0c\u6211\u4eec\u4e5f\u5e94\u8be5\u8981\u6ce8\u610f\u53cd\u4f8b\u3002\u5728\u539f\u6587\u7684motivation\u7ae0\u8282\uff0c\u7ed9\u51fa\u4e86\u66f4\u52a0\u8be6\u7ec6\u7684\u5bf9\u6bd4\u3002","title":"Problem"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Observer-pattern/#implementation","text":"NOTE: \u539f\u6587\u7684\u8fd9\u4e00\u8282\u7ed9\u51fa\u7684**Push Data**\u3001**Pull Data**\u5b9e\u73b0\u65b9\u5f0f","title":"Implementation"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Observer-pattern/#sample-code","text":"NOTE: \u539f\u6587\u7ed9\u51fa\u7684sample code\u975e\u5e38\u597d\u3002","title":"Sample code"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Observer-pattern/#microsoft-observer-design-pattern","text":"Events and routed events overview Handling and raising events","title":"microsoft Observer Design Pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Observer-pattern/#oodesign-observer-pattern","text":"","title":"oodesign Observer Pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Observer-pattern/#refactoring-observer","text":"NOTE: \u524d\u9762\u7ed9\u51fa\u7684\u793a\u4f8b\u90fd\u6ca1\u6709\u51c6\u786e\u63cf\u8ff0\u5bf9\u4e0d\u540c\u7c7b\u578b\u7684\u4e8b\u4ef6\uff0c\u6267\u884c\u4e0d\u540c\u7684\u51fd\u6570\uff0c\u800c\u672c\u6587\u7684\u793a\u4f8b\u5219\u5c55\u793a\u4e86\u8fd9\u4e00\u70b9\u3002\u5b83\u7684\u4ee3\u7801\u4e5f\u662f\u503c\u5f97\u9605\u8bfb\u7684https://refactoring.guru/design-patterns","title":"refactoring Observer"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Observer-pattern/#cpppatterns-observer","text":"","title":"cpppatterns Observer"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Observer-pattern/#todo","text":"observer pattern VS publish subscribe pattern https://hackernoon.com/observer-vs-pub-sub-pattern-50d3b27f838c","title":"TODO"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Code/","text":"Code w3sdesign \u5728 w3sdesign \u7684source code\u7ae0\u8282\u7ed9\u51fa\u4e86\u4f8b\u5b50\u3002 wikipedia \u7ef4\u57fa\u767e\u79d1 Observer pattern \u7ed9\u51fa\u7684 Example \u3002 Github TheLartians / Event martinmoene / observer-ptr-lite fnz / ObserverManager","title":"Introduction"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Code/#code","text":"","title":"Code"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Code/#w3sdesign","text":"\u5728 w3sdesign \u7684source code\u7ae0\u8282\u7ed9\u51fa\u4e86\u4f8b\u5b50\u3002","title":"w3sdesign"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Code/#wikipedia","text":"\u7ef4\u57fa\u767e\u79d1 Observer pattern \u7ed9\u51fa\u7684 Example \u3002","title":"wikipedia"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Code/#github","text":"","title":"Github"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Code/#thelartiansevent","text":"","title":"TheLartians/Event"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Code/#martinmoeneobserver-ptr-lite","text":"","title":"martinmoene/observer-ptr-lite"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Code/#fnzobservermanager","text":"","title":"fnz/ObserverManager"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Code/w3sdesign/Example1/","text":"Example 1 Basic Java code for implementing the sample UML diagrams.","title":"Example 1"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Code/w3sdesign/Example1/#example-1","text":"Basic Java code for implementing the sample UML diagrams.","title":"Example 1"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Code/w3sdesign/Example2/","text":"Example 2 Synchronizing state between a timer object (time of day) and a clock object.","title":"Example 2"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Code/w3sdesign/Example2/#example-2","text":"Synchronizing state between a timer object (time of day) and a clock object.","title":"Example 2"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Code/w3sdesign/Example3/","text":"Example 3 Event handling in a GUI application (Java Swing).","title":"Example 3"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Observer-pattern/Code/w3sdesign/Example3/#example-3","text":"Event handling in a GUI application (Java Swing).","title":"Example 3"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Publish-subscribe-pattern/Publish-subscribe-pattern/","text":"Publish\u2013subscribe pattern \u7ef4\u57fa\u767e\u79d1 Publish\u2013subscribe pattern","title":"Publish-subscribe-pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Publish-subscribe-pattern/Publish-subscribe-pattern/#publishsubscribe-pattern","text":"","title":"Publish\u2013subscribe pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Publish-subscribe-pattern/Publish-subscribe-pattern/#publishsubscribe-pattern_1","text":"","title":"\u7ef4\u57fa\u767e\u79d1Publish\u2013subscribe pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/State-pattern/State-pattern/","text":"State pattern CSDN Java\u8bbe\u8ba1\u6a21\u5f0f\u2014\u2014\u72b6\u6001\u6a21\u5f0f\uff08STATE PATTERN\uff09 \u6211\u662f\u901a\u8fc7\u9605\u8bfbCSDN\u7684 Java\u8bbe\u8ba1\u6a21\u5f0f\u2014\u2014\u72b6\u6001\u6a21\u5f0f\uff08STATE PATTERN\uff09 \u800c\u4e86\u89e3state pattern\u7684\uff0cstate pattern\u8ba9\u6211\u60f3\u5230\u4e86 state machine \uff08\u5728\u5de5\u7a0b automata-and-formal-language \u4e2d\u6709\u5bf9\u5b83\u7684\u63cf\u8ff0\uff09\uff0c\u6211\u7684\u611f\u89c9\u5b83\u662f\u4f7f\u7528\u9762\u5411\u5bf9\u8c61\u8bed\u8a00\u6765\u63cf\u8ff0state machine\uff08\u53e6\u5916\u4e00\u79cd\u63cf\u8ff0\u65b9\u5f0f\u662fgraph\uff09\uff0c\u540e\u6765\u9605\u8bfb\u7ef4\u57fa\u767e\u79d1 State pattern \uff0c\u5176\u4e2d\u4e5f\u6709\u8fd9\u6837\u7684\u63cf\u8ff0\uff0c\u7531\u6b64\u53ef\u89c1\uff0cstate machine \u6a21\u578b\u662f\u53ef\u4ee5\u523b\u753b\u5f88\u591a\u4e8b\u7269\u7684\u3002 \u53ef\u4ee5\u4f7f\u7528state pattern\u89e3\u51b3\u7684\u95ee\u9898 \u5176\u5b9e\uff0c\u5982\u679c\u6240\u9700\u8981\u89e3\u51b3\u7684\u95ee\u9898\u80fd\u591f\u4f7f\u7528state machine\u6765\u8fdb\u884c\u63cf\u8ff0\uff0c\u90a3\u4e48\uff0c\u8fd9\u4e9b\u95ee\u9898\u90fd\u662f\u53ef\u4ee5\u4f7f\u7528state pattern\u6765\u8fdb\u884c\u89e3\u51b3\u7684\uff0c\u6211\u4eec\u7ed3\u5408\u8fd9\u7bc7\u6587\u7ae0\u4e2d\u6240\u5217\u4e3e\u7684\u7535\u68af\u7684\u8fd9\u4e2a\u4f8b\u5b50\u6765\u770b\uff1a\u6709\u591a\u79cd\u72b6\u6001\u3001\u72b6\u6001\u4e4b\u95f4\u7684\u8f6c\u6362\u3001\u4e0d\u540c\u7684\u72b6\u6001\u4e0b\uff0c\u8fd0\u884c\u8fd0\u884c\u7684\u64cd\u4f5c\u662f\u4e0d\u540c\u7684\u3002 \u5b9e\u73b0\u65b9\u5f0f \u4f7f\u7528 class \u6765\u663e\u793a\u5730\u63cf\u8ff0state\uff0c\u4f7f\u7528context\u6765\u8bb0\u5f55\u7cfb\u7edf\u5f53\u524d\u7684state\u3002 \u90a3\u5982\u4f55\u6765\u5b9e\u73b0state\u4e4b\u95f4\u7684\u8f6c\u6362\u5462\uff1f\u5176\u5b9e\u7cfb\u7edf\u7684\u72b6\u6001\u662f\u7531\u7528\u6237\u7684\u64cd\u4f5c\u800c\u89e6\u53d1\u6765\u8fdb\u884c\u8f6c\u6362\u7684\uff0c\u72b6\u6001\u4e4b\u95f4\u7684\u8f6c\u6362\u5c31\u76f8\u5f53\u4e8e\u8fde\u63a5\u5b83\u4eec\u4e4b\u95f4\u7684\u8fb9\uff0c\u5b9e\u73b0\u65b9\u5f0f\u662f\u6bcf\u4e2a\u72b6\u6001\u90fd\u5b9a\u4e49\u5404\u79cd\u7528\u6237\u5141\u8bb8\u7684\u64cd\u4f5c\uff0c\u8bb0\u5f55\u5404\u79cd\u72b6\u6001\u5728\u5404\u79cd\u64cd\u4f5c\u7684\u8f6c\u6362\u3002 \u7ef4\u57fa\u767e\u79d1 State pattern","title":"State-pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/State-pattern/State-pattern/#state-pattern","text":"","title":"State pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/State-pattern/State-pattern/#csdn-javastate-pattern","text":"\u6211\u662f\u901a\u8fc7\u9605\u8bfbCSDN\u7684 Java\u8bbe\u8ba1\u6a21\u5f0f\u2014\u2014\u72b6\u6001\u6a21\u5f0f\uff08STATE PATTERN\uff09 \u800c\u4e86\u89e3state pattern\u7684\uff0cstate pattern\u8ba9\u6211\u60f3\u5230\u4e86 state machine \uff08\u5728\u5de5\u7a0b automata-and-formal-language \u4e2d\u6709\u5bf9\u5b83\u7684\u63cf\u8ff0\uff09\uff0c\u6211\u7684\u611f\u89c9\u5b83\u662f\u4f7f\u7528\u9762\u5411\u5bf9\u8c61\u8bed\u8a00\u6765\u63cf\u8ff0state machine\uff08\u53e6\u5916\u4e00\u79cd\u63cf\u8ff0\u65b9\u5f0f\u662fgraph\uff09\uff0c\u540e\u6765\u9605\u8bfb\u7ef4\u57fa\u767e\u79d1 State pattern \uff0c\u5176\u4e2d\u4e5f\u6709\u8fd9\u6837\u7684\u63cf\u8ff0\uff0c\u7531\u6b64\u53ef\u89c1\uff0cstate machine \u6a21\u578b\u662f\u53ef\u4ee5\u523b\u753b\u5f88\u591a\u4e8b\u7269\u7684\u3002","title":"CSDN Java\u8bbe\u8ba1\u6a21\u5f0f\u2014\u2014\u72b6\u6001\u6a21\u5f0f\uff08STATE PATTERN\uff09"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/State-pattern/State-pattern/#state-pattern_1","text":"\u5176\u5b9e\uff0c\u5982\u679c\u6240\u9700\u8981\u89e3\u51b3\u7684\u95ee\u9898\u80fd\u591f\u4f7f\u7528state machine\u6765\u8fdb\u884c\u63cf\u8ff0\uff0c\u90a3\u4e48\uff0c\u8fd9\u4e9b\u95ee\u9898\u90fd\u662f\u53ef\u4ee5\u4f7f\u7528state pattern\u6765\u8fdb\u884c\u89e3\u51b3\u7684\uff0c\u6211\u4eec\u7ed3\u5408\u8fd9\u7bc7\u6587\u7ae0\u4e2d\u6240\u5217\u4e3e\u7684\u7535\u68af\u7684\u8fd9\u4e2a\u4f8b\u5b50\u6765\u770b\uff1a\u6709\u591a\u79cd\u72b6\u6001\u3001\u72b6\u6001\u4e4b\u95f4\u7684\u8f6c\u6362\u3001\u4e0d\u540c\u7684\u72b6\u6001\u4e0b\uff0c\u8fd0\u884c\u8fd0\u884c\u7684\u64cd\u4f5c\u662f\u4e0d\u540c\u7684\u3002","title":"\u53ef\u4ee5\u4f7f\u7528state pattern\u89e3\u51b3\u7684\u95ee\u9898"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/State-pattern/State-pattern/#_1","text":"\u4f7f\u7528 class \u6765\u663e\u793a\u5730\u63cf\u8ff0state\uff0c\u4f7f\u7528context\u6765\u8bb0\u5f55\u7cfb\u7edf\u5f53\u524d\u7684state\u3002 \u90a3\u5982\u4f55\u6765\u5b9e\u73b0state\u4e4b\u95f4\u7684\u8f6c\u6362\u5462\uff1f\u5176\u5b9e\u7cfb\u7edf\u7684\u72b6\u6001\u662f\u7531\u7528\u6237\u7684\u64cd\u4f5c\u800c\u89e6\u53d1\u6765\u8fdb\u884c\u8f6c\u6362\u7684\uff0c\u72b6\u6001\u4e4b\u95f4\u7684\u8f6c\u6362\u5c31\u76f8\u5f53\u4e8e\u8fde\u63a5\u5b83\u4eec\u4e4b\u95f4\u7684\u8fb9\uff0c\u5b9e\u73b0\u65b9\u5f0f\u662f\u6bcf\u4e2a\u72b6\u6001\u90fd\u5b9a\u4e49\u5404\u79cd\u7528\u6237\u5141\u8bb8\u7684\u64cd\u4f5c\uff0c\u8bb0\u5f55\u5404\u79cd\u72b6\u6001\u5728\u5404\u79cd\u64cd\u4f5c\u7684\u8f6c\u6362\u3002","title":"\u5b9e\u73b0\u65b9\u5f0f"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/State-pattern/State-pattern/#state-pattern_2","text":"","title":"\u7ef4\u57fa\u767e\u79d1State pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Strategy-pattern/Strategy-pattern/","text":"\u7ef4\u57fa\u767e\u79d1 Strategy pattern","title":"Strategy-pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Strategy-pattern/Strategy-pattern/#strategy-pattern","text":"","title":"\u7ef4\u57fa\u767e\u79d1Strategy pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Visitor-pattern/","text":"Visitor pattern \u201cvisitor\u201d\u7684\u610f\u601d\u662f\u201c\u8bbf\u95ee\u8005\u201d\uff0c\u5728Visitor pattern\u4e2d\uff0c\u6709\u4e13\u95e8\u7684class\u6765\u201c\u626e\u6f14\u201d \u201cvisitor\u201d\u7684\u89d2\u8272\u3002 \u7ef4\u57fa\u767e\u79d1\u7684 Visitor pattern It is one way to follow the open/closed principle . \u8fd9\u53e5\u8bdd\u63d0\u793a\u6211\u4eecvisitor pattern\u7684\u7ec8\u6781\u76ee\u6807\u6240\u5728\uff0c\u5373\u9075\u5faa open/closed principle \uff0cvisitor pattern\u4e2d\uff0copen\u7684\u662f\u53ef\u4ee5\u6dfb\u52a0\u65b0\u7684visitor\uff0c\u5373\u5b9e\u73b0\u65b0\u7684algorithm\uff0cclose\u7684\u662f\u5bf9element\u7684\u4fee\u6539\uff0c\u5373\u6dfb\u52a0\u65b0\u7684algorithm\uff0c\u4e0d\u4f1a\u5bfc\u81f4element\u7684\u53d8\u66f4\u3002 C++ example #include <iostream> #include <vector> class AbstractDispatcher ; // Forward declare AbstractDispatcher class File { // Parent class for the elements (ArchivedFile, SplitFile and // ExtractedFile) public : // This function accepts an object of any class derived from // AbstractDispatcher and must be implemented in all derived classes virtual void Accept ( AbstractDispatcher & dispatcher ) = 0 ; }; // Forward declare specific elements (files) to be dispatched class ArchivedFile ; class SplitFile ; class ExtractedFile ; class AbstractDispatcher { // Declares the interface for the dispatcher public : // Declare overloads for each kind of a file to dispatch virtual void Dispatch ( ArchivedFile & file ) = 0 ; virtual void Dispatch ( SplitFile & file ) = 0 ; virtual void Dispatch ( ExtractedFile & file ) = 0 ; }; class ArchivedFile : public File { // Specific element class #1 public : // Resolved at runtime, it calls the dispatcher's overloaded function, // corresponding to ArchivedFile. void Accept ( AbstractDispatcher & dispatcher ) override { dispatcher . Dispatch ( * this ); } }; class SplitFile : public File { // Specific element class #2 public : // Resolved at runtime, it calls the dispatcher's overloaded function, // corresponding to SplitFile. void Accept ( AbstractDispatcher & dispatcher ) override { dispatcher . Dispatch ( * this ); } }; class ExtractedFile : public File { // Specific element class #3 public : // Resolved at runtime, it calls the dispatcher's overloaded function, // corresponding to ExtractedFile. void Accept ( AbstractDispatcher & dispatcher ) override { dispatcher . Dispatch ( * this ); } }; class Dispatcher : public AbstractDispatcher { // Implements dispatching of all // kind of elements (files) public : void Dispatch ( ArchivedFile & ) override { std :: cout << \"dispatching ArchivedFile\" << std :: endl ; } void Dispatch ( SplitFile & ) override { std :: cout << \"dispatching SplitFile\" << std :: endl ; } void Dispatch ( ExtractedFile & ) override { std :: cout << \"dispatching ExtractedFile\" << std :: endl ; } }; int main () { ArchivedFile archived_file ; SplitFile split_file ; ExtractedFile extracted_file ; std :: vector < File *> files = { & archived_file , & split_file , & extracted_file , }; Dispatcher dispatcher ; for ( File * file : files ) { file -> Accept ( dispatcher ); } } \u5728\u9605\u8bfb\u8fd9\u6bb5\u7684\u4f8b\u5b50\u7684\u65f6\u5019\uff0c\u6211\u60f3\u5230\u4e86\u4e00\u4e2a\u95ee\u9898\uff1a ArchivedFile \u3001 SplitFile \u3001 ExtractedFile \u90fd\u662f File \u7684\u5b50\u7c7b\uff0c\u5b83\u4eec\u90fdoverride\u4e86\u57fa\u7c7b\u7684 Accept \u65b9\u6cd5\uff0c\u53ef\u4ee5\u770b\u5230\u5b83\u4eec\u7684 Accept \u65b9\u6cd5\u7684\u5b9e\u73b0\u90fd\u662f\uff1a void Accept ( AbstractDispatcher & dispatcher ) override { dispatcher . Dispatch ( * this ); } \u90a3\u80fd\u5426\u5c06\u8fd9\u4e2a\u65b9\u6cd5\u653e\u5230\u57fa\u7c7b\u4e2d\u5462\uff1f\u5e94\u8be5\u662f\u4e0d\u80fd\u7684\uff0c\u8fd9\u5c31\u662fdouble dispatch\u6240\u89e3\u51b3\u7684\u95ee\u9898\u3002 Refactoring.Guru \u7684 Visitor Visitor is a behavioral design pattern that lets you separate algorithms from the objects on which they operate. \u5728\u539f\u6587\u7684Solution\u7ae0\u8282\u544a\u8bc9\u4e86\u6211\u4eec\uff1a\u7531visitor\u7c7b\u6765\u5b9e\u73b0\u201calgorithm\u201d The Visitor pattern suggests that you place the new behavior into a separate class called visitor , instead of trying to integrate it into existing classes. \u539f\u6587\u5728Problem\u7ae0\u8282\u7ed9\u51fa\u4e86\u4e0d\u5141\u8bb8\u4fee\u6539node classes\u7684\u539f\u56e0\uff1a The code was already in production and he\uff08system architect\uff09 didn\u2019t want to risk breaking it because of a potential bug in your changes. The primary job of these classes was to work with geodata. The XML export behavior would look alien there. to provide the ability to export into a different format \u539f\u6587\u7684Solution\u7ae0\u8282\u63cf\u8ff0\u4e86\u5982\u4f55\u4f7f\u7528visitor patter\u591f\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\u3002 \u9700\u8981\u89e3\u51b3\u7684\u4e00\u4e2a\u95ee\u9898\u662f\uff1a\u5982\u4f55\u6784\u5efanode class\u5230export\u65b9\u6cd5\u7684\u6620\u5c04\uff0c\u5373\u4e3a\u4e0d\u540c\u7684node class\u6307\u5b9a\u5bf9\u5e94\u7684export\u65b9\u6cd5\u3002\u539f\u6587\u7ed9\u51fa\u4e86\u4e24\u79cd\u65b9\u5f0f\uff1a conditional\uff0c\u5373\u901a\u8fc7 if else \u8bed\u53e5\u6765\u5b9e\u73b0\u6620\u5c04 Double Dispatch \u663e\u7136 Double Dispatch \u6709\u7740\u660e\u663e\u4f18\u52bf\uff0c\u4e0b\u9762\u5bf9\u6b64\u8fdb\u884c\u5206\u6790 Double dispatch Instead of letting the client select a proper version of the method to call, how about we delegate this choice to objects we\u2019re passing to the visitor as an argument? Since the objects know their own classes, they\u2019ll be able to pick a proper method on the visitor less awkwardly. They \u201caccept\u201d a visitor and tell it what visiting method should be executed. // Client code foreach (Node node in graph) node.accept(exportVisitor) // City class City is method accept(Visitor v) is v.doForCity(this) // ... // Industry class Industry is method accept(Visitor v) is v.doForIndustry(this) // ... Applicability \u5728\u539f\u6587\u7684Problem\u7ae0\u8282\u63d0\u51fa\u7684\u95ee\u9898\u548cReal-World Analogy\u7ae0\u8282\u63d0\u51fa\u7684\u4f8b\u5b50\u4e4b\u95f4\u5b58\u5728\u7740\u4e00\u5b9a\u7684\u5171\u6027\uff0c\u901a\u8fc7\u4e24\u8005\u6211\u4eec\u53ef\u4ee5\u603b\u7ed3\u9002\u5408\u4f7f\u7528visitor pattern\u6765\u89e3\u51b3\u7684\u95ee\u9898\uff1a \u9700\u8981\u904d\u5386\u4e0d\u540c\u7c7b\u578b\u7684object \u5bf9\u4e0d\u540c\u7c7b\u578b\u7684object\u9700\u8981\u6267\u884c\u7279\u5b9a\u7684\u64cd\u4f5c \u5176\u5b9e\u539f\u6587\u7684Intent\u7ae0\u8282\u4e2d\u7684\u914d\u56fe\u5df2\u7ecf\u5f62\u8c61\u7684\u5730\u5c55\u793a\u51fa\u4e86visitor pattern\u3002\u5728\u539f\u6587\u7684Applicability\u7ae0\u8282\u5bf9\u6b64\u8fdb\u884c\u4e86\u603b\u7ed3\u3002 \u4e0d\u53ef\u80fd\u5b8c\u5168\u4e0d\u4fee\u6539node classes\uff0c\u800c\u662f\u5c11\u91cf\u4fee\u6539\uff0c\u53ef\u63a7\u4fee\u6539\u3002 Visitor Pattern VS Iterator Pattern: visiting across hierarchy class? A \u8fd9\u4e2a\u56de\u7b54\u662f\u975e\u5e38\u597d\u7684\uff0c\u5728 Summary-of-design-pattern \u4e2d\u5bf9\u5b83\u8fdb\u884c\u4e86\u5206\u6790\u3002 Visitor pattern and double dispatch \u5728visitor pattern\u4e2d\uff0c\u7531\u4e8e\u5b58\u5728\u7740\u591a\u79cdelement\uff0c\u5b58\u5728\u7740\u591a\u79cdvisitor\uff0c\u6240\u4ee5\u6700\u7ec8\u5230\u5e95\u8981\u8c03\u7528\u54ea\u4e2aalgorithm\uff0c\u4f9d\u8d56\u4e8e\u8fd9\u4e24\u8005\uff0c\u5728\u6587\u7ae0 A polyglot's guide to multiple dispatch \u4e2d\u5bf9\u6b64\u8fdb\u884c\u4e86\u8be6\u7ec6\u7684\u5206\u6790\u3002\u5728 Multiple-dispatch \u4e2d\u5bf9\u6b64\u6587\u7ae0\u8fdb\u884c\u4e86\u6536\u5f55\u3002 Example In compiler \u7ef4\u57fa\u767e\u79d1 Abstract syntax tree \u7684 Design patterns \u7ae0\u8282 \u5728\u7ef4\u57fa\u767e\u79d1 Abstract syntax tree \u7684 Design patterns \u7ae0\u8282\uff0c\u603b\u7ed3\u4e86 visitor pattern \u5728compiler\u7684\u5b9e\u73b0\u4e2d\u7684\u5e94\u7528\uff1a Because the compiler traverses the tree several times to determine syntactic correctness, it is important to make traversing the tree a simple operation. The compiler executes a specific set of operations, depending on the type of each node, upon reaching it, so it often makes sense to use the visitor pattern . \u8fd9\u6bb5\u8bdd\u4e2d\u7684\u201cthe tree\u201d\u53ea\u7684\u662fcompiler\u6784\u9020\u7684abstract syntax tree\u3002compiler\u9700\u8981\u591a\u6b21\u904d\u5386\u8fd9\u68f5\u6811\uff0c\u6bcf\u6b21\u904d\u5386\u6267\u884c\u4e00\u4e9b\u64cd\u4f5c\uff0c\u663e\u7136\uff0c\u8fd9\u79cd\u573a\u666f\u662f\u975e\u5e38\u9002\u5408\u4e8e\u4f7f\u7528visitor pattern\u7684\u3002 Visitor Pattern VS Iterator Pattern: visiting across hierarchy class? \u7684 A \u5728\u8fd9\u56de\u7b54\u4e2d\u7ed9\u51fa\u4e86: LLVM source code CPython AST The other good example I know of shows up in abstract syntax tree manipulations. CPython and LLVM both use visitors. Using a visitor here prevents code that manipulates certain AST nodes from needing to know how to iterate over all the various AST nodes that might branch in complicated ways. Hierarchy structure \u5bf9\u5177\u6709hierarchy structure\u7684\u6570\u636e\u8fdb\u884c\u64cd\u4f5c\uff0c\u90fd\u53ef\u4ee5\u4f7f\u7528visitor pattern\u3002 \u6bd4\u5982 JSqlParser Mach7","title":"Visitor-pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Visitor-pattern/#visitor-pattern","text":"\u201cvisitor\u201d\u7684\u610f\u601d\u662f\u201c\u8bbf\u95ee\u8005\u201d\uff0c\u5728Visitor pattern\u4e2d\uff0c\u6709\u4e13\u95e8\u7684class\u6765\u201c\u626e\u6f14\u201d \u201cvisitor\u201d\u7684\u89d2\u8272\u3002","title":"Visitor pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Visitor-pattern/#visitor-pattern_1","text":"It is one way to follow the open/closed principle . \u8fd9\u53e5\u8bdd\u63d0\u793a\u6211\u4eecvisitor pattern\u7684\u7ec8\u6781\u76ee\u6807\u6240\u5728\uff0c\u5373\u9075\u5faa open/closed principle \uff0cvisitor pattern\u4e2d\uff0copen\u7684\u662f\u53ef\u4ee5\u6dfb\u52a0\u65b0\u7684visitor\uff0c\u5373\u5b9e\u73b0\u65b0\u7684algorithm\uff0cclose\u7684\u662f\u5bf9element\u7684\u4fee\u6539\uff0c\u5373\u6dfb\u52a0\u65b0\u7684algorithm\uff0c\u4e0d\u4f1a\u5bfc\u81f4element\u7684\u53d8\u66f4\u3002","title":"\u7ef4\u57fa\u767e\u79d1\u7684Visitor pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Visitor-pattern/#c-example","text":"#include <iostream> #include <vector> class AbstractDispatcher ; // Forward declare AbstractDispatcher class File { // Parent class for the elements (ArchivedFile, SplitFile and // ExtractedFile) public : // This function accepts an object of any class derived from // AbstractDispatcher and must be implemented in all derived classes virtual void Accept ( AbstractDispatcher & dispatcher ) = 0 ; }; // Forward declare specific elements (files) to be dispatched class ArchivedFile ; class SplitFile ; class ExtractedFile ; class AbstractDispatcher { // Declares the interface for the dispatcher public : // Declare overloads for each kind of a file to dispatch virtual void Dispatch ( ArchivedFile & file ) = 0 ; virtual void Dispatch ( SplitFile & file ) = 0 ; virtual void Dispatch ( ExtractedFile & file ) = 0 ; }; class ArchivedFile : public File { // Specific element class #1 public : // Resolved at runtime, it calls the dispatcher's overloaded function, // corresponding to ArchivedFile. void Accept ( AbstractDispatcher & dispatcher ) override { dispatcher . Dispatch ( * this ); } }; class SplitFile : public File { // Specific element class #2 public : // Resolved at runtime, it calls the dispatcher's overloaded function, // corresponding to SplitFile. void Accept ( AbstractDispatcher & dispatcher ) override { dispatcher . Dispatch ( * this ); } }; class ExtractedFile : public File { // Specific element class #3 public : // Resolved at runtime, it calls the dispatcher's overloaded function, // corresponding to ExtractedFile. void Accept ( AbstractDispatcher & dispatcher ) override { dispatcher . Dispatch ( * this ); } }; class Dispatcher : public AbstractDispatcher { // Implements dispatching of all // kind of elements (files) public : void Dispatch ( ArchivedFile & ) override { std :: cout << \"dispatching ArchivedFile\" << std :: endl ; } void Dispatch ( SplitFile & ) override { std :: cout << \"dispatching SplitFile\" << std :: endl ; } void Dispatch ( ExtractedFile & ) override { std :: cout << \"dispatching ExtractedFile\" << std :: endl ; } }; int main () { ArchivedFile archived_file ; SplitFile split_file ; ExtractedFile extracted_file ; std :: vector < File *> files = { & archived_file , & split_file , & extracted_file , }; Dispatcher dispatcher ; for ( File * file : files ) { file -> Accept ( dispatcher ); } } \u5728\u9605\u8bfb\u8fd9\u6bb5\u7684\u4f8b\u5b50\u7684\u65f6\u5019\uff0c\u6211\u60f3\u5230\u4e86\u4e00\u4e2a\u95ee\u9898\uff1a ArchivedFile \u3001 SplitFile \u3001 ExtractedFile \u90fd\u662f File \u7684\u5b50\u7c7b\uff0c\u5b83\u4eec\u90fdoverride\u4e86\u57fa\u7c7b\u7684 Accept \u65b9\u6cd5\uff0c\u53ef\u4ee5\u770b\u5230\u5b83\u4eec\u7684 Accept \u65b9\u6cd5\u7684\u5b9e\u73b0\u90fd\u662f\uff1a void Accept ( AbstractDispatcher & dispatcher ) override { dispatcher . Dispatch ( * this ); } \u90a3\u80fd\u5426\u5c06\u8fd9\u4e2a\u65b9\u6cd5\u653e\u5230\u57fa\u7c7b\u4e2d\u5462\uff1f\u5e94\u8be5\u662f\u4e0d\u80fd\u7684\uff0c\u8fd9\u5c31\u662fdouble dispatch\u6240\u89e3\u51b3\u7684\u95ee\u9898\u3002","title":"C++ example"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Visitor-pattern/#refactoringguruvisitor","text":"Visitor is a behavioral design pattern that lets you separate algorithms from the objects on which they operate. \u5728\u539f\u6587\u7684Solution\u7ae0\u8282\u544a\u8bc9\u4e86\u6211\u4eec\uff1a\u7531visitor\u7c7b\u6765\u5b9e\u73b0\u201calgorithm\u201d The Visitor pattern suggests that you place the new behavior into a separate class called visitor , instead of trying to integrate it into existing classes. \u539f\u6587\u5728Problem\u7ae0\u8282\u7ed9\u51fa\u4e86\u4e0d\u5141\u8bb8\u4fee\u6539node classes\u7684\u539f\u56e0\uff1a The code was already in production and he\uff08system architect\uff09 didn\u2019t want to risk breaking it because of a potential bug in your changes. The primary job of these classes was to work with geodata. The XML export behavior would look alien there. to provide the ability to export into a different format \u539f\u6587\u7684Solution\u7ae0\u8282\u63cf\u8ff0\u4e86\u5982\u4f55\u4f7f\u7528visitor patter\u591f\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\u3002 \u9700\u8981\u89e3\u51b3\u7684\u4e00\u4e2a\u95ee\u9898\u662f\uff1a\u5982\u4f55\u6784\u5efanode class\u5230export\u65b9\u6cd5\u7684\u6620\u5c04\uff0c\u5373\u4e3a\u4e0d\u540c\u7684node class\u6307\u5b9a\u5bf9\u5e94\u7684export\u65b9\u6cd5\u3002\u539f\u6587\u7ed9\u51fa\u4e86\u4e24\u79cd\u65b9\u5f0f\uff1a conditional\uff0c\u5373\u901a\u8fc7 if else \u8bed\u53e5\u6765\u5b9e\u73b0\u6620\u5c04 Double Dispatch \u663e\u7136 Double Dispatch \u6709\u7740\u660e\u663e\u4f18\u52bf\uff0c\u4e0b\u9762\u5bf9\u6b64\u8fdb\u884c\u5206\u6790","title":"Refactoring.Guru\u7684Visitor"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Visitor-pattern/#double-dispatch","text":"Instead of letting the client select a proper version of the method to call, how about we delegate this choice to objects we\u2019re passing to the visitor as an argument? Since the objects know their own classes, they\u2019ll be able to pick a proper method on the visitor less awkwardly. They \u201caccept\u201d a visitor and tell it what visiting method should be executed. // Client code foreach (Node node in graph) node.accept(exportVisitor) // City class City is method accept(Visitor v) is v.doForCity(this) // ... // Industry class Industry is method accept(Visitor v) is v.doForIndustry(this) // ...","title":"Double dispatch"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Visitor-pattern/#applicability","text":"\u5728\u539f\u6587\u7684Problem\u7ae0\u8282\u63d0\u51fa\u7684\u95ee\u9898\u548cReal-World Analogy\u7ae0\u8282\u63d0\u51fa\u7684\u4f8b\u5b50\u4e4b\u95f4\u5b58\u5728\u7740\u4e00\u5b9a\u7684\u5171\u6027\uff0c\u901a\u8fc7\u4e24\u8005\u6211\u4eec\u53ef\u4ee5\u603b\u7ed3\u9002\u5408\u4f7f\u7528visitor pattern\u6765\u89e3\u51b3\u7684\u95ee\u9898\uff1a \u9700\u8981\u904d\u5386\u4e0d\u540c\u7c7b\u578b\u7684object \u5bf9\u4e0d\u540c\u7c7b\u578b\u7684object\u9700\u8981\u6267\u884c\u7279\u5b9a\u7684\u64cd\u4f5c \u5176\u5b9e\u539f\u6587\u7684Intent\u7ae0\u8282\u4e2d\u7684\u914d\u56fe\u5df2\u7ecf\u5f62\u8c61\u7684\u5730\u5c55\u793a\u51fa\u4e86visitor pattern\u3002\u5728\u539f\u6587\u7684Applicability\u7ae0\u8282\u5bf9\u6b64\u8fdb\u884c\u4e86\u603b\u7ed3\u3002 \u4e0d\u53ef\u80fd\u5b8c\u5168\u4e0d\u4fee\u6539node classes\uff0c\u800c\u662f\u5c11\u91cf\u4fee\u6539\uff0c\u53ef\u63a7\u4fee\u6539\u3002","title":"Applicability"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Visitor-pattern/#visitor-pattern-vs-iterator-pattern-visiting-across-hierarchy-class","text":"","title":"Visitor Pattern VS Iterator Pattern: visiting across hierarchy class?"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Visitor-pattern/#a","text":"\u8fd9\u4e2a\u56de\u7b54\u662f\u975e\u5e38\u597d\u7684\uff0c\u5728 Summary-of-design-pattern \u4e2d\u5bf9\u5b83\u8fdb\u884c\u4e86\u5206\u6790\u3002","title":"A"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Visitor-pattern/#visitor-pattern-and-double-dispatch","text":"\u5728visitor pattern\u4e2d\uff0c\u7531\u4e8e\u5b58\u5728\u7740\u591a\u79cdelement\uff0c\u5b58\u5728\u7740\u591a\u79cdvisitor\uff0c\u6240\u4ee5\u6700\u7ec8\u5230\u5e95\u8981\u8c03\u7528\u54ea\u4e2aalgorithm\uff0c\u4f9d\u8d56\u4e8e\u8fd9\u4e24\u8005\uff0c\u5728\u6587\u7ae0 A polyglot's guide to multiple dispatch \u4e2d\u5bf9\u6b64\u8fdb\u884c\u4e86\u8be6\u7ec6\u7684\u5206\u6790\u3002\u5728 Multiple-dispatch \u4e2d\u5bf9\u6b64\u6587\u7ae0\u8fdb\u884c\u4e86\u6536\u5f55\u3002","title":"Visitor pattern and double dispatch"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Visitor-pattern/#example","text":"","title":"Example"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Visitor-pattern/#in-compiler","text":"","title":"In compiler"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Visitor-pattern/#abstract-syntax-treedesign-patterns","text":"\u5728\u7ef4\u57fa\u767e\u79d1 Abstract syntax tree \u7684 Design patterns \u7ae0\u8282\uff0c\u603b\u7ed3\u4e86 visitor pattern \u5728compiler\u7684\u5b9e\u73b0\u4e2d\u7684\u5e94\u7528\uff1a Because the compiler traverses the tree several times to determine syntactic correctness, it is important to make traversing the tree a simple operation. The compiler executes a specific set of operations, depending on the type of each node, upon reaching it, so it often makes sense to use the visitor pattern . \u8fd9\u6bb5\u8bdd\u4e2d\u7684\u201cthe tree\u201d\u53ea\u7684\u662fcompiler\u6784\u9020\u7684abstract syntax tree\u3002compiler\u9700\u8981\u591a\u6b21\u904d\u5386\u8fd9\u68f5\u6811\uff0c\u6bcf\u6b21\u904d\u5386\u6267\u884c\u4e00\u4e9b\u64cd\u4f5c\uff0c\u663e\u7136\uff0c\u8fd9\u79cd\u573a\u666f\u662f\u975e\u5e38\u9002\u5408\u4e8e\u4f7f\u7528visitor pattern\u7684\u3002","title":"\u7ef4\u57fa\u767e\u79d1Abstract syntax tree\u7684Design patterns\u7ae0\u8282"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Visitor-pattern/#visitor-pattern-vs-iterator-pattern-visiting-across-hierarchy-classa","text":"\u5728\u8fd9\u56de\u7b54\u4e2d\u7ed9\u51fa\u4e86: LLVM source code CPython AST The other good example I know of shows up in abstract syntax tree manipulations. CPython and LLVM both use visitors. Using a visitor here prevents code that manipulates certain AST nodes from needing to know how to iterate over all the various AST nodes that might branch in complicated ways.","title":"Visitor Pattern VS Iterator Pattern: visiting across hierarchy class?\u7684A"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Visitor-pattern/#hierarchy-structure","text":"\u5bf9\u5177\u6709hierarchy structure\u7684\u6570\u636e\u8fdb\u884c\u64cd\u4f5c\uff0c\u90fd\u53ef\u4ee5\u4f7f\u7528visitor pattern\u3002 \u6bd4\u5982 JSqlParser Mach7","title":"Hierarchy structure"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Code/Code/","text":"Code Examples Visitor in Python \u539f\u6587\u94fe\u63a5\uff1a Visitor in Python \u3002\u539f\u6587\u4ee3\u7801\u4f7f\u7528\u4e86python3.5\u4e2d\u5f15\u5165\u7684 Type Hints \u7279\u6027\uff0c\u6240\u4ee5\u9700\u8981\u5728python3.5\u53ca\u4ee5\u4e0a\u7248\u672c\u624d\u80fd\u591f\u6267\u884c\u3002 from __future__ import annotations from abc import ABC , abstractmethod from typing import List class Component ( ABC ): \"\"\" The Component interface declares an `accept` method that should take the base visitor interface as an argument. \"\"\" @abstractmethod def accept ( self , visitor : Visitor ) -> None : pass class ConcreteComponentA ( Component ): \"\"\" Each Concrete Component must implement the `accept` method in such a way that it calls the visitor's method corresponding to the component's class. \"\"\" def accept ( self , visitor : Visitor ) -> None : \"\"\" Note that we're calling `visitConcreteComponentA`, which matches the current class name. This way we let the visitor know the class of the component it works with. \"\"\" visitor . visit_concrete_component_a ( self ) def exclusive_method_of_concrete_component_a ( self ) -> str : \"\"\" Concrete Components may have special methods that don't exist in their base class or interface. The Visitor is still able to use these methods since it's aware of the component's concrete class. \"\"\" return \"A\" class ConcreteComponentB ( Component ): \"\"\" Same here: visitConcreteComponentB => ConcreteComponentB \"\"\" def accept ( self , visitor : Visitor ): visitor . visit_concrete_component_b ( self ) def special_method_of_concrete_component_b ( self ) -> str : return \"B\" class Visitor ( ABC ): \"\"\" The Visitor Interface declares a set of visiting methods that correspond to component classes. The signature of a visiting method allows the visitor to identify the exact class of the component that it's dealing with. \"\"\" @abstractmethod def visit_concrete_component_a ( self , element : ConcreteComponentA ) -> None : pass @abstractmethod def visit_concrete_component_b ( self , element : ConcreteComponentB ) -> None : pass \"\"\" Concrete Visitors implement several versions of the same algorithm, which can work with all concrete component classes. You can experience the biggest benefit of the Visitor pattern when using it with a complex object structure, such as a Composite tree. In this case, it might be helpful to store some intermediate state of the algorithm while executing visitor's methods over various objects of the structure. \"\"\" class ConcreteVisitor1 ( Visitor ): def visit_concrete_component_a ( self , element ) -> None : print ( f \"{element.exclusive_method_of_concrete_component_a()} + ConcreteVisitor1\" ) def visit_concrete_component_b ( self , element ) -> None : print ( f \"{element.special_method_of_concrete_component_b()} + ConcreteVisitor1\" ) class ConcreteVisitor2 ( Visitor ): def visit_concrete_component_a ( self , element ) -> None : print ( f \"{element.exclusive_method_of_concrete_component_a()} + ConcreteVisitor2\" ) def visit_concrete_component_b ( self , element ) -> None : print ( f \"{element.special_method_of_concrete_component_b()} + ConcreteVisitor2\" ) def client_code ( components : List [ Component ], visitor : Visitor ) -> None : \"\"\" The client code can run visitor operations over any set of elements without figuring out their concrete classes. The accept operation directs a call to the appropriate operation in the visitor object. \"\"\" # ... for component in components : component . accept ( visitor ) # ... if __name__ == \"__main__\" : components = [ ConcreteComponentA (), ConcreteComponentB ()] print ( \"The client code works with all visitors via the base Visitor interface:\" ) visitor1 = ConcreteVisitor1 () client_code ( components , visitor1 ) print ( \"It allows the same client code to work with different types of visitors:\" ) visitor2 = ConcreteVisitor2 () client_code ( components , visitor2 ) Visitor in C++ \u539f\u6587\u94fe\u63a5\uff1a Visitor in C++ \u3002\u539f\u6587\u4ee3\u7801\u4f7f\u7528\u4e86C++11\u7684\u7279\u6027\uff0c\u5176\u6b21\u539f\u6587\u4ee3\u7801\u7f3a\u5c11\u5934\u6587\u4ef6\uff0c\u5fc5\u987b\u6dfb\u52a0\u540e\u624d\u80fd\u591f\u7f16\u8bd1\u901a\u8fc7\u3002 #include <array> #include <iostream> /** * The Visitor Interface declares a set of visiting methods that correspond to * component classes. The signature of a visiting method allows the visitor to * identify the exact class of the component that it's dealing with. */ class ConcreteComponentA ; class ConcreteComponentB ; class Visitor { public : virtual void VisitConcreteComponentA ( const ConcreteComponentA * element ) const = 0 ; virtual void VisitConcreteComponentB ( const ConcreteComponentB * element ) const = 0 ; }; /** * The Component interface declares an `accept` method that should take the base * visitor interface as an argument. */ class Component { public : virtual ~ Component () {} virtual void Accept ( Visitor * visitor ) const = 0 ; }; /** * Each Concrete Component must implement the `Accept` method in such a way that * it calls the visitor's method corresponding to the component's class. */ class ConcreteComponentA : public Component { /** * Note that we're calling `visitConcreteComponentA`, which matches the * current class name. This way we let the visitor know the class of the * component it works with. */ public : void Accept ( Visitor * visitor ) const override { visitor -> VisitConcreteComponentA ( this ); } /** * Concrete Components may have special methods that don't exist in their base * class or interface. The Visitor is still able to use these methods since * it's aware of the component's concrete class. */ std :: string ExclusiveMethodOfConcreteComponentA () const { return \"A\" ; } }; class ConcreteComponentB : public Component { /** * Same here: visitConcreteComponentB => ConcreteComponentB */ public : void Accept ( Visitor * visitor ) const override { visitor -> VisitConcreteComponentB ( this ); } std :: string SpecialMethodOfConcreteComponentB () const { return \"B\" ; } }; /** * Concrete Visitors implement several versions of the same algorithm, which can * work with all concrete component classes. * * You can experience the biggest benefit of the Visitor pattern when using it * with a complex object structure, such as a Composite tree. In this case, it * might be helpful to store some intermediate state of the algorithm while * executing visitor's methods over various objects of the structure. */ class ConcreteVisitor1 : public Visitor { public : void VisitConcreteComponentA ( const ConcreteComponentA * element ) const override { std :: cout << element -> ExclusiveMethodOfConcreteComponentA () << \" + ConcreteVisitor1 \\n \" ; } void VisitConcreteComponentB ( const ConcreteComponentB * element ) const override { std :: cout << element -> SpecialMethodOfConcreteComponentB () << \" + ConcreteVisitor1 \\n \" ; } }; class ConcreteVisitor2 : public Visitor { public : void VisitConcreteComponentA ( const ConcreteComponentA * element ) const override { std :: cout << element -> ExclusiveMethodOfConcreteComponentA () << \" + ConcreteVisitor2 \\n \" ; } void VisitConcreteComponentB ( const ConcreteComponentB * element ) const override { std :: cout << element -> SpecialMethodOfConcreteComponentB () << \" + ConcreteVisitor2 \\n \" ; } }; /** * The client code can run visitor operations over any set of elements without * figuring out their concrete classes. The accept operation directs a call to * the appropriate operation in the visitor object. */ void ClientCode ( std :: array < const Component * , 2 > components , Visitor * visitor ) { // ... for ( const Component * comp : components ) { comp -> Accept ( visitor ); } // ... } int main () { std :: array < const Component * , 2 > components = { new ConcreteComponentA , new ConcreteComponentB }; std :: cout << \"The client code works with all visitors via the base Visitor interface: \\n \" ; ConcreteVisitor1 * visitor1 = new ConcreteVisitor1 ; ClientCode ( components , visitor1 ); std :: cout << \" \\n \" ; std :: cout << \"It allows the same client code to work with different types of visitors: \\n \" ; ConcreteVisitor2 * visitor2 = new ConcreteVisitor2 ; ClientCode ( components , visitor2 ); for ( const Component * comp : components ) { delete comp ; } delete visitor1 ; delete visitor2 ; return 0 ; } \u7f16\u8bd1 g++ --std=c++11 Visitor-pattern.cc -o visitor-pattern geeksforgeeks Visitor design pattern \u539f\u6587\u94fe\u63a5\uff1a Visitor design pattern interface ItemElement { public int accept ( ShoppingCartVisitor visitor ); } class Book implements ItemElement { private int price ; private String isbnNumber ; public Book ( int cost , String isbn ) { this . price = cost ; this . isbnNumber = isbn ; } public int getPrice () { return price ; } public String getIsbnNumber () { return isbnNumber ; } @Override public int accept ( ShoppingCartVisitor visitor ) { return visitor . visit ( this ); } } class Fruit implements ItemElement { private int pricePerKg ; private int weight ; private String name ; public Fruit ( int priceKg , int wt , String nm ) { this . pricePerKg = priceKg ; this . weight = wt ; this . name = nm ; } public int getPricePerKg () { return pricePerKg ; } public int getWeight () { return weight ; } public String getName () { return this . name ; } @Override public int accept ( ShoppingCartVisitor visitor ) { return visitor . visit ( this ); } } interface ShoppingCartVisitor { int visit ( Book book ); int visit ( Fruit fruit ); } class ShoppingCartVisitorImpl implements ShoppingCartVisitor { @Override public int visit ( Book book ) { int cost = 0 ; //apply 5$ discount if book price is greater than 50 if ( book . getPrice () > 50 ) { cost = book . getPrice ()- 5 ; } else cost = book . getPrice (); System . out . println ( \"Book ISBN::\" + book . getIsbnNumber () + \" cost =\" + cost ); return cost ; } @Override public int visit ( Fruit fruit ) { int cost = fruit . getPricePerKg ()* fruit . getWeight (); System . out . println ( fruit . getName () + \" cost = \" + cost ); return cost ; } } class ShoppingCartClient { public static void main ( String [] args ) { ItemElement [] items = new ItemElement []{ new Book ( 20 , \"1234\" ), new Book ( 100 , \"5678\" ), new Fruit ( 10 , 2 , \"Banana\" ), new Fruit ( 5 , 5 , \"Apple\" )}; int total = calculatePrice ( items ); System . out . println ( \"Total Cost = \" + total ); } private static int calculatePrice ( ItemElement [] items ) { ShoppingCartVisitor visitor = new ShoppingCartVisitorImpl (); int sum = 0 ; for ( ItemElement item : items ) { sum = sum + item . accept ( visitor ); } return sum ; } } //Write CPP code here #include <iostream> using namespace std ; class Stock { public : virtual void accept ( class Visitor * ) = 0 ; }; class Apple : public Stock { public : /*virtual*/ void accept ( Visitor * ); void buy () { cout << \"Apple::buy \\n \" ; } void sell () { cout << \"Apple::sell \\n \" ; } }; class Google : public Stock { public : /*virtual*/ void accept ( Visitor * ); void buy () { cout << \"Google::buy \\n \" ; } void sell () { cout << \"Google::sell \\n \" ; } }; class Visitor { public : virtual void visit ( Apple * ) = 0 ; virtual void visit ( Google * ) = 0 ; //private: static int m_num_apple , m_num_google ; void total_stocks () { cout << \"m_num_apple \" << m_num_apple << \", m_num_google \" << m_num_google << '\\n' ; } }; int Visitor :: m_num_apple = 0 ; int Visitor :: m_num_google = 0 ; class BuyVisitor : public Visitor { public : BuyVisitor () { m_num_apple = m_num_google = 0 ; } /*virtual*/ void visit ( Apple * r ) { ++ m_num_apple ; r -> buy (); cout << \"m_num_apple \" << m_num_apple << endl ; } /*virtual*/ void visit ( Google * b ) { ++ m_num_google ; b -> buy (); cout << \" m_num_google \" << m_num_google << '\\n' ; } }; class SellVisitor : public Visitor { public : /*virtual*/ void visit ( Apple * a ) { -- m_num_apple ; a -> sell (); cout << \"m_num_apple \" << m_num_apple << endl ; } /*virtual*/ void visit ( Google * g ) { -- m_num_google ; g -> sell (); cout << \"m_num_google \" << m_num_google << endl ; } }; void Apple :: accept ( Visitor * v ) { v -> visit ( this ); } void Google :: accept ( Visitor * v ) { v -> visit ( this ); } int main () { Stock * set [] = { new Apple , new Google , new Google , new Apple , new Apple , 0 }; BuyVisitor buy_operation ; SellVisitor sell_operation ; for ( int i = 0 ; set [ i ]; i ++ ) { set [ i ] -> accept ( & buy_operation ); } buy_operation . total_stocks (); for ( int i = 0 ; set [ i ]; i ++ ) { set [ i ] -> accept ( & sell_operation ); } sell_operation . total_stocks (); }","title":"Code"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Code/Code/#code-examples","text":"","title":"Code Examples"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Code/Code/#visitor-in-python","text":"\u539f\u6587\u94fe\u63a5\uff1a Visitor in Python \u3002\u539f\u6587\u4ee3\u7801\u4f7f\u7528\u4e86python3.5\u4e2d\u5f15\u5165\u7684 Type Hints \u7279\u6027\uff0c\u6240\u4ee5\u9700\u8981\u5728python3.5\u53ca\u4ee5\u4e0a\u7248\u672c\u624d\u80fd\u591f\u6267\u884c\u3002 from __future__ import annotations from abc import ABC , abstractmethod from typing import List class Component ( ABC ): \"\"\" The Component interface declares an `accept` method that should take the base visitor interface as an argument. \"\"\" @abstractmethod def accept ( self , visitor : Visitor ) -> None : pass class ConcreteComponentA ( Component ): \"\"\" Each Concrete Component must implement the `accept` method in such a way that it calls the visitor's method corresponding to the component's class. \"\"\" def accept ( self , visitor : Visitor ) -> None : \"\"\" Note that we're calling `visitConcreteComponentA`, which matches the current class name. This way we let the visitor know the class of the component it works with. \"\"\" visitor . visit_concrete_component_a ( self ) def exclusive_method_of_concrete_component_a ( self ) -> str : \"\"\" Concrete Components may have special methods that don't exist in their base class or interface. The Visitor is still able to use these methods since it's aware of the component's concrete class. \"\"\" return \"A\" class ConcreteComponentB ( Component ): \"\"\" Same here: visitConcreteComponentB => ConcreteComponentB \"\"\" def accept ( self , visitor : Visitor ): visitor . visit_concrete_component_b ( self ) def special_method_of_concrete_component_b ( self ) -> str : return \"B\" class Visitor ( ABC ): \"\"\" The Visitor Interface declares a set of visiting methods that correspond to component classes. The signature of a visiting method allows the visitor to identify the exact class of the component that it's dealing with. \"\"\" @abstractmethod def visit_concrete_component_a ( self , element : ConcreteComponentA ) -> None : pass @abstractmethod def visit_concrete_component_b ( self , element : ConcreteComponentB ) -> None : pass \"\"\" Concrete Visitors implement several versions of the same algorithm, which can work with all concrete component classes. You can experience the biggest benefit of the Visitor pattern when using it with a complex object structure, such as a Composite tree. In this case, it might be helpful to store some intermediate state of the algorithm while executing visitor's methods over various objects of the structure. \"\"\" class ConcreteVisitor1 ( Visitor ): def visit_concrete_component_a ( self , element ) -> None : print ( f \"{element.exclusive_method_of_concrete_component_a()} + ConcreteVisitor1\" ) def visit_concrete_component_b ( self , element ) -> None : print ( f \"{element.special_method_of_concrete_component_b()} + ConcreteVisitor1\" ) class ConcreteVisitor2 ( Visitor ): def visit_concrete_component_a ( self , element ) -> None : print ( f \"{element.exclusive_method_of_concrete_component_a()} + ConcreteVisitor2\" ) def visit_concrete_component_b ( self , element ) -> None : print ( f \"{element.special_method_of_concrete_component_b()} + ConcreteVisitor2\" ) def client_code ( components : List [ Component ], visitor : Visitor ) -> None : \"\"\" The client code can run visitor operations over any set of elements without figuring out their concrete classes. The accept operation directs a call to the appropriate operation in the visitor object. \"\"\" # ... for component in components : component . accept ( visitor ) # ... if __name__ == \"__main__\" : components = [ ConcreteComponentA (), ConcreteComponentB ()] print ( \"The client code works with all visitors via the base Visitor interface:\" ) visitor1 = ConcreteVisitor1 () client_code ( components , visitor1 ) print ( \"It allows the same client code to work with different types of visitors:\" ) visitor2 = ConcreteVisitor2 () client_code ( components , visitor2 )","title":"Visitor in Python"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Code/Code/#visitor-in-c","text":"\u539f\u6587\u94fe\u63a5\uff1a Visitor in C++ \u3002\u539f\u6587\u4ee3\u7801\u4f7f\u7528\u4e86C++11\u7684\u7279\u6027\uff0c\u5176\u6b21\u539f\u6587\u4ee3\u7801\u7f3a\u5c11\u5934\u6587\u4ef6\uff0c\u5fc5\u987b\u6dfb\u52a0\u540e\u624d\u80fd\u591f\u7f16\u8bd1\u901a\u8fc7\u3002 #include <array> #include <iostream> /** * The Visitor Interface declares a set of visiting methods that correspond to * component classes. The signature of a visiting method allows the visitor to * identify the exact class of the component that it's dealing with. */ class ConcreteComponentA ; class ConcreteComponentB ; class Visitor { public : virtual void VisitConcreteComponentA ( const ConcreteComponentA * element ) const = 0 ; virtual void VisitConcreteComponentB ( const ConcreteComponentB * element ) const = 0 ; }; /** * The Component interface declares an `accept` method that should take the base * visitor interface as an argument. */ class Component { public : virtual ~ Component () {} virtual void Accept ( Visitor * visitor ) const = 0 ; }; /** * Each Concrete Component must implement the `Accept` method in such a way that * it calls the visitor's method corresponding to the component's class. */ class ConcreteComponentA : public Component { /** * Note that we're calling `visitConcreteComponentA`, which matches the * current class name. This way we let the visitor know the class of the * component it works with. */ public : void Accept ( Visitor * visitor ) const override { visitor -> VisitConcreteComponentA ( this ); } /** * Concrete Components may have special methods that don't exist in their base * class or interface. The Visitor is still able to use these methods since * it's aware of the component's concrete class. */ std :: string ExclusiveMethodOfConcreteComponentA () const { return \"A\" ; } }; class ConcreteComponentB : public Component { /** * Same here: visitConcreteComponentB => ConcreteComponentB */ public : void Accept ( Visitor * visitor ) const override { visitor -> VisitConcreteComponentB ( this ); } std :: string SpecialMethodOfConcreteComponentB () const { return \"B\" ; } }; /** * Concrete Visitors implement several versions of the same algorithm, which can * work with all concrete component classes. * * You can experience the biggest benefit of the Visitor pattern when using it * with a complex object structure, such as a Composite tree. In this case, it * might be helpful to store some intermediate state of the algorithm while * executing visitor's methods over various objects of the structure. */ class ConcreteVisitor1 : public Visitor { public : void VisitConcreteComponentA ( const ConcreteComponentA * element ) const override { std :: cout << element -> ExclusiveMethodOfConcreteComponentA () << \" + ConcreteVisitor1 \\n \" ; } void VisitConcreteComponentB ( const ConcreteComponentB * element ) const override { std :: cout << element -> SpecialMethodOfConcreteComponentB () << \" + ConcreteVisitor1 \\n \" ; } }; class ConcreteVisitor2 : public Visitor { public : void VisitConcreteComponentA ( const ConcreteComponentA * element ) const override { std :: cout << element -> ExclusiveMethodOfConcreteComponentA () << \" + ConcreteVisitor2 \\n \" ; } void VisitConcreteComponentB ( const ConcreteComponentB * element ) const override { std :: cout << element -> SpecialMethodOfConcreteComponentB () << \" + ConcreteVisitor2 \\n \" ; } }; /** * The client code can run visitor operations over any set of elements without * figuring out their concrete classes. The accept operation directs a call to * the appropriate operation in the visitor object. */ void ClientCode ( std :: array < const Component * , 2 > components , Visitor * visitor ) { // ... for ( const Component * comp : components ) { comp -> Accept ( visitor ); } // ... } int main () { std :: array < const Component * , 2 > components = { new ConcreteComponentA , new ConcreteComponentB }; std :: cout << \"The client code works with all visitors via the base Visitor interface: \\n \" ; ConcreteVisitor1 * visitor1 = new ConcreteVisitor1 ; ClientCode ( components , visitor1 ); std :: cout << \" \\n \" ; std :: cout << \"It allows the same client code to work with different types of visitors: \\n \" ; ConcreteVisitor2 * visitor2 = new ConcreteVisitor2 ; ClientCode ( components , visitor2 ); for ( const Component * comp : components ) { delete comp ; } delete visitor1 ; delete visitor2 ; return 0 ; }","title":"Visitor in C++"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Code/Code/#_1","text":"g++ --std=c++11 Visitor-pattern.cc -o visitor-pattern","title":"\u7f16\u8bd1"},{"location":"Theory/Design-pattern/OOP-design-pattern/Behavioral-pattern/Visitor-pattern/Code/Code/#geeksforgeeks-visitor-design-pattern","text":"\u539f\u6587\u94fe\u63a5\uff1a Visitor design pattern interface ItemElement { public int accept ( ShoppingCartVisitor visitor ); } class Book implements ItemElement { private int price ; private String isbnNumber ; public Book ( int cost , String isbn ) { this . price = cost ; this . isbnNumber = isbn ; } public int getPrice () { return price ; } public String getIsbnNumber () { return isbnNumber ; } @Override public int accept ( ShoppingCartVisitor visitor ) { return visitor . visit ( this ); } } class Fruit implements ItemElement { private int pricePerKg ; private int weight ; private String name ; public Fruit ( int priceKg , int wt , String nm ) { this . pricePerKg = priceKg ; this . weight = wt ; this . name = nm ; } public int getPricePerKg () { return pricePerKg ; } public int getWeight () { return weight ; } public String getName () { return this . name ; } @Override public int accept ( ShoppingCartVisitor visitor ) { return visitor . visit ( this ); } } interface ShoppingCartVisitor { int visit ( Book book ); int visit ( Fruit fruit ); } class ShoppingCartVisitorImpl implements ShoppingCartVisitor { @Override public int visit ( Book book ) { int cost = 0 ; //apply 5$ discount if book price is greater than 50 if ( book . getPrice () > 50 ) { cost = book . getPrice ()- 5 ; } else cost = book . getPrice (); System . out . println ( \"Book ISBN::\" + book . getIsbnNumber () + \" cost =\" + cost ); return cost ; } @Override public int visit ( Fruit fruit ) { int cost = fruit . getPricePerKg ()* fruit . getWeight (); System . out . println ( fruit . getName () + \" cost = \" + cost ); return cost ; } } class ShoppingCartClient { public static void main ( String [] args ) { ItemElement [] items = new ItemElement []{ new Book ( 20 , \"1234\" ), new Book ( 100 , \"5678\" ), new Fruit ( 10 , 2 , \"Banana\" ), new Fruit ( 5 , 5 , \"Apple\" )}; int total = calculatePrice ( items ); System . out . println ( \"Total Cost = \" + total ); } private static int calculatePrice ( ItemElement [] items ) { ShoppingCartVisitor visitor = new ShoppingCartVisitorImpl (); int sum = 0 ; for ( ItemElement item : items ) { sum = sum + item . accept ( visitor ); } return sum ; } } //Write CPP code here #include <iostream> using namespace std ; class Stock { public : virtual void accept ( class Visitor * ) = 0 ; }; class Apple : public Stock { public : /*virtual*/ void accept ( Visitor * ); void buy () { cout << \"Apple::buy \\n \" ; } void sell () { cout << \"Apple::sell \\n \" ; } }; class Google : public Stock { public : /*virtual*/ void accept ( Visitor * ); void buy () { cout << \"Google::buy \\n \" ; } void sell () { cout << \"Google::sell \\n \" ; } }; class Visitor { public : virtual void visit ( Apple * ) = 0 ; virtual void visit ( Google * ) = 0 ; //private: static int m_num_apple , m_num_google ; void total_stocks () { cout << \"m_num_apple \" << m_num_apple << \", m_num_google \" << m_num_google << '\\n' ; } }; int Visitor :: m_num_apple = 0 ; int Visitor :: m_num_google = 0 ; class BuyVisitor : public Visitor { public : BuyVisitor () { m_num_apple = m_num_google = 0 ; } /*virtual*/ void visit ( Apple * r ) { ++ m_num_apple ; r -> buy (); cout << \"m_num_apple \" << m_num_apple << endl ; } /*virtual*/ void visit ( Google * b ) { ++ m_num_google ; b -> buy (); cout << \" m_num_google \" << m_num_google << '\\n' ; } }; class SellVisitor : public Visitor { public : /*virtual*/ void visit ( Apple * a ) { -- m_num_apple ; a -> sell (); cout << \"m_num_apple \" << m_num_apple << endl ; } /*virtual*/ void visit ( Google * g ) { -- m_num_google ; g -> sell (); cout << \"m_num_google \" << m_num_google << endl ; } }; void Apple :: accept ( Visitor * v ) { v -> visit ( this ); } void Google :: accept ( Visitor * v ) { v -> visit ( this ); } int main () { Stock * set [] = { new Apple , new Google , new Google , new Apple , new Apple , 0 }; BuyVisitor buy_operation ; SellVisitor sell_operation ; for ( int i = 0 ; set [ i ]; i ++ ) { set [ i ] -> accept ( & buy_operation ); } buy_operation . total_stocks (); for ( int i = 0 ; set [ i ]; i ++ ) { set [ i ] -> accept ( & sell_operation ); } sell_operation . total_stocks (); }","title":"geeksforgeeks Visitor design pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Creational/","text":"","title":"Introduction"},{"location":"Theory/Design-pattern/OOP-design-pattern/Creational/Singleton-pattern/Singleton-pattern/","text":"Singleton pattern \u7ef4\u57fa\u767e\u79d1 Singleton pattern","title":"Singleton-pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Creational/Singleton-pattern/Singleton-pattern/#singleton-pattern","text":"","title":"Singleton pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/Creational/Singleton-pattern/Singleton-pattern/#singleton-pattern_1","text":"","title":"\u7ef4\u57fa\u767e\u79d1Singleton pattern"},{"location":"Theory/Design-pattern/OOP-design-pattern/SOLID/Inversion-of-control/","text":"Inversion of control In software engineering , inversion of control ( IoC ) is a design principle in which custom-written portions of a computer program receive the flow of control from a generic framework . A software architecture with this design inverts control as compared to traditional procedural programming : in traditional programming, the custom code that expresses the purpose of the program calls into reusable libraries to take care of generic tasks, but with inversion of control, it is the framework that calls into the custom, or task-specific, code. Inversion of control is used to increase modularity of the program and make it extensible ,[ 1] and has applications in object-oriented programming and other programming paradigms . The term was used by Michael Mattsson in a thesis[ 2] , taken from there[ 3] by Stefano Mazzocchi and popularized by him in 1999 in a defunct Apache Software Foundation project, Avalon , then further popularized in 2004 by Robert C. Martin and Martin Fowler . The term is related to, but different from, the dependency inversion principle , which concerns itself with decoupling dependencies between high-level and low-level layers through shared abstractions . The general concept is also related to event-driven programming in that it is often implemented using IoC, so that the custom code is commonly only concerned with the handling of events, whereas the event loop and dispatch of events/messages is handled by the framework or the runtime environment. Overview As an example, with traditional programming, the main function of an application might make function calls into a menu library to display a list of available commands and query the user to select one.[ 4] The library thus would return the chosen option as the value of the function call, and the main function uses this value to execute the associated command. This style was common in text based interfaces . For example, an email client may show a screen with commands to load new mails, answer the current mail, start a new mail, etc., and the program execution would block until the user presses a key to select a command. With inversion of control , on the other hand, the program would be written using a software framework that knows common behavioral and graphical elements, such as windowing systems , menus, controlling the mouse, and so on. The custom code \"fills in the blanks\" for the framework , such as supplying a table of menu items and registering a code subroutine for each item, but it is the framework that monitors the user's actions and invokes the subroutine when a menu item is selected. In the mail client example, the framework could follow both the keyboard and mouse inputs and call the command invoked by the user by either means, and at the same time monitor the network interface to find out if new messages arrive and refresh the screen when some network activity is detected. The same framework could be used as the skeleton(\u6846\u67b6) for a spreadsheet program or a text editor. Conversely, the framework knows nothing about Web browsers, spreadsheets or text editors; implementing their functionality takes custom code. Inversion of control carries\uff08\u643a\u5e26\uff0c\u8fd0\u8f93\uff0c\u4f20\u9012\uff09 the strong connotation\uff08\u5185\u6db5\uff09 that the reusable code and the problem-specific code are developed independently even though they operate together in an application. Software frameworks , callbacks , schedulers , event loops , dependency injection , and the template method are examples of design patterns that follow the inversion of control principle, although the term is most commonly used in the context of object-oriented programming . Inversion of control serves the following design purposes: To decouple the execution of a task from implementation. To focus a module on the task it is designed for. To free modules from assumptions about how other systems do what they do and instead rely on contracts . To prevent side effects when replacing a module. Inversion of control is sometimes facetiously referred to as the \"Hollywood Principle: Don't call us, we'll call you\". Description In traditional programming, the flow of the business logic is determined by objects that are statically bound to one another. With inversion of control, the flow depends on the object graph that is built up during program execution. Such a dynamic flow is made possible by object interactions that are defined through abstractions. This run-time binding is achieved by mechanisms such as dependency injection or a service locator . In IoC, the code could also be linked statically during compilation, but finding the code to execute by reading its description from external configuration instead of with a direct reference in the code itself. In dependency injection, a dependent object or module is coupled to the object it needs at run time . Which particular object will satisfy the dependency during program execution typically cannot be known at compile time using static analysis . While described in terms of object interaction here, the principle can apply to other programming methodologies besides object-oriented programming . In order for the running program to bind objects to one another, the objects must possess compatible interfaces . For example, class A may delegate behavior to interface I which is implemented by class B ; the program instantiates A and B , and then injects B into A . SUMMARY :\u8981\u60f3\u5b9e\u73b0\u5728 Overview \u4e2d\u63cf\u8ff0\u7684\u601d\u60f3\uff0c\u9700\u8981\u91c7\u7528\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\u63cf\u8ff0\u7684\u5b9e\u73b0\u65b9\u5f0f\u3002 Implementation techniques In object-oriented programming , there are several basic techniques to implement inversion of control. These are: Using a service locator pattern Using dependency injection , for example Constructor injection Parameter injection Setter injection Interface injection Using a contextualized lookup Using template method design pattern Using strategy design pattern In an original article by Martin Fowler,[ 9] the first three different techniques are discussed. In a description about inversion of control types,[ 10] the last one is mentioned. Often the contextualized lookup will be accomplished using a service locator\u3002","title":"Inversion-of-control"},{"location":"Theory/Design-pattern/OOP-design-pattern/SOLID/Inversion-of-control/#inversion-of-control","text":"In software engineering , inversion of control ( IoC ) is a design principle in which custom-written portions of a computer program receive the flow of control from a generic framework . A software architecture with this design inverts control as compared to traditional procedural programming : in traditional programming, the custom code that expresses the purpose of the program calls into reusable libraries to take care of generic tasks, but with inversion of control, it is the framework that calls into the custom, or task-specific, code. Inversion of control is used to increase modularity of the program and make it extensible ,[ 1] and has applications in object-oriented programming and other programming paradigms . The term was used by Michael Mattsson in a thesis[ 2] , taken from there[ 3] by Stefano Mazzocchi and popularized by him in 1999 in a defunct Apache Software Foundation project, Avalon , then further popularized in 2004 by Robert C. Martin and Martin Fowler . The term is related to, but different from, the dependency inversion principle , which concerns itself with decoupling dependencies between high-level and low-level layers through shared abstractions . The general concept is also related to event-driven programming in that it is often implemented using IoC, so that the custom code is commonly only concerned with the handling of events, whereas the event loop and dispatch of events/messages is handled by the framework or the runtime environment.","title":"Inversion of control"},{"location":"Theory/Design-pattern/OOP-design-pattern/SOLID/Inversion-of-control/#overview","text":"As an example, with traditional programming, the main function of an application might make function calls into a menu library to display a list of available commands and query the user to select one.[ 4] The library thus would return the chosen option as the value of the function call, and the main function uses this value to execute the associated command. This style was common in text based interfaces . For example, an email client may show a screen with commands to load new mails, answer the current mail, start a new mail, etc., and the program execution would block until the user presses a key to select a command. With inversion of control , on the other hand, the program would be written using a software framework that knows common behavioral and graphical elements, such as windowing systems , menus, controlling the mouse, and so on. The custom code \"fills in the blanks\" for the framework , such as supplying a table of menu items and registering a code subroutine for each item, but it is the framework that monitors the user's actions and invokes the subroutine when a menu item is selected. In the mail client example, the framework could follow both the keyboard and mouse inputs and call the command invoked by the user by either means, and at the same time monitor the network interface to find out if new messages arrive and refresh the screen when some network activity is detected. The same framework could be used as the skeleton(\u6846\u67b6) for a spreadsheet program or a text editor. Conversely, the framework knows nothing about Web browsers, spreadsheets or text editors; implementing their functionality takes custom code. Inversion of control carries\uff08\u643a\u5e26\uff0c\u8fd0\u8f93\uff0c\u4f20\u9012\uff09 the strong connotation\uff08\u5185\u6db5\uff09 that the reusable code and the problem-specific code are developed independently even though they operate together in an application. Software frameworks , callbacks , schedulers , event loops , dependency injection , and the template method are examples of design patterns that follow the inversion of control principle, although the term is most commonly used in the context of object-oriented programming . Inversion of control serves the following design purposes: To decouple the execution of a task from implementation. To focus a module on the task it is designed for. To free modules from assumptions about how other systems do what they do and instead rely on contracts . To prevent side effects when replacing a module. Inversion of control is sometimes facetiously referred to as the \"Hollywood Principle: Don't call us, we'll call you\".","title":"Overview"},{"location":"Theory/Design-pattern/OOP-design-pattern/SOLID/Inversion-of-control/#description","text":"In traditional programming, the flow of the business logic is determined by objects that are statically bound to one another. With inversion of control, the flow depends on the object graph that is built up during program execution. Such a dynamic flow is made possible by object interactions that are defined through abstractions. This run-time binding is achieved by mechanisms such as dependency injection or a service locator . In IoC, the code could also be linked statically during compilation, but finding the code to execute by reading its description from external configuration instead of with a direct reference in the code itself. In dependency injection, a dependent object or module is coupled to the object it needs at run time . Which particular object will satisfy the dependency during program execution typically cannot be known at compile time using static analysis . While described in terms of object interaction here, the principle can apply to other programming methodologies besides object-oriented programming . In order for the running program to bind objects to one another, the objects must possess compatible interfaces . For example, class A may delegate behavior to interface I which is implemented by class B ; the program instantiates A and B , and then injects B into A . SUMMARY :\u8981\u60f3\u5b9e\u73b0\u5728 Overview \u4e2d\u63cf\u8ff0\u7684\u601d\u60f3\uff0c\u9700\u8981\u91c7\u7528\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\u63cf\u8ff0\u7684\u5b9e\u73b0\u65b9\u5f0f\u3002","title":"Description"},{"location":"Theory/Design-pattern/OOP-design-pattern/SOLID/Inversion-of-control/#implementation-techniques","text":"In object-oriented programming , there are several basic techniques to implement inversion of control. These are: Using a service locator pattern Using dependency injection , for example Constructor injection Parameter injection Setter injection Interface injection Using a contextualized lookup Using template method design pattern Using strategy design pattern In an original article by Martin Fowler,[ 9] the first three different techniques are discussed. In a description about inversion of control types,[ 10] the last one is mentioned. Often the contextualized lookup will be accomplished using a service locator\u3002","title":"Implementation techniques"},{"location":"Theory/Design-pattern/OOP-design-pattern/SOLID/Liskov-substitution-principle/","text":"Liskov substitution principle \u7ef4\u57fa\u767e\u79d1 Liskov substitution principle NOTE: Liskov substitution principle\u4e0e subtype polymorphism \u5bc6\u5207\u76f8\u5173 \u767e\u5ea6\u767e\u79d1 \u91cc\u6c0f\u66ff\u6362\u539f\u5219","title":"Liskov-substitution-principle"},{"location":"Theory/Design-pattern/OOP-design-pattern/SOLID/Liskov-substitution-principle/#liskov-substitution-principle","text":"","title":"Liskov substitution principle"},{"location":"Theory/Design-pattern/OOP-design-pattern/SOLID/Liskov-substitution-principle/#liskov-substitution-principle_1","text":"NOTE: Liskov substitution principle\u4e0e subtype polymorphism \u5bc6\u5207\u76f8\u5173","title":"\u7ef4\u57fa\u767e\u79d1Liskov substitution principle"},{"location":"Theory/Design-pattern/OOP-design-pattern/SOLID/Liskov-substitution-principle/#_1","text":"","title":"\u767e\u5ea6\u767e\u79d1\u91cc\u6c0f\u66ff\u6362\u539f\u5219"},{"location":"Theory/Design-pattern/OOP-design-pattern/SOLID/Open-closed-principle/","text":"Open\u2013closed principle","title":"Open-closed-principle"},{"location":"Theory/Design-pattern/OOP-design-pattern/SOLID/Open-closed-principle/#openclosed-principle","text":"","title":"Open\u2013closed principle"},{"location":"Theory/Design-pattern/OOP-design-pattern/SOLID/SOLID/","text":"SOLID \u7ef4\u57fa\u767e\u79d1 SOLID","title":"SOLID"},{"location":"Theory/Design-pattern/OOP-design-pattern/SOLID/SOLID/#solid","text":"","title":"SOLID"},{"location":"Theory/Design-pattern/OOP-design-pattern/SOLID/SOLID/#solid_1","text":"","title":"\u7ef4\u57fa\u767e\u79d1SOLID"},{"location":"Theory/Exception/Exception-handling/","text":"Exception handling \u7ef4\u57fa\u767e\u79d1 Exception handling \u7ef4\u57fa\u767e\u79d1 Exception handling syntax","title":"Exception-handling"},{"location":"Theory/Exception/Exception-handling/#exception-handling","text":"","title":"Exception handling"},{"location":"Theory/Exception/Exception-handling/#exception-handling_1","text":"","title":"\u7ef4\u57fa\u767e\u79d1Exception handling"},{"location":"Theory/Exception/Exception-handling/#exception-handling-syntax","text":"","title":"\u7ef4\u57fa\u767e\u79d1Exception handling syntax"},{"location":"Theory/Invariant/Class-invariant/","text":"What is a class invariant in java? I googled the topic, but besides Wikipedia I didn't find any further useful documentation or articles. Can anybody explain to me in simple words what it means or refer me to some nice and easy to understand documentation? COMMENTS : A more simple explanation - < stackoverflow.com/questions/112064/what-is-an-invariant?rq=1 > A It doesn't mean anything in particular in reference to java. A class invariant is simply a property that holds for all instances of a class, always, no matter what other code does. For example, class X { final Y y = new Y (); } X has the class invariant that there is a y property and it is never null and it has a value of type Y . class Counter { private int x ; public int count () { return x ++; } } fails to maintain two important invariants That count never returns a negative value because of possible underflow. That calls to count are strictly monotonically increasing. The modified class preserves those two invariants. class Counter { private int x ; public synchronized int count () { if ( x == Integer . MAX_VALUE ) { throw new IllegalStateException (); } return x ++; } } but fails to preserve the invariant that calls to count always succeed normally (absent TCB-violations\u2020) because count might throw an exception or it might block if a deadlocked thread owns the counter's monitor. Each language with classes make it easy to maintain some class invariants but not others. Java is no exception: Java classes consistently(\u4e00\u8d2f\u5730) have or do not have properties and methods, so interface invariants are easy to maintain. Java classes can protect their private fields, so invariants that rely on private data are easy to maintain. Java classes can be final, so invariants that rely on there being no code that violates an invariant by crafting a malicious subclass can be maintained. Java allows null values to sneak in in many ways, so it is tough to maintain \"has a real value\" invariants. Java has threads which means that classes that do not synchronize have trouble maintaining invariants that rely on sequential operations in a thread happening together. Java has exceptions which makes it easy to maintain invariants like \"returns a result with property p or returns no result\" but harder to maintain invariants like \"always returns a result\". \u2020 - An externality or TCB violation is an event which a systems designer optimistically assumes will not happen. Typically we just trust that the basic hardware works as advertised when talking about properties of high-level languages built on them, and our arguments that invariants hold don't take into account the possibility of: A programmer using debug hooks to alter local variables as a program runs in ways that code cannot. Your peers don't use reflection with setAccessible to modify private lookup tables. Loki altering physics causing your processor to incorrectly compare two numbers. For some systems our TCB might include only parts of the system, so we might not assume that An administrator or privileged daemon won't kill our JVM process, but we might assume that We can checkpoint to a reliable transactional file-system. The higher-level a system, the larger its TCB typically is, but the more unreliable things you can get out of your TCB, the more likely your invariants are to hold, and the more reliable your system will be in the long run. COMMENTS ruakh :Is \"that count never returns the same value twice\" really considered a class invariant? Mike Samuel : that's a good question. I'm not quite sure. Things like hashCode stability (for each instance i, i.hashCode() does not change) are often called class invariants which requires reasoning about values returned previously, so it seems reasonable to say that \"for each instance i, i.count() not in (previous results of i.count())\" is a class invariant. A Invariant means something that should stick to its conditions no matter whatever changes or whoever uses/transforms it. That is to say, a property of a class always fulfills or satisfies some condition even after going through transformations by using public methods. So, the client or user of this class is ensured about the class and its property. For example, condition on function argument is that, it should always be > 0 (greater than zero) or should not be null. minimum_account_balance property of an account class states, it cannot go below 100. So all public functions should respect this condition and ensure class invariant . rule based dependency between variables, that is, value of one variable depends on another, so if one changes, using some fix-rule, other must also change. This relationship between 2 variables must be preserved. If it does not, then invariant is violated. What is an invariant? The word seems to get used in a number of contexts. The best I can figure is that they mean a variable that can't change. Isn't that what constants/finals (darn you Java!) are for? A An invariant is more \"conceptual\" than a variable. In general, it's a property of the program state that is always true. A function or method that ensures that the invariant holds is said to maintain the invariant. For instance, a binary search tree might have the invariant that for every node, the key of the node's left child is less than the node's own key. A correctly written insertion function for this tree will maintain that invariant. As you can tell, that's not the sort of thing you can store in a variable: it's more a statement about the program. By figuring out what sort of invariants your program should maintain, then reviewing your code to make sure that it actually maintains those invariants, you can avoid logical errors in your code. Class invariant In computer programming , specifically object-oriented programming , a class invariant (or type invariant ) is an invariant used to constrain objects of a class . Methods of the class should preserve the invariant. The class invariant constrains the state stored in the object. Class invariants are established during construction and constantly maintained between calls to public methods. Code within functions may break invariants as long as the invariants are restored before a public function ends. An object invariant , or representation invariant, is a computer programming construct consisting of a set of invariant properties that remain uncompromised(\u4e0d\u59a5\u534f\u7684) regardless of the state of the object . This ensures that the object will always meet predefined conditions, and that methods may, therefore, always reference the object without the risk of making inaccurate presumptions. Defining class invariants can help programmers and testers to catch more bugs during software testing . Class invariants and inheritance The useful effect of class invariants in object-oriented software is enhanced in the presence of inheritance. Class invariants are inherited, that is, \"the invariants of all the parents of a class apply to the class itself.\"[ 1] Inheritance can allow descendant classes to alter implementation data of parent classes, so it would be possible for a descendant class to change the state of instances in a way that made them invalid from the viewpoint of the parent class. The concern for this type of misbehaving descendant is one reason object-oriented software designers give for favoring composition over inheritance (i.e., inheritance breaks encapsulation).[ 2] However, because class invariants are inherited, the class invariant for any particular class consists of any invariant assertions coded immediately on that class, logically \"and-ed\" with all the invariant clauses inherited from the class's parents. This means that even though descendant classes may have access to the implementation data of their parents, the class invariant can prevent them from manipulating those data in any way that produces an invalid instance at runtime. Example Inheritance An example in C++11 follows: class GameObject { public : virtual ~ GameObject () {} virtual void update () {} virtual void draw () {} virtual void collide ( GameObject objects []) {} }; class Visible : public GameObject { public : void draw () override { /* draw model at position of this object */ }; private : Model * model ; }; class Solid : public GameObject { public : void collide ( GameObject objects []) override { /* check and react to collisions with objects */ }; }; class Movable : public GameObject { public : void update () override { /* update position */ }; }; Then, we have concrete classes: class Player - which is Solid , Movable and Visible class Cloud - which is Movable and Visible , but not Solid class Building - which is Solid and Visible , but not Movable class Trap - which is Solid , but neither Visible nor Movable Note that multiple inheritance is dangerous if not implemented carefully, as it can lead to the diamond problem . One solution to avoid this is to create classes such as VisibleAndSolid , VisibleAndMovable , VisibleAndSolidAndMovable , etc. for every needed combination, though this leads to a large amount of repetitive code. Keep in mind that C++ solves the diamond problem of multiple inheritance by allowing virtual inheritance .","title":"Class-invariant"},{"location":"Theory/Invariant/Class-invariant/#what-is-a-class-invariant-in-java","text":"I googled the topic, but besides Wikipedia I didn't find any further useful documentation or articles. Can anybody explain to me in simple words what it means or refer me to some nice and easy to understand documentation? COMMENTS : A more simple explanation - < stackoverflow.com/questions/112064/what-is-an-invariant?rq=1 >","title":"What is a class invariant in java?"},{"location":"Theory/Invariant/Class-invariant/#a","text":"It doesn't mean anything in particular in reference to java. A class invariant is simply a property that holds for all instances of a class, always, no matter what other code does. For example, class X { final Y y = new Y (); } X has the class invariant that there is a y property and it is never null and it has a value of type Y . class Counter { private int x ; public int count () { return x ++; } } fails to maintain two important invariants That count never returns a negative value because of possible underflow. That calls to count are strictly monotonically increasing. The modified class preserves those two invariants. class Counter { private int x ; public synchronized int count () { if ( x == Integer . MAX_VALUE ) { throw new IllegalStateException (); } return x ++; } } but fails to preserve the invariant that calls to count always succeed normally (absent TCB-violations\u2020) because count might throw an exception or it might block if a deadlocked thread owns the counter's monitor. Each language with classes make it easy to maintain some class invariants but not others. Java is no exception: Java classes consistently(\u4e00\u8d2f\u5730) have or do not have properties and methods, so interface invariants are easy to maintain. Java classes can protect their private fields, so invariants that rely on private data are easy to maintain. Java classes can be final, so invariants that rely on there being no code that violates an invariant by crafting a malicious subclass can be maintained. Java allows null values to sneak in in many ways, so it is tough to maintain \"has a real value\" invariants. Java has threads which means that classes that do not synchronize have trouble maintaining invariants that rely on sequential operations in a thread happening together. Java has exceptions which makes it easy to maintain invariants like \"returns a result with property p or returns no result\" but harder to maintain invariants like \"always returns a result\". \u2020 - An externality or TCB violation is an event which a systems designer optimistically assumes will not happen. Typically we just trust that the basic hardware works as advertised when talking about properties of high-level languages built on them, and our arguments that invariants hold don't take into account the possibility of: A programmer using debug hooks to alter local variables as a program runs in ways that code cannot. Your peers don't use reflection with setAccessible to modify private lookup tables. Loki altering physics causing your processor to incorrectly compare two numbers. For some systems our TCB might include only parts of the system, so we might not assume that An administrator or privileged daemon won't kill our JVM process, but we might assume that We can checkpoint to a reliable transactional file-system. The higher-level a system, the larger its TCB typically is, but the more unreliable things you can get out of your TCB, the more likely your invariants are to hold, and the more reliable your system will be in the long run. COMMENTS ruakh :Is \"that count never returns the same value twice\" really considered a class invariant? Mike Samuel : that's a good question. I'm not quite sure. Things like hashCode stability (for each instance i, i.hashCode() does not change) are often called class invariants which requires reasoning about values returned previously, so it seems reasonable to say that \"for each instance i, i.count() not in (previous results of i.count())\" is a class invariant.","title":"A"},{"location":"Theory/Invariant/Class-invariant/#a_1","text":"Invariant means something that should stick to its conditions no matter whatever changes or whoever uses/transforms it. That is to say, a property of a class always fulfills or satisfies some condition even after going through transformations by using public methods. So, the client or user of this class is ensured about the class and its property. For example, condition on function argument is that, it should always be > 0 (greater than zero) or should not be null. minimum_account_balance property of an account class states, it cannot go below 100. So all public functions should respect this condition and ensure class invariant . rule based dependency between variables, that is, value of one variable depends on another, so if one changes, using some fix-rule, other must also change. This relationship between 2 variables must be preserved. If it does not, then invariant is violated.","title":"A"},{"location":"Theory/Invariant/Class-invariant/#what-is-an-invariant","text":"The word seems to get used in a number of contexts. The best I can figure is that they mean a variable that can't change. Isn't that what constants/finals (darn you Java!) are for?","title":"What is an invariant?"},{"location":"Theory/Invariant/Class-invariant/#a_2","text":"An invariant is more \"conceptual\" than a variable. In general, it's a property of the program state that is always true. A function or method that ensures that the invariant holds is said to maintain the invariant. For instance, a binary search tree might have the invariant that for every node, the key of the node's left child is less than the node's own key. A correctly written insertion function for this tree will maintain that invariant. As you can tell, that's not the sort of thing you can store in a variable: it's more a statement about the program. By figuring out what sort of invariants your program should maintain, then reviewing your code to make sure that it actually maintains those invariants, you can avoid logical errors in your code.","title":"A"},{"location":"Theory/Invariant/Class-invariant/#class-invariant","text":"In computer programming , specifically object-oriented programming , a class invariant (or type invariant ) is an invariant used to constrain objects of a class . Methods of the class should preserve the invariant. The class invariant constrains the state stored in the object. Class invariants are established during construction and constantly maintained between calls to public methods. Code within functions may break invariants as long as the invariants are restored before a public function ends. An object invariant , or representation invariant, is a computer programming construct consisting of a set of invariant properties that remain uncompromised(\u4e0d\u59a5\u534f\u7684) regardless of the state of the object . This ensures that the object will always meet predefined conditions, and that methods may, therefore, always reference the object without the risk of making inaccurate presumptions. Defining class invariants can help programmers and testers to catch more bugs during software testing .","title":"Class invariant"},{"location":"Theory/Invariant/Class-invariant/#class-invariants-and-inheritance","text":"The useful effect of class invariants in object-oriented software is enhanced in the presence of inheritance. Class invariants are inherited, that is, \"the invariants of all the parents of a class apply to the class itself.\"[ 1] Inheritance can allow descendant classes to alter implementation data of parent classes, so it would be possible for a descendant class to change the state of instances in a way that made them invalid from the viewpoint of the parent class. The concern for this type of misbehaving descendant is one reason object-oriented software designers give for favoring composition over inheritance (i.e., inheritance breaks encapsulation).[ 2] However, because class invariants are inherited, the class invariant for any particular class consists of any invariant assertions coded immediately on that class, logically \"and-ed\" with all the invariant clauses inherited from the class's parents. This means that even though descendant classes may have access to the implementation data of their parents, the class invariant can prevent them from manipulating those data in any way that produces an invalid instance at runtime.","title":"Class invariants and inheritance"},{"location":"Theory/Invariant/Class-invariant/#example","text":"","title":"Example"},{"location":"Theory/Invariant/Class-invariant/#inheritance","text":"An example in C++11 follows: class GameObject { public : virtual ~ GameObject () {} virtual void update () {} virtual void draw () {} virtual void collide ( GameObject objects []) {} }; class Visible : public GameObject { public : void draw () override { /* draw model at position of this object */ }; private : Model * model ; }; class Solid : public GameObject { public : void collide ( GameObject objects []) override { /* check and react to collisions with objects */ }; }; class Movable : public GameObject { public : void update () override { /* update position */ }; }; Then, we have concrete classes: class Player - which is Solid , Movable and Visible class Cloud - which is Movable and Visible , but not Solid class Building - which is Solid and Visible , but not Movable class Trap - which is Solid , but neither Visible nor Movable Note that multiple inheritance is dangerous if not implemented carefully, as it can lead to the diamond problem . One solution to avoid this is to create classes such as VisibleAndSolid , VisibleAndMovable , VisibleAndSolidAndMovable , etc. for every needed combination, though this leads to a large amount of repetitive code. Keep in mind that C++ solves the diamond problem of multiple inheritance by allowing virtual inheritance .","title":"Inheritance"},{"location":"Theory/Invariant/Invariant/","text":"Invariant Invariant (mathematics) Loop invariant Class invariant","title":"Invariant"},{"location":"Theory/Invariant/Invariant/#invariant","text":"","title":"Invariant"},{"location":"Theory/Invariant/Invariant/#invariant-mathematics","text":"","title":"Invariant (mathematics)"},{"location":"Theory/Invariant/Invariant/#loop-invariant","text":"","title":"Loop invariant"},{"location":"Theory/Invariant/Invariant/#class-invariant","text":"","title":"Class invariant"},{"location":"Theory/Lifetime/Object-lifetime/","text":"Object lifetime \u7ef4\u57fa\u767e\u79d1 Object lifetime","title":"Object-lifetime"},{"location":"Theory/Lifetime/Object-lifetime/#object-lifetime","text":"","title":"Object lifetime"},{"location":"Theory/Lifetime/Object-lifetime/#object-lifetime_1","text":"","title":"\u7ef4\u57fa\u767e\u79d1Object lifetime"},{"location":"Theory/Lifetime/Program-lifecycle/","text":"Program lifecycle \u7ef4\u57fa\u767e\u79d1 Program lifecycle phase","title":"Program-lifecycle"},{"location":"Theory/Lifetime/Program-lifecycle/#program-lifecycle","text":"","title":"Program lifecycle"},{"location":"Theory/Lifetime/Program-lifecycle/#program-lifecycle-phase","text":"","title":"\u7ef4\u57fa\u767e\u79d1Program lifecycle phase"},{"location":"Theory/Name/Name/","text":"name \u5728\u9605\u8bfbcppreference c++\u7684 Basic concepts \u65f6\uff0c\u5176\u4e2d\u63cf\u8ff0\u4e86\u201cname\u201d\u7684\u6982\u5ff5\u3002 \u5728\u9605\u8bfbpython 4. Execution model \u00b6 \u76844.2. Naming and binding \u00b6 \u7ae0\u8282\u7684\u65f6\u5019\uff0c\u5176\u4e2d\u4e5f\u63cf\u8ff0\u4e86\u201cname\u201d\u7684\u6982\u5ff5\u3002 \u4e24\u8005\u6bd4\u8f83\u7c7b\u4f3c\u7684\u662f\uff1a\u5728\u8ba8\u8bba\u201cname\u201d\u7684\u65f6\u5019\uff0c\u90fd\u8ba8\u8bba\u4e86scope\u3002 \u5176\u5b9e\uff0c\u201cname\u201d\u7684\u5b57\u9762\u610f\u601d\u975e\u5e38\u597d\u7406\u89e3\uff0c\u5b83\u8868\u793a\u7684\u662f\u201c\u540d\u79f0\u201d\uff0c\u663e\u7136\u901a\u8fc7name\u6765\u6807\u8bc6\u4e00\u4e2a\u4e8b\u7269\uff1a python\u662f\u4e00\u95e8\u89e3\u91ca\u578b\u8bed\u8a00\uff0cpython\u7684\u8bbe\u8ba1\u8005\uff0c\u63d0\u51fa\u4e86everything in python is an object\uff0c\u901a\u8fc7name\u6765refer to object\u3002 c++\u662f\u4e00\u95e8\u7f16\u8bd1\u578b\u8bed\u8a00\uff0cc++\u7684\u8bbe\u8ba1\u8005\uff0c\u63d0\u51fa\u4e86entity\u7684\u6982\u5ff5\uff0c\u901a\u8fc7name\u6765refer to entity\uff0c\u8fd9\u4e9bentity\u662f\u6709compiler\u6765\u8fdb\u884c\u7ffb\u8bd1\u3001\u8f6c\u6362\u7684\u3002c++\u4e2d\uff0c\u901a\u8fc7declaration\u6765\u5f15\u5165entity\u3002 namespace TODO name lookup name bind","title":"Name"},{"location":"Theory/Name/Name/#name","text":"\u5728\u9605\u8bfbcppreference c++\u7684 Basic concepts \u65f6\uff0c\u5176\u4e2d\u63cf\u8ff0\u4e86\u201cname\u201d\u7684\u6982\u5ff5\u3002 \u5728\u9605\u8bfbpython 4. Execution model \u00b6 \u76844.2. Naming and binding \u00b6 \u7ae0\u8282\u7684\u65f6\u5019\uff0c\u5176\u4e2d\u4e5f\u63cf\u8ff0\u4e86\u201cname\u201d\u7684\u6982\u5ff5\u3002 \u4e24\u8005\u6bd4\u8f83\u7c7b\u4f3c\u7684\u662f\uff1a\u5728\u8ba8\u8bba\u201cname\u201d\u7684\u65f6\u5019\uff0c\u90fd\u8ba8\u8bba\u4e86scope\u3002 \u5176\u5b9e\uff0c\u201cname\u201d\u7684\u5b57\u9762\u610f\u601d\u975e\u5e38\u597d\u7406\u89e3\uff0c\u5b83\u8868\u793a\u7684\u662f\u201c\u540d\u79f0\u201d\uff0c\u663e\u7136\u901a\u8fc7name\u6765\u6807\u8bc6\u4e00\u4e2a\u4e8b\u7269\uff1a python\u662f\u4e00\u95e8\u89e3\u91ca\u578b\u8bed\u8a00\uff0cpython\u7684\u8bbe\u8ba1\u8005\uff0c\u63d0\u51fa\u4e86everything in python is an object\uff0c\u901a\u8fc7name\u6765refer to object\u3002 c++\u662f\u4e00\u95e8\u7f16\u8bd1\u578b\u8bed\u8a00\uff0cc++\u7684\u8bbe\u8ba1\u8005\uff0c\u63d0\u51fa\u4e86entity\u7684\u6982\u5ff5\uff0c\u901a\u8fc7name\u6765refer to entity\uff0c\u8fd9\u4e9bentity\u662f\u6709compiler\u6765\u8fdb\u884c\u7ffb\u8bd1\u3001\u8f6c\u6362\u7684\u3002c++\u4e2d\uff0c\u901a\u8fc7declaration\u6765\u5f15\u5165entity\u3002","title":"name"},{"location":"Theory/Name/Name/#namespace","text":"TODO","title":"namespace"},{"location":"Theory/Name/Name/#name-lookup","text":"","title":"name lookup"},{"location":"Theory/Name/Name/#name-bind","text":"","title":"name bind"},{"location":"Theory/Programming-language/Comparison-of-programming-language/","text":"Comparison of programming language \u6709\u4e86\u4e00\u5b9a\u7684\u7406\u8bba\u57fa\u7840\u540e\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u66f4\u597d\u5730\u6765\u6bd4\u8f83\u5404\u79cdprogramming language\u4e86\u3002 \u4ece\u652f\u6301OO\u7684\u7a0b\u5ea6\u6765\u8fdb\u884c\u6bd4\u8f83 \u53c2\u89c1\u7ef4\u57fa\u767e\u79d1 Object-oriented programming \u7684 OOP languages \u6bb5\u3002 \u4ecetype system\u6765\u8fdb\u884c\u6bd4\u8f83","title":"Comparison-of-programming-language"},{"location":"Theory/Programming-language/Comparison-of-programming-language/#comparison-of-programming-language","text":"\u6709\u4e86\u4e00\u5b9a\u7684\u7406\u8bba\u57fa\u7840\u540e\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u66f4\u597d\u5730\u6765\u6bd4\u8f83\u5404\u79cdprogramming language\u4e86\u3002","title":"Comparison of programming language"},{"location":"Theory/Programming-language/Comparison-of-programming-language/#oo","text":"\u53c2\u89c1\u7ef4\u57fa\u767e\u79d1 Object-oriented programming \u7684 OOP languages \u6bb5\u3002","title":"\u4ece\u652f\u6301OO\u7684\u7a0b\u5ea6\u6765\u8fdb\u884c\u6bd4\u8f83"},{"location":"Theory/Programming-language/Comparison-of-programming-language/#type-system","text":"","title":"\u4ecetype system\u6765\u8fdb\u884c\u6bd4\u8f83"},{"location":"Theory/Programming-language/Expressive-of-programming-language/","text":"Expressive of programming language \u672c\u6587\u4e2d\u7684expressive\u5e76\u4e0d\u662f\u5728\u6587\u7ae0 Language \u4e2d\u7684expressive power\u6982\u5ff5\uff0c\u5b83\u6240\u6307\u7684\u662fprogramming language\u7684\u8868\u73b0\u529b\u3001\u63cf\u8ff0\u80fd\u529b\uff0c\u662f\u5426\u66f4\u52a0\u80fd\u591f\u63cf\u8ff0\u73b0\u5b9e\u751f\u6d3b\u4e2d\u7684\u95ee\u9898\u3002 \u4e0d\u540c\u7684programming language\u7684expressive\u662f\u4e0d\u540c\u7684\uff0c\u76f4\u89c2\u611f\u89c9\u5c31\u662fOOP\u6bd4\u9762\u5411\u8fc7\u7a0b\u8bed\u8a00\u66f4\u52a0expressive\uff0c\u5173\u4e8e\u6b64\uff0c\u53c2\u89c1 Summary of OO \u3002 \u5728\u7ef4\u57fa\u767e\u79d1 Parametric polymorphism \u4e2d\u6709\u8fd9\u6837\u7684\u63cf\u8ff0 In programming languages and type theory , parametric polymorphism is a way to make a language more expressive, while still maintaining full static type-safety . \u672c\u8d28\u4e0a\u6765\u8bf4\uff0c\u6211\u4eec\u4f7f\u7528\u8bed\u8a00\u6765\u8fdb\u884c\u63cf\u8ff0\uff0c\u6211\u4eec\u4e0d\u65ad\u5730\u5f80programming language\u4e2d\u6dfb\u52a0\u5404\u79cdfeature\uff0c\u6216\u8005\u8bf4\u4e0d\u65ad\u5730\u521b\u9020\u65b0\u7684programming language\uff0c\u6700\u7ec8\u76ee\u7684\u90fd\u662f\u8ba9programming language\u66f4\u52a0\u5730expressive\uff0c\u8868\u8fbe\uff08\u63cf\u8ff0\uff09\u8d77\u6765\u66f4\u52a0\u5730convenient\u3002 \u6bd4\u5982\u540c\u6837\u662fevent-driven programming\uff1a flask\u7684\u63cf\u8ff0\u65b9\u5f0f JavaScript\u7684\u63cf\u8ff0\u65b9\u5f0f tornado\u7684\u63cf\u8ff0\u65b9\u5f0f c++\u7684\u63cf\u8ff0\u65b9\u5f0f c\u7684\u63cf\u8ff0\u65b9\u5f0f","title":"Expressive-of-programming-language"},{"location":"Theory/Programming-language/Expressive-of-programming-language/#expressive-of-programming-language","text":"\u672c\u6587\u4e2d\u7684expressive\u5e76\u4e0d\u662f\u5728\u6587\u7ae0 Language \u4e2d\u7684expressive power\u6982\u5ff5\uff0c\u5b83\u6240\u6307\u7684\u662fprogramming language\u7684\u8868\u73b0\u529b\u3001\u63cf\u8ff0\u80fd\u529b\uff0c\u662f\u5426\u66f4\u52a0\u80fd\u591f\u63cf\u8ff0\u73b0\u5b9e\u751f\u6d3b\u4e2d\u7684\u95ee\u9898\u3002 \u4e0d\u540c\u7684programming language\u7684expressive\u662f\u4e0d\u540c\u7684\uff0c\u76f4\u89c2\u611f\u89c9\u5c31\u662fOOP\u6bd4\u9762\u5411\u8fc7\u7a0b\u8bed\u8a00\u66f4\u52a0expressive\uff0c\u5173\u4e8e\u6b64\uff0c\u53c2\u89c1 Summary of OO \u3002 \u5728\u7ef4\u57fa\u767e\u79d1 Parametric polymorphism \u4e2d\u6709\u8fd9\u6837\u7684\u63cf\u8ff0 In programming languages and type theory , parametric polymorphism is a way to make a language more expressive, while still maintaining full static type-safety . \u672c\u8d28\u4e0a\u6765\u8bf4\uff0c\u6211\u4eec\u4f7f\u7528\u8bed\u8a00\u6765\u8fdb\u884c\u63cf\u8ff0\uff0c\u6211\u4eec\u4e0d\u65ad\u5730\u5f80programming language\u4e2d\u6dfb\u52a0\u5404\u79cdfeature\uff0c\u6216\u8005\u8bf4\u4e0d\u65ad\u5730\u521b\u9020\u65b0\u7684programming language\uff0c\u6700\u7ec8\u76ee\u7684\u90fd\u662f\u8ba9programming language\u66f4\u52a0\u5730expressive\uff0c\u8868\u8fbe\uff08\u63cf\u8ff0\uff09\u8d77\u6765\u66f4\u52a0\u5730convenient\u3002 \u6bd4\u5982\u540c\u6837\u662fevent-driven programming\uff1a flask\u7684\u63cf\u8ff0\u65b9\u5f0f JavaScript\u7684\u63cf\u8ff0\u65b9\u5f0f tornado\u7684\u63cf\u8ff0\u65b9\u5f0f c++\u7684\u63cf\u8ff0\u65b9\u5f0f c\u7684\u63cf\u8ff0\u65b9\u5f0f","title":"Expressive of programming language"},{"location":"Theory/Programming-language/Programming-language/","text":"Programming language \u6211\u7684\u5de5\u7a0b\u4e2d\uff0c\u4e0eprogramming language\u76f8\u5173\u7684\u6709\uff1a \u5de5\u7a0b compiler-principle \u5de5\u7a0b automata-and-formal-language \u6587\u7ae0 Abstraction \u7684 Abstraction in programming language \u5c0f\u8282 \u7ef4\u57fa\u767e\u79d1 Programming language","title":"Programming-language"},{"location":"Theory/Programming-language/Programming-language/#programming-language","text":"\u6211\u7684\u5de5\u7a0b\u4e2d\uff0c\u4e0eprogramming language\u76f8\u5173\u7684\u6709\uff1a \u5de5\u7a0b compiler-principle \u5de5\u7a0b automata-and-formal-language \u6587\u7ae0 Abstraction \u7684 Abstraction in programming language \u5c0f\u8282","title":"Programming language"},{"location":"Theory/Programming-language/Programming-language/#programming-language_1","text":"","title":"\u7ef4\u57fa\u767e\u79d1Programming language"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/","text":"How to master programming language \u4f60\u662f\u5426\u601d\u8003\u8fc7\uff1ahow many programming languages are there\uff1fGoogle\u4e86\u4e00\u4e0b\uff0c\u7b2c\u4e00\u4e2a\u56de\u7b54\u662f there are about 700 programming languages \uff0c\u5982\u6b64 \u4e4b\u591a\u3002\u7ef4\u57fa\u767e\u79d1\u7684 List of programming languages \u4e2d\uff0c\u6536\u5f55\u4e86\u5927\u90e8\u5206programming language\uff0c\u4ece Timeline of programming languages \u4e2d\uff0c\u6211\u4eec\u5927\u81f4\u53ef\u4ee5\u770b\u5230 programming language\u7684\u53d8\u8fc1\u4e0e\u53d1\u5c55\u3002\u9762\u5bf9\u5982\u6b64\u4e4b\u591a\u3001\u4e0d\u65ad\u53d1\u5c55\u3001\u5c42\u51fa\u4e0d\u7a77\u7684programming language\uff0c\u6211\u4e0d\u7981\u601d\u8003\uff1ahow to master programming language\uff1f\u672c\u6587\u5c31\u5bf9\u8fd9\u4e2a\u95ee\u9898\u6765\u8fdb\u884c\u63a2\u8ba8\u3002 \u4ece\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u7684\u89d2\u5ea6\u51fa\u53d1\u6765\u5b66\u4e60\u4e00\u95e8\u8bed\u8a00 \u8ba9\u6211\u4ea7\u751f\u8fd9\u79cd\u60f3\u6cd5\u7684\u662f\u5728\u5bf9c\u548c c++ \u4e2d\u90fd\u6709\u7684 Storage duration\u548cLinkage \u6982\u5ff5\u7684\u601d\u8003\uff1a \u5728c\u548c c++ \u4e2d\u90fd\u6709 Storage duration\u548cLinkage \u7684\u6982\u5ff5\uff0c\u5728\u5bf9\u8fd9\u4e24\u4e2a\u6982\u5ff5\u7684\u7406\u89e3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u53d1\u73b0\u8fd9\u4e24\u4e2a\u6982\u5ff5\u662f\u548cprogram\u7684\u7f16\u8bd1\u3001\u8fd0\u884c\u6709\u7740\u975e\u5e38\u5bc6\u5207\u7684\u5173\u8054\uff1b\u540e\u6765\u60f3\u60f3\uff0c\u8fd9\u5176\u5b9e\u662f\u5fc5\u7136\u7684\uff0cc++\u548cc\u662fsystem language\uff0c\u5b83\u662f\u5141\u8bb8programmer\u64cd\u4f5cmemory\u7684\uff0c\u5982\u679c\u6211\u4eec\u7ad9\u5728c\u548cc++\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u7684\u89d2\u5ea6\u6765\u601d\u8003\uff0c\u4ed6\u4eec\u5728\u8bbe\u8ba1\u8fd9\u4e24\u95e8\u8bed\u8a00\u7684\u65f6\u5019\uff0c\u80af\u5b9a\u4e5f\u9700\u8981\u8003\u8651\u7a0b\u5e8f\u5728\u7f16\u8bd1\u8fc7\u7a0b\u3001\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u6d89\u53ca\u5230\u7684\u4e00\u4e9b\u7ec6\u8282\uff0c\u6240\u4ee5\u8fd9\u95e8\u8bed\u8a00\u9700\u8981\u63d0\u4f9b\u5404\u79cd\u5404\u6837\u7684specifier\u6765\u4f9bprogrammer\u5bf9\u8fd9\u4e24\u4e2a\u8fc7\u7a0b\u8fdb\u884c\u63a7\u5236\uff08\u6216\u8005\u8bf4\u5bf9\u8fd9\u4e24\u4e2a\u8fc7\u7a0b\u8fdb\u884c\u63cf\u8ff0\uff09\uff1b \u4ece\u6839\u672c\u4e0a\u6765\u8bf4\uff0c\u6211\u4eec\u4f7f\u7528programming language\u6765\u63cf\u8ff0\u8ba1\u7b97\uff08\u5728\u6587\u7ae0 Language \u4e2d\u6709\u5bf9\u6b64\u7684\u5206\u6790\uff09\uff0c\u8d8a\u662f\u5e95\u5c42\u7684\u8bed\u8a00\uff0c\u9700\u8981\u8003\u8651\u7684\u8ba1\u7b97\u7ec6\u8282\u8d8a\u591a\uff0c\u6240\u4ee5\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u9700\u8981\u63d0\u4f9bspecifier\u6765\u5bf9\u8fd9\u4e9b\u5185\u5bb9\u8fdb\u884c\u63cf\u8ff0\uff0c\u8fdb\u884c\u63a7\u5236\u3002 \u5982\u4f55\u8bbe\u8ba1\u4e00\u95e8programming language\uff1f\u6216\u8005\u8bf4\uff1a\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u5728\u8bbe\u8ba1\u8fd9\u4e00\u95e8\u8bed\u8a00\u7684\u65f6\u5019\uff0c\u9700\u8981\u8003\u8651\u5230\u54ea\u4e9b\u95ee\u9898\uff1f\u8fd9\u4e2a\u95ee\u9898\u6211\u65e0\u6cd5\u7ed9\u51fa\u51c6\u786e\u7684\u7b54\u6848\uff0c\u53ea\u80fd\u591f\u7ed9\u51fa\u57fa\u4e8e\u4f7f\u7528python\u3001c++\u548cc\u7684\u7ecf\u9a8c\u7ed9\u51fa\u4e00\u4e9b\u7ecf\u9a8c\u4e4b\u8c08\uff0c\u5f53\u6211\u4eec\u9605\u8bfb\u8fd9\u4e9b\u8bed\u8a00\u7684official doc\u7684\u65f6\u5019\uff0c\u4f1a\u53d1\u73b0programming language\u4e3b\u8981\u6d89\u53ca\u4e24\u5927\u5757\uff1alanguage reference\u548cstandard library\uff0c\u5176\u5b9e\uff0c\u8fd9\u4e9b\u5c31\u662f\u8fd9\u95e8\u8bed\u8a00\u7684standard\uff0c\u4e0b\u9762\u4ee5\u6b64\u4e3a\u4e3b\u8981\u7ebf\u7d22\u6765\u8fdb\u884c\u8be6\u7ec6\u8bf4\u660e\u3002 Language reference \uff08\u57fa\u672c\u4e0a\uff09\u6bcf\u79cdprogramming language\u90fd\u4f1a\u6709\u5b83\u7684Language reference\uff0cprogramming language\u867d\u7136\u591a\uff0c\u4f46\u662f\u5176\u5b9e\u5b83\u4eec\u7684Language reference\u4f1a\u6d89\u53ca\u5f88\u591a\u76f8\u540c\u7684\u4e3b\u9898\uff0c\u6240\u4ee5\u5982\u679c\u6211\u4eec\u5bf9\u8fd9\u4e9bcommon\u4e3b\u9898\u6709\u4e00\u5b9a\u7684\u4e86\u89e3\uff0c\u90a3\u4e48\u638c\u63e1\u4e00\u95e8programming language\u4f1a\u53d8\u5f97\u76f8\u5bf9\u5bb9\u6613\u3002 Syntax programming language\u5c5e\u4e8e formal language \uff0c\u6240\u4ee5\u90fd\u4f1a\u5b9a\u4e49\u4e25\u683c\u7684syntax\uff0c\u201csyntax\"\u5373\u8bed\u6cd5\u3002\u6b63\u5982\u7ef4\u57fa\u767e\u79d1 Syntax (programming languages) \u7684 Levels of syntax \u6bb5\u6240\u603b\u7ed3\u7684\uff1a Computer language syntax is generally distinguished into three levels: Words \u2013 the lexical level, determining how characters form tokens; Phrases \u2013 the grammar level, narrowly speaking, determining how tokens form phrases; Context \u2013 determining what objects or variables names refer to, if types are valid, etc. \u4e0a\u8ff0\u201cWords\u201d\u5373\u8bcd\u6cd5\uff0c\u201cPhrases\u201d\u5373\u8bed\u6cd5\uff0c\u5173\u4e8esyntax\uff0c\u53ef\u4ee5\u53c2\u8003\u5de5\u7a0b compiler-principle \u3002 expression\u3001statement\u7b49\u90fd\u662f\u5c5e\u4e8e\u6b64\u8303\u8f74\u3002 Semantics \u53c2\u89c1\u7ef4\u57fa\u767e\u79d1 Semantics (computer science) \u3002 Type system \u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\uff0c\u9700\u8981\u8003\u8651\u8fd9\u95e8\u8bed\u8a00\u7684type system\uff0c\u53c2\u89c1 Type system \u3002 \u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u8fd8\u4f1a\u5411\u5f00\u53d1\u8005\u63d0\u4f9b\u5bf9type system\u8fdb\u884c\u64cd\u4f5c\u7684\u63a5\u53e3\uff0c\u6bd4\u5982c++\u63d0\u4f9b\u4e86 typeid \uff0c dynamic_cast \uff0cpython\u63d0\u4f9b\u4e86 isinstance \uff0cJava\u63d0\u4f9b\u4e86 isinstanceof \u3002 Runtime model \u524d\u9762\u90fd\u662flanguage\u7684\u9759\u6001\u65f6\uff0c\u8fd8\u9700\u8981\u5bf9run time\u8fdb\u884c\u8bf4\u660e\uff0c\u6bd4\u5982data model\u3001\u7a0b\u5e8f\u7684\u8fd0\u884c\u6a21\u578b\u7b49\u3002 Data model \u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u9700\u8981\u4e3a \u8fd9\u95e8\u8bed\u8a00\u5b9a\u4e49\u7edf\u4e00\u7684data model\uff0c\u6bd4\u5982The Python Language Reference \u00b6 \u4e2d\u5c31\u6709\u4e13\u95e8\u63cf\u8ff0Data model \u00b6 \u7684 \u7ae0\u8282\uff0c\u4e0e\u6b64\u7c7b\u4f3c\u7684\u662f\uff0c\u5728cppreference\u7684 Object \u4e2d\uff0c\u5bf9c++\u8bed\u8a00\u7684data model\u8fdb\u884c\u4e86\u603b\u7ed3\u3002 Run model \u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u4f1a\u5047\u5b9a\u8be5\u4f7f\u7528\u8be5\u8bed\u8a00\u6240\u7f16\u5199\u7684\u7a0b\u5e8f\u8fd0\u884c\u4e0e\u4e00\u4e2aabstract machine\u4e0a\u4ee5\u4fbf\u5bf9run model\u8fdb\u884c\u63cf\u8ff0\uff0c\u6bd4\u5982\u5728cppreference\u7684 Memory model \u4e2d\u6709\u8fd9\u6837\u7684\u63cf\u8ff0\uff1a Defines the semantics of computer memory storage for the purpose of the C++ abstract machine. \u5728The Python Language Reference \u00b6 \u7684Execution model \u00b6 \u4e2d\u5bf9python\u7a0b\u5e8f\u7684run model\u8fdb\u884c\u4e86\u63cf\u8ff0\u3002 \u9700\u8981\u5bf9\u7a0b\u5e8f\u7684run model\u8fdb\u884c\u5206\u6790\u3002 Abstract machines Stack machine Library \u5404\u79cdprogramming language\u90fd\u63d0\u4f9b\u4e86\u5927\u91cf\u7684library\uff0c\u6240\u4ee5\u5728\u5b66\u4e60\u4e00\u95e8programming language\u7684\u65f6\u5019\uff0c\u5c24\u5176\u9700\u8981\u6ce8\u610f\u5176standard library\u3002 \u4e00\u822cstandard library\u90fd\u4f1a\u6d89\u53ca\u5230\u5982\u4e0b\u5185\u5bb9\uff1a Container container\u6307\u5404\u79cd\u5e38\u89c1\u7684\u6570\u636e\u7ed3\u6784\uff0c\u4e00\u822cprogramming language\u7684standard library\u90fd\u4f1a\u5305\u542b\u8fd9\u90e8\u5206\u5185\u5bb9\u3002 Language support library \u8fd9\u662f\u6211\u5728\u9605\u8bfb cppreference \u7684\u65f6\u5019\u53d1\u73b0\u7684\u4e00\u4e2a\u6982\u5ff5\uff0c\u5176\u4e2d\u7ed9\u51fa\u7684 Language support library \u89e3\u91ca\u5982\u4e0b\uff1a Language support libraries provide classes and functions that interact closely with language features and support common language idioms. \u4f9d\u636e\u6b64\uff0cpython\u6807\u51c6\u5e93\u4e2d\u7684\u5f88\u591alibrary\u90fd\u53ef\u4ee5\u5f52\u5165\u6b64\u8303\u8f74\uff1a Python Language Services Python Runtime Services built-in Run time info \u6bd4\u5982python\u7684\u6807\u51c6\u5e93\u63d0\u4f9b\u4e86Python Runtime Services \u00b6 \u6765\u4f9b\u7528\u6237\u8fdb\u884crun time\u3002 Declaration and definition \u5728\u6587\u7ae0 language \u4e2d\uff0c\u6211\u4eec\u5df2\u7ecf\u603b\u7ed3\u4e86\uff0c\u6211\u4eec\u4f5c\u4e3aprogrammer\u5728\u4f7f\u7528programming language\u6765\u201c\u63cf\u8ff0\u201d\u4e16\u754c\uff0c\u8fd9\u91cc\u7684\u63cf\u8ff0\uff0c\u4f7f\u7528\u66f4\u52a0\u4e13\u4e1a\u7684\u5c5e\u4e8e\u662fdeclaration \u548c definition\uff0c\u5927\u591a\u6570programming language\u90fd\u4f1a\u6d89\u53ca\u5230definition\u7684\u6982\u5ff5\uff0c\u50cfc\u548cc++\u8fd9\u6837\u7684\u8bed\u8a00\uff0c\u533a\u5206declaration\u548cdefinition\uff0c\u800c\u50cfpython\u548cc++\u8fd9\u6837\u7684\u8bed\u8a00\uff0c\u5219\u4e0d\u533a\u5206\uff0c\u662f\u5426\u533a\u5206\uff0c\u6709\u5229\u6709\u5f0a\uff0c\u540e\u9762\u6211\u4eec\u4f1a\u8fdb\u884c\u5206\u6790\u3002 Language construct \u5173\u4e8eLanguage construct\u7684\u6982\u5ff5\uff0c\u53ef\u4ee5\u53c2\u8003\u7ef4\u57fa\u767e\u79d1 Language construct \uff0c\u57fa\u672c\u4e0a\u5927\u591a\u6570programming language\u90fd\u4f1a\u6d89\u53ca\u5230\u5982\u4e0bconstruct\uff1a expression statement function class Philosophy programming language\u7684\u8bbe\u8ba1\u8005\u5f80\u5f80\u662f\u9075\u5faa\u7740\u4e00\u5b9a\u7684philosophy\u6765\u8bbe\u8ba1\u8fd9\u95e8\u8bed\u8a00\u7684\uff0c\u4f5c\u4e3a\u4f7f\u7528\u8005\uff0c\u4e86\u89e3\u8fd9\u95e8\u8bed\u8a00\u7684philosophy\uff0c\u4e5f\u6709\u52a9\u4e8e\u6211\u4eec\u5bf9\u5b83\u7684\u638c\u63e1\u3002 Programming paradigm \u6709\u5f88\u591a\u8bed\u8a00\u90fd\u53f7\u79f0\u662f\u652f\u6301\u201cmultiple programming paradigm \u201d\uff0c\u6211\u4eec\u6709\u5fc5\u8981\u4e86\u89e3programming paradigm\u7684\u77e5\u8bc6\uff0c\u53c2\u89c1 Programming paradigm \u3002 Programming language implementation \u5728programming language\u4e2d\uff0c\u4e5f\u6d89\u53ca\u6807\u51c6\u4e0e\u5b9e\u73b0\u7684\u95ee\u9898\uff0c\u4e00\u79cd\u8bed\u8a00\u6807\u51c6\uff0c\u53ef\u80fd\u6709\u591a\u79cd\u5b9e\u73b0\u3002 Compiler and interpreter \u76ee\u524d\u4e3b\u6d41\u7684programming language\u90fd\u4f1a\u6d89\u53cacompile\u8fc7\u7a0b\uff0c\u6240\u4ee5\u5b83\u4eec\u7684\u5b9e\u73b0\u90fd\u4f1a\u6d89\u53cacompiler\uff0c\u4e00\u4e9b\u8bed\u8a00\uff08\u5982python\u3001java\uff09\u8fd0\u884c\u4e8einterpreter\uff0c\u5173\u4e8ecompiler\u548c interpreter\uff0c\u53ef\u4ee5\u53c2\u89c1\u5de5\u7a0b compiler-principle \u3002 Compile-time and run time \u5728\u5b66\u4e60\u4e00\u95e8\u8bed\u8a00\u7684\u65f6\u5019\uff0c\u4ececompile time\u548crun time\u6765\u5206\u6790\u5404\u79cd\u6982\u5ff5\u662f\u975e\u5e38\u91cd\u8981\u7684\u3002 Common in development \u4e0b\u9762\u7f57\u5217\u4e86\u5728\u8fdb\u884cdevelopment\u4e2d\u4f1a\u6d89\u53ca\u5230\u7684\u4e00\u7cfb\u5217\u95ee\u9898\uff1a Design pattern design pattern\u662f\u524d\u4eba\u6240\u603b\u7ed3\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u4e0d\u7ba1\u662f\u54ea\u79cdprogramming language\uff0c\u90fd\u53ef\u4ee5\u8fd0\u7528\u5b83\uff0c\u5173\u4e8edesign pattern\uff0c\u53c2\u89c1 Design-pattern \u3002 Resource-management \u4e0d\u7ba1\u4f7f\u7528\u54ea\u79cdprogramming language\uff0c\u90fd\u4f1a\u6d89\u53ca\u90fdresource management\u7684\u95ee\u9898\uff0c\u53c2\u89c1 Resource-management \u3002 \u6ce8\u91ca \u5982\u4f55\u8fdb\u884c\u6ce8\u91ca\uff1f\u5982\u4f55\u751f\u6210document\uff1f\u5404\u79cdprogramming language\u5728\u8fd9\u65b9\u9762\u90fd\u505a\u4e86\u5404\u81ea\u7684\u52aa\u529b\uff0c\u4e5f\u6709\u5404\u81ea\u7684\u5b9e\u73b0\uff0c\u540e\u9762\u5728\u8ba8\u8bba\u5177\u4f53\u7684programming language\u7684\u65f6\u5019\u518d\u8fdb\u884c\u8bf4\u660e\u3002 \u6d4b\u8bd5 \u5982\u4f55\u8fdb\u884c\u6d4b\u8bd5\uff1f \u4ee3\u7801\u8986\u76d6\u7387 \u5982\u4f55\u7edf\u8ba1\u4ee3\u7801\u8986\u76d6\u7387\uff1f Profile \u5982\u4f55\u8fdb\u884cprofile\uff1f Linter \u5982\u4f55\u8fdb\u884clint\uff1f","title":"How-to-master-programming-language"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#how-to-master-programming-language","text":"\u4f60\u662f\u5426\u601d\u8003\u8fc7\uff1ahow many programming languages are there\uff1fGoogle\u4e86\u4e00\u4e0b\uff0c\u7b2c\u4e00\u4e2a\u56de\u7b54\u662f there are about 700 programming languages \uff0c\u5982\u6b64 \u4e4b\u591a\u3002\u7ef4\u57fa\u767e\u79d1\u7684 List of programming languages \u4e2d\uff0c\u6536\u5f55\u4e86\u5927\u90e8\u5206programming language\uff0c\u4ece Timeline of programming languages \u4e2d\uff0c\u6211\u4eec\u5927\u81f4\u53ef\u4ee5\u770b\u5230 programming language\u7684\u53d8\u8fc1\u4e0e\u53d1\u5c55\u3002\u9762\u5bf9\u5982\u6b64\u4e4b\u591a\u3001\u4e0d\u65ad\u53d1\u5c55\u3001\u5c42\u51fa\u4e0d\u7a77\u7684programming language\uff0c\u6211\u4e0d\u7981\u601d\u8003\uff1ahow to master programming language\uff1f\u672c\u6587\u5c31\u5bf9\u8fd9\u4e2a\u95ee\u9898\u6765\u8fdb\u884c\u63a2\u8ba8\u3002","title":"How to master programming language"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#_1","text":"\u8ba9\u6211\u4ea7\u751f\u8fd9\u79cd\u60f3\u6cd5\u7684\u662f\u5728\u5bf9c\u548c c++ \u4e2d\u90fd\u6709\u7684 Storage duration\u548cLinkage \u6982\u5ff5\u7684\u601d\u8003\uff1a \u5728c\u548c c++ \u4e2d\u90fd\u6709 Storage duration\u548cLinkage \u7684\u6982\u5ff5\uff0c\u5728\u5bf9\u8fd9\u4e24\u4e2a\u6982\u5ff5\u7684\u7406\u89e3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u53d1\u73b0\u8fd9\u4e24\u4e2a\u6982\u5ff5\u662f\u548cprogram\u7684\u7f16\u8bd1\u3001\u8fd0\u884c\u6709\u7740\u975e\u5e38\u5bc6\u5207\u7684\u5173\u8054\uff1b\u540e\u6765\u60f3\u60f3\uff0c\u8fd9\u5176\u5b9e\u662f\u5fc5\u7136\u7684\uff0cc++\u548cc\u662fsystem language\uff0c\u5b83\u662f\u5141\u8bb8programmer\u64cd\u4f5cmemory\u7684\uff0c\u5982\u679c\u6211\u4eec\u7ad9\u5728c\u548cc++\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u7684\u89d2\u5ea6\u6765\u601d\u8003\uff0c\u4ed6\u4eec\u5728\u8bbe\u8ba1\u8fd9\u4e24\u95e8\u8bed\u8a00\u7684\u65f6\u5019\uff0c\u80af\u5b9a\u4e5f\u9700\u8981\u8003\u8651\u7a0b\u5e8f\u5728\u7f16\u8bd1\u8fc7\u7a0b\u3001\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u6d89\u53ca\u5230\u7684\u4e00\u4e9b\u7ec6\u8282\uff0c\u6240\u4ee5\u8fd9\u95e8\u8bed\u8a00\u9700\u8981\u63d0\u4f9b\u5404\u79cd\u5404\u6837\u7684specifier\u6765\u4f9bprogrammer\u5bf9\u8fd9\u4e24\u4e2a\u8fc7\u7a0b\u8fdb\u884c\u63a7\u5236\uff08\u6216\u8005\u8bf4\u5bf9\u8fd9\u4e24\u4e2a\u8fc7\u7a0b\u8fdb\u884c\u63cf\u8ff0\uff09\uff1b \u4ece\u6839\u672c\u4e0a\u6765\u8bf4\uff0c\u6211\u4eec\u4f7f\u7528programming language\u6765\u63cf\u8ff0\u8ba1\u7b97\uff08\u5728\u6587\u7ae0 Language \u4e2d\u6709\u5bf9\u6b64\u7684\u5206\u6790\uff09\uff0c\u8d8a\u662f\u5e95\u5c42\u7684\u8bed\u8a00\uff0c\u9700\u8981\u8003\u8651\u7684\u8ba1\u7b97\u7ec6\u8282\u8d8a\u591a\uff0c\u6240\u4ee5\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u9700\u8981\u63d0\u4f9bspecifier\u6765\u5bf9\u8fd9\u4e9b\u5185\u5bb9\u8fdb\u884c\u63cf\u8ff0\uff0c\u8fdb\u884c\u63a7\u5236\u3002 \u5982\u4f55\u8bbe\u8ba1\u4e00\u95e8programming language\uff1f\u6216\u8005\u8bf4\uff1a\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u5728\u8bbe\u8ba1\u8fd9\u4e00\u95e8\u8bed\u8a00\u7684\u65f6\u5019\uff0c\u9700\u8981\u8003\u8651\u5230\u54ea\u4e9b\u95ee\u9898\uff1f\u8fd9\u4e2a\u95ee\u9898\u6211\u65e0\u6cd5\u7ed9\u51fa\u51c6\u786e\u7684\u7b54\u6848\uff0c\u53ea\u80fd\u591f\u7ed9\u51fa\u57fa\u4e8e\u4f7f\u7528python\u3001c++\u548cc\u7684\u7ecf\u9a8c\u7ed9\u51fa\u4e00\u4e9b\u7ecf\u9a8c\u4e4b\u8c08\uff0c\u5f53\u6211\u4eec\u9605\u8bfb\u8fd9\u4e9b\u8bed\u8a00\u7684official doc\u7684\u65f6\u5019\uff0c\u4f1a\u53d1\u73b0programming language\u4e3b\u8981\u6d89\u53ca\u4e24\u5927\u5757\uff1alanguage reference\u548cstandard library\uff0c\u5176\u5b9e\uff0c\u8fd9\u4e9b\u5c31\u662f\u8fd9\u95e8\u8bed\u8a00\u7684standard\uff0c\u4e0b\u9762\u4ee5\u6b64\u4e3a\u4e3b\u8981\u7ebf\u7d22\u6765\u8fdb\u884c\u8be6\u7ec6\u8bf4\u660e\u3002","title":"\u4ece\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u7684\u89d2\u5ea6\u51fa\u53d1\u6765\u5b66\u4e60\u4e00\u95e8\u8bed\u8a00"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#language-reference","text":"\uff08\u57fa\u672c\u4e0a\uff09\u6bcf\u79cdprogramming language\u90fd\u4f1a\u6709\u5b83\u7684Language reference\uff0cprogramming language\u867d\u7136\u591a\uff0c\u4f46\u662f\u5176\u5b9e\u5b83\u4eec\u7684Language reference\u4f1a\u6d89\u53ca\u5f88\u591a\u76f8\u540c\u7684\u4e3b\u9898\uff0c\u6240\u4ee5\u5982\u679c\u6211\u4eec\u5bf9\u8fd9\u4e9bcommon\u4e3b\u9898\u6709\u4e00\u5b9a\u7684\u4e86\u89e3\uff0c\u90a3\u4e48\u638c\u63e1\u4e00\u95e8programming language\u4f1a\u53d8\u5f97\u76f8\u5bf9\u5bb9\u6613\u3002","title":"Language reference"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#syntax","text":"programming language\u5c5e\u4e8e formal language \uff0c\u6240\u4ee5\u90fd\u4f1a\u5b9a\u4e49\u4e25\u683c\u7684syntax\uff0c\u201csyntax\"\u5373\u8bed\u6cd5\u3002\u6b63\u5982\u7ef4\u57fa\u767e\u79d1 Syntax (programming languages) \u7684 Levels of syntax \u6bb5\u6240\u603b\u7ed3\u7684\uff1a Computer language syntax is generally distinguished into three levels: Words \u2013 the lexical level, determining how characters form tokens; Phrases \u2013 the grammar level, narrowly speaking, determining how tokens form phrases; Context \u2013 determining what objects or variables names refer to, if types are valid, etc. \u4e0a\u8ff0\u201cWords\u201d\u5373\u8bcd\u6cd5\uff0c\u201cPhrases\u201d\u5373\u8bed\u6cd5\uff0c\u5173\u4e8esyntax\uff0c\u53ef\u4ee5\u53c2\u8003\u5de5\u7a0b compiler-principle \u3002 expression\u3001statement\u7b49\u90fd\u662f\u5c5e\u4e8e\u6b64\u8303\u8f74\u3002","title":"Syntax"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#semantics","text":"\u53c2\u89c1\u7ef4\u57fa\u767e\u79d1 Semantics (computer science) \u3002","title":"Semantics"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#type-system","text":"\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\uff0c\u9700\u8981\u8003\u8651\u8fd9\u95e8\u8bed\u8a00\u7684type system\uff0c\u53c2\u89c1 Type system \u3002 \u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u8fd8\u4f1a\u5411\u5f00\u53d1\u8005\u63d0\u4f9b\u5bf9type system\u8fdb\u884c\u64cd\u4f5c\u7684\u63a5\u53e3\uff0c\u6bd4\u5982c++\u63d0\u4f9b\u4e86 typeid \uff0c dynamic_cast \uff0cpython\u63d0\u4f9b\u4e86 isinstance \uff0cJava\u63d0\u4f9b\u4e86 isinstanceof \u3002","title":"Type system"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#runtime-model","text":"\u524d\u9762\u90fd\u662flanguage\u7684\u9759\u6001\u65f6\uff0c\u8fd8\u9700\u8981\u5bf9run time\u8fdb\u884c\u8bf4\u660e\uff0c\u6bd4\u5982data model\u3001\u7a0b\u5e8f\u7684\u8fd0\u884c\u6a21\u578b\u7b49\u3002","title":"Runtime model"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#data-model","text":"\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u9700\u8981\u4e3a \u8fd9\u95e8\u8bed\u8a00\u5b9a\u4e49\u7edf\u4e00\u7684data model\uff0c\u6bd4\u5982The Python Language Reference \u00b6 \u4e2d\u5c31\u6709\u4e13\u95e8\u63cf\u8ff0Data model \u00b6 \u7684 \u7ae0\u8282\uff0c\u4e0e\u6b64\u7c7b\u4f3c\u7684\u662f\uff0c\u5728cppreference\u7684 Object \u4e2d\uff0c\u5bf9c++\u8bed\u8a00\u7684data model\u8fdb\u884c\u4e86\u603b\u7ed3\u3002","title":"Data model"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#run-model","text":"\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u4f1a\u5047\u5b9a\u8be5\u4f7f\u7528\u8be5\u8bed\u8a00\u6240\u7f16\u5199\u7684\u7a0b\u5e8f\u8fd0\u884c\u4e0e\u4e00\u4e2aabstract machine\u4e0a\u4ee5\u4fbf\u5bf9run model\u8fdb\u884c\u63cf\u8ff0\uff0c\u6bd4\u5982\u5728cppreference\u7684 Memory model \u4e2d\u6709\u8fd9\u6837\u7684\u63cf\u8ff0\uff1a Defines the semantics of computer memory storage for the purpose of the C++ abstract machine. \u5728The Python Language Reference \u00b6 \u7684Execution model \u00b6 \u4e2d\u5bf9python\u7a0b\u5e8f\u7684run model\u8fdb\u884c\u4e86\u63cf\u8ff0\u3002 \u9700\u8981\u5bf9\u7a0b\u5e8f\u7684run model\u8fdb\u884c\u5206\u6790\u3002","title":"Run model"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#abstract-machines","text":"Stack machine","title":"Abstract machines"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#library","text":"\u5404\u79cdprogramming language\u90fd\u63d0\u4f9b\u4e86\u5927\u91cf\u7684library\uff0c\u6240\u4ee5\u5728\u5b66\u4e60\u4e00\u95e8programming language\u7684\u65f6\u5019\uff0c\u5c24\u5176\u9700\u8981\u6ce8\u610f\u5176standard library\u3002 \u4e00\u822cstandard library\u90fd\u4f1a\u6d89\u53ca\u5230\u5982\u4e0b\u5185\u5bb9\uff1a","title":"Library"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#container","text":"container\u6307\u5404\u79cd\u5e38\u89c1\u7684\u6570\u636e\u7ed3\u6784\uff0c\u4e00\u822cprogramming language\u7684standard library\u90fd\u4f1a\u5305\u542b\u8fd9\u90e8\u5206\u5185\u5bb9\u3002","title":"Container"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#language-support-library","text":"\u8fd9\u662f\u6211\u5728\u9605\u8bfb cppreference \u7684\u65f6\u5019\u53d1\u73b0\u7684\u4e00\u4e2a\u6982\u5ff5\uff0c\u5176\u4e2d\u7ed9\u51fa\u7684 Language support library \u89e3\u91ca\u5982\u4e0b\uff1a Language support libraries provide classes and functions that interact closely with language features and support common language idioms. \u4f9d\u636e\u6b64\uff0cpython\u6807\u51c6\u5e93\u4e2d\u7684\u5f88\u591alibrary\u90fd\u53ef\u4ee5\u5f52\u5165\u6b64\u8303\u8f74\uff1a Python Language Services Python Runtime Services built-in","title":"Language support library"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#run-time-info","text":"\u6bd4\u5982python\u7684\u6807\u51c6\u5e93\u63d0\u4f9b\u4e86Python Runtime Services \u00b6 \u6765\u4f9b\u7528\u6237\u8fdb\u884crun time\u3002","title":"Run time info"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#declaration-and-definition","text":"\u5728\u6587\u7ae0 language \u4e2d\uff0c\u6211\u4eec\u5df2\u7ecf\u603b\u7ed3\u4e86\uff0c\u6211\u4eec\u4f5c\u4e3aprogrammer\u5728\u4f7f\u7528programming language\u6765\u201c\u63cf\u8ff0\u201d\u4e16\u754c\uff0c\u8fd9\u91cc\u7684\u63cf\u8ff0\uff0c\u4f7f\u7528\u66f4\u52a0\u4e13\u4e1a\u7684\u5c5e\u4e8e\u662fdeclaration \u548c definition\uff0c\u5927\u591a\u6570programming language\u90fd\u4f1a\u6d89\u53ca\u5230definition\u7684\u6982\u5ff5\uff0c\u50cfc\u548cc++\u8fd9\u6837\u7684\u8bed\u8a00\uff0c\u533a\u5206declaration\u548cdefinition\uff0c\u800c\u50cfpython\u548cc++\u8fd9\u6837\u7684\u8bed\u8a00\uff0c\u5219\u4e0d\u533a\u5206\uff0c\u662f\u5426\u533a\u5206\uff0c\u6709\u5229\u6709\u5f0a\uff0c\u540e\u9762\u6211\u4eec\u4f1a\u8fdb\u884c\u5206\u6790\u3002","title":"Declaration and definition"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#language-construct","text":"\u5173\u4e8eLanguage construct\u7684\u6982\u5ff5\uff0c\u53ef\u4ee5\u53c2\u8003\u7ef4\u57fa\u767e\u79d1 Language construct \uff0c\u57fa\u672c\u4e0a\u5927\u591a\u6570programming language\u90fd\u4f1a\u6d89\u53ca\u5230\u5982\u4e0bconstruct\uff1a expression statement function class","title":"Language construct"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#philosophy","text":"programming language\u7684\u8bbe\u8ba1\u8005\u5f80\u5f80\u662f\u9075\u5faa\u7740\u4e00\u5b9a\u7684philosophy\u6765\u8bbe\u8ba1\u8fd9\u95e8\u8bed\u8a00\u7684\uff0c\u4f5c\u4e3a\u4f7f\u7528\u8005\uff0c\u4e86\u89e3\u8fd9\u95e8\u8bed\u8a00\u7684philosophy\uff0c\u4e5f\u6709\u52a9\u4e8e\u6211\u4eec\u5bf9\u5b83\u7684\u638c\u63e1\u3002","title":"Philosophy"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#programming-paradigm","text":"\u6709\u5f88\u591a\u8bed\u8a00\u90fd\u53f7\u79f0\u662f\u652f\u6301\u201cmultiple programming paradigm \u201d\uff0c\u6211\u4eec\u6709\u5fc5\u8981\u4e86\u89e3programming paradigm\u7684\u77e5\u8bc6\uff0c\u53c2\u89c1 Programming paradigm \u3002","title":"Programming paradigm"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#programming-language-implementation","text":"\u5728programming language\u4e2d\uff0c\u4e5f\u6d89\u53ca\u6807\u51c6\u4e0e\u5b9e\u73b0\u7684\u95ee\u9898\uff0c\u4e00\u79cd\u8bed\u8a00\u6807\u51c6\uff0c\u53ef\u80fd\u6709\u591a\u79cd\u5b9e\u73b0\u3002","title":"Programming language implementation"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#compiler-and-interpreter","text":"\u76ee\u524d\u4e3b\u6d41\u7684programming language\u90fd\u4f1a\u6d89\u53cacompile\u8fc7\u7a0b\uff0c\u6240\u4ee5\u5b83\u4eec\u7684\u5b9e\u73b0\u90fd\u4f1a\u6d89\u53cacompiler\uff0c\u4e00\u4e9b\u8bed\u8a00\uff08\u5982python\u3001java\uff09\u8fd0\u884c\u4e8einterpreter\uff0c\u5173\u4e8ecompiler\u548c interpreter\uff0c\u53ef\u4ee5\u53c2\u89c1\u5de5\u7a0b compiler-principle \u3002","title":"Compiler and interpreter"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#compile-time-and-run-time","text":"\u5728\u5b66\u4e60\u4e00\u95e8\u8bed\u8a00\u7684\u65f6\u5019\uff0c\u4ececompile time\u548crun time\u6765\u5206\u6790\u5404\u79cd\u6982\u5ff5\u662f\u975e\u5e38\u91cd\u8981\u7684\u3002","title":"Compile-time and run time"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#common-in-development","text":"\u4e0b\u9762\u7f57\u5217\u4e86\u5728\u8fdb\u884cdevelopment\u4e2d\u4f1a\u6d89\u53ca\u5230\u7684\u4e00\u7cfb\u5217\u95ee\u9898\uff1a","title":"Common in development"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#design-pattern","text":"design pattern\u662f\u524d\u4eba\u6240\u603b\u7ed3\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u4e0d\u7ba1\u662f\u54ea\u79cdprogramming language\uff0c\u90fd\u53ef\u4ee5\u8fd0\u7528\u5b83\uff0c\u5173\u4e8edesign pattern\uff0c\u53c2\u89c1 Design-pattern \u3002","title":"Design pattern"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#resource-management","text":"\u4e0d\u7ba1\u4f7f\u7528\u54ea\u79cdprogramming language\uff0c\u90fd\u4f1a\u6d89\u53ca\u90fdresource management\u7684\u95ee\u9898\uff0c\u53c2\u89c1 Resource-management \u3002","title":"Resource-management"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#_2","text":"\u5982\u4f55\u8fdb\u884c\u6ce8\u91ca\uff1f\u5982\u4f55\u751f\u6210document\uff1f\u5404\u79cdprogramming language\u5728\u8fd9\u65b9\u9762\u90fd\u505a\u4e86\u5404\u81ea\u7684\u52aa\u529b\uff0c\u4e5f\u6709\u5404\u81ea\u7684\u5b9e\u73b0\uff0c\u540e\u9762\u5728\u8ba8\u8bba\u5177\u4f53\u7684programming language\u7684\u65f6\u5019\u518d\u8fdb\u884c\u8bf4\u660e\u3002","title":"\u6ce8\u91ca"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#_3","text":"\u5982\u4f55\u8fdb\u884c\u6d4b\u8bd5\uff1f","title":"\u6d4b\u8bd5"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#_4","text":"\u5982\u4f55\u7edf\u8ba1\u4ee3\u7801\u8986\u76d6\u7387\uff1f","title":"\u4ee3\u7801\u8986\u76d6\u7387"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#profile","text":"\u5982\u4f55\u8fdb\u884cprofile\uff1f","title":"Profile"},{"location":"Theory/Programming-language/Master-programming-language/How-to-master-programming-language/#linter","text":"\u5982\u4f55\u8fdb\u884clint\uff1f","title":"Linter"},{"location":"Theory/Programming-language/Master-programming-language/Reading-language-reference/","text":"Reading language reference \u5728\u4e0a\u4e00\u7bc7\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4ece\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u7684\u89d2\u5ea6\u6765\u5b66\u4e60programming language\uff0c\u4e00\u822c\u8fd9\u4e9b\u5185\u5bb9\u90fd\u7f6e\u4e8eprogramming language doc\u7684language reference\u4e2d\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981reading language reference\uff0c\u4e0b\u9762\u603b\u7ed3\u4e86\u6211\u5728\u9605\u8bfb\u4e0d\u540c\u8bed\u8a00\u7684language reference\u65f6\u6240\u603b\u7ed3\u7684\u4e00\u4e9b\u7ecf\u9a8c\u3002 Class-based OOP\u8bed\u8a00\u63cf\u8ff0\u7c7b\u578b\u7279\u6027 python\u548cc++\u90fd\u662f\u90fd\u662fclass-based OOP\u8bed\u8a00\uff0c\u7c7b\u53ef\u4ee5\u770b\u505a\u662f\u4e00\u79cd\u7c7b\u578b\uff0c\u9605\u8bfb\u8fd9\u4e24\u79cd\u8bed\u8a00\u7684language reference\uff0c\u4f60\u5c31\u4f1a\u53d1\u73b0\uff1alanguage reference\u9700\u8981\u63cf\u8ff0\u7c7b\u578b\u7684**\u7279\u6027**\uff0c\u6216\u8005\u8bf4\u5f53\u5bf9\u67d0\u79cd\u7c7b\u578b\u7684\u5bf9\u8c61\u8fdb\u884c\u64cd\u4f5c\u7684\u65f6\u5019\uff0c\u671f\u671b\u5b83\u5177\u5907\u67d0\u79cd\u7279\u6027\uff0c\u4ee5\u4f7f\u8fd9\u79cd\u64cd\u4f5c\u53ef\u4ee5\u8fdb\u884c\uff0c\u5b9a\u4e49\u8fd9\u4e9b\u7279\u6027\uff0c\u80fd\u591f\u4f7f\u5bf9\u8bed\u8a00\u7684\u8868\u8ff0\u975e\u5e38\u4fbf\u5229\uff0c\u6e05\u6670\uff0c\u6613\u61c2\u3002 \u8fd9\u4e9b\u7279\u6027\u5f80\u5f80\u662f\u201cable\u201d\uff0c\u6bd4\u5982callable\u3001iterable\u3001awaitable c++\u901a\u8fc7named requirement\u6765\u5b9a\u4e49\u8fd9\u4e9b\u7279\u6027\uff0cpython\u4e2d\u4e5f\u6709\u7c7b\u4f3c\u7684\u6982\u5ff5\uff0c\u4f46\u662f\u8c8c\u4f3cpython\u5e76\u6ca1\u6709\u50cfc++\u8fd9\u6837\u8fdb\u884c\u663e\u5f0f\u5730\u5b9a\u4e49\u3002 \u76f8\u540c\u7684\u662f\uff0c\u8fd9\u4e24\u79cd\u8bed\u8a00\u90fd\u662f\u8ba9user-defined class\u901a\u8fc7\u5b9e\u73b0magic function\u6765\u4e3a\u8fd9\u4e2a\u7c7b\u578b\u6dfb\u52a0\u67d0\u79cd\u7279\u6027\u3002c++\u4e2d\uff0c\u5c06\u6b64\u79f0\u4e3aoverload\u3002 c++ Named requirements python able iterable asynchronous iterable awaitable hashable immutable mutable executable callable","title":"Reading-language-reference"},{"location":"Theory/Programming-language/Master-programming-language/Reading-language-reference/#reading-language-reference","text":"\u5728\u4e0a\u4e00\u7bc7\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4ece\u8bed\u8a00\u7684\u8bbe\u8ba1\u8005\u7684\u89d2\u5ea6\u6765\u5b66\u4e60programming language\uff0c\u4e00\u822c\u8fd9\u4e9b\u5185\u5bb9\u90fd\u7f6e\u4e8eprogramming language doc\u7684language reference\u4e2d\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981reading language reference\uff0c\u4e0b\u9762\u603b\u7ed3\u4e86\u6211\u5728\u9605\u8bfb\u4e0d\u540c\u8bed\u8a00\u7684language reference\u65f6\u6240\u603b\u7ed3\u7684\u4e00\u4e9b\u7ecf\u9a8c\u3002","title":"Reading language reference"},{"location":"Theory/Programming-language/Master-programming-language/Reading-language-reference/#class-based-oop","text":"python\u548cc++\u90fd\u662f\u90fd\u662fclass-based OOP\u8bed\u8a00\uff0c\u7c7b\u53ef\u4ee5\u770b\u505a\u662f\u4e00\u79cd\u7c7b\u578b\uff0c\u9605\u8bfb\u8fd9\u4e24\u79cd\u8bed\u8a00\u7684language reference\uff0c\u4f60\u5c31\u4f1a\u53d1\u73b0\uff1alanguage reference\u9700\u8981\u63cf\u8ff0\u7c7b\u578b\u7684**\u7279\u6027**\uff0c\u6216\u8005\u8bf4\u5f53\u5bf9\u67d0\u79cd\u7c7b\u578b\u7684\u5bf9\u8c61\u8fdb\u884c\u64cd\u4f5c\u7684\u65f6\u5019\uff0c\u671f\u671b\u5b83\u5177\u5907\u67d0\u79cd\u7279\u6027\uff0c\u4ee5\u4f7f\u8fd9\u79cd\u64cd\u4f5c\u53ef\u4ee5\u8fdb\u884c\uff0c\u5b9a\u4e49\u8fd9\u4e9b\u7279\u6027\uff0c\u80fd\u591f\u4f7f\u5bf9\u8bed\u8a00\u7684\u8868\u8ff0\u975e\u5e38\u4fbf\u5229\uff0c\u6e05\u6670\uff0c\u6613\u61c2\u3002 \u8fd9\u4e9b\u7279\u6027\u5f80\u5f80\u662f\u201cable\u201d\uff0c\u6bd4\u5982callable\u3001iterable\u3001awaitable c++\u901a\u8fc7named requirement\u6765\u5b9a\u4e49\u8fd9\u4e9b\u7279\u6027\uff0cpython\u4e2d\u4e5f\u6709\u7c7b\u4f3c\u7684\u6982\u5ff5\uff0c\u4f46\u662f\u8c8c\u4f3cpython\u5e76\u6ca1\u6709\u50cfc++\u8fd9\u6837\u8fdb\u884c\u663e\u5f0f\u5730\u5b9a\u4e49\u3002 \u76f8\u540c\u7684\u662f\uff0c\u8fd9\u4e24\u79cd\u8bed\u8a00\u90fd\u662f\u8ba9user-defined class\u901a\u8fc7\u5b9e\u73b0magic function\u6765\u4e3a\u8fd9\u4e2a\u7c7b\u578b\u6dfb\u52a0\u67d0\u79cd\u7279\u6027\u3002c++\u4e2d\uff0c\u5c06\u6b64\u79f0\u4e3aoverload\u3002","title":"Class-based OOP\u8bed\u8a00\u63cf\u8ff0\u7c7b\u578b\u7279\u6027"},{"location":"Theory/Programming-language/Master-programming-language/Reading-language-reference/#c-named-requirements","text":"","title":"c++ Named requirements"},{"location":"Theory/Programming-language/Master-programming-language/Reading-language-reference/#python-able","text":"iterable asynchronous iterable awaitable hashable immutable mutable executable callable","title":"python able"},{"location":"Theory/Programming-language/Scripting-language/Read-eval-print-loop/","text":"Read\u2013eval\u2013print loop A read\u2013eval\u2013print loop ( REPL ), also termed an interactive toplevel or language shell , is a simple, interactive computer programming environment that takes single user inputs (i.e., single expressions ), evaluates (executes) them, and returns the result to the user; a program written in a REPL environment is executed piecewise. The term is usually used to refer to programming interfaces similar to the classic Lisp machine interactive environment. Common examples include command line shells and similar environments for programming languages , and the technique is very characteristic of scripting languages .","title":"Read-eval-print-loop"},{"location":"Theory/Programming-language/Scripting-language/Read-eval-print-loop/#readevalprint-loop","text":"A read\u2013eval\u2013print loop ( REPL ), also termed an interactive toplevel or language shell , is a simple, interactive computer programming environment that takes single user inputs (i.e., single expressions ), evaluates (executes) them, and returns the result to the user; a program written in a REPL environment is executed piecewise. The term is usually used to refer to programming interfaces similar to the classic Lisp machine interactive environment. Common examples include command line shells and similar environments for programming languages , and the technique is very characteristic of scripting languages .","title":"Read\u2013eval\u2013print loop"},{"location":"Theory/Programming-language/Scripting-language/Scripting-language/","text":"Scripting language \u7ef4\u57fa\u767e\u79d1 Scripting language","title":"Scripting-language"},{"location":"Theory/Programming-language/Scripting-language/Scripting-language/#scripting-language","text":"","title":"Scripting language"},{"location":"Theory/Programming-language/Scripting-language/Scripting-language/#scripting-language_1","text":"","title":"\u7ef4\u57fa\u767e\u79d1Scripting language"},{"location":"Theory/Programming-paradigm/","text":"\u5173\u4e8e\u672c\u7ae0 \u6709\u5f88\u591aprogramming language\u90fd\u58f0\u79f0\u81ea\u5df1\u662f\u201c multi-paradigm \"\uff0c\u6bd4\u5982\uff1a Python (programming language) : Python is dynamically typed and garbage-collected . It supports multiple programming paradigms , including procedural , object-oriented, and functional programming . C++ \u672c\u7ae0\u5c31\u5bf9programming language\u7684paradigm\u8fdb\u884c\u5206\u6790\u3002","title":"Introduction"},{"location":"Theory/Programming-paradigm/#_1","text":"\u6709\u5f88\u591aprogramming language\u90fd\u58f0\u79f0\u81ea\u5df1\u662f\u201c multi-paradigm \"\uff0c\u6bd4\u5982\uff1a Python (programming language) : Python is dynamically typed and garbage-collected . It supports multiple programming paradigms , including procedural , object-oriented, and functional programming . C++ \u672c\u7ae0\u5c31\u5bf9programming language\u7684paradigm\u8fdb\u884c\u5206\u6790\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Theory/Programming-paradigm/Programming-paradigm/","text":"Programming paradigm \u7ef4\u57fa\u767e\u79d1 Programming paradigm Programming paradigms are a way to classify programming languages based on their features. Languages can be classified into multiple paradigms. NOTE\uff1a\u5b83\u662f\u4e00\u79cd\u5bf9programming language\u8fdb\u884c\u5206\u7c7b\u7684\u65b9\u6cd5 Some paradigms are concerned mainly with implications for the execution model of the language, such as allowing side effects , or whether the sequence of operations is defined by the execution model. Other paradigms are concerned mainly with the way that code is organized, such as grouping a code into units along with the state that is modified by the code. Yet others are concerned mainly with the style of syntax and grammar. NOTE\uff1a\u4e0d\u540c\u7684paradigm\u6240\u5173\u6ce8\u7684\u70b9\u662f\u4e0d\u540c\u7684 Common programming paradigms include: imperative\uff08\u547d\u4ee4\u5f0f\uff09 in which the programmer instructs\uff08\u6307\u793a\uff09 the machine how to change its state, procedural which groups instructions into procedures, object-oriented which groups instructions together with the part of the state they operate on, declarative\uff08\u9648\u8ff0\u5f0f\uff09 in which the programmer merely declares properties of the desired result, but not how to compute it functional in which the desired result is declared as the value of a series of function applications, logic in which the desired result is declared as the answer to a question about a system of facts and rules, mathematical in which the desired result is declared as the solution of an optimization problem NOTE: \u76ee\u524d\u7684\u4e3b\u6d41programming language\u57fa\u672c\u4e0a\u5c5e\u4e8e\u4e0a\u8ff0\u4e24\u5927\u7c7b\u3002 Symbolic techniques such as reflection , which allow the program to refer to itself, might also be considered as a programming paradigm . However, this is compatible with the major paradigms and thus is not a real paradigm in its own right. For example, languages that fall into the imperative paradigm have two main features: they state the order in which operations occur, with constructs that explicitly control that order, and they allow side effects , in which state can be modified at one point in time, within one unit of code, and then later read at a different point in time inside a different unit of code. The communication between the units of code is not explicit. Meanwhile, in object-oriented programming, code is organized into objects that contain state that is only modified by the code that is part of the object. Most object-oriented languages are also imperative languages. NOTE\uff1a\u5f53\u5230\u4e86\u73b0\u5728\u7684\u8fd9\u4e2a\u5c42\u7ea7\uff0c\u5c31\u4f1a\u9605\u8bfb\u8d8a\u6765\u8d8a\u591a\u7684\u7f16\u7a0b\u7684\u7406\u8bba\uff0c\u5982\u679c\u6211\u6ca1\u6709\u8bb0\u9519\u7684\u8bdd\uff0c state**\u8fd9\u4e2a\u672f\u8bed\u5728\u591a\u7bc7\u6587\u7ae0\u4e2d\u51fa\u73b0\u8fc7\uff0c\u5728\u9605\u8bfb Overview \u7684\u65f6\u5019\uff0c\u5176\u4e2d\u6709\u8fd9\u6837\u7684\u4e00\u6bb5\u8bdd\u201c In functional programming , programs are treated as a sequence of **stateless function evaluations.\u201d\uff0c\u8fd9\u7a81\u7136\u8ba9\u6211\u60f3\u8d77\u6765\u8fd9\u662f\u548c\u9762\u5411\u5bf9\u8c61\u76f8\u53cd\u7684\uff0c\u9762\u5411\u5bf9\u8c61\u662fstate\u7684\uff0c\u662f\u6709side effect\u7684\uff1bstate\u7684\u6982\u5ff5\u5728\u7f16\u7a0b\u8bed\u8a00\u7406\u8bba\u662f\u662f\u975e\u5e38\u91cd\u8981\u7684\uff1b In contrast, languages that fit the declarative paradigm do not state the order in which to execute operations. Instead, they supply a number of operations that are available in the system, along with the conditions under which each is allowed to execute. The implementation of the language's execution model tracks which operations are free to execute and chooses the order on its own. More at Comparison of multi-paradigm programming languages . Overview Just as software engineering (as a process) is defined by differing methodologies , so the programming languages (as models of computation) are defined by differing paradigms . Some languages are designed to support one paradigm ( Smalltalk supports object-oriented programming, Haskell supports functional programming), while other programming languages support multiple paradigms (such as Object Pascal , C++ , Java , C# , Scala , Visual Basic , Common Lisp , Scheme , Perl , PHP , Python , Ruby , Oz , and F# ). For example, programs written in C++, Object Pascal or PHP can be purely procedural , purely object-oriented , or can contain elements of both or other paradigms. Software designers and programmers decide how to use those paradigm elements. In object-oriented programming, programs are treated as a set of interacting objects. In functional programming , programs are treated as a sequence of stateless function evaluations. When programming computers or systems with many processors, in process-oriented programming , programs are treated as sets of concurrent processes acting on logically shared data structures . NOTE\uff1a\u4e0a\u9762\u8fd9\u6bb5\u4e2d\u5173\u4e8efunctional programming \u7684\u63cf\u8ff0\u4e2d\u7684stateless\u4e0eobject-oriented language\u7684state\u662f\u975e\u5e38\u5177\u5bf9\u6bd4\u4ef7\u503c\u7684\uff1b Programming paradigms can also be compared with programming models which allow invoking an execution model by using only an API. Programming models can also be classified into paradigms, based on features of the execution model. For parallel computing , using a programming model instead of a language is common. The reason is that details of the parallel hardware leak into(\u6cc4\u9732) the abstractions used to program the hardware. This causes the programmer to have to map patterns in the algorithm onto patterns in the execution model (which have been inserted due to leakage of hardware into the abstraction). As a consequence, no one parallel programming language maps well to all computation problems. It is thus more convenient to use a base sequential language and insert API calls to parallel execution models , via a programming model. Such parallel programming models can be classified according to abstractions that reflect the hardware, such as shared memory, distributed memory with message passing, notions of place visible in the code, and so forth. These can be considered flavors of programming paradigm that apply to only parallel languages and programming models. NOTE\uff1a\u4e0a\u9762\u8fd9\u6bb5\u4e2d\u7684\u5173\u4e8e\u5728parallel computing\u4e2d\u4f7f\u7528programming model\u800c\u975elanguage\u7684\u89e3\u91ca\u53ef\u4ee5\u7ed3\u5408\u5728* programming models \u89e3\u91ca\u76f8\u7ed3\u5408\u3002\u7531\u4e8ethe execution model of **parallel hardware* often must expose features of the hardware in order to achieve high performance\uff0c The large amount of variation in parallel hardware causes a concurrent need for a similarly large number of parallel execution models.\u8fd9\u5c31\u5bfc\u81f4\u4e86It is impractical to make a new language for each execution model, hence it is a common practice to invoke the behaviors of the parallel execution model via an API. \u7ef4\u57fa\u767e\u79d1 Comparison of programming paradigms NOTE: \u5bf9\u4e8e\u6709\u4e00\u5b9a\u7f16\u7a0b\u7ecf\u9a8c\u7684\u4eba\u5458\uff0c\u63a8\u8350\u9996\u5148\u9605\u8bfb\u8fd9\u7bc7\u6587\u7ae0\uff0c\u5b83\u5bf9programming paradigm\u7684\u603b\u7ed3\u662f\u975e\u5e38\u597d\u7684\uff0c\u5728\u5176 Pseudocode examples comparing various paradigms \u6bb5\u6240\u5217\u4e3e\u7684\u4f8b\u5b50\u975e\u5e38\u5177\u6709\u542f\u53d1\u6027\uff0c\u80dc\u8fc7\u4e86\u4e00\u5806\u7406\u8bba\u7684\u63cf\u8ff0\u3002 Summary of paradigm OOP VS Procedural programming \u7ef4\u57fa\u767e\u79d1 Procedural programming Procedural programming\u7684\u4e00\u79cd\u5178\u578b\u5199\u6cd5\u5c31\u662f\uff1a pthread_mutex_t lock; pthread_mutex_init(&lock, NULL); pthread_mutex_lock(&lock); pthread_mutex_unlock(&lock); pthread_mutex_destroy(&lock); \u5b83\u7684\u6a21\u5f0f\u662f\uff1a\u5b9a\u4e49\u4e00\u4e2a struct \uff0c\u7136\u540e\u5b9a\u4e49\u5404\u79cd\u5bf9\u8fd9\u4e2a struct \u8fdb\u884c\u64cd\u4f5c\u7684\u51fd\u6570\u3002\u53ef\u4ee5\u53c2\u89c1redis\u7684\u5b9e\u73b0\u3002 OOP\u4e2d\uff0c\u5219\u5b8c\u5168\u4e0d\u540c\uff0cOOP\u4e2d\uff0c\u6574\u4e2a\u7a0b\u5e8f\u662fobject\u4e4b\u95f4\u7684\u4ea4\u4e92\uff0cobject\u4e4b\u95f4\u662f\u901a\u8fc7\u53d1\u9001message\u6765\u8fdb\u884c\u4ea4\u4e92\u7684\u3002 Declarative programming VS Imperative programming \u8fd9\u4e24\u79cd\u662f\u5178\u578b\u7684\u5bf9\u7acb\u7684\u4e24\u79cdparadigm\u3002 OOP VS FP OOP\u662f\u6709state\u7684\uff0cFP\uff08functional programming\uff09\u662f\u6ca1\u6709state\u7684\u3002","title":"Programming-paradigm"},{"location":"Theory/Programming-paradigm/Programming-paradigm/#programming-paradigm","text":"","title":"Programming paradigm"},{"location":"Theory/Programming-paradigm/Programming-paradigm/#programming-paradigm_1","text":"Programming paradigms are a way to classify programming languages based on their features. Languages can be classified into multiple paradigms. NOTE\uff1a\u5b83\u662f\u4e00\u79cd\u5bf9programming language\u8fdb\u884c\u5206\u7c7b\u7684\u65b9\u6cd5 Some paradigms are concerned mainly with implications for the execution model of the language, such as allowing side effects , or whether the sequence of operations is defined by the execution model. Other paradigms are concerned mainly with the way that code is organized, such as grouping a code into units along with the state that is modified by the code. Yet others are concerned mainly with the style of syntax and grammar. NOTE\uff1a\u4e0d\u540c\u7684paradigm\u6240\u5173\u6ce8\u7684\u70b9\u662f\u4e0d\u540c\u7684 Common programming paradigms include: imperative\uff08\u547d\u4ee4\u5f0f\uff09 in which the programmer instructs\uff08\u6307\u793a\uff09 the machine how to change its state, procedural which groups instructions into procedures, object-oriented which groups instructions together with the part of the state they operate on, declarative\uff08\u9648\u8ff0\u5f0f\uff09 in which the programmer merely declares properties of the desired result, but not how to compute it functional in which the desired result is declared as the value of a series of function applications, logic in which the desired result is declared as the answer to a question about a system of facts and rules, mathematical in which the desired result is declared as the solution of an optimization problem NOTE: \u76ee\u524d\u7684\u4e3b\u6d41programming language\u57fa\u672c\u4e0a\u5c5e\u4e8e\u4e0a\u8ff0\u4e24\u5927\u7c7b\u3002 Symbolic techniques such as reflection , which allow the program to refer to itself, might also be considered as a programming paradigm . However, this is compatible with the major paradigms and thus is not a real paradigm in its own right. For example, languages that fall into the imperative paradigm have two main features: they state the order in which operations occur, with constructs that explicitly control that order, and they allow side effects , in which state can be modified at one point in time, within one unit of code, and then later read at a different point in time inside a different unit of code. The communication between the units of code is not explicit. Meanwhile, in object-oriented programming, code is organized into objects that contain state that is only modified by the code that is part of the object. Most object-oriented languages are also imperative languages. NOTE\uff1a\u5f53\u5230\u4e86\u73b0\u5728\u7684\u8fd9\u4e2a\u5c42\u7ea7\uff0c\u5c31\u4f1a\u9605\u8bfb\u8d8a\u6765\u8d8a\u591a\u7684\u7f16\u7a0b\u7684\u7406\u8bba\uff0c\u5982\u679c\u6211\u6ca1\u6709\u8bb0\u9519\u7684\u8bdd\uff0c state**\u8fd9\u4e2a\u672f\u8bed\u5728\u591a\u7bc7\u6587\u7ae0\u4e2d\u51fa\u73b0\u8fc7\uff0c\u5728\u9605\u8bfb Overview \u7684\u65f6\u5019\uff0c\u5176\u4e2d\u6709\u8fd9\u6837\u7684\u4e00\u6bb5\u8bdd\u201c In functional programming , programs are treated as a sequence of **stateless function evaluations.\u201d\uff0c\u8fd9\u7a81\u7136\u8ba9\u6211\u60f3\u8d77\u6765\u8fd9\u662f\u548c\u9762\u5411\u5bf9\u8c61\u76f8\u53cd\u7684\uff0c\u9762\u5411\u5bf9\u8c61\u662fstate\u7684\uff0c\u662f\u6709side effect\u7684\uff1bstate\u7684\u6982\u5ff5\u5728\u7f16\u7a0b\u8bed\u8a00\u7406\u8bba\u662f\u662f\u975e\u5e38\u91cd\u8981\u7684\uff1b In contrast, languages that fit the declarative paradigm do not state the order in which to execute operations. Instead, they supply a number of operations that are available in the system, along with the conditions under which each is allowed to execute. The implementation of the language's execution model tracks which operations are free to execute and chooses the order on its own. More at Comparison of multi-paradigm programming languages .","title":"\u7ef4\u57fa\u767e\u79d1Programming paradigm"},{"location":"Theory/Programming-paradigm/Programming-paradigm/#overview","text":"Just as software engineering (as a process) is defined by differing methodologies , so the programming languages (as models of computation) are defined by differing paradigms . Some languages are designed to support one paradigm ( Smalltalk supports object-oriented programming, Haskell supports functional programming), while other programming languages support multiple paradigms (such as Object Pascal , C++ , Java , C# , Scala , Visual Basic , Common Lisp , Scheme , Perl , PHP , Python , Ruby , Oz , and F# ). For example, programs written in C++, Object Pascal or PHP can be purely procedural , purely object-oriented , or can contain elements of both or other paradigms. Software designers and programmers decide how to use those paradigm elements. In object-oriented programming, programs are treated as a set of interacting objects. In functional programming , programs are treated as a sequence of stateless function evaluations. When programming computers or systems with many processors, in process-oriented programming , programs are treated as sets of concurrent processes acting on logically shared data structures . NOTE\uff1a\u4e0a\u9762\u8fd9\u6bb5\u4e2d\u5173\u4e8efunctional programming \u7684\u63cf\u8ff0\u4e2d\u7684stateless\u4e0eobject-oriented language\u7684state\u662f\u975e\u5e38\u5177\u5bf9\u6bd4\u4ef7\u503c\u7684\uff1b Programming paradigms can also be compared with programming models which allow invoking an execution model by using only an API. Programming models can also be classified into paradigms, based on features of the execution model. For parallel computing , using a programming model instead of a language is common. The reason is that details of the parallel hardware leak into(\u6cc4\u9732) the abstractions used to program the hardware. This causes the programmer to have to map patterns in the algorithm onto patterns in the execution model (which have been inserted due to leakage of hardware into the abstraction). As a consequence, no one parallel programming language maps well to all computation problems. It is thus more convenient to use a base sequential language and insert API calls to parallel execution models , via a programming model. Such parallel programming models can be classified according to abstractions that reflect the hardware, such as shared memory, distributed memory with message passing, notions of place visible in the code, and so forth. These can be considered flavors of programming paradigm that apply to only parallel languages and programming models. NOTE\uff1a\u4e0a\u9762\u8fd9\u6bb5\u4e2d\u7684\u5173\u4e8e\u5728parallel computing\u4e2d\u4f7f\u7528programming model\u800c\u975elanguage\u7684\u89e3\u91ca\u53ef\u4ee5\u7ed3\u5408\u5728* programming models \u89e3\u91ca\u76f8\u7ed3\u5408\u3002\u7531\u4e8ethe execution model of **parallel hardware* often must expose features of the hardware in order to achieve high performance\uff0c The large amount of variation in parallel hardware causes a concurrent need for a similarly large number of parallel execution models.\u8fd9\u5c31\u5bfc\u81f4\u4e86It is impractical to make a new language for each execution model, hence it is a common practice to invoke the behaviors of the parallel execution model via an API.","title":"Overview"},{"location":"Theory/Programming-paradigm/Programming-paradigm/#comparison-of-programming-paradigms","text":"NOTE: \u5bf9\u4e8e\u6709\u4e00\u5b9a\u7f16\u7a0b\u7ecf\u9a8c\u7684\u4eba\u5458\uff0c\u63a8\u8350\u9996\u5148\u9605\u8bfb\u8fd9\u7bc7\u6587\u7ae0\uff0c\u5b83\u5bf9programming paradigm\u7684\u603b\u7ed3\u662f\u975e\u5e38\u597d\u7684\uff0c\u5728\u5176 Pseudocode examples comparing various paradigms \u6bb5\u6240\u5217\u4e3e\u7684\u4f8b\u5b50\u975e\u5e38\u5177\u6709\u542f\u53d1\u6027\uff0c\u80dc\u8fc7\u4e86\u4e00\u5806\u7406\u8bba\u7684\u63cf\u8ff0\u3002","title":"\u7ef4\u57fa\u767e\u79d1Comparison of programming paradigms"},{"location":"Theory/Programming-paradigm/Programming-paradigm/#summary-of-paradigm","text":"","title":"Summary of paradigm"},{"location":"Theory/Programming-paradigm/Programming-paradigm/#oop-vs-procedural-programming","text":"\u7ef4\u57fa\u767e\u79d1 Procedural programming Procedural programming\u7684\u4e00\u79cd\u5178\u578b\u5199\u6cd5\u5c31\u662f\uff1a pthread_mutex_t lock; pthread_mutex_init(&lock, NULL); pthread_mutex_lock(&lock); pthread_mutex_unlock(&lock); pthread_mutex_destroy(&lock); \u5b83\u7684\u6a21\u5f0f\u662f\uff1a\u5b9a\u4e49\u4e00\u4e2a struct \uff0c\u7136\u540e\u5b9a\u4e49\u5404\u79cd\u5bf9\u8fd9\u4e2a struct \u8fdb\u884c\u64cd\u4f5c\u7684\u51fd\u6570\u3002\u53ef\u4ee5\u53c2\u89c1redis\u7684\u5b9e\u73b0\u3002 OOP\u4e2d\uff0c\u5219\u5b8c\u5168\u4e0d\u540c\uff0cOOP\u4e2d\uff0c\u6574\u4e2a\u7a0b\u5e8f\u662fobject\u4e4b\u95f4\u7684\u4ea4\u4e92\uff0cobject\u4e4b\u95f4\u662f\u901a\u8fc7\u53d1\u9001message\u6765\u8fdb\u884c\u4ea4\u4e92\u7684\u3002","title":"OOP VS Procedural programming"},{"location":"Theory/Programming-paradigm/Programming-paradigm/#declarative-programming-vs-imperative-programming","text":"\u8fd9\u4e24\u79cd\u662f\u5178\u578b\u7684\u5bf9\u7acb\u7684\u4e24\u79cdparadigm\u3002","title":"Declarative programming VS Imperative programming"},{"location":"Theory/Programming-paradigm/Programming-paradigm/#oop-vs-fp","text":"OOP\u662f\u6709state\u7684\uff0cFP\uff08functional programming\uff09\u662f\u6ca1\u6709state\u7684\u3002","title":"OOP VS FP"},{"location":"Theory/Programming-paradigm/Aspect-oriented-programming/Aspect-oriented-programming/","text":"Aspect-oriented programming 20181216 Metaclass Programming In Python Metaclasses enable certain types of \"aspect oriented programming,\" e.g. allow you to enhance classes with features like tracing capabilities, object persistence, exception logging, and more.","title":"Aspect-oriented-programming"},{"location":"Theory/Programming-paradigm/Aspect-oriented-programming/Aspect-oriented-programming/#aspect-oriented-programming","text":"","title":"Aspect-oriented programming"},{"location":"Theory/Programming-paradigm/Aspect-oriented-programming/Aspect-oriented-programming/#20181216","text":"Metaclass Programming In Python Metaclasses enable certain types of \"aspect oriented programming,\" e.g. allow you to enhance classes with features like tracing capabilities, object persistence, exception logging, and more.","title":"20181216"},{"location":"Theory/Programming-paradigm/Event-driven-programming/","text":"\u5173\u4e8e\u672c\u7ae0 \u5728\u6587\u7ae0 Abstraction and model \u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 Event-driven model \uff0c\u6211\u89c9\u5f97event-driven model\u662f\u4e00\u4e2a\u975e\u5e38\u5f3a\u5927\u7684**\u6a21\u578b**\uff0c\u80fd\u591f\u63cf\u8ff0\u975e\u5e38\u975e\u5e38\u5e7f\u6cdb\u7684\u95ee\u9898\uff0c\u6bd4\u5982\uff1a Linux OS kernel is event-driven \u672c\u7ae0\u8ba8\u8bba\u5982\u4f55\u5b9e\u73b0event-driven model\uff0c\u8fd9\u5c31\u662f Event-driven programming \u3002","title":"Introduction"},{"location":"Theory/Programming-paradigm/Event-driven-programming/#_1","text":"\u5728\u6587\u7ae0 Abstraction and model \u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 Event-driven model \uff0c\u6211\u89c9\u5f97event-driven model\u662f\u4e00\u4e2a\u975e\u5e38\u5f3a\u5927\u7684**\u6a21\u578b**\uff0c\u80fd\u591f\u63cf\u8ff0\u975e\u5e38\u975e\u5e38\u5e7f\u6cdb\u7684\u95ee\u9898\uff0c\u6bd4\u5982\uff1a Linux OS kernel is event-driven \u672c\u7ae0\u8ba8\u8bba\u5982\u4f55\u5b9e\u73b0event-driven model\uff0c\u8fd9\u5c31\u662f Event-driven programming \u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-VS-exception-VS-signal/","text":"Event VS signal VS exception \u6b63\u5982\u5728 Event-driven-model \u4e2d\u6240\u603b\u7ed3\u7684\uff1a Event\u662f\u4e00\u4e2a\u975e\u5e38\u6982\u62ec\u3001\u5bbd\u6cdb\u7684\u6982\u5ff5 Exception\u53ef\u4ee5\u53ef\u770b\u505a\u662f\u4e00\u79cdevent\uff0c\u5373\u5b83\u662f\u7531external environment\u6216\u8005\u7a0b\u5e8f\u5185\u90e8\u6240\u4ea7\u751f\u7684\uff0c\u73b0\u4ee3programming language\u5bf9\u8fd9\u79cdevent\u8fdb\u884c\u4e86\u62bd\u8c61\uff0c\u4f7f\u7528\u66f4\u52a0\u5177\u4f53\u7684\u3001\u66f4\u52a0\u660e\u786e\u7684exception\u7684\u6982\u5ff5\u6765\u63cf\u8ff0\u5b83\u3002 Signal\u4e5f\u53ef\u4ee5\u770b\u505a\u662f\u4e00\u79cdevent\u3002","title":"Event-VS-exception-VS-signal"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-VS-exception-VS-signal/#event-vs-signal-vs-exception","text":"\u6b63\u5982\u5728 Event-driven-model \u4e2d\u6240\u603b\u7ed3\u7684\uff1a Event\u662f\u4e00\u4e2a\u975e\u5e38\u6982\u62ec\u3001\u5bbd\u6cdb\u7684\u6982\u5ff5 Exception\u53ef\u4ee5\u53ef\u770b\u505a\u662f\u4e00\u79cdevent\uff0c\u5373\u5b83\u662f\u7531external environment\u6216\u8005\u7a0b\u5e8f\u5185\u90e8\u6240\u4ea7\u751f\u7684\uff0c\u73b0\u4ee3programming language\u5bf9\u8fd9\u79cdevent\u8fdb\u884c\u4e86\u62bd\u8c61\uff0c\u4f7f\u7528\u66f4\u52a0\u5177\u4f53\u7684\u3001\u66f4\u52a0\u660e\u786e\u7684exception\u7684\u6982\u5ff5\u6765\u63cf\u8ff0\u5b83\u3002 Signal\u4e5f\u53ef\u4ee5\u770b\u505a\u662f\u4e00\u79cdevent\u3002","title":"Event VS signal VS exception"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/","text":"Event-driven model \u5728\u6587\u7ae0 Abstraction and model \u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 Event-driven model \uff0c\u5b83\u662f\u4e00\u4e2a\u975e\u5e38\u5f3a\u5927\u7684\u6a21\u578b\uff0c\u80fd\u591f\u63cf\u8ff0\u975e\u5e38\u975e\u5e38\u5e7f\u6cdb\u7684\u95ee\u9898\u3002\u5728\u672c\u6587\uff0c\u6211\u4eec\u5c06\u8bf4\u660e\u4ec0\u4e48\u662fevent-driven model\u3001\u4ec0\u4e48\u662fevent\u3001\u5982\u4f55\u5b9e\u73b0event-driven model\u3002 Event-driven model Event-driven model\u9700\u8981\u6301\u7eed\u4e0d\u65ad\u5730\u8fdb\u884c\u8fd0\u8f6c\u4ee5\u76d1\u63a7\u4e8b\u4ef6\u6e90\u3001\u6536\u96c6event\uff0c\u4e00\u65e6\u6536\u96c6\u5230\u4e86event\uff0c\u5c31\u8fdb\u884cdispatch\uff0c\u5373\u6839\u636eevent\u548cevent handler\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\uff0c\u8c03\u7528\u8fd9\u4e2aevent\u5bf9\u5e94\u7684event handler\u3002\u5176\u5b9e\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u5b83\u770b\u505a\u662f\u4e00\u4e2a**abstract machine**\u3002 on \u53ef\u4ee5\u4f7f\u7528Event-driven model\u6765\u8fdb\u884c\u63cf\u8ff0\u7684\u95ee\u9898\u7684\u4e00\u4e2a\u5178\u578b\u7684\u6a21\u5f0f\u5c31\u662f\uff1a\u5f53\u67d0\u4e2a\u4e8b\u4ef6\u53d1\u751f\u7684\u65f6\u5019\uff0c\u5c31\u6267\u884c\u67d0\u4e2a\u51fd\u6570\u3002\u6211\u89c9\u5f97\u8fd9\u79cd\u6a21\u5f0f\uff0c\u4f7f\u7528JavaScript\u6765\u8fdb\u884c\u63cf\u8ff0\u662f\u6700\u6700\u4fbf\u5229\u7684\u3002 https://www.w3schools.com/js/js_events.asp https://storm.cis.fordham.edu/~mesterharm/2350/event.html Example \u7406\u89e3event-driven model\u7684\u6700\u6700\u7b80\u5355\u7684\u4f8b\u5b50\u5c31\u662flinux OS kernel\u548chardware\u7684\u4ea4\u4e92\uff0c\u5728\u5de5\u7a0b Linux-OS \u7684\u6587\u7ae0 Linux-OS-kernel-is-event-driven \u4e2d\u6211\u4eec\u5df2\u7ecf\u603b\u7ed3\u4e86\u53ef\u4ee5\u4f7f\u7528 Event-driven model \u6765\u63cf\u8ff0linux OS kernel\u548chardware\u7684\u4ea4\u4e92\u3002\u5728hardware\u5c42\uff0c\u4e00\u65e6\u901a\u7535\uff0c\u5219hardware\u5c31\u6301\u7eed\u4e0d\u65ad\u5730\u8fd0\u8f6c\u8d77\u6765\u4e86\uff0c\u4e00\u65e6\u89e6\u53d1\u4e86interrupt\uff0c\u5219\u5b83\u7684interrupt handler\u5c31\u4f1a\u88ab\u6267\u884c\u3002 Event-driven model\u7684\u7ec4\u6210 \u4e00\u4e2aevent-driven model\u7684\u7ec4\u6210\u6210\u5206\uff1a monitor/listener\uff0c\u76d1\u63a7event event\u548cevent handler\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\u8868 dispatcher\uff0c\u6d3e\u53d1event\uff0c\u5373\u6309\u7167event\u548cevent handler\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\uff0c\u901a\u77e5executor\u6267\u884cevent handler executor\uff0c\u6267\u884cevent handler What is event? Event\u662f\u4e00\u4e2a\u975e\u5e38\u6982\u62ec\u3001\u5bbd\u6cdb\u7684\u6982\u5ff5\uff0c\u5728Event-driven model\u4e2d\uff0c\u975e\u5e38\u591a\u7684\u884c\u4e3a\u90fd\u4f1a\u4ea7\u751fevent\uff0c\u6211\u4eec\u628a\u5b83\u79f0\u4e3asource of event\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06source of event\u5212\u5206\u4e3a\u4e24\u7c7b\uff1a external environment \u6211\u4eec\u4ee5\u81ea\u5e95\u5411\u4e0a\u7684\u601d\u8def\u6765\u5206\u6790\u6e90\u81eaexternal environment\u7684event\uff0c\u4e00\u4e2a computing system \u7684\u6700\u5e95\u5c42\u662fhardware\uff0chardware\u4ea7\u751f\u7684 interrupt \uff0c\u7136\u540e\u7531OS kernel\u5c06\u8fd9\u4e9binterrupt\u201c\u8f6c\u6362\u201d\u4e3asignal\uff08\u73b0\u4ee3programming language\u4f1a\u4f7f\u7528exception\u6765\u62bd\u8c61signal\uff09\u3001IO\uff08\u56e0\u4e3aIO\u7684\u5b9e\u73b0\u662f\u4f9d\u8d56\u4e8einterrupt\u7684\uff0cIO\u5305\u62ec\u4e86\u975e\u5e38\u591a\u7684\u5185\u5bb9\uff0c\u7528\u6237\u64cd\u4f5c\u3001\u7f51\u7edc\u901a\u4fe1\u7b49\u90fd\u53ef\u4ee5\u770b\u505a\u662fIO\uff0cevents can represent availability of new data for reading a file or network stream.\uff09event\u7b49\uff0c\u5e76\u901a\u77e5\u5230application process\u3002 \u5173\u4e8e\u8fd9\u4e00\u70b9\uff0c\u53c2\u89c1\u7ef4\u57fa\u767e\u79d1 Event (computing) \u7684 Event handler \u6bb5\u3002 \u7a0b\u5e8f\u5185\u90e8 Event\u53ef\u80fd\u6e90\u81ea\u4e8eexternal environment\uff0c\u4e5f\u53ef\u80fd\u6e90\u81ea\u4e8e\u7a0b\u5e8f\u4e4b\u5185\uff0c\u5373\u7a0b\u5e8f\u5185\u90e8\u5c06\u4e00\u4e9b\u6761\u4ef6\u7b49\u770b\u505aevent\uff0c\u6bd4\u5982condition variable\u3002 TODO: \u9700\u8981\u8865\u5145\u4e00\u4e9b\u5177\u4f53\u4f8b\u5b50\u3002 \u4e0b\u9762\u8865\u5145\u4e86\u7ef4\u57fa\u767e\u79d1 Event (computing) \u6765\u8fdb\u884c\u8be6\u7ec6\u8bf4\u660e\u3002 \u7ef4\u57fa\u767e\u79d1 Event (computing) Delegate event model NOTE: \u539f\u6587\u7684\u8fd9\u4e00\u6bb5\u6ca1\u6709\u8bfb\u61c2\u3002 Event-driven programming Event-driven programming\u544a\u8bc9\u6211\u4eec\u5982\u4f55\u5b9e\u73b0event-driven model\u3002 Event-driven programming\u4e2d\u9700\u8981\u8003\u8651\u7684\u4e00\u4e9b\u95ee\u9898 Event-driven model\u5b9e\u73b0\u4e2d\u9700\u8981\u8003\u8651\u7684\u4e00\u4e9b\u95ee\u9898\uff1a \u5982\u4f55\u58f0\u660eevent\u548cevent handler\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u663e\u7136event driven model\u9700\u8981\u8bb0\u5f55\u4e0bevent\u548cevent handler\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\uff1f \u5982\u4f55\u8fdb\u884c\u6301\u7eed\u76d1\u63a7\uff0c\u5373\u5982\u4f55\u5b9e\u73b0monitor\uff1f Monitor\uff1a\u5982\u4f55\u8fdb\u884c\u6301\u7eed\u76d1\u63a7 \u5728\u786c\u4ef6\u5c42\uff0c\u53ea\u8981\u901a\u7535\u540e\uff0c\u5219hardware\u5c31\u6301\u7eed\u4e0d\u65ad\u5730\u8fd0\u8f6c\u8d77\u6765\u4e86\uff0c\u4e00\u65e6\u89e6\u53d1\u4e86interrupt\uff0c\u5219\u5b83\u7684interrupt handler\u5c31\u4f1a\u88ab\u6267\u884c\u3002\u5728\u8f6f\u4ef6\u5c42\uff0c\u6211\u4eec\u9700\u8981\u663e\u5f0f\u5730\u4f7f\u7528\u4e00\u4e2a main loop \u6765\u6307\u793a\u6574\u4e2amodel\u9700\u8981\u4e0d\u65ad\u5730\u8fd0\u8f6c\u4e0b\u53bb\u3002 \u5173\u4e8e\u8fd9\u4e00\u70b9\uff0c\u53c2\u89c1\u7ef4\u57fa\u767e\u79d1 Event-driven programming \u7684\u7b2c\u4e8c\u6bb5\u3002 \u5173\u8054event\u548cevent handler Event-driven model\u80af\u5b9a\u9700\u8981\u8bb0\u5f55\u4e0bevent\u548cevent handler\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\uff0c\u5b9e\u73b0\u8fd9\u79cd\u6620\u5c04\u5173\u7cfb\u7684\u65b9\u5f0f\u662f\u975e\u5e38\u591a\u7684\uff0c\u53ef\u4ee5\u663e\u793a\u5730\u4f7f\u7528\u8bf8\u5982map\u7684\u6570\u636e\u7ed3\u6784\u3002 \u4e0b\u9762\u7f57\u5217\u4e86\u4e00\u4e9b\u5b9e\u73b0\u6848\u4f8b\uff1a Interrupt Descriptor Table \u53c2\u89c1\uff1a\u5de5\u7a0b Linux-OS \u7684 4.2-Interrupts-and-Exceptions \u7684 4.2.3. Interrupt Descriptor Table \u7ef4\u57fa\u767e\u79d1 Interrupt descriptor table Dispatcher \u6240\u8c13\u7684event dispatcher\u662f\u6307\u5f53event\u53d1\u751f\u65f6\uff0cevent-driven model\u5c06event\u4f20\u9012\u5230executor\uff0c\u901a\u77e5executor\u6267\u884c\u5bf9\u5e94\u7684handler\u3002Dispatcher\u7684\u5b9e\u73b0\u65b9\u5f0f\u662f\u6709executor\u51b3\u5b9a\u7684\uff0c \u5728\u4e0b\u4e00\u8282\u5bf9\u6b64\u8fdb\u884c\u5177\u4f53\u60c5\u51b5\u5177\u4f53\u8bf4\u660e\u3002 Executor\uff1aexecution of event handler \u5982\u4f55\u6765\u6267\u884cevent handler\uff1f\u5728\u51b3\u5b9a\u5982\u4f55\u6765\u6267\u884cevent handler\u7684\u65f6\u5019\uff0c\u5f00\u53d1\u8005\u9700\u8981\u8003\u8651\u5982\u4e0b\u95ee\u9898\uff1a event handler\u6267\u884c\u7684\u6210\u672c\uff0c\u6b64\u5904\u7684\u6210\u672c\u53ef\u4ee5\u6709\u591a\u79cd\u89e3\u91ca\uff0c\u6bd4\u5982\uff0c\u5b83\u53ef\u4ee5\u8868\u793aevent handler\u6267\u884c\u7684\u65f6\u957f\u3001\u53ef\u4ee5\u8868\u793aevent handler\u6267\u884c\u7684\u8d44\u6e90\u8017\u8d39 \u5e76\u53d1\u6027\uff0c\u540c\u65f6\u53d1\u751f\u7684\u4e8b\u4ef6\u53d1\u751f\u53ef\u80fd\u591a\uff0c\u5982\u4f55\u5feb\u901f\u5730\u5904\u7406\u8fd9\u4e9b\u4e8b\u4ef6\u5462\uff1f\u663e\u7136\u8fd9\u5c31\u6d89\u53ca\u4e86concurrency\u7684\u95ee\u9898\uff0c\u5373\u5e76\u53d1\u5730\u6267\u884chandler\uff08event and concurrency\uff09 \u6240\u4ee5\u5f00\u53d1\u8005\u9700\u8981\u6839\u636e\u9700\u6c42\u9009\u62e9\u5408\u9002\u7684\u5b9e\u73b0\u65b9\u5f0f\u3002\u4e0b\u9762\u7f57\u5217\u4e00\u4e9b\u6267\u884c\u65b9\u5f0f\uff1a Single process single thread monitor\u548cexecutor\u4f4d\u4e8e\u540c\u4e00\u4e2a\u7ebf\u7a0b\uff0c\u8fd9\u79cd\u6bd4\u8f83\u9002\u5408event handler\u7684\u6267\u884c\u6210\u672c\u6bd4\u8f83\u5c0f\u7684\u60c5\u51b5\u3002 multi thread monitor\u548cexecutor\u5206\u522b\u5904\u4e8e\u4e24\u4e2a\u4e0d\u540c\u7684\u7ebf\u7a0b\uff0c\u8fd9\u79cd\u60c5\u51b5dispatcher\u7684\u5b9e\u73b0\u663e\u7136\u6d89\u53ca\u5230inter-thread communication\u3002 Multiple process monitor\u548cexecutor\u5206\u522b\u5904\u4e8e\u4e24\u4e2a\u4e0d\u540c\u7684\u8fdb\u7a0b\uff0c\u8fd9\u79cd\u60c5\u51b5dispatcher\u7684\u5b9e\u73b0\u663e\u7136\u6d89\u53cainter-process communication\u3002 \u5bf9\u4e8e\u8fd9\u79cd\u60c5\u51b5\uff0c\u53ef\u4ee5\u5c06\u6574\u4f53\u770b\u505a\u662f\u4e00\u4e2aevent-driven system\uff0c\u4e5f\u53ef\u4ee5\u770b\u505a\u662f\u591a\u4e2aevent-driven system\u8fdb\u884cpipeline\u3002 \u7ef4\u57fa\u767e\u79d1 Event-driven programming In computer programming , event-driven programming is a programming paradigm in which the flow of the program is determined by events such as user actions ( mouse clicks, key presses), sensor outputs, or messages from other programs or threads . Event-driven programming is the dominant paradigm used in graphical user interfaces and other applications (e.g., JavaScript web applications ) that are centered on performing certain actions in response to user input . This is also true of programming for device drivers (e.g., P in USB device driver stacks). In an event-driven application, there is generally a main loop that listens for events, and then triggers a callback function when one of those events is detected. In embedded systems , the same may be achieved using hardware interrupts instead of a constantly running main loop. Event-driven programs can be written in any programming language , although the task is easier in languages that provide high-level abstractions , such as await and closures . NOTE: \u7ef4\u57fa\u767e\u79d1\u7684\u8fd9\u7bc7\u6587\u7ae0\u5bf9event-driven programming\u603b\u7ed3\u5730\u975e\u5e38\u597d\u3002 Event handlers Main article: Event handler A trivial event handler Because the code for checking for events and the main loop are common amongst applications, many programming frameworks take care of their implementation and expect the user to provide only the code for the event handlers. NOTE: programming framework always do things common In this simple example there may be a call to an event handler called OnKeyEnter() that includes an argument with a string of characters, corresponding to what the user typed before hitting the ENTER key. To add two numbers, storage outside the event handler must be used. The implementation might look like below. Common uses In addition, systems such as Node.js are also event-driven. Pattern \u5b9e\u73b0event-driven model\u7684\u4e00\u4e9bpattern\u3002 Message queue Observer pattern Publish\u2013subscribe pattern \u4e00\u4e2a\u5178\u578b\u7684\u4f8b\u5b50\u5c31\u662fredis\u7684pub/sub \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0cpub\u9700\u8981\u6ce8\u518c\u56de\u8c03\u51fd\u6570\uff0c\u7528\u4e8e\u6307\u5b9a\u5f53\u6536\u5230\u4fe1\u606f\u65f6\uff0c\u9700\u8981\u6267\u884c\u7684\u52a8\u4f5c\u3002\u8fd9\u975e\u5e38\u7c7b\u4f3c\u4e8esignal handler\u3002 Actor model \u53c2\u89c1 Actor model Reactor pattern Proactor pattern Messaging pattern Framework/library \u53c2\u89c1 Event-library.md \u3002","title":"Event-driven-model"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#event-driven-model","text":"\u5728\u6587\u7ae0 Abstraction and model \u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 Event-driven model \uff0c\u5b83\u662f\u4e00\u4e2a\u975e\u5e38\u5f3a\u5927\u7684\u6a21\u578b\uff0c\u80fd\u591f\u63cf\u8ff0\u975e\u5e38\u975e\u5e38\u5e7f\u6cdb\u7684\u95ee\u9898\u3002\u5728\u672c\u6587\uff0c\u6211\u4eec\u5c06\u8bf4\u660e\u4ec0\u4e48\u662fevent-driven model\u3001\u4ec0\u4e48\u662fevent\u3001\u5982\u4f55\u5b9e\u73b0event-driven model\u3002","title":"Event-driven model"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#event-driven-model_1","text":"Event-driven model\u9700\u8981\u6301\u7eed\u4e0d\u65ad\u5730\u8fdb\u884c\u8fd0\u8f6c\u4ee5\u76d1\u63a7\u4e8b\u4ef6\u6e90\u3001\u6536\u96c6event\uff0c\u4e00\u65e6\u6536\u96c6\u5230\u4e86event\uff0c\u5c31\u8fdb\u884cdispatch\uff0c\u5373\u6839\u636eevent\u548cevent handler\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\uff0c\u8c03\u7528\u8fd9\u4e2aevent\u5bf9\u5e94\u7684event handler\u3002\u5176\u5b9e\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u5b83\u770b\u505a\u662f\u4e00\u4e2a**abstract machine**\u3002","title":"Event-driven model"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#on","text":"\u53ef\u4ee5\u4f7f\u7528Event-driven model\u6765\u8fdb\u884c\u63cf\u8ff0\u7684\u95ee\u9898\u7684\u4e00\u4e2a\u5178\u578b\u7684\u6a21\u5f0f\u5c31\u662f\uff1a\u5f53\u67d0\u4e2a\u4e8b\u4ef6\u53d1\u751f\u7684\u65f6\u5019\uff0c\u5c31\u6267\u884c\u67d0\u4e2a\u51fd\u6570\u3002\u6211\u89c9\u5f97\u8fd9\u79cd\u6a21\u5f0f\uff0c\u4f7f\u7528JavaScript\u6765\u8fdb\u884c\u63cf\u8ff0\u662f\u6700\u6700\u4fbf\u5229\u7684\u3002 https://www.w3schools.com/js/js_events.asp https://storm.cis.fordham.edu/~mesterharm/2350/event.html","title":"on"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#example","text":"\u7406\u89e3event-driven model\u7684\u6700\u6700\u7b80\u5355\u7684\u4f8b\u5b50\u5c31\u662flinux OS kernel\u548chardware\u7684\u4ea4\u4e92\uff0c\u5728\u5de5\u7a0b Linux-OS \u7684\u6587\u7ae0 Linux-OS-kernel-is-event-driven \u4e2d\u6211\u4eec\u5df2\u7ecf\u603b\u7ed3\u4e86\u53ef\u4ee5\u4f7f\u7528 Event-driven model \u6765\u63cf\u8ff0linux OS kernel\u548chardware\u7684\u4ea4\u4e92\u3002\u5728hardware\u5c42\uff0c\u4e00\u65e6\u901a\u7535\uff0c\u5219hardware\u5c31\u6301\u7eed\u4e0d\u65ad\u5730\u8fd0\u8f6c\u8d77\u6765\u4e86\uff0c\u4e00\u65e6\u89e6\u53d1\u4e86interrupt\uff0c\u5219\u5b83\u7684interrupt handler\u5c31\u4f1a\u88ab\u6267\u884c\u3002","title":"Example"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#event-driven-model_2","text":"\u4e00\u4e2aevent-driven model\u7684\u7ec4\u6210\u6210\u5206\uff1a monitor/listener\uff0c\u76d1\u63a7event event\u548cevent handler\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\u8868 dispatcher\uff0c\u6d3e\u53d1event\uff0c\u5373\u6309\u7167event\u548cevent handler\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\uff0c\u901a\u77e5executor\u6267\u884cevent handler executor\uff0c\u6267\u884cevent handler","title":"Event-driven model\u7684\u7ec4\u6210"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#what-is-event","text":"Event\u662f\u4e00\u4e2a\u975e\u5e38\u6982\u62ec\u3001\u5bbd\u6cdb\u7684\u6982\u5ff5\uff0c\u5728Event-driven model\u4e2d\uff0c\u975e\u5e38\u591a\u7684\u884c\u4e3a\u90fd\u4f1a\u4ea7\u751fevent\uff0c\u6211\u4eec\u628a\u5b83\u79f0\u4e3asource of event\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06source of event\u5212\u5206\u4e3a\u4e24\u7c7b\uff1a","title":"What is event?"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#external-environment","text":"\u6211\u4eec\u4ee5\u81ea\u5e95\u5411\u4e0a\u7684\u601d\u8def\u6765\u5206\u6790\u6e90\u81eaexternal environment\u7684event\uff0c\u4e00\u4e2a computing system \u7684\u6700\u5e95\u5c42\u662fhardware\uff0chardware\u4ea7\u751f\u7684 interrupt \uff0c\u7136\u540e\u7531OS kernel\u5c06\u8fd9\u4e9binterrupt\u201c\u8f6c\u6362\u201d\u4e3asignal\uff08\u73b0\u4ee3programming language\u4f1a\u4f7f\u7528exception\u6765\u62bd\u8c61signal\uff09\u3001IO\uff08\u56e0\u4e3aIO\u7684\u5b9e\u73b0\u662f\u4f9d\u8d56\u4e8einterrupt\u7684\uff0cIO\u5305\u62ec\u4e86\u975e\u5e38\u591a\u7684\u5185\u5bb9\uff0c\u7528\u6237\u64cd\u4f5c\u3001\u7f51\u7edc\u901a\u4fe1\u7b49\u90fd\u53ef\u4ee5\u770b\u505a\u662fIO\uff0cevents can represent availability of new data for reading a file or network stream.\uff09event\u7b49\uff0c\u5e76\u901a\u77e5\u5230application process\u3002 \u5173\u4e8e\u8fd9\u4e00\u70b9\uff0c\u53c2\u89c1\u7ef4\u57fa\u767e\u79d1 Event (computing) \u7684 Event handler \u6bb5\u3002","title":"external environment"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#_1","text":"Event\u53ef\u80fd\u6e90\u81ea\u4e8eexternal environment\uff0c\u4e5f\u53ef\u80fd\u6e90\u81ea\u4e8e\u7a0b\u5e8f\u4e4b\u5185\uff0c\u5373\u7a0b\u5e8f\u5185\u90e8\u5c06\u4e00\u4e9b\u6761\u4ef6\u7b49\u770b\u505aevent\uff0c\u6bd4\u5982condition variable\u3002 TODO: \u9700\u8981\u8865\u5145\u4e00\u4e9b\u5177\u4f53\u4f8b\u5b50\u3002 \u4e0b\u9762\u8865\u5145\u4e86\u7ef4\u57fa\u767e\u79d1 Event (computing) \u6765\u8fdb\u884c\u8be6\u7ec6\u8bf4\u660e\u3002","title":"\u7a0b\u5e8f\u5185\u90e8"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#event-computing","text":"","title":"\u7ef4\u57fa\u767e\u79d1Event (computing)"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#delegate-event-model","text":"NOTE: \u539f\u6587\u7684\u8fd9\u4e00\u6bb5\u6ca1\u6709\u8bfb\u61c2\u3002","title":"Delegate event model"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#event-driven-programming","text":"Event-driven programming\u544a\u8bc9\u6211\u4eec\u5982\u4f55\u5b9e\u73b0event-driven model\u3002","title":"Event-driven programming"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#event-driven-programming_1","text":"Event-driven model\u5b9e\u73b0\u4e2d\u9700\u8981\u8003\u8651\u7684\u4e00\u4e9b\u95ee\u9898\uff1a \u5982\u4f55\u58f0\u660eevent\u548cevent handler\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u663e\u7136event driven model\u9700\u8981\u8bb0\u5f55\u4e0bevent\u548cevent handler\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\uff1f \u5982\u4f55\u8fdb\u884c\u6301\u7eed\u76d1\u63a7\uff0c\u5373\u5982\u4f55\u5b9e\u73b0monitor\uff1f","title":"Event-driven programming\u4e2d\u9700\u8981\u8003\u8651\u7684\u4e00\u4e9b\u95ee\u9898"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#monitor","text":"\u5728\u786c\u4ef6\u5c42\uff0c\u53ea\u8981\u901a\u7535\u540e\uff0c\u5219hardware\u5c31\u6301\u7eed\u4e0d\u65ad\u5730\u8fd0\u8f6c\u8d77\u6765\u4e86\uff0c\u4e00\u65e6\u89e6\u53d1\u4e86interrupt\uff0c\u5219\u5b83\u7684interrupt handler\u5c31\u4f1a\u88ab\u6267\u884c\u3002\u5728\u8f6f\u4ef6\u5c42\uff0c\u6211\u4eec\u9700\u8981\u663e\u5f0f\u5730\u4f7f\u7528\u4e00\u4e2a main loop \u6765\u6307\u793a\u6574\u4e2amodel\u9700\u8981\u4e0d\u65ad\u5730\u8fd0\u8f6c\u4e0b\u53bb\u3002 \u5173\u4e8e\u8fd9\u4e00\u70b9\uff0c\u53c2\u89c1\u7ef4\u57fa\u767e\u79d1 Event-driven programming \u7684\u7b2c\u4e8c\u6bb5\u3002","title":"Monitor\uff1a\u5982\u4f55\u8fdb\u884c\u6301\u7eed\u76d1\u63a7"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#eventevent-handler","text":"Event-driven model\u80af\u5b9a\u9700\u8981\u8bb0\u5f55\u4e0bevent\u548cevent handler\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\uff0c\u5b9e\u73b0\u8fd9\u79cd\u6620\u5c04\u5173\u7cfb\u7684\u65b9\u5f0f\u662f\u975e\u5e38\u591a\u7684\uff0c\u53ef\u4ee5\u663e\u793a\u5730\u4f7f\u7528\u8bf8\u5982map\u7684\u6570\u636e\u7ed3\u6784\u3002 \u4e0b\u9762\u7f57\u5217\u4e86\u4e00\u4e9b\u5b9e\u73b0\u6848\u4f8b\uff1a","title":"\u5173\u8054event\u548cevent handler"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#interrupt-descriptor-table","text":"\u53c2\u89c1\uff1a\u5de5\u7a0b Linux-OS \u7684 4.2-Interrupts-and-Exceptions \u7684 4.2.3. Interrupt Descriptor Table \u7ef4\u57fa\u767e\u79d1 Interrupt descriptor table","title":"Interrupt Descriptor Table"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#dispatcher","text":"\u6240\u8c13\u7684event dispatcher\u662f\u6307\u5f53event\u53d1\u751f\u65f6\uff0cevent-driven model\u5c06event\u4f20\u9012\u5230executor\uff0c\u901a\u77e5executor\u6267\u884c\u5bf9\u5e94\u7684handler\u3002Dispatcher\u7684\u5b9e\u73b0\u65b9\u5f0f\u662f\u6709executor\u51b3\u5b9a\u7684\uff0c \u5728\u4e0b\u4e00\u8282\u5bf9\u6b64\u8fdb\u884c\u5177\u4f53\u60c5\u51b5\u5177\u4f53\u8bf4\u660e\u3002","title":"Dispatcher"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#executorexecution-of-event-handler","text":"\u5982\u4f55\u6765\u6267\u884cevent handler\uff1f\u5728\u51b3\u5b9a\u5982\u4f55\u6765\u6267\u884cevent handler\u7684\u65f6\u5019\uff0c\u5f00\u53d1\u8005\u9700\u8981\u8003\u8651\u5982\u4e0b\u95ee\u9898\uff1a event handler\u6267\u884c\u7684\u6210\u672c\uff0c\u6b64\u5904\u7684\u6210\u672c\u53ef\u4ee5\u6709\u591a\u79cd\u89e3\u91ca\uff0c\u6bd4\u5982\uff0c\u5b83\u53ef\u4ee5\u8868\u793aevent handler\u6267\u884c\u7684\u65f6\u957f\u3001\u53ef\u4ee5\u8868\u793aevent handler\u6267\u884c\u7684\u8d44\u6e90\u8017\u8d39 \u5e76\u53d1\u6027\uff0c\u540c\u65f6\u53d1\u751f\u7684\u4e8b\u4ef6\u53d1\u751f\u53ef\u80fd\u591a\uff0c\u5982\u4f55\u5feb\u901f\u5730\u5904\u7406\u8fd9\u4e9b\u4e8b\u4ef6\u5462\uff1f\u663e\u7136\u8fd9\u5c31\u6d89\u53ca\u4e86concurrency\u7684\u95ee\u9898\uff0c\u5373\u5e76\u53d1\u5730\u6267\u884chandler\uff08event and concurrency\uff09 \u6240\u4ee5\u5f00\u53d1\u8005\u9700\u8981\u6839\u636e\u9700\u6c42\u9009\u62e9\u5408\u9002\u7684\u5b9e\u73b0\u65b9\u5f0f\u3002\u4e0b\u9762\u7f57\u5217\u4e00\u4e9b\u6267\u884c\u65b9\u5f0f\uff1a","title":"Executor\uff1aexecution of event handler"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#single-process","text":"","title":"Single process"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#single-thread","text":"monitor\u548cexecutor\u4f4d\u4e8e\u540c\u4e00\u4e2a\u7ebf\u7a0b\uff0c\u8fd9\u79cd\u6bd4\u8f83\u9002\u5408event handler\u7684\u6267\u884c\u6210\u672c\u6bd4\u8f83\u5c0f\u7684\u60c5\u51b5\u3002","title":"single thread"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#multi-thread","text":"monitor\u548cexecutor\u5206\u522b\u5904\u4e8e\u4e24\u4e2a\u4e0d\u540c\u7684\u7ebf\u7a0b\uff0c\u8fd9\u79cd\u60c5\u51b5dispatcher\u7684\u5b9e\u73b0\u663e\u7136\u6d89\u53ca\u5230inter-thread communication\u3002","title":"multi thread"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#multiple-process","text":"monitor\u548cexecutor\u5206\u522b\u5904\u4e8e\u4e24\u4e2a\u4e0d\u540c\u7684\u8fdb\u7a0b\uff0c\u8fd9\u79cd\u60c5\u51b5dispatcher\u7684\u5b9e\u73b0\u663e\u7136\u6d89\u53cainter-process communication\u3002 \u5bf9\u4e8e\u8fd9\u79cd\u60c5\u51b5\uff0c\u53ef\u4ee5\u5c06\u6574\u4f53\u770b\u505a\u662f\u4e00\u4e2aevent-driven system\uff0c\u4e5f\u53ef\u4ee5\u770b\u505a\u662f\u591a\u4e2aevent-driven system\u8fdb\u884cpipeline\u3002","title":"Multiple process"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#event-driven-programming_2","text":"In computer programming , event-driven programming is a programming paradigm in which the flow of the program is determined by events such as user actions ( mouse clicks, key presses), sensor outputs, or messages from other programs or threads . Event-driven programming is the dominant paradigm used in graphical user interfaces and other applications (e.g., JavaScript web applications ) that are centered on performing certain actions in response to user input . This is also true of programming for device drivers (e.g., P in USB device driver stacks). In an event-driven application, there is generally a main loop that listens for events, and then triggers a callback function when one of those events is detected. In embedded systems , the same may be achieved using hardware interrupts instead of a constantly running main loop. Event-driven programs can be written in any programming language , although the task is easier in languages that provide high-level abstractions , such as await and closures . NOTE: \u7ef4\u57fa\u767e\u79d1\u7684\u8fd9\u7bc7\u6587\u7ae0\u5bf9event-driven programming\u603b\u7ed3\u5730\u975e\u5e38\u597d\u3002","title":"\u7ef4\u57fa\u767e\u79d1Event-driven programming"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#event-handlers","text":"Main article: Event handler","title":"Event handlers"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#a-trivial-event-handler","text":"Because the code for checking for events and the main loop are common amongst applications, many programming frameworks take care of their implementation and expect the user to provide only the code for the event handlers. NOTE: programming framework always do things common In this simple example there may be a call to an event handler called OnKeyEnter() that includes an argument with a string of characters, corresponding to what the user typed before hitting the ENTER key. To add two numbers, storage outside the event handler must be used. The implementation might look like below.","title":"A trivial event handler"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#common-uses","text":"In addition, systems such as Node.js are also event-driven.","title":"Common uses"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#pattern","text":"\u5b9e\u73b0event-driven model\u7684\u4e00\u4e9bpattern\u3002","title":"Pattern"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#message-queue","text":"","title":"Message queue"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#observer-pattern","text":"","title":"Observer pattern"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#publishsubscribe-pattern","text":"\u4e00\u4e2a\u5178\u578b\u7684\u4f8b\u5b50\u5c31\u662fredis\u7684pub/sub \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0cpub\u9700\u8981\u6ce8\u518c\u56de\u8c03\u51fd\u6570\uff0c\u7528\u4e8e\u6307\u5b9a\u5f53\u6536\u5230\u4fe1\u606f\u65f6\uff0c\u9700\u8981\u6267\u884c\u7684\u52a8\u4f5c\u3002\u8fd9\u975e\u5e38\u7c7b\u4f3c\u4e8esignal handler\u3002","title":"Publish\u2013subscribe pattern"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#actor-model","text":"\u53c2\u89c1 Actor model","title":"Actor model"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#reactor-pattern","text":"","title":"Reactor pattern"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#proactor-pattern","text":"","title":"Proactor pattern"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#messaging-pattern","text":"","title":"Messaging pattern"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-driven-model/#frameworklibrary","text":"\u53c2\u89c1 Event-library.md \u3002","title":"Framework/library"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-message-passing/","text":"Event/message passing \u8981\u5b9e\u73b0event passing\uff0c\u662f\u6709\u591a\u79cd\u65b9\u5f0f\u53ef\u9009\u7684\u3002 Inter-process communication Message queue \u53c2\u89c1 Message queue AMQP\u53c2\u89c1 Advanced Message Queuing Protocol Inter-thread communication condition variable \u53c2\u89c1 Monitor (synchronization) \u5728youdao notebook\u7684\u300a cppreference-std-condition_variable.md \u300b\u4e2d\uff0c\u5bf9condition variable\u548cevent passing\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb\u8fdb\u884c\u4e86\u6bd4\u8f83\u6df1\u523b\u7684\u5206\u6790\uff1b Messaging pattern Publish\u2013subscribe pattern \u4e00\u4e2a\u5178\u578b\u7684\u4f8b\u5b50\u5c31\u662fredis\u7684pub/sub \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0cpub\u9700\u8981\u6ce8\u518c\u56de\u8c03\u51fd\u6570\uff0c\u7528\u4e8e\u6307\u5b9a\u5f53\u6536\u5230\u4fe1\u606f\u65f6\uff0c\u9700\u8981\u6267\u884c\u7684\u52a8\u4f5c\u3002\u8fd9\u975e\u5e38\u7c7b\u4f3c\u4e8esignal handler\u3002","title":"Event-message-passing"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-message-passing/#eventmessage-passing","text":"\u8981\u5b9e\u73b0event passing\uff0c\u662f\u6709\u591a\u79cd\u65b9\u5f0f\u53ef\u9009\u7684\u3002","title":"Event/message passing"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-message-passing/#inter-process-communication","text":"","title":"Inter-process communication"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-message-passing/#message-queue","text":"\u53c2\u89c1 Message queue AMQP\u53c2\u89c1 Advanced Message Queuing Protocol","title":"Message queue"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-message-passing/#inter-thread-communication","text":"","title":"Inter-thread communication"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-message-passing/#condition-variable","text":"\u53c2\u89c1 Monitor (synchronization) \u5728youdao notebook\u7684\u300a cppreference-std-condition_variable.md \u300b\u4e2d\uff0c\u5bf9condition variable\u548cevent passing\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb\u8fdb\u884c\u4e86\u6bd4\u8f83\u6df1\u523b\u7684\u5206\u6790\uff1b","title":"condition variable"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-message-passing/#messaging-pattern","text":"","title":"Messaging pattern"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-message-passing/#publishsubscribe-pattern","text":"\u4e00\u4e2a\u5178\u578b\u7684\u4f8b\u5b50\u5c31\u662fredis\u7684pub/sub \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0cpub\u9700\u8981\u6ce8\u518c\u56de\u8c03\u51fd\u6570\uff0c\u7528\u4e8e\u6307\u5b9a\u5f53\u6536\u5230\u4fe1\u606f\u65f6\uff0c\u9700\u8981\u6267\u884c\u7684\u52a8\u4f5c\u3002\u8fd9\u975e\u5e38\u7c7b\u4f3c\u4e8esignal handler\u3002","title":"Publish\u2013subscribe pattern"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-stream-processing/","text":"Event stream processing \u7ef4\u57fa\u767e\u79d1 Event stream processing","title":"Event-stream-processing"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-stream-processing/#event-stream-processing","text":"","title":"Event stream processing"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-stream-processing/#event-stream-processing_1","text":"","title":"\u7ef4\u57fa\u767e\u79d1Event stream processing"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/Event-loop-and-multithread/","text":"Single Threaded Event Loop vs Multi Threaded Non Blocking Worker in Node.JS Node.JS biggest advantage is it's non blocking nature. It's single threaded, so it doesn't need to spawn a new thread for each new incoming connection. Behind the event-loop (which is in fact single threaded ), there is a \"Non blocking Worker\". This thing is not single threaded anymore, so (as far as I understood) it can spawn a new thread for each task. Maybe I misunderstood something, but where exactly is the advantage. If there are to many tasks to handle, wouldn't be the Non Blocking Working turn into a Blocking Worker? Thanks Christian A You need to read about libuv , the \"magic\" behind node's non-blocking I/O. The important thing to take away from the libuv book is that libuv uses the host OS's asynchronous I/O facilities ; it does not simply create a new thread for every connection. libuv tells the OS that it would like to know about any changes (connection state, data received, etc) that happen on a particular set of sockets . It is then up to the OS to deal with managing the connections. The OS itself may create one or more threads to accomplish that, but that's not our concern. (And it certainly won't create a thread for every connection.) For other types of operations like calls to C libraries that may be computationally expensive (ie crypto), libuv provides a thread pool on which those operations may run. Since it is a thread pool, again you don't have to worry about thread count growing without bound. When the pool is fully busy, operations are queued. So yes, JavaScript runs on a single thread . Yes, node (via libuv) spawns many threads in the background to do work so that it need not block the JavaScript thread. However, the thread count is always controlled, and I/O generally doesn't even get its own node-allocated thread because that's handled by the OS. A Alright, let's break this down a bit. Single threaded applications have advantages: you can never get deadlocks or race conditions. These issues stem from simultaneous memory access in multi-threaded systems. If two threads access the same piece of information weird things can happen. So why does JavaScript have Workers? If you need do some heavy processing you're going to block the event loop, you could try to split up the workload by generating timer events but that's tedious. A Worker allows you to spawn a thread under one condition: no shared memory access . This solves the issue of heavy processing in a single threaded environment while avoiding the pitfalls of multi-threaded environments (deadlocks, race-conditions). And as @dandavis said, if you have a multi-core CPU (which everyone does these days) the Worker threads can be offloaded to the other cores. You have to appreciate that, although JavaScript is single threaded, the environment around it is still very much multi-threaded. Reading a file is non-blocking in Node.JS but there is likely a thread to support it in the OS. As a minor addendum I would say that Node.JS's biggest advantage is that it allows you to write JavaScript on the server, which allows you to share code between the client and the server. The fact that it's non-blocking is nice but threads already solve that. The non-blocking IO stems from the single threaded-ness. It's very inconvenient to have a single thread with blocking IO. Threads vs Event Loop, Again I still get asked this, from time to time. Maybe it\u2019s because I only use event loops , maybe it\u2019s because I\u2019ve written libuEv , or maybe people still don\u2019t understand: Why an event loop, why not use threads? So here\u2019s my response, once more. With the advent of light-weight processes (threads) programmers these days have a golden hammer they often swing without consideration. Event loops and non-blocking I/O is often a far easier approach, as well as less error prone. The purpose of many applications is, with a little logic sprinkled on top, to act on network packets entering an interface, timeouts expiring, mouse clicks, or other types of events. Such applications are often very well suited to use an event loop . SUMMARY : \u9002\u5408event loop\u7684\u60c5\u5f62 Applications that need to churn massively parallel algorithms are more suitable for running multiple (independent) threads on several CPU cores. However, threaded applications must deal with the side effects of concurrency, like race conditions, deadlocks, live locks, etc. Writing error free threaded applications is hard, debugging them can be even harder. SUMMARY : \u9002\u5408multiple threads\u7684\u60c5\u5f62 Sometimes the combination of multiple threads and an event loop per thread can be the best approach, but each application of course needs to be broken down individually to find the most optimal approach. Do keep in mind, however, that not all systems your application will run on have multiple CPU cores \u2013 some small embedded systems still use a single CPU core, even though they run Linux, with multiple threads a program may actually run slower! Always profile your program, and if possible, test it on different architectures. SUMMARY : combine event loop and multiple threads 20190710 \u73b0\u5728\u60f3\u60f3\uff0c\u5176\u5b9e\u8fd9\u4e2a\u95ee\u9898\u66f4\u5e94\u8be5\u662freactor\u548cmultithread\u4e4b\u95f4\u7684\u5f02\u4e0e\u540c","title":"[Single Threaded Event Loop vs Multi Threaded Non Blocking Worker in Node.JS](https://stackoverflow.com/questions/21485920/single-threaded-event-loop-vs-multi-threaded-non-blocking-worker-in-node-js)"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/Event-loop-and-multithread/#single-threaded-event-loop-vs-multi-threaded-non-blocking-worker-in-nodejs","text":"Node.JS biggest advantage is it's non blocking nature. It's single threaded, so it doesn't need to spawn a new thread for each new incoming connection. Behind the event-loop (which is in fact single threaded ), there is a \"Non blocking Worker\". This thing is not single threaded anymore, so (as far as I understood) it can spawn a new thread for each task. Maybe I misunderstood something, but where exactly is the advantage. If there are to many tasks to handle, wouldn't be the Non Blocking Working turn into a Blocking Worker? Thanks Christian","title":"Single Threaded Event Loop vs Multi Threaded Non Blocking Worker in Node.JS"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/Event-loop-and-multithread/#a","text":"You need to read about libuv , the \"magic\" behind node's non-blocking I/O. The important thing to take away from the libuv book is that libuv uses the host OS's asynchronous I/O facilities ; it does not simply create a new thread for every connection. libuv tells the OS that it would like to know about any changes (connection state, data received, etc) that happen on a particular set of sockets . It is then up to the OS to deal with managing the connections. The OS itself may create one or more threads to accomplish that, but that's not our concern. (And it certainly won't create a thread for every connection.) For other types of operations like calls to C libraries that may be computationally expensive (ie crypto), libuv provides a thread pool on which those operations may run. Since it is a thread pool, again you don't have to worry about thread count growing without bound. When the pool is fully busy, operations are queued. So yes, JavaScript runs on a single thread . Yes, node (via libuv) spawns many threads in the background to do work so that it need not block the JavaScript thread. However, the thread count is always controlled, and I/O generally doesn't even get its own node-allocated thread because that's handled by the OS.","title":"A"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/Event-loop-and-multithread/#a_1","text":"Alright, let's break this down a bit. Single threaded applications have advantages: you can never get deadlocks or race conditions. These issues stem from simultaneous memory access in multi-threaded systems. If two threads access the same piece of information weird things can happen. So why does JavaScript have Workers? If you need do some heavy processing you're going to block the event loop, you could try to split up the workload by generating timer events but that's tedious. A Worker allows you to spawn a thread under one condition: no shared memory access . This solves the issue of heavy processing in a single threaded environment while avoiding the pitfalls of multi-threaded environments (deadlocks, race-conditions). And as @dandavis said, if you have a multi-core CPU (which everyone does these days) the Worker threads can be offloaded to the other cores. You have to appreciate that, although JavaScript is single threaded, the environment around it is still very much multi-threaded. Reading a file is non-blocking in Node.JS but there is likely a thread to support it in the OS. As a minor addendum I would say that Node.JS's biggest advantage is that it allows you to write JavaScript on the server, which allows you to share code between the client and the server. The fact that it's non-blocking is nice but threads already solve that. The non-blocking IO stems from the single threaded-ness. It's very inconvenient to have a single thread with blocking IO.","title":"A"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/Event-loop-and-multithread/#threads-vs-event-loop-again","text":"I still get asked this, from time to time. Maybe it\u2019s because I only use event loops , maybe it\u2019s because I\u2019ve written libuEv , or maybe people still don\u2019t understand: Why an event loop, why not use threads? So here\u2019s my response, once more. With the advent of light-weight processes (threads) programmers these days have a golden hammer they often swing without consideration. Event loops and non-blocking I/O is often a far easier approach, as well as less error prone. The purpose of many applications is, with a little logic sprinkled on top, to act on network packets entering an interface, timeouts expiring, mouse clicks, or other types of events. Such applications are often very well suited to use an event loop . SUMMARY : \u9002\u5408event loop\u7684\u60c5\u5f62 Applications that need to churn massively parallel algorithms are more suitable for running multiple (independent) threads on several CPU cores. However, threaded applications must deal with the side effects of concurrency, like race conditions, deadlocks, live locks, etc. Writing error free threaded applications is hard, debugging them can be even harder. SUMMARY : \u9002\u5408multiple threads\u7684\u60c5\u5f62 Sometimes the combination of multiple threads and an event loop per thread can be the best approach, but each application of course needs to be broken down individually to find the most optimal approach. Do keep in mind, however, that not all systems your application will run on have multiple CPU cores \u2013 some small embedded systems still use a single CPU core, even though they run Linux, with multiple threads a program may actually run slower! Always profile your program, and if possible, test it on different architectures. SUMMARY : combine event loop and multiple threads","title":"Threads vs Event Loop, Again"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/Event-loop-and-multithread/#20190710","text":"\u73b0\u5728\u60f3\u60f3\uff0c\u5176\u5b9e\u8fd9\u4e2a\u95ee\u9898\u66f4\u5e94\u8be5\u662freactor\u548cmultithread\u4e4b\u95f4\u7684\u5f02\u4e0e\u540c","title":"20190710"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/Event-loop/","text":"Event loop \u7ef4\u57fa\u767e\u79d1 Event loop In computer science , the event loop , message dispatcher , message loop , message pump , or run loop is a programming construct that waits for and dispatches events or messages in a program . It works by making a request to some internal or external \"event provider\" (that generally blocks the request until an event has arrived), and then it calls the relevant event handler (\"dispatches the event\"). The event-loop may be used in conjunction with a reactor , if the event provider follows the file interface , which can be selected or 'polled' (the Unix system call, not actual polling ). The event loop almost always operates asynchronously with the message originator. NOTE:\u5173\u4e8e\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\"that generally blocks the request until an event has arrived\"\u7684\u89e3\u91ca\uff1a\u5b83\u662f\u6307\u901a\u5e38\u60c5\u51b5\u4e0b\uff0c\u4e3a\u4e86\u6548\u7387\u8d77\u89c1\uff0cevent provider\u5728\u6ca1\u6709event\u7684\u65f6\u5019\u4f1ablock \u6389event loop\u67e5\u8be2event\u7684\u8bf7\u6c42\uff0credis\u7684 BRPOP \u548c BLPOP \u5c31\u662f\u6309\u7167\u8fd9\u79cd\u601d\u8def\u6765\u5b9e\u73b0\u7684\uff0c\u5728 \u8fd9\u7bc7\u6587\u7ae0 \u4e2d\u5bf9\u8fd9\u4e9b\u8fdb\u884c\u4e86\u8be6\u7ec6\u4ecb\u7ecd\u3002 \u5176\u5b9e\uff0c\u4ece\u8fd9\u91cc\u4e5f\u53ef\u4ee5\u770b\u51fablock\u548casynchronous\u4e4b\u95f4\u7684\u5dee\u5f02\u6240\u5728\u3002 When the event loop forms the central control flow construct of a program, as it often does, it may be termed(\u79f0\u4e4b\u4e3a) the main loop or main event loop . This title is appropriate, because such an event loop is at the highest level of control within the program. Message passing Message pumps are said to 'pump' messages from the program's message queue (assigned and usually owned by the underlying operating system) into the program for processing. In the strictest sense, an event loop is one of the methods for implementing inter-process communication . In fact, message processing exists in many systems, including a kernel-level component of the Mach operating system . The event loop is a specific implementation technique of systems that use message passing . Alternative designs This approach is in contrast to a number of other alternatives: Traditionally, a program simply ran once, then terminated. This type of program was very common in the early days of computing, and lacked any form of user interactivity. This is still used frequently, particularly in the form of command-line-driven programs. Any parameters are set up in advance and passed in one go when the program starts. Menu-driven designs. These still may feature a main loop, but are not usually thought of as event driven in the usual sense[ citation needed ]. Instead, the user is presented with an ever-narrowing set of options until the task they wish to carry out is the only option available. Limited interactivity through the menus is available. Usage Due to the predominance(\u4f18\u52bf) of graphical user interfaces , most modern applications feature a main loop . The get_next_message() routine is typically provided by the operating system , and blocks until a message is available. Thus, the loop is only entered when there is something to process. function main initialize() while message != quit message := get_next_message() process_message(message) end while end function File interface Under Unix , the \" everything is a file \" paradigm naturally leads to a file-based event loop . Reading from and writing to files, inter-process communication, network communication, and device control are all achieved using file I/O , with the target identified by a file descriptor . The select and poll system calls allow a set of file descriptors to be monitored for a change of state, e.g. when data becomes available to be read. For example, consider a program that reads from a continuously updated file and displays its contents in the X Window System , which communicates with clients over a socket (either Unix domain or Berkeley ): main(): file_fd = open (\"logfile\") x_fd = open_display () construct_interface () while changed_fds = select ({file_fd, x_fd}): if file_fd in changed_fds: data = read_from (file_fd) append_to_display (data) send_repaint_message () if x_fd in changed_fds: process_x_messages () Handling signals One of the few things in Unix that does not conform to the file interface are asynchronous events ( signals ). Signals are received in signal handlers , small, limited pieces of code that run while the rest of the task is suspended; if a signal is received and handled while the task is blocking in select() , select will return early with EINTR ; if a signal is received while the task is CPU bound , the task will be suspended between instructions until the signal handler returns. Thus an obvious way to handle signals is for signal handlers to set a global flag and have the event loop check for the flag immediately before and after the select() call; if it is set, handle the signal in the same manner as with events on file descriptors . Unfortunately, this gives rise to a race condition : if a signal arrives immediately between checking the flag and calling select() , it will not be handled until select() returns for some other reason (for example, being interrupted by a frustrated user). NOTE: \u4e0a\u8ff0\u8fd9\u79cd\u601d\u8def\u53ef\u4ee5\u53c2\u89c1\uff1a Interrupting blocked read \u4e2d\u7ed9\u51fa\u7684demo\uff1b NOTE : \u4e0d\u5e78\u7684\u662f\uff0c\u8fd9\u4f1a\u5f15\u8d77\u7ade\u4e89\u6761\u4ef6\uff1a\u5982\u679c\u4fe1\u53f7\u5728\u68c0\u67e5\u6807\u5fd7\u548c\u8c03\u7528select\uff08\uff09\u4e4b\u95f4\u7acb\u5373\u5230\u8fbe\uff0c\u5219\u76f4\u5230select\uff08\uff09\u56e0\u67d0\u4e9b\u5176\u4ed6\u539f\u56e0\uff08\u4f8b\u5982\u88ab\u6cae\u4e27\u7684\u7528\u6237\u4e2d\u65ad\uff09\u8fd4\u56de\u65f6\u624d\u4f1a\u5904\u7406\u5b83\uff1b\u8fd9\u6bb5\u8bdd\u4e2d\u6240\u63cf\u8ff0\u7684race condition\u5e76\u6ca1\u6709\u641e\u6e05\u695a\uff1b The solution arrived at by POSIX is the pselect() call, which is similar to select() but takes an additional sigmask parameter, which describes a signal mask . This allows an application to mask signals in the main task , then remove the mask for the duration of the select() call such that signal handlers are only called while the application is I/O bound . However, implementations of pselect() have only recently[ when? ] become reliable; versions of Linux prior to 2.6.16 do not have a pselect() system call, forcing glibc to emulate it via a method prone to the very same race condition pselect() is intended to avoid. An alternative, more portable solution, is to convert asynchronous events to file-based events using the self-pipe trick ,[ 1] where \"a signal handler writes a byte to a pipe whose other end is monitored by select() in the main program\".[ 2] In Linux kernel version 2.6.22, a new system call signalfd() was added, which allows receiving signals via a special file descriptor . SUMMARY :\u53c2\u89c1\u300athe linux program interface \u300b\u7684 63.5.2 The Self-Pipe Trick Is an event loop just a for/while loop with optimized polling? NOTE:\u770b\u4e86\u8fd9\u4e48\u591a\uff0c\u53d1\u73b0\u63d0\u95ee\u8005\u7684\u6700\u7ec8\u610f\u56fe\u662f\u60f3\u8981\u77e5\u9053event loop\u662f\u5982\u4f55\u5b9e\u73b0\u7684\uff0c\u63d0\u95ee\u8005\u8ba4\u4e3aevent loop\u7684\u5b9e\u73b0\u65b9\u5f0f\u662f\u7c7b\u4f3cpolling\u7684\uff1b\u6839\u636e\u4e0b\u9762\u7684\u56de\u7b54\uff0c\u663e\u7136\u7b54\u6848\u662fNo\u3002\u7b54\u6848 A4 \u662f\u975e\u5e38\u76f4\u63a5\u7684\u7ed9\u51fa\u4e86\u7b54\u6848\uff1b\u5b83\u5f15\u7528\u4e86Wikipedia\u7684\u4e0a\u7684 Polling \u6587\u7ae0\uff0c\u5728\u8fd9\u7bc7\u6587\u7ae0\u4e2d\uff0c\u6709\u4e0b\u9762\u7684\u4e00\u6bb5\u8bdd\uff1a Although not as wasteful of CPU cycles as busy waiting, this is generally not as efficient as the alternative to polling, interrupt -driven I/O. \u8fd9\u6bb5\u8bdd\u4e2d\u7684 interrupt -driven I/O\u6b63\u662fevent loop\u6240\u91c7\u7528\u7684\u3002 I'm trying to understand what an event loop is. Often the explanation is that in an event loop, you do something until you're notified that an event has occurred. You then handle the event and continue doing what you were doing before. keyword \uff1anotify To map the above definition with an example. I have a server which 'listens' in a event loop, and when a socket connection is detected, the data from it gets read and displayed, after which the server resumes/starts listening as it did before. However, this event happening and us getting notified 'just like that' are to much for me to handle. You can say: \"It's not 'just like that' you have to register an event listener\". But what's an event listener but a function which for some reason isn't returning. Is it in it's own loop, waiting to be notified when an event happens? Should the event listener also register an event listener? Where does it end? Events are a nice abstraction to work with, however just an abstraction. I believe that in the end, polling is unavoidable . Perhaps we are not doing it in our code, but the lower levels (the programming language implementation or the OS) are doing it for us. NOTE: \u4ece\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u53ef\u4ee5\u770b\u51fa\uff0c\u63d0\u95ee\u8005\u7684\u6700\u7ec8\u610f\u56fe\u662f\u60f3\u8981\u77e5\u9053event loop\u5230\u5e95\u662f\u5982\u4f55\u5b9e\u73b0\u7684\u3002 It basically comes down to the following pseudo code which is running somewhere low enough so it doesn't result in busy waiting: while(True): do stuff check if event has happened (poll) do other stuff This is my understanding of the whole idea, and I would like to hear if this is correct. I'm open in accepting that the whole idea is fundamentally wrong, in which case I would like the correct explanation. COMMENTS Event systems are implementations of the Observer pattern . Understanding the pattern should cement your understanding of events. No polling is required. \u2013 Steven Evers Oct 18 '13 at 20:21 Ultimately yes, even if language constructs abstract it away. \u2013 GrandmasterB Oct 18 '13 at 20:30 @SteveEvers In your wiki link. What is the EventSource doing if not polling the keyboard input? \u2013 TheMeaningfulEngineer Oct 18 '13 at 20:36 @Alan : It could be doing anything, but for keyboard input specifically there do exist APIs to register your application as listening to keyboard events, which you can then use as your eventsource with no polling involved. Of course, if you go down far enough, USB is always polling, but let's assume we're using a PS/2 keyboard, which is interrupt driven, and then you have a keyboard input stack based on events with zero polling.\u2013 Phoshi Oct 25 '13 at 8:25 I've had this questions since years, but I can't tell why I never bothered to ask it. Thanks, I am now satisfied with the understanding @Karl Bielefeldt has enlightened me with. \u2013 0xc0de Dec 2 '18 at 5:03 A1 Most event loops will suspend if there are no events ready(\u6ca1\u6709event\u5c31\u7eea\uff0c\u5219event loop\u5c31\u4f1a\u88ab\u6302\u8d77), which means the operating system will not give the task any execution time until an event happens. NOTE:\u8fd9\u6bb5\u8bdd\u5c31\u76f4\u63a5\u70b9\u660e\u4e86event loop\u548cpolling\u4e4b\u95f4\u7684\u5dee\u5f02\u6240\u5728\u3002 Say the event is a key being pressed. You might ask if there's a loop somewhere in the operating system checking for keypresses. The answer is no. Keys being pressed generate an interrupt , which is handled asynchronously by the hardware. Likewise for timers, mouse movements, a packet arriving, etc. NOTE: interrupt \u662f\u7ed5\u5f00loop\u7684\u4e00\u79cd\u975e\u5e38\u597d\u7684\u65b9\u5f0f\uff0c\u8fd9\u5c31\u662f\u5b9e\u73b0event loop\u7684\u4e00\u79cd\u975e\u5e38\u597d\u7684\u65b9\u5f0f\u3002 In fact, for most operating systems, polling for events is the abstraction\uff08\u4e5f\u5c31\u662f\u8bf4\u5b9e\u73b0\u53ef\u80fd\u5e76\u975e\u5982\u6b64\uff09. The hardware and OS handle events asynchronously and put them in a queue that can be polled by applications. You only really see true polling at the hardware level in embedded systems, and even there not always. \u8ba8\u8bba\uff1a Isn't an interrupt a change of voltage on a wire? Can that trigger an event by itself or must we poll the pin for the voltage value? \u2013 TheMeaningfulEngineer That can trigger an event by itself. The processor is designed that way. In fact a processor can be woken up from sleep by an interrupt. \u2013 Karl Bielefeldt I am confused with the statement Most event loops will block . How does this fit into the \"the event loop paradigm, opposed to using threads, uses nonblocking asynchronous calls\"? \u2013 TheMeaningfulEngineer If you look at event loops for a library like GTK+, they check for new events then call event handlers in a loop, but if there aren't any events, they block on a semaphore or a timer or something. Individual developers make their own event loops that don't block on an empty event queue, but the widely-used libraries all block. Event loops are too inefficient otherwise. \u2013 Karl Bielefeldt SUMMARY :\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u6307\u51fa\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u5982empty queue\uff0cevent loop\u5c06\u88abblock\uff0c\u663e\u7136\u8fd9\u5c31\u89e3\u91ca\u4e86 Most event loops will block \uff1b\u81f3\u4e8e How does this fit into the \"the event loop paradigm, opposed to using threads, uses nonblocking asynchronous calls\"\uff0c\u6211\u60f3\u8fd9\u4e2a\u95ee\u9898\u4e2d\u6240\u63cf\u8ff0\u7684\u662f\u6307\uff0c\u5f53event loop\u88ab\u901a\u77e5\u67d0\u4e2aevent\u7684\u65f6\u5019\uff0c\u5b83\u6267\u884cevent handler\u662f\u91c7\u7528\u7684nonblocking asynchronous calls\u3002 A2 Event systems are implementations of the Observer pattern . Understanding the pattern should cement your understanding of events. No polling is required. \u2013 Steven Evers A3 I think of an event listener not as a function running its own loop, but as a relay race\uff08\u63a5\u529b\u6bd4\u8d5b\uff09 with the first runner waiting for the starting gun. A significant reason for using events instead of polling is that they are more efficient with CPU cycles. Why? Look at it from the hardware up (rather than the source code down). Consider a Web server. When your server calls listen() and blocks, your code is taking its place as a relay runner. When the first packet of a new connection arrives, the network card starts the race by interrupting \uff08\u4e2d\u65ad\uff09 the operating system. The OS runs an interrupt service routine (ISR) that grabs the packet. The ISR passes the baton\uff08\u63a5\u529b\u68d2\uff09 to a higher-level routine that establishes the connection. Once the connection is alive, that routine passes the baton to listen() , which passes the baton up to your code. At that point, you can do what you want with the connection. For all we know, between races each relay runner could be going to the pub. A strength of the event abstraction is that your code doesn't have to know or care. SUMMARY :\u4e0a\u9762\u5bf9\u89e6\u53d1\u5f0f\u7684\u6bd4\u55bb\u6bd4\u8f83\u5f62\u8c61\uff1b\u611f\u89c9\u8fd9\u975e\u5e38\u50cf\u7ecf\u5178\u7684Unix\u7f51\u7edc\u7f16\u7a0b\u6a21\u578b\u3002 Some operating systems include event-handling code that runs its portion of the race, hands off the baton, then loops back to its starting point to wait for the next race to start. In that sense, event handling is optimized polling in lots of concurrent loops. However, there is always an outside trigger that kicks off the process. The event listener is not a function that isn't returning, but a function that is waiting for that external trigger before it runs. Rather than: while(True): do stuff check if event has happened (poll) do other stuff I think of this as: on(some event): //I got the baton do stuff signal the next level up //Pass the baton and between the signal and the next time the handler runs, there is conceptually no code running or looping. SUMMARY :\u5bf9\u6bd4\u4e0a\u9762\u4e24\u6bb5\u4f2a\u4ee3\u7801\uff0con\u53ef\u4ee5\u7ffb\u8bd1\u4e3a\u201c\u5f53\u201d\uff0c\u8fd9\u662f\u975e\u5e38\u5951\u5408interrupt\u7684\uff1b A4 No. It is not \"optimized polling.\" An event-loop uses interrupt-driven I/O instead of polling. While, Until, For, etc. loops are polling loops. \"Polling\" is the process of repeatedly checking something. Since the loop code executes continuously, and because it is a small, \"tight\" loop, there is little time for the processor to switch tasks and do anything else. Almost all \"hangs,\" \"freezes,\" \"lockups\" or whatever you want to call it when the computer becomes unresponsive, are the manifestation\uff08\u5c55\u793a\uff09 of code being stuck in an unintended polling loop. Instrumentation will show 100% CPU usage. Interrupt-driven event loops are far more efficient than polling loops. Polling is an extremely wasteful use of CPU cycles so every effort is made to eliminate or minimize it. However, to optimize code quality, most languages try to use the polling loop paradigm as closely as possible for event handing commands since they serve functionally similar purposes within a program\uff08\u56e0\u4e3a\u5b83\u4eec\u5728\u7a0b\u5e8f\u4e2d\u63d0\u4f9b\u529f\u80fd\u4e0a\u7c7b\u4f3c\u7684\u7528\u9014\uff09. Thus, with polling being the more familiar way to wait for a keypress or something, it is easy for the inexperienced\uff08\u4e0d\u719f\u7ec3\u7684\uff09 to use it and wind up with a program that may run fine by itself\uff08\u6700\u7ec8\u4f7f\u7528\u53ef\u80fd\u81ea\u884c\u8fd0\u884c\u7684\u7a0b\u5e8f\uff09, but nothing else works while it's running. It has \"taken over\" the machine. As explained in other answers, in interrupt-driven event handing , essentially a \"flag\" is set within the CPU and the process is \"suspended\" (not allowed to run) until that flag is changed by some other process (such as the keyboard driver changing it when the user has pressed a key). If the flag is an actual hardware condition such as a line being \"pulled high,\" it's called an \"interrupt\" or \"hardware interrupt.\" Most however, are implemented as just a memory address on the CPU or in main memory (RAM) and are called \"semaphores.\" Semaphores can be changed under software control and so can provide a very fast, simple signalling mechanism between software processes. Interrupts, however, can only be changed by hardware. The most ubiquitous\uff08\u666e\u904d\u5b58\u5728\u7684\uff09 use of interrupts is the one triggered at regular intervals by the internal clock chip. One of the countless kinds of software actions activated by clock interrupts, is the changing of semaphores. I've left out a lot but had to stop somewhere. Please ask if you need more details.","title":"Event-loop"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/Event-loop/#event-loop","text":"","title":"Event loop"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/Event-loop/#event-loop_1","text":"In computer science , the event loop , message dispatcher , message loop , message pump , or run loop is a programming construct that waits for and dispatches events or messages in a program . It works by making a request to some internal or external \"event provider\" (that generally blocks the request until an event has arrived), and then it calls the relevant event handler (\"dispatches the event\"). The event-loop may be used in conjunction with a reactor , if the event provider follows the file interface , which can be selected or 'polled' (the Unix system call, not actual polling ). The event loop almost always operates asynchronously with the message originator. NOTE:\u5173\u4e8e\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\"that generally blocks the request until an event has arrived\"\u7684\u89e3\u91ca\uff1a\u5b83\u662f\u6307\u901a\u5e38\u60c5\u51b5\u4e0b\uff0c\u4e3a\u4e86\u6548\u7387\u8d77\u89c1\uff0cevent provider\u5728\u6ca1\u6709event\u7684\u65f6\u5019\u4f1ablock \u6389event loop\u67e5\u8be2event\u7684\u8bf7\u6c42\uff0credis\u7684 BRPOP \u548c BLPOP \u5c31\u662f\u6309\u7167\u8fd9\u79cd\u601d\u8def\u6765\u5b9e\u73b0\u7684\uff0c\u5728 \u8fd9\u7bc7\u6587\u7ae0 \u4e2d\u5bf9\u8fd9\u4e9b\u8fdb\u884c\u4e86\u8be6\u7ec6\u4ecb\u7ecd\u3002 \u5176\u5b9e\uff0c\u4ece\u8fd9\u91cc\u4e5f\u53ef\u4ee5\u770b\u51fablock\u548casynchronous\u4e4b\u95f4\u7684\u5dee\u5f02\u6240\u5728\u3002 When the event loop forms the central control flow construct of a program, as it often does, it may be termed(\u79f0\u4e4b\u4e3a) the main loop or main event loop . This title is appropriate, because such an event loop is at the highest level of control within the program.","title":"\u7ef4\u57fa\u767e\u79d1Event loop"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/Event-loop/#message-passing","text":"Message pumps are said to 'pump' messages from the program's message queue (assigned and usually owned by the underlying operating system) into the program for processing. In the strictest sense, an event loop is one of the methods for implementing inter-process communication . In fact, message processing exists in many systems, including a kernel-level component of the Mach operating system . The event loop is a specific implementation technique of systems that use message passing .","title":"Message passing"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/Event-loop/#alternative-designs","text":"This approach is in contrast to a number of other alternatives: Traditionally, a program simply ran once, then terminated. This type of program was very common in the early days of computing, and lacked any form of user interactivity. This is still used frequently, particularly in the form of command-line-driven programs. Any parameters are set up in advance and passed in one go when the program starts. Menu-driven designs. These still may feature a main loop, but are not usually thought of as event driven in the usual sense[ citation needed ]. Instead, the user is presented with an ever-narrowing set of options until the task they wish to carry out is the only option available. Limited interactivity through the menus is available.","title":"Alternative designs"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/Event-loop/#usage","text":"Due to the predominance(\u4f18\u52bf) of graphical user interfaces , most modern applications feature a main loop . The get_next_message() routine is typically provided by the operating system , and blocks until a message is available. Thus, the loop is only entered when there is something to process. function main initialize() while message != quit message := get_next_message() process_message(message) end while end function","title":"Usage"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/Event-loop/#file-interface","text":"Under Unix , the \" everything is a file \" paradigm naturally leads to a file-based event loop . Reading from and writing to files, inter-process communication, network communication, and device control are all achieved using file I/O , with the target identified by a file descriptor . The select and poll system calls allow a set of file descriptors to be monitored for a change of state, e.g. when data becomes available to be read. For example, consider a program that reads from a continuously updated file and displays its contents in the X Window System , which communicates with clients over a socket (either Unix domain or Berkeley ): main(): file_fd = open (\"logfile\") x_fd = open_display () construct_interface () while changed_fds = select ({file_fd, x_fd}): if file_fd in changed_fds: data = read_from (file_fd) append_to_display (data) send_repaint_message () if x_fd in changed_fds: process_x_messages ()","title":"File interface"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/Event-loop/#handling-signals","text":"One of the few things in Unix that does not conform to the file interface are asynchronous events ( signals ). Signals are received in signal handlers , small, limited pieces of code that run while the rest of the task is suspended; if a signal is received and handled while the task is blocking in select() , select will return early with EINTR ; if a signal is received while the task is CPU bound , the task will be suspended between instructions until the signal handler returns. Thus an obvious way to handle signals is for signal handlers to set a global flag and have the event loop check for the flag immediately before and after the select() call; if it is set, handle the signal in the same manner as with events on file descriptors . Unfortunately, this gives rise to a race condition : if a signal arrives immediately between checking the flag and calling select() , it will not be handled until select() returns for some other reason (for example, being interrupted by a frustrated user). NOTE: \u4e0a\u8ff0\u8fd9\u79cd\u601d\u8def\u53ef\u4ee5\u53c2\u89c1\uff1a Interrupting blocked read \u4e2d\u7ed9\u51fa\u7684demo\uff1b NOTE : \u4e0d\u5e78\u7684\u662f\uff0c\u8fd9\u4f1a\u5f15\u8d77\u7ade\u4e89\u6761\u4ef6\uff1a\u5982\u679c\u4fe1\u53f7\u5728\u68c0\u67e5\u6807\u5fd7\u548c\u8c03\u7528select\uff08\uff09\u4e4b\u95f4\u7acb\u5373\u5230\u8fbe\uff0c\u5219\u76f4\u5230select\uff08\uff09\u56e0\u67d0\u4e9b\u5176\u4ed6\u539f\u56e0\uff08\u4f8b\u5982\u88ab\u6cae\u4e27\u7684\u7528\u6237\u4e2d\u65ad\uff09\u8fd4\u56de\u65f6\u624d\u4f1a\u5904\u7406\u5b83\uff1b\u8fd9\u6bb5\u8bdd\u4e2d\u6240\u63cf\u8ff0\u7684race condition\u5e76\u6ca1\u6709\u641e\u6e05\u695a\uff1b The solution arrived at by POSIX is the pselect() call, which is similar to select() but takes an additional sigmask parameter, which describes a signal mask . This allows an application to mask signals in the main task , then remove the mask for the duration of the select() call such that signal handlers are only called while the application is I/O bound . However, implementations of pselect() have only recently[ when? ] become reliable; versions of Linux prior to 2.6.16 do not have a pselect() system call, forcing glibc to emulate it via a method prone to the very same race condition pselect() is intended to avoid. An alternative, more portable solution, is to convert asynchronous events to file-based events using the self-pipe trick ,[ 1] where \"a signal handler writes a byte to a pipe whose other end is monitored by select() in the main program\".[ 2] In Linux kernel version 2.6.22, a new system call signalfd() was added, which allows receiving signals via a special file descriptor . SUMMARY :\u53c2\u89c1\u300athe linux program interface \u300b\u7684 63.5.2 The Self-Pipe Trick","title":"Handling signals"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/Event-loop/#is-an-event-loop-just-a-forwhile-loop-with-optimized-polling","text":"NOTE:\u770b\u4e86\u8fd9\u4e48\u591a\uff0c\u53d1\u73b0\u63d0\u95ee\u8005\u7684\u6700\u7ec8\u610f\u56fe\u662f\u60f3\u8981\u77e5\u9053event loop\u662f\u5982\u4f55\u5b9e\u73b0\u7684\uff0c\u63d0\u95ee\u8005\u8ba4\u4e3aevent loop\u7684\u5b9e\u73b0\u65b9\u5f0f\u662f\u7c7b\u4f3cpolling\u7684\uff1b\u6839\u636e\u4e0b\u9762\u7684\u56de\u7b54\uff0c\u663e\u7136\u7b54\u6848\u662fNo\u3002\u7b54\u6848 A4 \u662f\u975e\u5e38\u76f4\u63a5\u7684\u7ed9\u51fa\u4e86\u7b54\u6848\uff1b\u5b83\u5f15\u7528\u4e86Wikipedia\u7684\u4e0a\u7684 Polling \u6587\u7ae0\uff0c\u5728\u8fd9\u7bc7\u6587\u7ae0\u4e2d\uff0c\u6709\u4e0b\u9762\u7684\u4e00\u6bb5\u8bdd\uff1a Although not as wasteful of CPU cycles as busy waiting, this is generally not as efficient as the alternative to polling, interrupt -driven I/O. \u8fd9\u6bb5\u8bdd\u4e2d\u7684 interrupt -driven I/O\u6b63\u662fevent loop\u6240\u91c7\u7528\u7684\u3002 I'm trying to understand what an event loop is. Often the explanation is that in an event loop, you do something until you're notified that an event has occurred. You then handle the event and continue doing what you were doing before. keyword \uff1anotify To map the above definition with an example. I have a server which 'listens' in a event loop, and when a socket connection is detected, the data from it gets read and displayed, after which the server resumes/starts listening as it did before. However, this event happening and us getting notified 'just like that' are to much for me to handle. You can say: \"It's not 'just like that' you have to register an event listener\". But what's an event listener but a function which for some reason isn't returning. Is it in it's own loop, waiting to be notified when an event happens? Should the event listener also register an event listener? Where does it end? Events are a nice abstraction to work with, however just an abstraction. I believe that in the end, polling is unavoidable . Perhaps we are not doing it in our code, but the lower levels (the programming language implementation or the OS) are doing it for us. NOTE: \u4ece\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u53ef\u4ee5\u770b\u51fa\uff0c\u63d0\u95ee\u8005\u7684\u6700\u7ec8\u610f\u56fe\u662f\u60f3\u8981\u77e5\u9053event loop\u5230\u5e95\u662f\u5982\u4f55\u5b9e\u73b0\u7684\u3002 It basically comes down to the following pseudo code which is running somewhere low enough so it doesn't result in busy waiting: while(True): do stuff check if event has happened (poll) do other stuff This is my understanding of the whole idea, and I would like to hear if this is correct. I'm open in accepting that the whole idea is fundamentally wrong, in which case I would like the correct explanation. COMMENTS Event systems are implementations of the Observer pattern . Understanding the pattern should cement your understanding of events. No polling is required. \u2013 Steven Evers Oct 18 '13 at 20:21 Ultimately yes, even if language constructs abstract it away. \u2013 GrandmasterB Oct 18 '13 at 20:30 @SteveEvers In your wiki link. What is the EventSource doing if not polling the keyboard input? \u2013 TheMeaningfulEngineer Oct 18 '13 at 20:36 @Alan : It could be doing anything, but for keyboard input specifically there do exist APIs to register your application as listening to keyboard events, which you can then use as your eventsource with no polling involved. Of course, if you go down far enough, USB is always polling, but let's assume we're using a PS/2 keyboard, which is interrupt driven, and then you have a keyboard input stack based on events with zero polling.\u2013 Phoshi Oct 25 '13 at 8:25 I've had this questions since years, but I can't tell why I never bothered to ask it. Thanks, I am now satisfied with the understanding @Karl Bielefeldt has enlightened me with. \u2013 0xc0de Dec 2 '18 at 5:03","title":"Is an event loop just a for/while loop with optimized polling?"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/Event-loop/#a1","text":"Most event loops will suspend if there are no events ready(\u6ca1\u6709event\u5c31\u7eea\uff0c\u5219event loop\u5c31\u4f1a\u88ab\u6302\u8d77), which means the operating system will not give the task any execution time until an event happens. NOTE:\u8fd9\u6bb5\u8bdd\u5c31\u76f4\u63a5\u70b9\u660e\u4e86event loop\u548cpolling\u4e4b\u95f4\u7684\u5dee\u5f02\u6240\u5728\u3002 Say the event is a key being pressed. You might ask if there's a loop somewhere in the operating system checking for keypresses. The answer is no. Keys being pressed generate an interrupt , which is handled asynchronously by the hardware. Likewise for timers, mouse movements, a packet arriving, etc. NOTE: interrupt \u662f\u7ed5\u5f00loop\u7684\u4e00\u79cd\u975e\u5e38\u597d\u7684\u65b9\u5f0f\uff0c\u8fd9\u5c31\u662f\u5b9e\u73b0event loop\u7684\u4e00\u79cd\u975e\u5e38\u597d\u7684\u65b9\u5f0f\u3002 In fact, for most operating systems, polling for events is the abstraction\uff08\u4e5f\u5c31\u662f\u8bf4\u5b9e\u73b0\u53ef\u80fd\u5e76\u975e\u5982\u6b64\uff09. The hardware and OS handle events asynchronously and put them in a queue that can be polled by applications. You only really see true polling at the hardware level in embedded systems, and even there not always. \u8ba8\u8bba\uff1a Isn't an interrupt a change of voltage on a wire? Can that trigger an event by itself or must we poll the pin for the voltage value? \u2013 TheMeaningfulEngineer That can trigger an event by itself. The processor is designed that way. In fact a processor can be woken up from sleep by an interrupt. \u2013 Karl Bielefeldt I am confused with the statement Most event loops will block . How does this fit into the \"the event loop paradigm, opposed to using threads, uses nonblocking asynchronous calls\"? \u2013 TheMeaningfulEngineer If you look at event loops for a library like GTK+, they check for new events then call event handlers in a loop, but if there aren't any events, they block on a semaphore or a timer or something. Individual developers make their own event loops that don't block on an empty event queue, but the widely-used libraries all block. Event loops are too inefficient otherwise. \u2013 Karl Bielefeldt SUMMARY :\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u6307\u51fa\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u5982empty queue\uff0cevent loop\u5c06\u88abblock\uff0c\u663e\u7136\u8fd9\u5c31\u89e3\u91ca\u4e86 Most event loops will block \uff1b\u81f3\u4e8e How does this fit into the \"the event loop paradigm, opposed to using threads, uses nonblocking asynchronous calls\"\uff0c\u6211\u60f3\u8fd9\u4e2a\u95ee\u9898\u4e2d\u6240\u63cf\u8ff0\u7684\u662f\u6307\uff0c\u5f53event loop\u88ab\u901a\u77e5\u67d0\u4e2aevent\u7684\u65f6\u5019\uff0c\u5b83\u6267\u884cevent handler\u662f\u91c7\u7528\u7684nonblocking asynchronous calls\u3002","title":"A1"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/Event-loop/#a2","text":"Event systems are implementations of the Observer pattern . Understanding the pattern should cement your understanding of events. No polling is required. \u2013 Steven Evers","title":"A2"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/Event-loop/#a3","text":"I think of an event listener not as a function running its own loop, but as a relay race\uff08\u63a5\u529b\u6bd4\u8d5b\uff09 with the first runner waiting for the starting gun. A significant reason for using events instead of polling is that they are more efficient with CPU cycles. Why? Look at it from the hardware up (rather than the source code down). Consider a Web server. When your server calls listen() and blocks, your code is taking its place as a relay runner. When the first packet of a new connection arrives, the network card starts the race by interrupting \uff08\u4e2d\u65ad\uff09 the operating system. The OS runs an interrupt service routine (ISR) that grabs the packet. The ISR passes the baton\uff08\u63a5\u529b\u68d2\uff09 to a higher-level routine that establishes the connection. Once the connection is alive, that routine passes the baton to listen() , which passes the baton up to your code. At that point, you can do what you want with the connection. For all we know, between races each relay runner could be going to the pub. A strength of the event abstraction is that your code doesn't have to know or care. SUMMARY :\u4e0a\u9762\u5bf9\u89e6\u53d1\u5f0f\u7684\u6bd4\u55bb\u6bd4\u8f83\u5f62\u8c61\uff1b\u611f\u89c9\u8fd9\u975e\u5e38\u50cf\u7ecf\u5178\u7684Unix\u7f51\u7edc\u7f16\u7a0b\u6a21\u578b\u3002 Some operating systems include event-handling code that runs its portion of the race, hands off the baton, then loops back to its starting point to wait for the next race to start. In that sense, event handling is optimized polling in lots of concurrent loops. However, there is always an outside trigger that kicks off the process. The event listener is not a function that isn't returning, but a function that is waiting for that external trigger before it runs. Rather than: while(True): do stuff check if event has happened (poll) do other stuff I think of this as: on(some event): //I got the baton do stuff signal the next level up //Pass the baton and between the signal and the next time the handler runs, there is conceptually no code running or looping. SUMMARY :\u5bf9\u6bd4\u4e0a\u9762\u4e24\u6bb5\u4f2a\u4ee3\u7801\uff0con\u53ef\u4ee5\u7ffb\u8bd1\u4e3a\u201c\u5f53\u201d\uff0c\u8fd9\u662f\u975e\u5e38\u5951\u5408interrupt\u7684\uff1b","title":"A3"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/Event-loop/#a4","text":"No. It is not \"optimized polling.\" An event-loop uses interrupt-driven I/O instead of polling. While, Until, For, etc. loops are polling loops. \"Polling\" is the process of repeatedly checking something. Since the loop code executes continuously, and because it is a small, \"tight\" loop, there is little time for the processor to switch tasks and do anything else. Almost all \"hangs,\" \"freezes,\" \"lockups\" or whatever you want to call it when the computer becomes unresponsive, are the manifestation\uff08\u5c55\u793a\uff09 of code being stuck in an unintended polling loop. Instrumentation will show 100% CPU usage. Interrupt-driven event loops are far more efficient than polling loops. Polling is an extremely wasteful use of CPU cycles so every effort is made to eliminate or minimize it. However, to optimize code quality, most languages try to use the polling loop paradigm as closely as possible for event handing commands since they serve functionally similar purposes within a program\uff08\u56e0\u4e3a\u5b83\u4eec\u5728\u7a0b\u5e8f\u4e2d\u63d0\u4f9b\u529f\u80fd\u4e0a\u7c7b\u4f3c\u7684\u7528\u9014\uff09. Thus, with polling being the more familiar way to wait for a keypress or something, it is easy for the inexperienced\uff08\u4e0d\u719f\u7ec3\u7684\uff09 to use it and wind up with a program that may run fine by itself\uff08\u6700\u7ec8\u4f7f\u7528\u53ef\u80fd\u81ea\u884c\u8fd0\u884c\u7684\u7a0b\u5e8f\uff09, but nothing else works while it's running. It has \"taken over\" the machine. As explained in other answers, in interrupt-driven event handing , essentially a \"flag\" is set within the CPU and the process is \"suspended\" (not allowed to run) until that flag is changed by some other process (such as the keyboard driver changing it when the user has pressed a key). If the flag is an actual hardware condition such as a line being \"pulled high,\" it's called an \"interrupt\" or \"hardware interrupt.\" Most however, are implemented as just a memory address on the CPU or in main memory (RAM) and are called \"semaphores.\" Semaphores can be changed under software control and so can provide a very fast, simple signalling mechanism between software processes. Interrupts, however, can only be changed by hardware. The most ubiquitous\uff08\u666e\u904d\u5b58\u5728\u7684\uff09 use of interrupts is the one triggered at regular intervals by the internal clock chip. One of the countless kinds of software actions activated by clock interrupts, is the changing of semaphores. I've left out a lot but had to stop somewhere. Please ask if you need more details.","title":"A4"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/JavaScript-event-loop/","text":"JavaScript event loop https://developer.mozilla.org/en-US/docs/Web/JavaScript/EventLoop \u8fd9\u7bc7\u6587\u7ae0\u975e\u5e38\u503c\u5f97\u4e00\u8bfb\u3002 \u8fd9\u662f\u4e00\u79cd\u5178\u578b\u7684client event loop JavaScript\u5c31\u662f\u5178\u578b\u7684asynchronous\uff0c\u53d1\u9001\u4e86\u8bf7\u6c42\u5c31\u4e0d\u7ba1\u4e86\uff0c\u7136\u540e\u201c\u5f53\u201d\u67e5\u8be2\u597d\u4e86\u540e\uff0c\u518d\u901a\u77e5\u3002","title":"JavaScript-event-loop"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Event-loop/JavaScript-event-loop/#javascript-event-loop","text":"https://developer.mozilla.org/en-US/docs/Web/JavaScript/EventLoop \u8fd9\u7bc7\u6587\u7ae0\u975e\u5e38\u503c\u5f97\u4e00\u8bfb\u3002 \u8fd9\u662f\u4e00\u79cd\u5178\u578b\u7684client event loop JavaScript\u5c31\u662f\u5178\u578b\u7684asynchronous\uff0c\u53d1\u9001\u4e86\u8bf7\u6c42\u5c31\u4e0d\u7ba1\u4e86\uff0c\u7136\u540e\u201c\u5f53\u201d\u67e5\u8be2\u597d\u4e86\u540e\uff0c\u518d\u901a\u77e5\u3002","title":"JavaScript event loop"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Library/Event-library/","text":"Event library \u975e\u5e38\u591a\u7684\u6210\u719f\u7684\u6846\u67b6\uff0c\u8fdb\u884c\u4e86\u975e\u5e38\u62bd\u8c61\u3001\u5c01\u88c5\uff0c\u6700\u7ec8user\u53ea\u9700\u8981\u6307\u5b9aevent\u548cevent handler\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\u5373\u53ef\u3002\u6bd4\u5982flask\u3001libevent\u3001libuv\u3002 web framework\u90fd\u53ef\u4ee5\u770b\u505a\u662fevent-driven model\u7684\u5b9e\u73b0\u3002 Python Eventlet gevent C \u6709\u975e\u5e38\u591a\u7684\u57fa\u4e8eevent loop\u6a21\u578b\u7684software redis libevent libuv JavaScript node.js JavaScript","title":"Event-library"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Library/Event-library/#event-library","text":"\u975e\u5e38\u591a\u7684\u6210\u719f\u7684\u6846\u67b6\uff0c\u8fdb\u884c\u4e86\u975e\u5e38\u62bd\u8c61\u3001\u5c01\u88c5\uff0c\u6700\u7ec8user\u53ea\u9700\u8981\u6307\u5b9aevent\u548cevent handler\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\u5373\u53ef\u3002\u6bd4\u5982flask\u3001libevent\u3001libuv\u3002 web framework\u90fd\u53ef\u4ee5\u770b\u505a\u662fevent-driven model\u7684\u5b9e\u73b0\u3002","title":"Event library"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Library/Event-library/#python","text":"Eventlet gevent","title":"Python"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Library/Event-library/#c","text":"\u6709\u975e\u5e38\u591a\u7684\u57fa\u4e8eevent loop\u6a21\u578b\u7684software redis libevent libuv","title":"C"},{"location":"Theory/Programming-paradigm/Event-driven-programming/Library/Event-library/#javascript","text":"node.js JavaScript","title":"JavaScript"},{"location":"Theory/Programming-paradigm/Functional-programming/Functional-programming/","text":"Functional programming \u201cfunctional programming\"\u5373\u201d\u51fd\u6570\u5f0f\u7f16\u7a0b\u201c\u3002 \u7ef4\u57fa\u767e\u79d1 Functional programming NOTE: \u7ef4\u57fa\u767e\u79d1\u7684\u8fd9\u7bc7\u6587\u7ae0\u6709\u4e9b\u96be\u4ee5\u7406\u89e3\uff0c\u6211\u89c9\u5f97\u7406\u89e3Functional programming\u7684\u5173\u952e\u6709\uff1a Functional programming\u662f\u4e00\u79cd Declarative programming \u5176\u6b21\u662f\uff1a treats computation as the evaluation of mathematical functions and avoids changing- state and mutable data \u8fd9\u8bf4\u660e\u5728functional programming\u4e2d\uff0c\u662f\u6ca1\u6709\u6211\u4eec\u719f\u77e5\u7684\u90a3\u4e9b statement \uff0c\u6b63\u5982 assignment \uff0c\u56e0\u4e3a assignment \u53ef\u80fd\u4f1achange state\uff0c\u6240\u4ee5\u5728functional programming\u4e2d\uff0c\u4ec5\u4ec5\u53ea\u6709expression\u3002 \u9700\u8981\u7ed3\u5408\u5177\u4f53\u4f8b\u5b50\u6765\u8fdb\u884c\u7406\u89e3\u4e5f\u662f\u4e00\u79cd\u6377\u5f84\uff0c\u5728\u539f\u6587\u7684 Coding styles \u4e2d\u7ed9\u51fa\u7684\u4f8b\u5b50\u5c31\u975e\u5e38\u6613\u61c2\u3002 \u6309\u7167\uff0cfunctional programming\u7684\u5b9a\u4e49\uff0c\u4f7f\u7528 higher-order function \u4e0d\u4e00\u5b9a\u662ffunctional programming\u3002","title":"Functional-programming"},{"location":"Theory/Programming-paradigm/Functional-programming/Functional-programming/#functional-programming","text":"\u201cfunctional programming\"\u5373\u201d\u51fd\u6570\u5f0f\u7f16\u7a0b\u201c\u3002","title":"Functional programming"},{"location":"Theory/Programming-paradigm/Functional-programming/Functional-programming/#functional-programming_1","text":"NOTE: \u7ef4\u57fa\u767e\u79d1\u7684\u8fd9\u7bc7\u6587\u7ae0\u6709\u4e9b\u96be\u4ee5\u7406\u89e3\uff0c\u6211\u89c9\u5f97\u7406\u89e3Functional programming\u7684\u5173\u952e\u6709\uff1a Functional programming\u662f\u4e00\u79cd Declarative programming \u5176\u6b21\u662f\uff1a treats computation as the evaluation of mathematical functions and avoids changing- state and mutable data \u8fd9\u8bf4\u660e\u5728functional programming\u4e2d\uff0c\u662f\u6ca1\u6709\u6211\u4eec\u719f\u77e5\u7684\u90a3\u4e9b statement \uff0c\u6b63\u5982 assignment \uff0c\u56e0\u4e3a assignment \u53ef\u80fd\u4f1achange state\uff0c\u6240\u4ee5\u5728functional programming\u4e2d\uff0c\u4ec5\u4ec5\u53ea\u6709expression\u3002 \u9700\u8981\u7ed3\u5408\u5177\u4f53\u4f8b\u5b50\u6765\u8fdb\u884c\u7406\u89e3\u4e5f\u662f\u4e00\u79cd\u6377\u5f84\uff0c\u5728\u539f\u6587\u7684 Coding styles \u4e2d\u7ed9\u51fa\u7684\u4f8b\u5b50\u5c31\u975e\u5e38\u6613\u61c2\u3002 \u6309\u7167\uff0cfunctional programming\u7684\u5b9a\u4e49\uff0c\u4f7f\u7528 higher-order function \u4e0d\u4e00\u5b9a\u662ffunctional programming\u3002","title":"\u7ef4\u57fa\u767e\u79d1Functional programming"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Glossary/","text":"Glossary Object-oriented Programming Class (computer programming) Instance (computer science) Abstract data type Interface (computing) Implementation Cohesion (computer science)","title":"Glossary"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Glossary/#glossary","text":"Object-oriented Programming Class (computer programming) Instance (computer science) Abstract data type Interface (computing) Implementation Cohesion (computer science)","title":"Glossary"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Method-(computer-programming)/","text":"Method \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u201cmethod\u201d\u662f\u5177\u6709\u7279\u6b8a\u542b\u4e49\u7684\uff0c\u663e\u7136\u5b83\u662f\u4e3a\u4e86\u548c\u6211\u4eec\u666e\u901a\u7684subroutine\u8fdb\u884c\u533a\u5206\u3002 \u7ef4\u57fa\u767e\u79d1 Method (computer programming)","title":"Method"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Method-(computer-programming)/#method","text":"\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u201cmethod\u201d\u662f\u5177\u6709\u7279\u6b8a\u542b\u4e49\u7684\uff0c\u663e\u7136\u5b83\u662f\u4e3a\u4e86\u548c\u6211\u4eec\u666e\u901a\u7684subroutine\u8fdb\u884c\u533a\u5206\u3002","title":"Method"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Method-(computer-programming)/#method-computer-programming","text":"","title":"\u7ef4\u57fa\u767e\u79d1Method (computer programming)"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Object-oriented-programming/","text":"Object-oriented programming \u672c\u6587\u4e3b\u8981\u57fa\u4e8e\u7ef4\u57fa\u767e\u79d1[Object-oriented programming\u3002\u5982\u679c\u6709\u4e00\u5b9a\u7684\u7f16\u7a0b\u7ecf\u9a8c\u7684\u8bdd\uff0c\u53ef\u4ee5\u8f83\u597d\u7406\u89e3\uff0c\u5982\u679c\u6ca1\u6709OOP\u7684\u7ecf\u9a8c\uff0c\u53ef\u4ee5\u9605\u8bfb\u4e0b\u4e00\u7ae0 Thinking-in-java \uff0c\u5176\u4e2d\u5bf9OOP\u7406\u8bba\u6709\u975e\u5e38\u597d\u7684\u63cf\u8ff0\u3002OOP\u6709\u5982\u4e0b\u6d41\u6d3e\uff1a Class-based programming \uff0c\u5178\u578b\u4ee3\u8868\u6709C++\u3001Java\u3001Python Prototype-based programming \uff0c\u5178\u578b\u4ee3\u8868\u5c31\u662f JavaScript \u7ef4\u57fa\u767e\u79d1 Object-oriented programming Object-oriented programming ( OOP ) is a programming paradigm based on the concept of \" objects \", which can contain data , in the form of fields (often known as attributes or properties ), and code, in the form of procedures (often known as methods ). A feature of objects is an object's procedures that can access and often modify the data fields of the object with which they are associated (objects have a notion of \" this \" or \"self\"). In OOP, computer programs are designed by making them out of objects that interact with one another. Features NOTE: \u539f\u6587\u7684\u672c\u6bb5\u8bf4\u660e\u975e\u5e38\u591a\u6211\u4eec\u5e73\u65f6\u6240\u542c\u5230\u7684\u4e0eOOP\u76f8\u5173\u7684\u6982\u5ff5\u3002\u6211\u5c06\u4e0eclass-base OOP\u76f8\u5173\u7684\u5185\u5bb9\u653e\u5230\u4e86 Class-based OOP \u4e2d\u3002 Shared with non-OOP predecessor languages Objects and classes NOTE: \u5728 Class-based OOP \u4e2d\u4f1a\u5bf9\u6b64\u8fdb\u884c\u4ecb\u7ecd\u3002 Class-based vs prototype-based Dynamic dispatch/message passing NOTE: \u8fd9\u662fOOP\u4e2d\u975e\u5e38\u4e3b\u8981\u7684\u4e00\u4e2a\u6982\u5ff5 It is the responsibility of the object, not any external code, to select the procedural code to execute in response to a method call, typically by looking up the method at run time in a table associated with the object. This feature is known as dynamic dispatch , and distinguishes an object from an abstract data type (or module), which has a fixed (static) implementation of the operations for all instances. If the call variability \uff08\u53ef\u53d8\u6027\uff09 relies on more than the single type of the object on which it is called (i.e. at least one other parameter object is involved in the method choice), one speaks of multiple dispatch . A method call is also known as message passing . It is conceptualized as a message (the name of the method and its input parameters) being passed to the object for dispatch. Encapsulation Composition, inheritance, and delegation Objects can contain other objects in their instance variables; this is known as object composition . For example, an object in the Employee class might contain (either directly or through a pointer) an object in the Address class, in addition to its own instance variables like \"first_name\" and \"position\". Object composition is used to represent \"has-a\" relationships. Languages that support classes almost always support inheritance . This allows classes to be arranged in a hierarchy that represents \"is-a-type-of\" relationships. Subclasses can override the methods defined by superclasses. Delegation is another language feature that can be used as an alternative to inheritance. Polymorphism Subtyping \u2013 a form of polymorphism \u2013 is when calling code can be agnostic as to which class in the supported hierarchy it is operating on \u2013 the parent class or one of its descendants. Meanwhile, the same operation name among objects in an inheritance hierarchy may behave differently. Open recursion OOP languages NOTE: \u6211\u4eec\u5e38\u5e38\u4f1a\u542c\u5230\u201c\u7eaf\u9762\u5411\u5bf9\u8c61\u201d\u3001\u201c\u90e8\u5206\u652f\u6301\u660e\u7ec6\u5bf9\u8c61\u201d\u7b49\u8bf4\u6cd5\uff0c\u539f\u6587\u7684\u8fd9\u4e00\u6bb5\u5bf9\u6b64\u8fdb\u884c\u4e86\u8bf4\u660e\u3002 Concerning the degree of object orientation , the following distinctions can be made: Languages called \"pure\" OO languages, because everything in them is treated consistently as an object , from primitives such as characters and punctuation, all the way up to whole classes, prototypes, blocks, modules, etc. They were designed specifically to facilitate, even enforce, OO methods. Examples: Python Languages designed mainly for OO programming, but with some procedural elements. Examples: Java , C++ Class-based vs prototype-based \u5173\u4e8eClass-based vs prototype-based\uff0c\u5728\u7ef4\u57fa\u767e\u79d1 Object-oriented programming \u7684 Class-based vs prototype-based \u6bb5\u4e2d\u6709\u603b\u7ed3\u3002\u4e0b\u9762\u662f\u6211\u6839\u636e\u81ea\u5df1\u7684\u4e00\u4e9b\u7ecf\u9a8c\u6240\u603b\u7ed3\u7684\uff1a \u4ecetype system\u7684\u89d2\u5ea6\u6765\u8fdb\u884c\u5bf9\u6bd4 OOP\u7684class-based\u6d41\u6d3e\uff0c\u6bcf\u4e2a**class**\u5bf9\u5e94\u4e00\u79cd**\u7c7b\u578b**\uff0c\u5f80\u5f80\u662f**\u5f3a\u7c7b\u578b**\u8bed\u8a00\u4f7f\u7528\uff0c\u6bd4\u5982c++\uff0cJava\u7b49\u3002 OOP\u7684prototype-based\u6d41\u6d3e\uff0c\u5e76\u6ca1\u6709class\u7684\u6982\u5ff5\uff0c\u5f80\u5f80\u662fweak\u7c7b\u578b\u8bed\u8a00\u4f7f\u7528\uff0c\u6bd4\u5982JavaScript\u3002","title":"Object-oriented-programming"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Object-oriented-programming/#object-oriented-programming","text":"\u672c\u6587\u4e3b\u8981\u57fa\u4e8e\u7ef4\u57fa\u767e\u79d1[Object-oriented programming\u3002\u5982\u679c\u6709\u4e00\u5b9a\u7684\u7f16\u7a0b\u7ecf\u9a8c\u7684\u8bdd\uff0c\u53ef\u4ee5\u8f83\u597d\u7406\u89e3\uff0c\u5982\u679c\u6ca1\u6709OOP\u7684\u7ecf\u9a8c\uff0c\u53ef\u4ee5\u9605\u8bfb\u4e0b\u4e00\u7ae0 Thinking-in-java \uff0c\u5176\u4e2d\u5bf9OOP\u7406\u8bba\u6709\u975e\u5e38\u597d\u7684\u63cf\u8ff0\u3002OOP\u6709\u5982\u4e0b\u6d41\u6d3e\uff1a Class-based programming \uff0c\u5178\u578b\u4ee3\u8868\u6709C++\u3001Java\u3001Python Prototype-based programming \uff0c\u5178\u578b\u4ee3\u8868\u5c31\u662f JavaScript","title":"Object-oriented programming"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Object-oriented-programming/#object-oriented-programming_1","text":"Object-oriented programming ( OOP ) is a programming paradigm based on the concept of \" objects \", which can contain data , in the form of fields (often known as attributes or properties ), and code, in the form of procedures (often known as methods ). A feature of objects is an object's procedures that can access and often modify the data fields of the object with which they are associated (objects have a notion of \" this \" or \"self\"). In OOP, computer programs are designed by making them out of objects that interact with one another.","title":"\u7ef4\u57fa\u767e\u79d1Object-oriented programming"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Object-oriented-programming/#features","text":"NOTE: \u539f\u6587\u7684\u672c\u6bb5\u8bf4\u660e\u975e\u5e38\u591a\u6211\u4eec\u5e73\u65f6\u6240\u542c\u5230\u7684\u4e0eOOP\u76f8\u5173\u7684\u6982\u5ff5\u3002\u6211\u5c06\u4e0eclass-base OOP\u76f8\u5173\u7684\u5185\u5bb9\u653e\u5230\u4e86 Class-based OOP \u4e2d\u3002","title":"Features"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Object-oriented-programming/#shared-with-non-oop-predecessor-languages","text":"","title":"Shared with non-OOP predecessor languages"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Object-oriented-programming/#objects-and-classes","text":"NOTE: \u5728 Class-based OOP \u4e2d\u4f1a\u5bf9\u6b64\u8fdb\u884c\u4ecb\u7ecd\u3002","title":"Objects and classes"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Object-oriented-programming/#class-based-vs-prototype-based","text":"","title":"Class-based vs prototype-based"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Object-oriented-programming/#dynamic-dispatchmessage-passing","text":"NOTE: \u8fd9\u662fOOP\u4e2d\u975e\u5e38\u4e3b\u8981\u7684\u4e00\u4e2a\u6982\u5ff5 It is the responsibility of the object, not any external code, to select the procedural code to execute in response to a method call, typically by looking up the method at run time in a table associated with the object. This feature is known as dynamic dispatch , and distinguishes an object from an abstract data type (or module), which has a fixed (static) implementation of the operations for all instances. If the call variability \uff08\u53ef\u53d8\u6027\uff09 relies on more than the single type of the object on which it is called (i.e. at least one other parameter object is involved in the method choice), one speaks of multiple dispatch . A method call is also known as message passing . It is conceptualized as a message (the name of the method and its input parameters) being passed to the object for dispatch.","title":"Dynamic dispatch/message passing"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Object-oriented-programming/#encapsulation","text":"","title":"Encapsulation"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Object-oriented-programming/#composition-inheritance-and-delegation","text":"Objects can contain other objects in their instance variables; this is known as object composition . For example, an object in the Employee class might contain (either directly or through a pointer) an object in the Address class, in addition to its own instance variables like \"first_name\" and \"position\". Object composition is used to represent \"has-a\" relationships. Languages that support classes almost always support inheritance . This allows classes to be arranged in a hierarchy that represents \"is-a-type-of\" relationships. Subclasses can override the methods defined by superclasses. Delegation is another language feature that can be used as an alternative to inheritance.","title":"Composition, inheritance, and delegation"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Object-oriented-programming/#polymorphism","text":"Subtyping \u2013 a form of polymorphism \u2013 is when calling code can be agnostic as to which class in the supported hierarchy it is operating on \u2013 the parent class or one of its descendants. Meanwhile, the same operation name among objects in an inheritance hierarchy may behave differently.","title":"Polymorphism"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Object-oriented-programming/#open-recursion","text":"","title":"Open recursion"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Object-oriented-programming/#oop-languages","text":"NOTE: \u6211\u4eec\u5e38\u5e38\u4f1a\u542c\u5230\u201c\u7eaf\u9762\u5411\u5bf9\u8c61\u201d\u3001\u201c\u90e8\u5206\u652f\u6301\u660e\u7ec6\u5bf9\u8c61\u201d\u7b49\u8bf4\u6cd5\uff0c\u539f\u6587\u7684\u8fd9\u4e00\u6bb5\u5bf9\u6b64\u8fdb\u884c\u4e86\u8bf4\u660e\u3002 Concerning the degree of object orientation , the following distinctions can be made: Languages called \"pure\" OO languages, because everything in them is treated consistently as an object , from primitives such as characters and punctuation, all the way up to whole classes, prototypes, blocks, modules, etc. They were designed specifically to facilitate, even enforce, OO methods. Examples: Python Languages designed mainly for OO programming, but with some procedural elements. Examples: Java , C++","title":"OOP languages"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Object-oriented-programming/#class-based-vs-prototype-based_1","text":"\u5173\u4e8eClass-based vs prototype-based\uff0c\u5728\u7ef4\u57fa\u767e\u79d1 Object-oriented programming \u7684 Class-based vs prototype-based \u6bb5\u4e2d\u6709\u603b\u7ed3\u3002\u4e0b\u9762\u662f\u6211\u6839\u636e\u81ea\u5df1\u7684\u4e00\u4e9b\u7ecf\u9a8c\u6240\u603b\u7ed3\u7684\uff1a","title":"Class-based vs prototype-based"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Object-oriented-programming/#type-system","text":"OOP\u7684class-based\u6d41\u6d3e\uff0c\u6bcf\u4e2a**class**\u5bf9\u5e94\u4e00\u79cd**\u7c7b\u578b**\uff0c\u5f80\u5f80\u662f**\u5f3a\u7c7b\u578b**\u8bed\u8a00\u4f7f\u7528\uff0c\u6bd4\u5982c++\uff0cJava\u7b49\u3002 OOP\u7684prototype-based\u6d41\u6d3e\uff0c\u5e76\u6ca1\u6709class\u7684\u6982\u5ff5\uff0c\u5f80\u5f80\u662fweak\u7c7b\u578b\u8bed\u8a00\u4f7f\u7528\uff0c\u6bd4\u5982JavaScript\u3002","title":"\u4ecetype system\u7684\u89d2\u5ea6\u6765\u8fdb\u884c\u5bf9\u6bd4"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Summary-of-OO/","text":"Summary of OO \u4ece\u9762\u5411\u8fc7\u7a0b\u5230\u9762\u5411\u5bf9\u8c61 \u6709\u4e86 Abstraction \u548c Language \u7684\u6982\u5ff5\uff0c\u518d\u6765\u9605\u8bfb Thinking-in-java \u4e2dOO\u7406\u8bba\u7684\u8bf4\u660e\u5c31\u975e\u5e38\u5bb9\u6613\u4e86\u3002 \u6211\u4eec\u4f7f\u7528\u8bed\u8a00\u6765\u63cf\u8ff0\u8fd9\u4e2a\u4e16\u754c\uff0c\u9762\u5411\u8fc7\u7a0b\u8bed\u8a00\u5982c\uff0c\u4f7f\u7528\u4e00\u4e2a\u4e00\u4e2a\u8fc7\u7a0b\u3002\u9762\u5411\u5bf9\u8c61\u8bed\u8a00\u66f4\u52a0expressive\uff0c\u80fd\u591f\u66f4\u597d\u5730\u63cf\u8ff0\u62bd\u8c61\u6982\u5ff5\uff0c\u7c7b\u7684\u7ee7\u627f\u5173\u7cfb\u548c\u6982\u5ff5\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u66f4\u52a0\u6613\u4e8e\u7406\u89e3\u3002 \u4eceprogramming language\u53d1\u5c55\u53f2\u6765\u770b\uff0c\u8bed\u8a00\u8d8a\u6765\u8d8a\u5bb9\u6613\u7406\u89e3\uff0c\u8d8a\u6765\u8d8aexpressive\u3002 \u5bf9\u95ee\u9898\u7684\u63cf\u8ff0\uff08\u4f7f\u7528class\u6765\u63cf\u8ff0concept\uff09\uff0c\u5bf9\u95ee\u9898\u7684\u6c42\u89e3\uff08\u4e00\u4e2a\u4e00\u4e2a\u7684object\u4e4b\u95f4\u7684\u4ea4\u4e92\uff09\u3002 \u5c06\u5bf9\u8c61\u770b\u505a\u662f\u4e00\u4e2acomputer\u3001service provider\u3001\u4e00\u4e2a\u72ec\u7acb\u7684\u4e2a\u4f53\uff0c\u5219\u6574\u4e2a\u4f7f\u7528OO\u5b9e\u73b0\u7684\u5c31\u662f\u591a\u4e2aobject\u4e4b\u95f4\u7684\u4ea4\u4e92\u4e86\u3002 \u6211\u4eec\u4f7f\u7528 class \u6765\u63cf\u8ff0\u6982\u5ff5\uff0c\u5bf9\u8c61\u662f\u8fd0\u884c\u65f6\u7684\u6982\u5ff5\uff0c\u8fd0\u884c\u65f6\u624d\u4f1a\u521b\u5efa\u5bf9\u8c61\u3002 Python VS c++ \u9762\u5411\u5bf9\u8c61\u7684\u5b9e\u73b0 \u53c2\u89c1 Programming language implementation Python\u4e2d\u4e00\u5207\u7686\u5bf9\u8c61\uff0c\u5b83\u7684class\u662f\u7531\u5bf9\u8c61\u6765\u8fdb\u884c\u63cf\u8ff0\u3002Python\u4e2d\u9762\u5411\u5bf9\u8c61\u7279\u6027\u7684\u5b9e\u73b0\uff1aattribute lookup\uff0c __dict__ \u3002Python program\u4f1a\u88ab\u7ffb\u8bd1\u4e3abyte code\u7531interpreter\u6765\u6267\u884c\u3002 Python statement\u4e0ebytecode\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb\u3002 c++\u7684\u9762\u5411\u5bf9\u8c61\u7531compile\u7406\u89e3\uff0c\u6700\u7ec8\u90fd\u662f\u8981\u7ffb\u8bd1\u4e3ainstruction\u7684\u3002 c++\u4e2d\u7684\u5bf9\u8c61\u672c\u8d28\u4e0a\u662f\u4e00\u7247\u5185\u5b58\u533a\u57df\uff0c\u5728\u8fdb\u884cprogramming\u7684\u65f6\u5019\uff0c\u53ef\u4ee5\u901a\u8fc7\u6210\u5458\u65b9\u6cd5\u6765\u64cd\u4f5c\u8fd9\u7247\u5185\u5b58\u533a\u57df\uff0cthis\u6307\u9488\u6307\u5411\u8fd9\u7247\u5185\u5b58\u533a\u57df\u3002 c++\u5e76\u975e\u4e00\u5207\u7686\u5bf9\u8c61\u3002 run model\u90fd\u662f\uff1auser-defined action\u662fsubroutine\uff0c\u4f7f\u7528self\u3001this\u6765\u6307\u5411object\u3002 \u4ecetype system\u6765\u770b\uff0cclass\u5c31\u662f\u4e00\u79cdtype\uff0c\u662f\u4e00\u79cd\u6982\u5ff5\uff0c\u4e00\u79cd\u62bd\u8c61\u3002 \u6211\u4eec\u4f7f\u7528\u8bed\u8a00\u6765\u63cf\u8ff0\u4e16\u754c\uff0cOO\u662f\u4e00\u79cd\u66f4\u52a0\u5f3a\u5927\u7684\u63cf\u8ff0\u65b9\u5f0f\uff0c\u4f46\u662f\u4f7f\u7528OO\u7f16\u5199\u7684program\u7684run model\u662f\u4e00\u81f4\u7684\u3002 object-oriented programming OOP Traditional Programming class define data + processing object data + processing attribute data (a field) method function message function call instantiate allocate a structure","title":"Summary-of-OO"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Summary-of-OO/#summary-of-oo","text":"","title":"Summary of OO"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Summary-of-OO/#_1","text":"\u6709\u4e86 Abstraction \u548c Language \u7684\u6982\u5ff5\uff0c\u518d\u6765\u9605\u8bfb Thinking-in-java \u4e2dOO\u7406\u8bba\u7684\u8bf4\u660e\u5c31\u975e\u5e38\u5bb9\u6613\u4e86\u3002 \u6211\u4eec\u4f7f\u7528\u8bed\u8a00\u6765\u63cf\u8ff0\u8fd9\u4e2a\u4e16\u754c\uff0c\u9762\u5411\u8fc7\u7a0b\u8bed\u8a00\u5982c\uff0c\u4f7f\u7528\u4e00\u4e2a\u4e00\u4e2a\u8fc7\u7a0b\u3002\u9762\u5411\u5bf9\u8c61\u8bed\u8a00\u66f4\u52a0expressive\uff0c\u80fd\u591f\u66f4\u597d\u5730\u63cf\u8ff0\u62bd\u8c61\u6982\u5ff5\uff0c\u7c7b\u7684\u7ee7\u627f\u5173\u7cfb\u548c\u6982\u5ff5\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u66f4\u52a0\u6613\u4e8e\u7406\u89e3\u3002 \u4eceprogramming language\u53d1\u5c55\u53f2\u6765\u770b\uff0c\u8bed\u8a00\u8d8a\u6765\u8d8a\u5bb9\u6613\u7406\u89e3\uff0c\u8d8a\u6765\u8d8aexpressive\u3002 \u5bf9\u95ee\u9898\u7684\u63cf\u8ff0\uff08\u4f7f\u7528class\u6765\u63cf\u8ff0concept\uff09\uff0c\u5bf9\u95ee\u9898\u7684\u6c42\u89e3\uff08\u4e00\u4e2a\u4e00\u4e2a\u7684object\u4e4b\u95f4\u7684\u4ea4\u4e92\uff09\u3002 \u5c06\u5bf9\u8c61\u770b\u505a\u662f\u4e00\u4e2acomputer\u3001service provider\u3001\u4e00\u4e2a\u72ec\u7acb\u7684\u4e2a\u4f53\uff0c\u5219\u6574\u4e2a\u4f7f\u7528OO\u5b9e\u73b0\u7684\u5c31\u662f\u591a\u4e2aobject\u4e4b\u95f4\u7684\u4ea4\u4e92\u4e86\u3002 \u6211\u4eec\u4f7f\u7528 class \u6765\u63cf\u8ff0\u6982\u5ff5\uff0c\u5bf9\u8c61\u662f\u8fd0\u884c\u65f6\u7684\u6982\u5ff5\uff0c\u8fd0\u884c\u65f6\u624d\u4f1a\u521b\u5efa\u5bf9\u8c61\u3002","title":"\u4ece\u9762\u5411\u8fc7\u7a0b\u5230\u9762\u5411\u5bf9\u8c61"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Summary-of-OO/#python-vs-c","text":"\u53c2\u89c1 Programming language implementation Python\u4e2d\u4e00\u5207\u7686\u5bf9\u8c61\uff0c\u5b83\u7684class\u662f\u7531\u5bf9\u8c61\u6765\u8fdb\u884c\u63cf\u8ff0\u3002Python\u4e2d\u9762\u5411\u5bf9\u8c61\u7279\u6027\u7684\u5b9e\u73b0\uff1aattribute lookup\uff0c __dict__ \u3002Python program\u4f1a\u88ab\u7ffb\u8bd1\u4e3abyte code\u7531interpreter\u6765\u6267\u884c\u3002 Python statement\u4e0ebytecode\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb\u3002 c++\u7684\u9762\u5411\u5bf9\u8c61\u7531compile\u7406\u89e3\uff0c\u6700\u7ec8\u90fd\u662f\u8981\u7ffb\u8bd1\u4e3ainstruction\u7684\u3002 c++\u4e2d\u7684\u5bf9\u8c61\u672c\u8d28\u4e0a\u662f\u4e00\u7247\u5185\u5b58\u533a\u57df\uff0c\u5728\u8fdb\u884cprogramming\u7684\u65f6\u5019\uff0c\u53ef\u4ee5\u901a\u8fc7\u6210\u5458\u65b9\u6cd5\u6765\u64cd\u4f5c\u8fd9\u7247\u5185\u5b58\u533a\u57df\uff0cthis\u6307\u9488\u6307\u5411\u8fd9\u7247\u5185\u5b58\u533a\u57df\u3002 c++\u5e76\u975e\u4e00\u5207\u7686\u5bf9\u8c61\u3002 run model\u90fd\u662f\uff1auser-defined action\u662fsubroutine\uff0c\u4f7f\u7528self\u3001this\u6765\u6307\u5411object\u3002 \u4ecetype system\u6765\u770b\uff0cclass\u5c31\u662f\u4e00\u79cdtype\uff0c\u662f\u4e00\u79cd\u6982\u5ff5\uff0c\u4e00\u79cd\u62bd\u8c61\u3002 \u6211\u4eec\u4f7f\u7528\u8bed\u8a00\u6765\u63cf\u8ff0\u4e16\u754c\uff0cOO\u662f\u4e00\u79cd\u66f4\u52a0\u5f3a\u5927\u7684\u63cf\u8ff0\u65b9\u5f0f\uff0c\u4f46\u662f\u4f7f\u7528OO\u7f16\u5199\u7684program\u7684run model\u662f\u4e00\u81f4\u7684\u3002","title":"Python VS c++ \u9762\u5411\u5bf9\u8c61\u7684\u5b9e\u73b0"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Summary-of-OO/#object-oriented-programming","text":"OOP Traditional Programming class define data + processing object data + processing attribute data (a field) method function message function call instantiate allocate a structure","title":"object-oriented programming"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Class-based-OOP/Class-based-OOP/","text":"Class-based OOP \u6211\u4eec\u5df2\u7ecf\u77e5\u9053\u4e86class-based OOP\u662fOOP\u7684\u4e00\u4e2a\u6d41\u6d3e\uff0c\u672c\u6587\u5c06\u5bf9class-based OOP\u8fdb\u884c\u8be6\u7ec6\u5206\u6790\u3002 \u7ef4\u57fa\u767e\u79d1 Class-based programming \u539f\u6587\u5728\u5f88\u591a\u4e0b\u9762\u8fd9\u6bb5\u8bdd\u6211\u89c9\u5f97\u975e\u5e38\u5177\u6709\u542f\u53d1\u6027 Object-oriented programming is more than just classes and objects; it's a whole programming paradigm based around objects (data structures) that contain data fields and methods. It is essential to understand this; using classes to organize a bunch of unrelated methods together is not object orientation. Junade Ali, Mastering PHP Design Patterns Encapsulation Inheritance \u4e09\u5927\u7279\u6027 \u6211\u4eec\u5e73\u65f6\u6240\u8bf4\u7684\u201c\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\u201d\u7684\u4e09\u5927\u7279\u6027\uff0c\u66f4\u52a0\u4e25\u683c\u5730\u8bf4\u5e94\u8be5\u662fclass-based OOP\u7684\u4e09\u5927\u7279\u6027\u3002\u8fd9\u4e09\u5927\u7279\u6027\u8c8c\u4f3c\u5e76\u6ca1\u6709\u5f62\u5f0f\u5316\u5730\u5b9a\u4e49\uff0c\u5e94\u8be5\u662f\u7ea6\u5b9a\u4fd7\u6210\u7684\u4e00\u79cd\u8bf4\u6cd5\u3002 \u672c\u6bb5\u53c2\u8003\u7684\u5185\u5bb9\u6709\uff1a Features of Object-Oriented Programming Languages object-oriented programming \u6982\u5ff5 NOTE: \u672c\u6bb5\u5185\u5bb9\u622a\u53d6\u81ea\u7ef4\u57fa\u767e\u79d1 Object-oriented programming \u7684 Objects and classes \u6bb5\u3002 Languages that support object-oriented programming (OOP) typically use inheritance for code reuse and extensibility in the form of either classes or prototypes . Those that use classes support two main concepts: Classes \u2013 the definitions for the data format and available procedures for a given type or class of object; may also contain data and procedures (known as class methods) themselves, i.e. classes contain the data members and member functions Objects \u2013 instances of classes Objects sometimes correspond to things found in the real world. For example, a graphics program may have objects such as \"circle\", \"square\", \"menu\". An online shopping system might have objects such as \"shopping cart\", \"customer\", and \"product\".[ 7] Sometimes objects represent more abstract entities, like an object that represents an open file, or an object that provides the service of translating measurements from U.S. customary to metric. Object-oriented programming is more than just classes and objects; it's a whole programming paradigm based around [ sic ] objects (data structures) that contain data fields and methods. It is essential to understand this; using classes to organize a bunch of unrelated methods together is not object orientation. Junade Ali, Mastering PHP Design Patterns [ 8] Each object is said to be an instance of a particular class (for example, an object with its name field set to \"Mary\" might be an instance of class Employee). Procedures in object-oriented programming are known as methods ; variables are also known as fields , members, attributes, or properties. This leads to the following terms: Class variables \u2013 belong to the class as a whole ; there is only one copy of each one Instance variables or attributes \u2013 data that belongs to individual objects ; every object has its own copy of each one Member variables \u2013 refers to both the class and instance variables that are defined by a particular class Class methods \u2013 belong to the class as a whole and have access only to class variables and inputs from the procedure call Instance methods \u2013 belong to individual objects , and have access to instance variables for the specific object they are called on, inputs, and class variables Objects are accessed somewhat like variables with complex internal structure, and in many languages are effectively pointers , serving as actual references to a single instance of said object in memory within a heap or stack. They provide a layer of abstraction which can be used to separate internal from external code. External code can use an object by calling a specific instance method with a certain set of input parameters, read an instance variable, or write to an instance variable. Objects are created by calling a special type of method in the class known as a constructor . A program may create many instances of the same class as it runs, which operate independently. This is an easy way for the same procedures to be used on different sets of data. Object-oriented programming that uses classes is sometimes called class-based programming , while prototype-based programming does not typically use classes. As a result, a significantly different yet analogous terminology is used to define the concepts of object and instance . In some languages classes and objects can be composed using other concepts like traits and mixins .","title":"Class-based-OOP"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Class-based-OOP/Class-based-OOP/#class-based-oop","text":"\u6211\u4eec\u5df2\u7ecf\u77e5\u9053\u4e86class-based OOP\u662fOOP\u7684\u4e00\u4e2a\u6d41\u6d3e\uff0c\u672c\u6587\u5c06\u5bf9class-based OOP\u8fdb\u884c\u8be6\u7ec6\u5206\u6790\u3002","title":"Class-based OOP"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Class-based-OOP/Class-based-OOP/#class-based-programming","text":"\u539f\u6587\u5728\u5f88\u591a\u4e0b\u9762\u8fd9\u6bb5\u8bdd\u6211\u89c9\u5f97\u975e\u5e38\u5177\u6709\u542f\u53d1\u6027 Object-oriented programming is more than just classes and objects; it's a whole programming paradigm based around objects (data structures) that contain data fields and methods. It is essential to understand this; using classes to organize a bunch of unrelated methods together is not object orientation. Junade Ali, Mastering PHP Design Patterns","title":"\u7ef4\u57fa\u767e\u79d1Class-based programming"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Class-based-OOP/Class-based-OOP/#encapsulation","text":"","title":"Encapsulation"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Class-based-OOP/Class-based-OOP/#inheritance","text":"","title":"Inheritance"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Class-based-OOP/Class-based-OOP/#_1","text":"\u6211\u4eec\u5e73\u65f6\u6240\u8bf4\u7684\u201c\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\u201d\u7684\u4e09\u5927\u7279\u6027\uff0c\u66f4\u52a0\u4e25\u683c\u5730\u8bf4\u5e94\u8be5\u662fclass-based OOP\u7684\u4e09\u5927\u7279\u6027\u3002\u8fd9\u4e09\u5927\u7279\u6027\u8c8c\u4f3c\u5e76\u6ca1\u6709\u5f62\u5f0f\u5316\u5730\u5b9a\u4e49\uff0c\u5e94\u8be5\u662f\u7ea6\u5b9a\u4fd7\u6210\u7684\u4e00\u79cd\u8bf4\u6cd5\u3002 \u672c\u6bb5\u53c2\u8003\u7684\u5185\u5bb9\u6709\uff1a Features of Object-Oriented Programming Languages object-oriented programming","title":"\u4e09\u5927\u7279\u6027"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Class-based-OOP/Class-based-OOP/#_2","text":"NOTE: \u672c\u6bb5\u5185\u5bb9\u622a\u53d6\u81ea\u7ef4\u57fa\u767e\u79d1 Object-oriented programming \u7684 Objects and classes \u6bb5\u3002 Languages that support object-oriented programming (OOP) typically use inheritance for code reuse and extensibility in the form of either classes or prototypes . Those that use classes support two main concepts: Classes \u2013 the definitions for the data format and available procedures for a given type or class of object; may also contain data and procedures (known as class methods) themselves, i.e. classes contain the data members and member functions Objects \u2013 instances of classes Objects sometimes correspond to things found in the real world. For example, a graphics program may have objects such as \"circle\", \"square\", \"menu\". An online shopping system might have objects such as \"shopping cart\", \"customer\", and \"product\".[ 7] Sometimes objects represent more abstract entities, like an object that represents an open file, or an object that provides the service of translating measurements from U.S. customary to metric. Object-oriented programming is more than just classes and objects; it's a whole programming paradigm based around [ sic ] objects (data structures) that contain data fields and methods. It is essential to understand this; using classes to organize a bunch of unrelated methods together is not object orientation. Junade Ali, Mastering PHP Design Patterns [ 8] Each object is said to be an instance of a particular class (for example, an object with its name field set to \"Mary\" might be an instance of class Employee). Procedures in object-oriented programming are known as methods ; variables are also known as fields , members, attributes, or properties. This leads to the following terms: Class variables \u2013 belong to the class as a whole ; there is only one copy of each one Instance variables or attributes \u2013 data that belongs to individual objects ; every object has its own copy of each one Member variables \u2013 refers to both the class and instance variables that are defined by a particular class Class methods \u2013 belong to the class as a whole and have access only to class variables and inputs from the procedure call Instance methods \u2013 belong to individual objects , and have access to instance variables for the specific object they are called on, inputs, and class variables Objects are accessed somewhat like variables with complex internal structure, and in many languages are effectively pointers , serving as actual references to a single instance of said object in memory within a heap or stack. They provide a layer of abstraction which can be used to separate internal from external code. External code can use an object by calling a specific instance method with a certain set of input parameters, read an instance variable, or write to an instance variable. Objects are created by calling a special type of method in the class known as a constructor . A program may create many instances of the same class as it runs, which operate independently. This is an easy way for the same procedures to be used on different sets of data. Object-oriented programming that uses classes is sometimes called class-based programming , while prototype-based programming does not typically use classes. As a result, a significantly different yet analogous terminology is used to define the concepts of object and instance . In some languages classes and objects can be composed using other concepts like traits and mixins .","title":"\u6982\u5ff5"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/","text":"\u5173\u4e8e\u672c\u7ae0 \u5728OOP\u4e2d\uff0c\u201cpolymorphism\u201d\u5373\u201c\u591a\u6001\u201d\u662f\u4e00\u4e2a\u7ecf\u5e38\u88ab\u63d0\u8d77\u7684\u8bcd\u8bed\uff0c\u672c\u7ae0\u5c06\u5bf9\u201cpolymorphism\u201d\u8fdb\u884c\u8be6\u7ec6\u5206\u6790\u3002","title":"Introduction"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/#_1","text":"\u5728OOP\u4e2d\uff0c\u201cpolymorphism\u201d\u5373\u201c\u591a\u6001\u201d\u662f\u4e00\u4e2a\u7ecf\u5e38\u88ab\u63d0\u8d77\u7684\u8bcd\u8bed\uff0c\u672c\u7ae0\u5c06\u5bf9\u201cpolymorphism\u201d\u8fdb\u884c\u8be6\u7ec6\u5206\u6790\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Ad-hoc-polymorphism/","text":"Ad hoc polymorphism \u201cAd hoc polymorphism\u201d\u5373\u201c\u7279\u522b\u591a\u6001\u201d\u3002\u5173\u4e8e\u201cAd hoc\u201d\uff0c\u5728\u540e\u6587\u4e2d\u4f1a\u6709\u89e3\u91ca\u3002 \u7ef4\u57fa\u767e\u79d1 Ad hoc polymorphism The term ad hoc in this context is not intended to be pejorative; it refers simply to the fact that this type of polymorphism is not a fundamental feature of the type system .","title":"Ad-hoc-polymorphism"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Ad-hoc-polymorphism/#ad-hoc-polymorphism","text":"\u201cAd hoc polymorphism\u201d\u5373\u201c\u7279\u522b\u591a\u6001\u201d\u3002\u5173\u4e8e\u201cAd hoc\u201d\uff0c\u5728\u540e\u6587\u4e2d\u4f1a\u6709\u89e3\u91ca\u3002","title":"Ad hoc polymorphism"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Ad-hoc-polymorphism/#ad-hoc-polymorphism_1","text":"The term ad hoc in this context is not intended to be pejorative; it refers simply to the fact that this type of polymorphism is not a fundamental feature of the type system .","title":"\u7ef4\u57fa\u767e\u79d1Ad hoc polymorphism"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Code/","text":"Example code C++ examples of polymorphism","title":"Code"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Code/#example-code","text":"C++ examples of polymorphism","title":"Example code"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Parametric-polymorphism/","text":"Parametric polymorphism \u201cParametric polymorphism\u201d\u5373\u201c\u53c2\u6570\u591a\u6001\u6027\u201d\uff0c\u5b83\u548c Template metaprogramming \u5bc6\u5207\u76f8\u5173\u3002 \u7ef4\u57fa\u767e\u79d1 Parametric polymorphism","title":"Parametric-polymorphism"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Parametric-polymorphism/#parametric-polymorphism","text":"\u201cParametric polymorphism\u201d\u5373\u201c\u53c2\u6570\u591a\u6001\u6027\u201d\uff0c\u5b83\u548c Template metaprogramming \u5bc6\u5207\u76f8\u5173\u3002","title":"Parametric polymorphism"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Parametric-polymorphism/#parametric-polymorphism_1","text":"","title":"\u7ef4\u57fa\u767e\u79d1Parametric polymorphism"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Polymorphism/","text":"Polymorphism \u201cpolymorphism\u201d\u5373\u201c\u591a\u6001\u201d\uff0c\u521d\u6b21\u89c1\u5230\u8fd9\u4e2a\u8bcd\u8bed\uff0c\u6211\u7684\u7b2c\u4e00\u5370\u8c61\u662f\u201c\u591a\u79cd\u5f62\u6001\u201d\u3002 Polymorphism (computer science) In programming languages and type theory , polymorphism is the provision of a single interface to entities of different types or the use of a single symbol to represent multiple different types. NOTE: \u8fd9\u6bb5\u8bdd\u7684\u610f\u601d\u662f\uff1a\u5728\u7f16\u7a0b\u8bed\u8a00\u548c\u7c7b\u578b\u7406\u8bba\u4e2d\uff0c\u591a\u6001\u6027\u662f\u5411\u4e0d\u540c\u7c7b\u578b\u7684\u5b9e\u4f53\u63d0\u4f9b\u5355\u4e00\u63a5\u53e3\uff0c\u6216\u4f7f\u7528\u5355\u4e00\u7b26\u53f7\u8868\u793a\u591a\u4e2a\u4e0d\u540c\u7c7b\u578b\u3002 \u663e\u7136\uff0cpolymorphism\u4e2d\u8574\u542b\u662f\uff1asingle\u548cmultiple\uff0c\u6240\u4ee5\u5b83\u548cdispatch\u662f\u5bc6\u5207\u76f8\u5173\u7684\u3002 \u4ece\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230\uff0c polymorphism \u548c type \uff0c\u6216\u8005\u66f4\u52a0\u5177\u4f53\u6765\u8bf4 \u548c type systems \u5bc6\u5207\u76f8\u5173\uff0c\u53c2\u89c1\u539f\u6587\u7684 History \u7ae0\u8282\u3002 The most commonly recognized major classes of polymorphism are: Ad hoc polymorphism Parametric polymorphism Subtyping (also called subtype polymorphism or inclusion polymorphism ) a single interface to entities of different types Ad hoc polymorphism a single symbol to represent multiple different types Subtyping polymorphism Ad hoc polymorphism Function overloading Operator overloading Parametric polymorphism Generic function Generic programming Subtyping Virtual function Single and dynamic dispatch Double dispatch Multiple dispatch Types Ad hoc polymorphism \u53c2\u89c1 Ad hoc polymorphism Parametric polymorphism \u53c2\u89c1 Parametric polymorphism Subtyping Main article: Subtyping Implementation aspects Static and dynamic polymorphism Static(at compile time) Dynamic(at run time) static dispatch dynamic dispatch Static polymorphism dynamic polymorphism Static/early binding Late/dynamic binding Ad hoc polymorphism \u548c Parametric polymorphism \u90fd\u5c5e\u4e8e Static polymorphism \uff0c\u800c Subtyping \u5219\u5c5e\u4e8e dynamic polymorphism \u3002 Polymorphism\u7684\u672c\u8d28 \u6211\u89c9\u5f97Polymorphism\u7684\u672c\u8d28\u662f\u63cf\u8ff0\u4e86\u4e00\u79cdone-to-many\u5173\u7cfb\u3002","title":"Polymorphism"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Polymorphism/#polymorphism","text":"\u201cpolymorphism\u201d\u5373\u201c\u591a\u6001\u201d\uff0c\u521d\u6b21\u89c1\u5230\u8fd9\u4e2a\u8bcd\u8bed\uff0c\u6211\u7684\u7b2c\u4e00\u5370\u8c61\u662f\u201c\u591a\u79cd\u5f62\u6001\u201d\u3002","title":"Polymorphism"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Polymorphism/#polymorphism-computer-science","text":"In programming languages and type theory , polymorphism is the provision of a single interface to entities of different types or the use of a single symbol to represent multiple different types. NOTE: \u8fd9\u6bb5\u8bdd\u7684\u610f\u601d\u662f\uff1a\u5728\u7f16\u7a0b\u8bed\u8a00\u548c\u7c7b\u578b\u7406\u8bba\u4e2d\uff0c\u591a\u6001\u6027\u662f\u5411\u4e0d\u540c\u7c7b\u578b\u7684\u5b9e\u4f53\u63d0\u4f9b\u5355\u4e00\u63a5\u53e3\uff0c\u6216\u4f7f\u7528\u5355\u4e00\u7b26\u53f7\u8868\u793a\u591a\u4e2a\u4e0d\u540c\u7c7b\u578b\u3002 \u663e\u7136\uff0cpolymorphism\u4e2d\u8574\u542b\u662f\uff1asingle\u548cmultiple\uff0c\u6240\u4ee5\u5b83\u548cdispatch\u662f\u5bc6\u5207\u76f8\u5173\u7684\u3002 \u4ece\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230\uff0c polymorphism \u548c type \uff0c\u6216\u8005\u66f4\u52a0\u5177\u4f53\u6765\u8bf4 \u548c type systems \u5bc6\u5207\u76f8\u5173\uff0c\u53c2\u89c1\u539f\u6587\u7684 History \u7ae0\u8282\u3002 The most commonly recognized major classes of polymorphism are: Ad hoc polymorphism Parametric polymorphism Subtyping (also called subtype polymorphism or inclusion polymorphism ) a single interface to entities of different types Ad hoc polymorphism a single symbol to represent multiple different types Subtyping polymorphism Ad hoc polymorphism Function overloading Operator overloading Parametric polymorphism Generic function Generic programming Subtyping Virtual function Single and dynamic dispatch Double dispatch Multiple dispatch","title":"Polymorphism (computer science)"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Polymorphism/#types","text":"","title":"Types"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Polymorphism/#ad-hoc-polymorphism","text":"\u53c2\u89c1 Ad hoc polymorphism","title":"Ad hoc polymorphism"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Polymorphism/#parametric-polymorphism","text":"\u53c2\u89c1 Parametric polymorphism","title":"Parametric polymorphism"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Polymorphism/#subtyping","text":"Main article: Subtyping","title":"Subtyping"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Polymorphism/#implementation-aspects","text":"","title":"Implementation aspects"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Polymorphism/#static-and-dynamic-polymorphism","text":"Static(at compile time) Dynamic(at run time) static dispatch dynamic dispatch Static polymorphism dynamic polymorphism Static/early binding Late/dynamic binding Ad hoc polymorphism \u548c Parametric polymorphism \u90fd\u5c5e\u4e8e Static polymorphism \uff0c\u800c Subtyping \u5219\u5c5e\u4e8e dynamic polymorphism \u3002","title":"Static and dynamic polymorphism"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Polymorphism/#polymorphism_1","text":"\u6211\u89c9\u5f97Polymorphism\u7684\u672c\u8d28\u662f\u63cf\u8ff0\u4e86\u4e00\u79cdone-to-many\u5173\u7cfb\u3002","title":"Polymorphism\u7684\u672c\u8d28"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Subtyping-polymorphism/Dispatch/","text":"Dynamic dispatch Dispatch\u7684\u672c\u8d28 \u5728\u6587\u7ae0 Polymorphism \u4e2d\uff0c\u6211\u4eec\u5df2\u7ecf\u603b\u7ed3\u4e86\uff1a Polymorphism\u7684\u672c\u8d28\u662f\u63cf\u8ff0\u4e86\u4e00\u79cdone-to-many\u5173\u7cfb dispatch\u53ef\u4ee5\u770b\u505a\u662f\u5bf9Polymorphism\u7684\u4e00\u79cd\u5b9e\u73b0\uff0c\u5373\u5b83\u6240\u5b9e\u73b0\u7684\u662f\u4e00\u79cdone-to-many\u5173\u7cfb\u3002 \u7ef4\u57fa\u767e\u79d1 Dynamic dispatch Single and multiple dispatch Dynamic dispatch mechanisms NOTE: \u63cf\u8ff0\u5982\u4f55\u8bd5\u4e0bdynamic dispatch \u7ef4\u57fa\u767e\u79d1 Multiple dispatch \u7ef4\u57fa\u767e\u79d1 Double dispatch Double Dispatch: the next best thing with respect to Dependency Injection How does double dispatch work in Visitor pattern? Double Dispatch is a Code Smell \u00b7 Los Techies A polyglot's guide to multiple dispatch","title":"Dispatch"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Subtyping-polymorphism/Dispatch/#dynamic-dispatch","text":"","title":"Dynamic dispatch"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Subtyping-polymorphism/Dispatch/#dispatch","text":"\u5728\u6587\u7ae0 Polymorphism \u4e2d\uff0c\u6211\u4eec\u5df2\u7ecf\u603b\u7ed3\u4e86\uff1a Polymorphism\u7684\u672c\u8d28\u662f\u63cf\u8ff0\u4e86\u4e00\u79cdone-to-many\u5173\u7cfb dispatch\u53ef\u4ee5\u770b\u505a\u662f\u5bf9Polymorphism\u7684\u4e00\u79cd\u5b9e\u73b0\uff0c\u5373\u5b83\u6240\u5b9e\u73b0\u7684\u662f\u4e00\u79cdone-to-many\u5173\u7cfb\u3002","title":"Dispatch\u7684\u672c\u8d28"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Subtyping-polymorphism/Dispatch/#dynamic-dispatch_1","text":"","title":"\u7ef4\u57fa\u767e\u79d1Dynamic dispatch"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Subtyping-polymorphism/Dispatch/#single-and-multiple-dispatch","text":"","title":"Single and multiple dispatch"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Subtyping-polymorphism/Dispatch/#dynamic-dispatch-mechanisms","text":"NOTE: \u63cf\u8ff0\u5982\u4f55\u8bd5\u4e0bdynamic dispatch","title":"Dynamic dispatch mechanisms"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Subtyping-polymorphism/Dispatch/#multiple-dispatch","text":"","title":"\u7ef4\u57fa\u767e\u79d1Multiple dispatch"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Subtyping-polymorphism/Dispatch/#double-dispatch","text":"Double Dispatch: the next best thing with respect to Dependency Injection How does double dispatch work in Visitor pattern? Double Dispatch is a Code Smell \u00b7 Los Techies A polyglot's guide to multiple dispatch","title":"\u7ef4\u57fa\u767e\u79d1Double dispatch"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Subtyping-polymorphism/Multiple-dispatch/","text":"Multiple dispatch \u5173\u4e8emultiple dispatch\uff0c\u4e0b\u9762\u8fd9\u7bc7\u6587\u7ae0\u7684\u5206\u6790\u662f\u975e\u5e38\u5230\u4f4d\u7684\u3002 A polyglot's guide to multiple dispatch Polymorphism, single dispatch, multiple dispatch A natural extension of this idea is multiple dispatch , wherein the decision which function to call is based on the runtime types of multiple objects. Why is this useful? It's not a tool programmers reach for very often, but when it is appropriate, alternatives\uff08\u53ef\u9009\u65b9\u6848\uff09 tend to be cumbersome and repetitive\uff08\u91cd\u590d\u7684\uff09. A telling sign that multiple dispatch may be in order is when you have some operation that involves more than one class and there is no single obvious class where this operation belongs. Think of simulating a sound when a drumstick\uff08\u9e21\u817f\uff09 hits a drum. There are many kinds of drumsticks, and many kinds of drums; their combinations produce different sounds. Say we want to write a function (or family of functions) that determines which sound is produced. Should this function be a method of the Drum class or the DrumStick class? Forcing this decision is one of the follies\uff08\u7f6a\u6076\uff09 of classical OOP, and multiple dispatch helps us solve it naturally without adding a kludg\uff08\u7ec4\u88c5\uff09e into our design. NOTE: \u5f53\u51fa\u73b0\u7ec4\u5408\u7684\u60c5\u51b5\u65f6\uff0cmultiple dispatch\u5c31\u975e\u5e38\u6709\u6548\u3002 A simpler and more canonical example is computing intersections\uff08\u4ea4\u96c6\uff09 of shapes - maybe for computer graphics, or for simulation, or other use cases. A generic shape intersection computation can be complex to implement, but in many specific cases it's easy. For example, computing intersections of rectangles with rectangles is trivial; same for circles and ellipses; rectangles with triangles may be a tiny bit harder, but still much simpler than artibrary polygons, and so on [ 2] . How do we write code to handle all these cases? All in all, we just need an intersect function that takes two shapes and computes an intersection. This function may have a whole bunch of special cases inside for different combinations of shapes it knows how to do easily, before it resorts to some heavy-handed generic polygon intersection approach. Such code, however, would be gross to develop and maintain. Wouldn't it be nice if we could have: void Intersect ( const Rectangle * r , const Ellipse * e ) { // implement intersection of rectangle with ellipse } void Intersect ( const Rectangle * r1 , const Rectangle * r2 ) { // implement intersection of rectangle with another rectangle } void Intersect ( const Shape * s1 , const Shape * s2 ) { // implement interesction of two generic shapes } And then the call Intersect(some_shape, other_shape) would just magically dispatch to the right function? This capability is what's most often referred to by multiple dispatch in programming language parlance [ 3] . A failed attempt in C++ You may be tempted to come up with the following \"trivial\" solution in C++: class Shape { public : virtual std :: string name () const { return typeid ( * this ). name (); } }; class Rectangle : public Shape {}; class Ellipse : public Shape {}; class Triangle : public Shape {}; // Overloaded Intersect methods. void Intersect ( const Rectangle * r , const Ellipse * e ) { std :: cout << \"Rectangle x Ellipse [names r=\" << r -> name () << \", e=\" << e -> name () << \"] \\n \" ; } void Intersect ( const Rectangle * r1 , const Rectangle * r2 ) { std :: cout << \"Rectangle x Rectangle [names r1=\" << r1 -> name () << \", r2=\" << r2 -> name () << \"] \\n \" ; } // Fallback to shapes void Intersect ( const Shape * s1 , const Shape * s2 ) { std :: cout << \"Shape x Shape [names s1=\" << s1 -> name () << \", s2=\" << s2 -> name () << \"] \\n \" ; } Now in main : Rectangle r1 , r2 ; Ellipse e ; Triangle t ; std :: cout << \"Static type dispatch \\n \" ; Intersect ( & r1 , & e ); Intersect ( & r1 , & r2 ); Intersect ( & r1 , & t ); We'll see: Static type dispatch Rectangle x Ellipse [names r=9Rectangle, e=7Ellipse] Rectangle x Rectangle [names r1=9Rectangle, r2=9Rectangle] Shape x Shape [names s1=9Rectangle, s2=8Triangle] Note how the intersections get dispatched to specialized functions when these exist and to a generic catch-all Shape x Shape handler when there is no specialized function. NOTE: specialized and generic catch-all So that's it, multiple dispatch works out of the box? Not so fast... What we see here is just C++ function overloading in action. The compiler knows the static, compile-time types of the pointers passed to the Intersect calls, so it just emits the right call. Function overloading is great and useful, but this is not the general problem we're trying to solve. In a realistic code-base, you won't be passing pointers to concrete subclasses of Shape around. You are almost certainly going to be dealing with pointers to the Shape base class\uff08 Design by contract \uff09. Let's try to see how the code in the previous sample works with dynamic types : std :: unique_ptr < Shape > pr1 ( new Rectangle ); std :: unique_ptr < Shape > pr2 ( new Rectangle ); std :: unique_ptr < Shape > pe ( new Ellipse ); std :: unique_ptr < Shape > pt ( new Triangle ); std :: cout << \"Dynamic type dispatch \\n \" ; Intersect ( pr1 . get (), pe . get ()); Intersect ( pr1 . get (), pr2 . get ()); Intersect ( pr1 . get (), pt . get ()); Prints: Dynamic type dispatch Shape x Shape [names s1=9Rectangle, s2=7Ellipse] Shape x Shape [names s1=9Rectangle, s2=9Rectangle] Shape x Shape [names s1=9Rectangle, s2=8Triangle] Yeah... that's not good. All calls were dispatched to the generic Shape x Shape handler, even though the runtime types of the objects are different (see the names gathered from typeid ). This is hardly surprising, because when the compiler sees Intersect(pr1.get(), pr2.get()) , the static types for the two arguments are Shape* and Shape* . You could be forgiven for thinking that the compiler may invoke virtual dispatch here, but virtual dispatch in C++ doesn't work this way. It only works when a virtual method is called on a pointer to a base object , which is not what's happening here. NOTE: \u6700\u540e\u4e00\u53e5\u7684\u610f\u601d\u662f\uff0c\u4f7f\u7528\u4e00\u4e2astatic type\u4e3a\u57fa\u7c7b\u7684\u6307\u9488\u6765\u8c03\u7528\u4e00\u4e2avirtual method\u65f6\uff0c\u624d\u4f1a\u89e6\u53d1virtual dispatch\u3002 NOTE: static type\u548cruntime type\u662fc++ type system\u4e2d\u7684\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u6982\u5ff5\uff0c\u53c2\u89c1cppreference Type \u3002 Multiple dispatch in C++ with the visitor pattern I'll admit I'm calling this approach \"the visitor pattern\" only because this is how it's called elsewhere and because I don't have a better name for it. In fact, it's probably closer to an \"inverted\" visitor pattern, and in general the pattern name may obscure the code more than help. So forget about the name, and just study the code. The last paragraph of the previous section ended with an important observation: virtual dispatch in C++ kicks in only when a virtual method is called on a pointer to a base object. Let's leverage this idea to simulate double dispatch on our hierarchy of shapes. The plan is to arrange Intersect to hop through virtual dispatches on both its arguments to get to the right method for their runtime types. NOTE: \u6700\u540e\u4e00\u53e5\u7684\u610f\u601d\u662f\uff1a\u901a\u8fc7\u5728\u4e24\u4e2aarguments\u4e0a\u90fd\u4f7f\u7528virtual dispatch\u6765\u5b9e\u73b0\u4e3aruntime type\u8c03\u7528\u6b63\u786e\u7684method\u3002 We'll start by defining Shape like this: class Shape { public : virtual std :: string name () const { return typeid ( * this ). name (); } // Dispatcher that should be called by clients to intersect different shapes. virtual void Intersect ( const Shape * ) const = 0 ; // Specific interesection methods implemented by subclasses. If subclass A // has a special way to intersect with subclass B, it should implement // InteresectWith(const B*). virtual void IntersectWith ( const Shape * ) const {} virtual void IntersectWith ( const Rectangle * ) const {} virtual void IntersectWith ( const Ellipse * ) const {} }; The Intersect method is what the users of the code will invoke. To be able to make use of virtual dispatches , we are forced to turn a two-argument call Intersect(A*, B*) to a method call A->Intersect(B) . The IntersectWith methods are concrete implementations of intersections the code will dispatch to and should be implemented by subclasses on a case-per-case basis. class Rectangle : public Shape { public : virtual void Intersect ( const Shape * s ) const { s -> IntersectWith ( this ); } virtual void IntersectWith ( const Shape * s ) const { std :: cout << \"Rectangle x Shape [names this=\" << this -> name () << \", s=\" << s -> name () << \"] \\n \" ; } virtual void IntersectWith ( const Rectangle * r ) const { std :: cout << \"Rectangle x Rectangle [names this=\" << this -> name () << \", r=\" << r -> name () << \"] \\n \" ; } }; class Ellipse : public Shape { public : virtual void Intersect ( const Shape * s ) const { s -> IntersectWith ( this ); } virtual void IntersectWith ( const Rectangle * r ) const { std :: cout << \"Ellipse x Rectangle [names this=\" << this -> name () << \", r=\" << r -> name () << \"] \\n \" ; } }; std :: unique_ptr < Shape > pr1 ( new Rectangle ); std :: unique_ptr < Shape > pr2 ( new Rectangle ); std :: unique_ptr < Shape > pe ( new Ellipse ); std :: cout << \"Dynamic type dispatch \\n \" ; pr1 -> Intersect ( pe . get ()); pr1 -> Intersect ( pr2 . get ()); Will now print: Dynamic type dispatch Ellipse x Rectangle [names this=7Ellipse, r=9Rectangle] Rectangle x Rectangle [names this=9Rectangle, r=9Rectangle] Success! Even though we're dealing solely in pointers to Shape , the right intersections are computed. Why does this work? As I've mentioned before, the key here is use C++'s virtual function dispatch capability , twice . Let's trace through one execution to see what's going on. We have: pr1 -> Intersect ( pe . get ()); pr1 is a pointer to Shape , and Intersect is a virtual method . Therefore, the runtime type 's Intersect is called here, which is Rectangle::Intersect . The argument passed into the method is another pointer to Shape which at runtime points to an Ellipse ( pe ). Rectangle::Intersect calls s->IntersectWith(this) . The compiler sees that s is a Shape* , and IntersectWith is a virtual method , so this is another virtual dispatch. What gets called is Ellipse::IntersectWith . But which overload of this method is called? NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u4e24\u6b21dispatch\u53d1\u751f\u7684\u8be6\u7ec6\u60c5\u51b5\u3002 This is an extremely crucial point in the explanation, so please focus :-) Here is Rectangle::Intersect again: virtual void Intersect ( const Shape * s ) const { s -> IntersectWith ( this ); } s->IntersectWith is called with this , which the compiler knows is a pointer to Rectangle , statically . If you wondered why I define Intersect in each subclass rather than doing it once in Shape , even though its code is exactly the same for each subclass, this is the reason. Had I defined it in Shape , the compiler would think the type of this is Shape* and would always dispatch to the IntersectWith(const Shape*) overload. Defining this method in each subclass helps the compiler leverage overloading to call the right method. What happens eventually is that the call pr1->Intersect(pe.get()) gets routed to Ellipse::IntersectWith(const Rectangle*) , thanks to two virtual dispatches and one use of method overloading. The end result is double dispatch! [ 4] But wait a second, how did we end up with Ellipse::IntersectWith(Rectangle) ? Shouldn't pr1->Intersect(pe.get()) go to Rectangle::IntersectWith(Ellipse) instead? Well, yes and no. Yes because this is what you'd expect from how the call is syntactically structured. No because you almost certainly want double dispatches to be symmetric. I'll discuss this and other related issues in the next section. Symmetry and base-class defaults When we come up with ways to do multiple dispatch, whether in C++ or in other languages, there are two aspects of the solution we should always keep in mind: Does it permit symmetry? In other words, does the order of objects dispatched upon matters? And if it doesn't, how much extra code is needed to express this fact. Does base-class default dispatch work as expected? Suppose we create a new subclass of Rectangle , called Square and we don't explicitly create an IntersectWith method for Square and Ellipse . Will the right thing happen and the intersection between a Rectangle and Ellipse be invoked when we ask for Square x Ellipse ? This is the right thing because this is what we've come to expect from class hierarchies in object-oriented languages. In the visitor-based solution presented above, both aspects will work, though symmetry needs a bit of extra code. The full code sample is available here (and the accompanying .cpp file). It's conceptually similar to the code shown above, but with a bit more details. In particular, it implements symmetry between rectangle and ellipse intersections as follows: namespace { // All intersections between rectangles and ellipses dispatch here. void SymmetricIntersectRectangleEllipse ( const Rectangle * r , const Ellipse * e ) { std :: cout << \"IntersectRectangleEllipse [names r=\" << r -> name () << \", e=\" << e -> name () << \"] \\n \" ; } } void Rectangle :: IntersectWith ( const Ellipse * e ) const { SymmetricIntersectRectangleEllipse ( this , e ); } void Ellipse :: IntersectWith ( const Rectangle * r ) const { SymmetricIntersectRectangleEllipse ( r , this ); } This ensures that both rectangle->Intersect(ellipse) and ellipse->Intersect(rectangle) end up in the same function. As far as I know there's not way to do this automatically in the visitor approach, so a bit of extra coding is due when symmetry between subclasses is desired. Note also that this method doesn't force symmetry either. If some form of dispatch is order-dependent, it's easy to express. The problem with the visitor-based approach Although the visitor-based approach works, enables fairly clean client code and is efficient (constant time - two virtual calls), there's a glaring issue with it that's apparent with the most cursory look at the code: it's very intrusive\uff08\u4fb5\u5165\u7684\uff09, and hence hard to maintain. Imagine we want to add a new kind of shape - a HyperFrob . Suppose also that there's an efficient algorithm for intersecting a HyperFrob with an Ellipse . Ideally, we'd only have to write code for the new functionality: Define the new HyperFrob class deriving from Shape . Implement the generic HyperFrob x Shape intersection algorithm. Implement the specific HyperFrom x Ellipse algorithm. But in reality, we're forced to modify the definition of the base class Shape to add an overload of IntersectWith for HyperFrob . Moreover, if we want intersections between HyperFrob and Ellipse to be symmetric (which we almost certainly do), we'll have to modify Ellipse as well to add the same overload. If we don't control the Shape base class at all, we're in real trouble. This is an instance of the expression problem . I'll have more to say about the expression problem in a future post, but for now the Wikipedia link will have to do. It's not an easy problem to solve in C++, and the approaches to implement multiple dispatch should be judged by how flexible they are in this respect, along with the other considerations.","title":"Multiple-dispatch"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Subtyping-polymorphism/Multiple-dispatch/#multiple-dispatch","text":"\u5173\u4e8emultiple dispatch\uff0c\u4e0b\u9762\u8fd9\u7bc7\u6587\u7ae0\u7684\u5206\u6790\u662f\u975e\u5e38\u5230\u4f4d\u7684\u3002","title":"Multiple dispatch"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Subtyping-polymorphism/Multiple-dispatch/#a-polyglots-guide-to-multiple-dispatch","text":"","title":"A polyglot's guide to multiple dispatch"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Subtyping-polymorphism/Multiple-dispatch/#polymorphism-single-dispatch-multiple-dispatch","text":"A natural extension of this idea is multiple dispatch , wherein the decision which function to call is based on the runtime types of multiple objects. Why is this useful? It's not a tool programmers reach for very often, but when it is appropriate, alternatives\uff08\u53ef\u9009\u65b9\u6848\uff09 tend to be cumbersome and repetitive\uff08\u91cd\u590d\u7684\uff09. A telling sign that multiple dispatch may be in order is when you have some operation that involves more than one class and there is no single obvious class where this operation belongs. Think of simulating a sound when a drumstick\uff08\u9e21\u817f\uff09 hits a drum. There are many kinds of drumsticks, and many kinds of drums; their combinations produce different sounds. Say we want to write a function (or family of functions) that determines which sound is produced. Should this function be a method of the Drum class or the DrumStick class? Forcing this decision is one of the follies\uff08\u7f6a\u6076\uff09 of classical OOP, and multiple dispatch helps us solve it naturally without adding a kludg\uff08\u7ec4\u88c5\uff09e into our design. NOTE: \u5f53\u51fa\u73b0\u7ec4\u5408\u7684\u60c5\u51b5\u65f6\uff0cmultiple dispatch\u5c31\u975e\u5e38\u6709\u6548\u3002 A simpler and more canonical example is computing intersections\uff08\u4ea4\u96c6\uff09 of shapes - maybe for computer graphics, or for simulation, or other use cases. A generic shape intersection computation can be complex to implement, but in many specific cases it's easy. For example, computing intersections of rectangles with rectangles is trivial; same for circles and ellipses; rectangles with triangles may be a tiny bit harder, but still much simpler than artibrary polygons, and so on [ 2] . How do we write code to handle all these cases? All in all, we just need an intersect function that takes two shapes and computes an intersection. This function may have a whole bunch of special cases inside for different combinations of shapes it knows how to do easily, before it resorts to some heavy-handed generic polygon intersection approach. Such code, however, would be gross to develop and maintain. Wouldn't it be nice if we could have: void Intersect ( const Rectangle * r , const Ellipse * e ) { // implement intersection of rectangle with ellipse } void Intersect ( const Rectangle * r1 , const Rectangle * r2 ) { // implement intersection of rectangle with another rectangle } void Intersect ( const Shape * s1 , const Shape * s2 ) { // implement interesction of two generic shapes } And then the call Intersect(some_shape, other_shape) would just magically dispatch to the right function? This capability is what's most often referred to by multiple dispatch in programming language parlance [ 3] .","title":"Polymorphism, single dispatch, multiple dispatch"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Subtyping-polymorphism/Multiple-dispatch/#a-failed-attempt-in-c","text":"You may be tempted to come up with the following \"trivial\" solution in C++: class Shape { public : virtual std :: string name () const { return typeid ( * this ). name (); } }; class Rectangle : public Shape {}; class Ellipse : public Shape {}; class Triangle : public Shape {}; // Overloaded Intersect methods. void Intersect ( const Rectangle * r , const Ellipse * e ) { std :: cout << \"Rectangle x Ellipse [names r=\" << r -> name () << \", e=\" << e -> name () << \"] \\n \" ; } void Intersect ( const Rectangle * r1 , const Rectangle * r2 ) { std :: cout << \"Rectangle x Rectangle [names r1=\" << r1 -> name () << \", r2=\" << r2 -> name () << \"] \\n \" ; } // Fallback to shapes void Intersect ( const Shape * s1 , const Shape * s2 ) { std :: cout << \"Shape x Shape [names s1=\" << s1 -> name () << \", s2=\" << s2 -> name () << \"] \\n \" ; } Now in main : Rectangle r1 , r2 ; Ellipse e ; Triangle t ; std :: cout << \"Static type dispatch \\n \" ; Intersect ( & r1 , & e ); Intersect ( & r1 , & r2 ); Intersect ( & r1 , & t ); We'll see: Static type dispatch Rectangle x Ellipse [names r=9Rectangle, e=7Ellipse] Rectangle x Rectangle [names r1=9Rectangle, r2=9Rectangle] Shape x Shape [names s1=9Rectangle, s2=8Triangle] Note how the intersections get dispatched to specialized functions when these exist and to a generic catch-all Shape x Shape handler when there is no specialized function. NOTE: specialized and generic catch-all So that's it, multiple dispatch works out of the box? Not so fast... What we see here is just C++ function overloading in action. The compiler knows the static, compile-time types of the pointers passed to the Intersect calls, so it just emits the right call. Function overloading is great and useful, but this is not the general problem we're trying to solve. In a realistic code-base, you won't be passing pointers to concrete subclasses of Shape around. You are almost certainly going to be dealing with pointers to the Shape base class\uff08 Design by contract \uff09. Let's try to see how the code in the previous sample works with dynamic types : std :: unique_ptr < Shape > pr1 ( new Rectangle ); std :: unique_ptr < Shape > pr2 ( new Rectangle ); std :: unique_ptr < Shape > pe ( new Ellipse ); std :: unique_ptr < Shape > pt ( new Triangle ); std :: cout << \"Dynamic type dispatch \\n \" ; Intersect ( pr1 . get (), pe . get ()); Intersect ( pr1 . get (), pr2 . get ()); Intersect ( pr1 . get (), pt . get ()); Prints: Dynamic type dispatch Shape x Shape [names s1=9Rectangle, s2=7Ellipse] Shape x Shape [names s1=9Rectangle, s2=9Rectangle] Shape x Shape [names s1=9Rectangle, s2=8Triangle] Yeah... that's not good. All calls were dispatched to the generic Shape x Shape handler, even though the runtime types of the objects are different (see the names gathered from typeid ). This is hardly surprising, because when the compiler sees Intersect(pr1.get(), pr2.get()) , the static types for the two arguments are Shape* and Shape* . You could be forgiven for thinking that the compiler may invoke virtual dispatch here, but virtual dispatch in C++ doesn't work this way. It only works when a virtual method is called on a pointer to a base object , which is not what's happening here. NOTE: \u6700\u540e\u4e00\u53e5\u7684\u610f\u601d\u662f\uff0c\u4f7f\u7528\u4e00\u4e2astatic type\u4e3a\u57fa\u7c7b\u7684\u6307\u9488\u6765\u8c03\u7528\u4e00\u4e2avirtual method\u65f6\uff0c\u624d\u4f1a\u89e6\u53d1virtual dispatch\u3002 NOTE: static type\u548cruntime type\u662fc++ type system\u4e2d\u7684\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u6982\u5ff5\uff0c\u53c2\u89c1cppreference Type \u3002","title":"A failed attempt in C++"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Subtyping-polymorphism/Multiple-dispatch/#multiple-dispatch-in-c-with-the-visitor-pattern","text":"I'll admit I'm calling this approach \"the visitor pattern\" only because this is how it's called elsewhere and because I don't have a better name for it. In fact, it's probably closer to an \"inverted\" visitor pattern, and in general the pattern name may obscure the code more than help. So forget about the name, and just study the code. The last paragraph of the previous section ended with an important observation: virtual dispatch in C++ kicks in only when a virtual method is called on a pointer to a base object. Let's leverage this idea to simulate double dispatch on our hierarchy of shapes. The plan is to arrange Intersect to hop through virtual dispatches on both its arguments to get to the right method for their runtime types. NOTE: \u6700\u540e\u4e00\u53e5\u7684\u610f\u601d\u662f\uff1a\u901a\u8fc7\u5728\u4e24\u4e2aarguments\u4e0a\u90fd\u4f7f\u7528virtual dispatch\u6765\u5b9e\u73b0\u4e3aruntime type\u8c03\u7528\u6b63\u786e\u7684method\u3002 We'll start by defining Shape like this: class Shape { public : virtual std :: string name () const { return typeid ( * this ). name (); } // Dispatcher that should be called by clients to intersect different shapes. virtual void Intersect ( const Shape * ) const = 0 ; // Specific interesection methods implemented by subclasses. If subclass A // has a special way to intersect with subclass B, it should implement // InteresectWith(const B*). virtual void IntersectWith ( const Shape * ) const {} virtual void IntersectWith ( const Rectangle * ) const {} virtual void IntersectWith ( const Ellipse * ) const {} }; The Intersect method is what the users of the code will invoke. To be able to make use of virtual dispatches , we are forced to turn a two-argument call Intersect(A*, B*) to a method call A->Intersect(B) . The IntersectWith methods are concrete implementations of intersections the code will dispatch to and should be implemented by subclasses on a case-per-case basis. class Rectangle : public Shape { public : virtual void Intersect ( const Shape * s ) const { s -> IntersectWith ( this ); } virtual void IntersectWith ( const Shape * s ) const { std :: cout << \"Rectangle x Shape [names this=\" << this -> name () << \", s=\" << s -> name () << \"] \\n \" ; } virtual void IntersectWith ( const Rectangle * r ) const { std :: cout << \"Rectangle x Rectangle [names this=\" << this -> name () << \", r=\" << r -> name () << \"] \\n \" ; } }; class Ellipse : public Shape { public : virtual void Intersect ( const Shape * s ) const { s -> IntersectWith ( this ); } virtual void IntersectWith ( const Rectangle * r ) const { std :: cout << \"Ellipse x Rectangle [names this=\" << this -> name () << \", r=\" << r -> name () << \"] \\n \" ; } }; std :: unique_ptr < Shape > pr1 ( new Rectangle ); std :: unique_ptr < Shape > pr2 ( new Rectangle ); std :: unique_ptr < Shape > pe ( new Ellipse ); std :: cout << \"Dynamic type dispatch \\n \" ; pr1 -> Intersect ( pe . get ()); pr1 -> Intersect ( pr2 . get ()); Will now print: Dynamic type dispatch Ellipse x Rectangle [names this=7Ellipse, r=9Rectangle] Rectangle x Rectangle [names this=9Rectangle, r=9Rectangle] Success! Even though we're dealing solely in pointers to Shape , the right intersections are computed. Why does this work? As I've mentioned before, the key here is use C++'s virtual function dispatch capability , twice . Let's trace through one execution to see what's going on. We have: pr1 -> Intersect ( pe . get ()); pr1 is a pointer to Shape , and Intersect is a virtual method . Therefore, the runtime type 's Intersect is called here, which is Rectangle::Intersect . The argument passed into the method is another pointer to Shape which at runtime points to an Ellipse ( pe ). Rectangle::Intersect calls s->IntersectWith(this) . The compiler sees that s is a Shape* , and IntersectWith is a virtual method , so this is another virtual dispatch. What gets called is Ellipse::IntersectWith . But which overload of this method is called? NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u4e24\u6b21dispatch\u53d1\u751f\u7684\u8be6\u7ec6\u60c5\u51b5\u3002 This is an extremely crucial point in the explanation, so please focus :-) Here is Rectangle::Intersect again: virtual void Intersect ( const Shape * s ) const { s -> IntersectWith ( this ); } s->IntersectWith is called with this , which the compiler knows is a pointer to Rectangle , statically . If you wondered why I define Intersect in each subclass rather than doing it once in Shape , even though its code is exactly the same for each subclass, this is the reason. Had I defined it in Shape , the compiler would think the type of this is Shape* and would always dispatch to the IntersectWith(const Shape*) overload. Defining this method in each subclass helps the compiler leverage overloading to call the right method. What happens eventually is that the call pr1->Intersect(pe.get()) gets routed to Ellipse::IntersectWith(const Rectangle*) , thanks to two virtual dispatches and one use of method overloading. The end result is double dispatch! [ 4] But wait a second, how did we end up with Ellipse::IntersectWith(Rectangle) ? Shouldn't pr1->Intersect(pe.get()) go to Rectangle::IntersectWith(Ellipse) instead? Well, yes and no. Yes because this is what you'd expect from how the call is syntactically structured. No because you almost certainly want double dispatches to be symmetric. I'll discuss this and other related issues in the next section.","title":"Multiple dispatch in C++ with the visitor pattern"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Subtyping-polymorphism/Multiple-dispatch/#symmetry-and-base-class-defaults","text":"When we come up with ways to do multiple dispatch, whether in C++ or in other languages, there are two aspects of the solution we should always keep in mind: Does it permit symmetry? In other words, does the order of objects dispatched upon matters? And if it doesn't, how much extra code is needed to express this fact. Does base-class default dispatch work as expected? Suppose we create a new subclass of Rectangle , called Square and we don't explicitly create an IntersectWith method for Square and Ellipse . Will the right thing happen and the intersection between a Rectangle and Ellipse be invoked when we ask for Square x Ellipse ? This is the right thing because this is what we've come to expect from class hierarchies in object-oriented languages. In the visitor-based solution presented above, both aspects will work, though symmetry needs a bit of extra code. The full code sample is available here (and the accompanying .cpp file). It's conceptually similar to the code shown above, but with a bit more details. In particular, it implements symmetry between rectangle and ellipse intersections as follows: namespace { // All intersections between rectangles and ellipses dispatch here. void SymmetricIntersectRectangleEllipse ( const Rectangle * r , const Ellipse * e ) { std :: cout << \"IntersectRectangleEllipse [names r=\" << r -> name () << \", e=\" << e -> name () << \"] \\n \" ; } } void Rectangle :: IntersectWith ( const Ellipse * e ) const { SymmetricIntersectRectangleEllipse ( this , e ); } void Ellipse :: IntersectWith ( const Rectangle * r ) const { SymmetricIntersectRectangleEllipse ( r , this ); } This ensures that both rectangle->Intersect(ellipse) and ellipse->Intersect(rectangle) end up in the same function. As far as I know there's not way to do this automatically in the visitor approach, so a bit of extra coding is due when symmetry between subclasses is desired. Note also that this method doesn't force symmetry either. If some form of dispatch is order-dependent, it's easy to express.","title":"Symmetry and base-class defaults"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Polymorphism/Subtyping-polymorphism/Multiple-dispatch/#the-problem-with-the-visitor-based-approach","text":"Although the visitor-based approach works, enables fairly clean client code and is efficient (constant time - two virtual calls), there's a glaring issue with it that's apparent with the most cursory look at the code: it's very intrusive\uff08\u4fb5\u5165\u7684\uff09, and hence hard to maintain. Imagine we want to add a new kind of shape - a HyperFrob . Suppose also that there's an efficient algorithm for intersecting a HyperFrob with an Ellipse . Ideally, we'd only have to write code for the new functionality: Define the new HyperFrob class deriving from Shape . Implement the generic HyperFrob x Shape intersection algorithm. Implement the specific HyperFrom x Ellipse algorithm. But in reality, we're forced to modify the definition of the base class Shape to add an overload of IntersectWith for HyperFrob . Moreover, if we want intersections between HyperFrob and Ellipse to be symmetric (which we almost certainly do), we'll have to modify Ellipse as well to add the same overload. If we don't control the Shape base class at all, we're in real trouble. This is an instance of the expression problem . I'll have more to say about the expression problem in a future post, but for now the Wikipedia link will have to do. It's not an easy problem to solve in C++, and the approaches to implement multiple dispatch should be judged by how flexible they are in this respect, along with the other considerations.","title":"The problem with the visitor-based approach"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/","text":"\u5173\u4e8e\u672c\u7ae0 \u6211\u5728\u5927\u5b66\u7684\u65f6\u5019\u9605\u8bfb\u8fc7\u300aThinking in Java\u300b\uff0c\u5176\u4e2d\u63cf\u8ff0OOP\u7406\u8bba\u7684\u5185\u5bb9\u901a\u4fd7\u6613\u61c2\u3001\u6df1\u5165\u6d45\u51fa\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u63cf\u8ff0OOP\u7406\u8bba\u7684\u5178\u8303\u3002\u672c\u7ae0\u4e3b\u8981\u622a\u53d6\u5176\u4e2d\u63cf\u8ff0OOP\u7406\u8bba\u7684\u7ae0\u8282\u3002","title":"About-this-chapter"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/#_1","text":"\u6211\u5728\u5927\u5b66\u7684\u65f6\u5019\u9605\u8bfb\u8fc7\u300aThinking in Java\u300b\uff0c\u5176\u4e2d\u63cf\u8ff0OOP\u7406\u8bba\u7684\u5185\u5bb9\u901a\u4fd7\u6613\u61c2\u3001\u6df1\u5165\u6d45\u51fa\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u63cf\u8ff0OOP\u7406\u8bba\u7684\u5178\u8303\u3002\u672c\u7ae0\u4e3b\u8981\u622a\u53d6\u5176\u4e2d\u63cf\u8ff0OOP\u7406\u8bba\u7684\u7ae0\u8282\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Everything-is-an-object/","text":"Everything Is an Object \u201cIf we spoke a different language, we would perceive a somewhat different world.\u201d Ludwig Wittgenstein (1889-1951) Although it is based on C++, Java is more of a \u201cpure\u201d object-oriented language.","title":"Everything-is-an-object"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Everything-is-an-object/#everything-is-an-object","text":"\u201cIf we spoke a different language, we would perceive a somewhat different world.\u201d Ludwig Wittgenstein (1889-1951) Although it is based on C++, Java is more of a \u201cpure\u201d object-oriented language.","title":"Everything Is an Object"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Introduction-to-Objects/","text":"Introduction to Objects \u201cWe cut nature up, organize it into concepts , and ascribe significances as we do, largely because we are parties to an agreement that holds throughout our speech community and is codified in the patterns of our language \u2026 we cannot talk at all except by subscribing to the organization and classification of data which the agreement decrees.\u201d Benjamin Lee Whorf (1897-1941) NOTE: \u6211\u4eec\u4e4b\u6240\u4ee5\u5c06\u81ea\u7136\u5206\u89e3\uff0c\u7ec4\u7ec7\u6210\u5404\u79cd\u6982\u5ff5\uff0c\u5e76\u6309\u5176\u542b\u4e49\u5206\u7c7b\uff0c\u4e3b\u8981\u662f\u6211\u4eec\u662f\u6574\u4e2a\u53e3\u8bed\u4ea4\u6d41\u793e\u4f1a\u5171\u540c\u9075\u5b88\u7684\u534f\u5b9a\u7684\u53c2\u4e0e\u8005\uff0c\u8fd9\u4e2a\u534f\u5b9a\u4ee5\u8bed\u8a00\u7684\u5f62\u5f0f\u56fa\u5b9a\u4e0b\u6765...\u9664\u975e\u8d5e\u6210\u8fd9\u4e2a\u8fd9\u4e2a\u534f\u5b9a\u4e2d\u6709\u5173\u8bed\u8a00\u7684\u7ec4\u7ec7\u548c\u5206\u7c7b\uff0c\u5426\u5219\u6211\u4eec\u65e0\u6cd5\u4ea4\u8c08\u3002 The genesis\uff08\u8d77\u6e90\uff09 of the computer revolution was in a machine . The genesis of our programming languages thus tends to look like that machine. NOTE: \u201cThe genesis of our programming languages thus tends to look like that machine\u201d\u7684\u610f\u601d\u662f\uff1a\u8d77\u521d\u7684programming language\u662f\u975e\u5e38\u7c7b\u4f3c\u4e8emachine\u7684\u3002\u4f5c\u8005\u6b64\u5904\u6240\u8868\u8fbe\u7684\u610f\u601d\uff0c\u65e9\u671f\u7684programming language\u4e3b\u8981\u662f\u4e3a\u4e86\u201c\u63cf\u8ff0\u201dmachine\u3002\u5173\u4e8e\u201c\u63cf\u8ff0\u201d\u53c2\u89c1\u6587\u7ae0 Language \u3002 But computers are not so much machines as they are mind amplification\uff08\u653e\u5927\uff09 tools (\u201cbicycles for the mind,\u201d as Steve Jobs is fond of saying) and a different kind of expressive medium . As a result, the tools are beginning to look less like machines and more like parts of our minds , and also like other forms of expression such as writing, painting, sculpture, animation, and filmmaking. Object-oriented programming (OOP) is part of this movement toward using the computer as an expressive medium . NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8868\u8fbe\u7684\u610f\u601d\u662fprogramming language\u7684\u53d1\u5c55\u8d8b\u52bf\u662f\u201c\u63cf\u8ff0\u201d mind\u3002\u663e\u7136OOP\u5c31\u662f\u5728\u8fd9\u79cd\u6d6a\u6f6e\u4e0b\u8bde\u751f\u7684\u3002 \u5173\u4e8eprogramming language\uff0c\u53c2\u89c1\u6587\u7ae0 Abstraction \u7684 Abstraction in programming language \u7ae0\u8282\u3002 This chapter will introduce you to the basic concepts of OOP, including an overview of development methods. This chapter is background and supplementary material. Many people do not feel comfortable wading into object-oriented programming without understanding the big picture first. Thus, there are many concepts that are introduced here to give you a solid overview of OOP. However, other people may not get the big picture concepts until they\u2019ve seen some of the mechanics first; these people may become bogged down and lost without some code to get their hands on. If you\u2019re part of this latter group and are eager to get to the specifics of the language, feel free to jump past this chapter\u2014skipping it at this point will not prevent you from writing programs or learning the language. However, you will want to come back here eventually to fill in your knowledge so you can understand why objects are important and how to design with them. The progress of abstraction NOTE: \u672c\u8282\u4e3b\u8981\u63cf\u8ff0OO\u601d\u60f3\u3002 All programming languages provide abstractions . It can be argued that the complexity of the problems you\u2019re able to solve is directly related to the kind and quality of abstraction. By \u201ckind\u201d I mean, \u201cWhat is it that you are abstracting?\u201d Assembly language is a small abstraction of the underlying machine. Many so-called \u201cimperative\u201d languages that followed (such as FORTRAN, BASIC, and C) were abstractions of assembly language . These languages are big improvements over assembly language, but their primary abstraction still requires you to think in terms of the structure of the computer rather than the structure of the problem you are trying to solve\uff08\u4e5f\u5c31\u662f\u8bf4\uff0c\u5b83\u4eec\u8fd8\u4e0d\u591f\u62bd\u8c61\uff0c\u8fd8\u662f\u592a\u5e95\u5c42\u4e86\uff09. The programmer must establish the association between the machine model (in the \u201c solution space ,\u201d which is the place where you\u2019re implementing that solution, such as a computer) and the model of the problem that is actually being solved (in the \u201c problem space ,\u201d which is the place where the problem exists, such as a business). The effort required to perform this mapping, and the fact that it is extrinsic\uff08\u975e\u56fa\u6709\u7684\uff09 to the programming language, produces programs that are difficult to write and expensive to maintain, and as a side effect created the entire \u201cprogramming methods\u201d industry. NOTE: \u201cprogramming methods\u201d\u7684\u610f\u601d\u662f\u201c\u7a0b\u5e8f\u8bbe\u8ba1\u65b9\u6cd5\u5b66\u201d The alternative to modeling the machine is to model the problem you\u2019re trying to solve. Early languages such as LISP and APL chose particular views of the world (\u201cAll problems are ultimately lists\u201d or \u201cAll problems are algorithmic,\u201d respectively). Prolog casts all problems into chains of decisions. Languages have been created for constraint-based programming and for programming exclusively by manipulating graphical symbols. (The latter proved to be too restrictive.) Each of these approaches may be a good solution to the particular class of problem they\u2019re designed to solve, but when you step outside of that domain they become awkward. The object-oriented approach goes a step further by providing tools for the programmer to represent elements in the problem space . This representation is general enough that the programmer is not constrained to any particular type of problem. We refer to the elements in the problem space and their representations in the solution space as \u201c objects .\u201d (You will also need other objects that don\u2019t have problem-space analogs.) The idea is that the program is allowed to adapt itself to the lingo\uff08\u672f\u8bed\uff09 of the problem by adding new types of objects , so when you read the code describing the solution , you\u2019re reading words that also express the problem . This is a more flexible and powerful language abstraction than what we\u2019ve had before. Thus, OOP allows you to describe the problem in terms of the problem, rather than in terms of the computer where the solution will run. There\u2019s still a connection back to the computer: Each object looks quite a bit like a little computer \u2014it has a state , and it has operations that you can ask it to perform. However, this doesn\u2019t seem like such a bad analogy to objects in the real world\u2014they all have characteristics and behaviors. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u63cf\u8ff0\u4e86OO\u7684\u601d\u60f3\uff0c\u4f18\u52bf\u3002\u6211\u89c9\u5f97OO\u7684\u6838\u5fc3\u601d\u60f3\u5c31\u662f\u4f7f\u7528class\u6765\u63cf\u8ff0problem space\u4e2d\u7684\u5404\u79cd\u62bd\u8c61\u6982\u5ff5\uff0c\u7136\u540e\u5bf9\u95ee\u9898\u8fdb\u884c\u5efa\u6a21\uff0c\u8fdb\u884c\u5b9e\u73b0\u3002OO\u7684\u4f18\u52bf\u5728\u4e8e\uff1a OO\u66f4\u52a0\u62bd\u8c61\uff0c\u66f4\u52a0expressive OO\u662fgeneral\u7684\uff0c\u800c\u4e0d\u662fspecific\u7684 \u5173\u4e8eabstraction\uff0c\u53c2\u89c1\u6587\u7ae0 Abstraction \uff0c\u5176\u4e2d Abstraction in programming language \u7ae0\u8282\uff0c\u8ba8\u8bba\u4e86programming language\u7684\u53d1\u5c55\u7b80\u53f2\u3002 \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\u7684\u201cEach object looks quite a bit like a little computer \u201d\u6240\u8868\u8fbe\u7684\u601d\u60f3\u548c\u4e0b\u9762\u201cAn object provides services\u201d\u5c0f\u8282\u4e2d\u8868\u8fbe\u7684\u601d\u60f3\u7c7b\u4f3c\u3002 Alan Kay summarized five basic characteristics of Smalltalk , the first successful object-oriented language and one of the languages upon which Java is based. These characteristics represent a pure approach to object-oriented programming : Everything is an object . Think of an object as a fancy variable ; it stores data, but you can \u201cmake requests\u201d to that object, asking it to perform operations on itself. In theory, you can take any conceptual component in the problem you\u2019re trying to solve (dogs, buildings, services, etc.) and represent it as an object in your program. A program is a bunch of objects telling each other what to do by sending messages. To make a request of an object, you \u201csend a message\u201d to that object . More concretely, you can think of a message as a request to call a method that belongs to a particular object. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u603b\u7ed3\u4eceOOP\u7684\u89d2\u5ea6\u6765\u63cf\u8ff0\u7a0b\u5e8f\u7684\u8fd0\u884c\u3002 \u7262\u8bb0\u201csend a message\u201d\u548c\"make a request\u201c\uff0c\u540e\u9762\u4f1a\u9891\u7e41\u51fa\u73b0\uff0c\u5728\u4e0b\u4e00\u8282\u4f1a\u63cf\u8ff0\u5982\u4f55\u6765\u5b9e\u73b0\u201csend a message\u201d\u3002 Each object has its own memory made up of other objects . Put another way, you create a new kind of object by making a package containing existing objects. Thus, you can build complexity into a program while hiding it behind the simplicity of objects. NOTE: \u8fd9\u5c31\u662f\u6211\u4eec\u5e38\u5e38\u6240\u8bf4\u7684 Object composition Every object has a type . Using the parlance, each object is an instance of a class , in which \u201cclass\u201d is synonymous with \u201ctype.\u201d The most important distinguishing characteristic of a class is \u201cWhat messages can you send to it?\u201d All objects of a particular type can receive the same messages . This is actually a loaded statement, as you will see later. Because an object of type \u201ccircle\u201d is also an object of type \u201cshape,\u201d a circle is guaranteed to accept shape messages. This means you can write code that talks to shapes and automatically handle anything that fits the description of a shape. This substitutability is one of the powerful concepts in OOP. NOTE: \u4e0a\u97625\u6761\u5bf9OOP\u7684\u603b\u7ed3\u975e\u5e38\u597d\u3002 Booch offers an even more succinct description of an object: An object has state, behavior and identity. This means that an object can have internal data (which gives it state), methods (to produce behavior), and each object can be uniquely distinguished from every other object\u2014to put this in a concrete sense, each object has a unique address in memory. ATTENTION: This is actually a bit restrictive, since objects can conceivably exist in different machines and address spaces, and they can also be stored on disk. In these cases, the identity of the object must be determined by something other than memory address. An object has an interface NOTE: \u672c\u8282\u4e3b\u8981\u5206\u6790\u7684\u662fobject\u548cclass\u4e4b\u95f4\u7684\u5173\u7cfb\u3001class\u548ctype\u4e4b\u95f4\u7684\u5173\u7cfb\u3001\u5982\u4f55\u6765\u5b9e\u73b0\u201csent a message\u201d\u3002 Aristotle\uff08\u4e9a\u91cc\u58eb\u591a\u5fb7\uff09 was probably the first to begin a careful study of the concept of type ; he spoke of \u201cthe class of fishes and the class of birds.\u201d The idea that all objects, while being unique, are also part of a class of objects that have characteristics and behaviors in common was used directly in the first object-oriented language, Simula-67 , with its fundamental keyword class that introduces a new type into a program. Simula, as its name implies, was created for developing simulations such as the classic \u201cbank teller problem.\u201d In this, you have numerous tellers, customers, accounts, transactions, and units of money\u2014a lot of \u201cobjects.\u201d Objects that are identical except for their state during a program\u2019s execution are grouped together into \u201cclasses of objects,\u201d and that\u2019s where the keyword class came from. Creating abstract data types (classes) is a fundamental concept in object-oriented programming . Abstract data types work almost exactly like built-in types: You can create variables of a type (called objects or instances in object-oriented parlance) and manipulate those variables (called sending messages or requests ; you send a message and the object figures out what to do with it). The members (elements) of each class share some commonality: Every account has a balance, every teller can accept a deposit, etc. At the same time, each member has its own state: Each account has a different balance, each teller has a name. Thus, the tellers, customers, accounts, transactions, etc., can each be represented with a unique entity in the computer program. This entity is the object, and each object belongs to a particular class that defines its characteristics and behaviors. So, although what we really do in object-oriented programming is create new data types , virtually all object-oriented programming languages use the \u201cclass\u201d keyword. When you see the word \u201c type \u201d think \u201c class \u201d and vice versa. ATTENTION: Some people make a distinction, stating that type determines the interface while class is a particular implementation of that interface. Since a class describes a set of objects that have identical characteristics (data elements) and behaviors (functionality), a class is really a data type because a floating point number, for example, also has a set of characteristics and behaviors. The difference is that a programmer defines a class to fit a problem rather than being forced to use an existing data type that was designed to represent a unit of storage in a machine. You extend the programming language by adding new data types specific to your needs. The programming system welcomes the new classes and gives them all the care and type checking that it gives to built-in types. The object-oriented approach is not limited to building simulations. Whether or not you agree that any program is a simulation of the system you\u2019re designing, the use of OOP techniques can easily reduce a large set of problems to a simple solution. Once a class is established, you can make as many objects of that class as you like, and then manipulate those objects as if they are the elements that exist in the problem you are trying to solve. Indeed, one of the challenges of object-oriented programming is to create a one-to-one mapping between the elements in the problem space and objects in the solution space . NOTE: OOP\u7684challenge\u3002 But how do you get an object to do useful work for you? There needs to be a way to make a request of the object so that it will do something, such as complete a transaction, draw something on the screen, or turn on a switch. And each object can satisfy only certain requests. The requests you can make of an object are defined by its interface , and the type is what determines the interface. A simple example might be a representation of a light bulb: The interface determines the requests that you can make for a particular object. However, there must be code somewhere to satisfy that request. This, along with the hidden data , comprises the implementation . From a procedural programming standpoint, it\u2019s not that complicated. A type has a method associated with each possible request, and when you make a particular request to an object, that method is called. This process is usually summarized by saying that you \u201c send a message \u201d ( make a request ) to an object, and the object figures out what to do with that message (it executes code). The preceding diagram follows the format of the Unified Modeling Language (UML). Each class is represented by a box, with the type name in the top portion of the box, any data members that you care to describe in the middle portion of the box, and the methods (the functions that belong to this object, which receive any messages you send to that object) in the bottom portion of the box. Often, only the name of the class and the public methods are shown in UML design diagrams, so the middle portion is not shown, as in this case. If you\u2019re interested only in the class name, then the bottom portion doesn\u2019t need to be shown, either. An object provides services NOTE: \u672c\u8282\u4e3b\u8981\u8bb2\u8ff0\u4e86\u5982\u4f55\u6765\u66f4\u597d\u5730\u4f7f\u7528OO\u6765\u89e3\u51b3\u95ee\u9898\uff0c\u79c9\u6301\uff1a\u5c06object\u7406\u89e3\u4e3a\u201cservice provider\u201d\u7684\u601d\u60f3\u3002 While you\u2019re trying to develop or understand a program design, one of the best ways to think about objects is as \u201c service providers .\u201d Your program itself will provide services to the user, and it will accomplish this by using the services offered by other objects. Your goal is to produce (or even better, locate in existing code libraries) a set of objects that provide the ideal services to solve your problem. Thinking of an object as a service provider has an additional benefit: It helps to improve the cohesiveness of the object. High cohesion is a fundamental quality of software design: It means that the various aspects of a software component (such as an object, although this could also apply to a method or a library of objects) \u201cfit together\u201d well. One problem people have when designing objects is cramming\uff08\u585e\u8fdb\uff09 too much functionality into one object. For example, in your check printing module, you may decide you need an object that knows all about formatting and printing. You\u2019ll probably discover that this is too much for one object, and that what you need is three or more objects. One object might be a catalog of all the possible check layouts, which can be queried for information about how to print a check. One object or set of objects can be a generic printing interface that knows all about different kinds of printers (but nothing about bookkeeping\u2014this one is a candidate for buying rather than writing yourself). And a third object could use the services of the other two to accomplish the task. Thus, each object has a cohesive set of services it offers. In a good object-oriented design, each object does one thing well, but doesn\u2019t try to do too much. This not only allows the discovery of objects that might be purchased (the printer interface object), but it also produces new objects that might be reused somewhere else (the catalog of check layouts). Treating objects as service providers is a great simplifying tool. This is useful not only during the design process, but also when someone else is trying to understand your code or reuse an object. If they can see the value of the object based on what service it provides, it makes it much easier to fit it into the design. The hidden implementation It is helpful to break up the playing field into class creators (those who create new data types) and client programmers (the class consumers who use the data types in their applications). The goal of the client programmer is to collect a toolbox full of classes to use for rapid application development. The goal of the class creator is to build a class that exposes only what\u2019s necessary to the client programmer and keeps everything else hidden . Why? Because if it\u2019s hidden, the client programmer can\u2019t access it, which means that the class creator can change the hidden portion at will without worrying about the impact on anyone else. The hidden portion usually represents the tender insides of an object that could easily be corrupted by a careless or uninformed client programmer, so hiding the implementation reduces program bugs. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u6240\u63cf\u8ff0\u7684\u662f\u4f7f\u7528OOP\u5e26\u6765\u7684\u4e00\u4e2a\u597d\u5904\uff1ahidden\u3002 In any relationship it\u2019s important to have boundaries that are respected by all parties involved. When you create a library, you establish a relationship with the client programmer, who is also a programmer, but one who is putting together an application by using your library, possibly to build a bigger library. If all the members of a class are available to everyone, then the client programmer can do anything with that class and there\u2019s no way to enforce rules. Even though you might really prefer that the client programmer not directly manipulate some of the members of your class, without access control there\u2019s no way to prevent it. Everything\u2019s naked to the world. So the first reason for access control is to keep client programmers\u2019 hands off portions they shouldn\u2019t touch\u2014parts that are necessary for the internal operation of the data type but not part of the interface that users need in order to solve their particular problems. This is actually a service to client programmers because they can easily see what\u2019s important to them and what they can ignore. The second reason for access control is to allow the library designer to change the internal workings of the class without worrying about how it will affect the client programmer. For example, you might implement a particular class in a simple fashion to ease development, and then later discover that you need to rewrite it in order to make it run faster. If the interface and implementation are clearly separated and protected, you can accomplish this easily. Java uses three explicit keywords to set the boundaries in a class: public, private, and protected. These access specifiers determine who can use the definitions that follow. public means the following element is available to everyone. The private keyword, on the other hand, means that no one can access that element except you, the creator of the type, inside methods of that type. private is a brick wall between you and the client programmer. Someone who tries to access a private member will get a compile-time error. The protected keyword acts like private, with the exception that an inheriting class has access to protected members, but not private members. Inheritance will be introduced shortly. Java also has a \u201cdefault\u201d access, which comes into play if you don\u2019t use one of the aforementioned specifiers. This is usually called package access because classes can access the members of other classes in the same package (library component), but outside of the package those same members appear to be private. Reusing the implementation Once a class has been created and tested, it should (ideally) represent a useful unit of code. It turns out that this reusability is not nearly so easy to achieve as many would hope; it takes experience and insight to produce a reusable object design. But once you have such a design, it begs to be reused. Code reuse is one of the greatest advantages that object-oriented programming languages provide. The simplest way to reuse a class is to just use an object of that class directly, but you can also place an object of that class inside a new class. We call this \u201ccreating a member object.\u201d Your new class can be made up of any number and type of other objects, in any combination that you need to achieve the functionality desired in your new class. Because you are composing a new class from existing classes, this concept is called composition (if the composition happens dynamically, it\u2019s usually called aggregation). Composition is often referred to as a \u201chas-a\u201d relationship, as in \u201cA car has an engine.\u201d (This UML diagram indicates composition with the filled diamond, which states there is one car. I will typically use a simpler form: just a line, without the diamond, to indicate an association. 5 ) Composition comes with a great deal of flexibility. The member objects of your new class are typically private, making them inaccessible to the client programmers who are using the class. This allows you to change those members without disturbing existing client code. You can also change the member objects at run time, to dynamically change the behavior of your program. Inheritance, which is described next, does not have this flexibility since the compiler must place compile-time restrictions on classes created with inheritance. Because inheritance is so important in object-oriented programming, it is often highly emphasized, and the new programmer can get the idea that inheritance should be used everywhere. This can result in awkward and overly complicated designs. Instead, you should first look to composition when creating new classes, since it is simpler and more flexible. If you take this approach, your designs will be cleaner. Once you\u2019ve had some experience, it will be reasonably obvious when you need inheritance. Inheritance By itself, the idea of an object is a convenient tool. It allows you to package data and functionality together by concept, so you can represent an appropriate problem-space idea rather than being forced to use the idioms of the underlying machine. These concepts are expressed as fundamental units in the programming language by using the class keyword. It seems a pity, however, to go to all the trouble to create a class and then be forced to create a brand new one that might have similar functionality. It\u2019s nicer if we can take the existing class, clone it, and then make additions and modifications to the clone. This is effectively what you get with inheritance, with the exception that if the original class (called the base class or superclass or parent class) is changed, the modified \u201cclone\u201d (called the derived class or inherited class or subclass or child class) also reflects those changes. (The arrow in this UML diagram points from the derived class to the base class. As you will see, there is commonly more than one derived class.) A type does more than describe the constraints on a set of objects; it also has a relationship with other types. Two types can have characteristics and behaviors in common, but one type may contain more characteristics than another and may also handle more messages (or handle them differently). Inheritance expresses this similarity between types by using the concept of base types and derived types. A base type contains all of the characteristics and behaviors that are shared among the types derived from it. You create a base type to represent the core of your ideas about some objects in your system. From the base type, you derive other types to express the different ways that this core can be realized. For example, a trash-recycling machine sorts pieces of trash. The base type is \u201ctrash\u201d, and each piece of trash has a weight, a value, and so on, and can be shredded, melted, or decomposed. From this, more specific types of trash are derived that may have additional characteristics (a bottle has a color) or behaviors (an aluminum can may be crushed, a steel can is magnetic). In addition, some behaviors may be different (the value of paper depends on its type and condition). Using inheritance, you can build a type hierarchy that expresses the problem you\u2019re trying to solve in terms of its types. A second example is the classic \u201cshape\u201d example, perhaps used in a computer-aided design system or game simulation. The base type is \u201cshape,\u201d and each shape has a size, a color, a position, and so on. Each shape can be drawn, erased, moved, colored, etc. From this, specific types of shapes are derived (inherited)\u2014circle, square, triangle, and so on\u2014each of which may have additional characteristics and behaviors. Certain shapes can be flipped, for example. Some behaviors may be different, such as when you want to calculate the area of a shape. The type hierarchy embodies both the similarities and differences between the shapes. Casting the solution in the same terms as the problem is very useful because you don\u2019t need a lot of intermediate models to get from a description of the problem to a description of the solution. With objects, the type hierarchy is the primary model, so you go directly from the description of the system in the real world to the description of the system in code. Indeed, one of the difficulties people have with object-oriented design is that it\u2019s too simple to get from the beginning to the end. A mind trained to look for complex solutions can initially be stumped by this simplicity. When you inherit from an existing type, you create a new type. This new type contains not only all the members of the existing type (although the private ones are hidden away and inaccessible), but more importantly it duplicates the interface of the base class. That is, all the messages you can send to objects of the base class you can also send to objects of the derived class. Since we know the type of a class by the messages we can send to it, this means that the derived class is the same type as the base class. In the previous example, \u201cA circle is a shape.\u201d This type equivalence via inheritance is one of the fundamental gateways in understanding the meaning of object-oriented programming. Since both the base class and derived class have the same fundamental interface, there must be some implementation to go along with that interface. That is, there must be some code to execute when an object receives a particular message. If you simply inherit a class and don\u2019t do anything else, the methods from the base-class interface come right along into the derived class. That means objects of the derived class have not only the same type, they also have the same behavior, which isn\u2019t particularly interesting. You have two ways to differentiate your new derived class from the original base class. The first is quite straightforward: You simply add brand new methods to the derived class. These new methods are not part of the base-class interface. This means that the base class simply didn\u2019t do as much as you wanted it to, so you added more methods. This simple and primitive use for inheritance is, at times, the perfect solution to your problem. However, you should look closely for the possibility that your base class might also need these additional methods. This process of discovery and iteration of your design happens regularly in object-oriented programming. Although inheritance may sometimes imply (especially in Java, where the keyword for inheritance is extends) that you are going to add new methods to the interface, that\u2019s not necessarily true. The second and more important way to differentiate your new class is to change the behavior of an existing base-class method. This is referred to as overriding that method. To override a method, you simply create a new definition for the method in the derived class. You\u2019re saying, \u201cI\u2019m using the same interface method here, but I want it to do something different for my new type.\u201d Is-a vs. is-like-a relationships There\u2019s a certain debate that can occur about inheritance: Should inheritance override only baseclass methods (and not add new methods that aren\u2019t in the base class)? This would mean that the derived class is exactly the same type as the base class since it has exactly the same interface. As a result, you can exactly substitute an object of the derived class for an object of the base class. This can be thought of as pure substitution, and it\u2019s often referred to as the substitution principle. In a sense, this is the ideal way to treat inheritance. We often refer to the relationship between the base class and derived classes in this case as an is-a relationship, because you can say, \u201cA circle is a shape.\u201d A test for inheritance is to determine whether you can state the is-a relationship about the classes and have it make sense. There are times when you must add new interface elements to a derived type, thus extending the interface. The new type can still be substituted for the base type, but the substitution isn\u2019t perfect because your new methods are not accessible from the base type. This can be described as an islike-a relationship (my term). The new type has the interface of the old type but it also contains other methods, so you can\u2019t really say it\u2019s exactly the same. For example, consider an air conditioner. Suppose your house is wired with all the controls for cooling; that is, it has an interface that allows you to control cooling. Imagine that the air conditioner breaks down and you replace it with a heat pump, which can both heat and cool. The heat pump is-like-an air conditioner, but it can do more. Because the control system of your house is designed only to control cooling, it is restricted to communication with the cooling part of the new object. The interface of the new object has been extended, and the existing system doesn\u2019t know about anything except the original interface. Of course, once you see this design it becomes clear that the base class \u201ccooling system\u201d is not general enough, and should be renamed to \u201ctemperature control system\u201d so that it can also include heating\u2014at which point the substitution principle will work. However, this diagram is an example of what can happen with design in the real world. When you see the substitution principle it\u2019s easy to feel like this approach (pure substitution) is the only way to do things, and in fact it is nice if your design works out that way. But you\u2019ll find that there are times when it\u2019s equally clear that you must add new methods to the interface of a derived class. With inspection both cases should be reasonably obvious. Interchangeable objects with polymorphism When dealing with type hierarchies, you often want to treat an object not as the specific type that it is, but instead as its base type. This allows you to write code that doesn\u2019t depend on specific types. In the shape example, methods manipulate generic shapes, unconcerned about whether they\u2019re circles, squares, triangles, or some shape that hasn\u2019t even been defined yet. All shapes can be drawn, erased, and moved, so these methods simply send a message to a shape object; they don\u2019t worry about how the object copes with the message. Such code is unaffected by the addition of new types, and adding new types is the most common way to extend an object-oriented program to handle new situations. For example, you can derive a new subtype of shape called pentagon without modifying the methods that deal only with generic shapes. This ability to easily extend a design by deriving new subtypes is one of the essential ways to encapsulate change. This greatly improves designs while reducing the cost of software maintenance. There\u2019s a problem, however, with attempting to treat derived-type objects as their generic base types (circles as shapes, bicycles as vehicles, cormorants as birds, etc.). If a method is going to tell a generic shape to draw itself, or a generic vehicle to steer, or a generic bird to move, the compiler cannot know at compile time precisely what piece of code will be executed. That\u2019s the whole point\u2014when the message is sent, the programmer doesn\u2019t want to know what piece of code will be executed; the draw method can be applied equally to a circle, a square, or a triangle, and the object will execute the proper code depending on its specific type. If you don\u2019t have to know what piece of code will be executed, then when you add a new subtype, the code it executes can be different without requiring changes to the method that calls it. Therefore, the compiler cannot know precisely what piece of code is executed, so what does it do? For example, in the following diagram the BirdController object just works with generic Bird objects and does not know what exact type they are. This is convenient from BirdController\u2019s perspective because it doesn\u2019t have to write special code to determine the exact type of Bird it\u2019s working with or that Bird\u2019s behavior. So how does it happen that, when move( ) is called while ignoring the specific type of Bird, the right behavior will occur (a Goose walks, flies, or swims, and a Penguin walks or swims)? The answer is the primary twist in object-oriented programming: The compiler cannot make a function call in the traditional sense. The function call generated by a non-OOP compiler causes what is called early binding, a term you may not have heard before because you\u2019ve never thought about it any other way. It means the compiler generates a call to a specific function name, and the runtime system resolves this call to the absolute address of the code to be executed. In OOP, the program cannot determine the address of the code until run time, so some other scheme is necessary when a message is sent to a generic object. To solve the problem, object-oriented languages use the concept of late binding. When you send a message to an object, the code being called isn\u2019t determined until run time. The compiler does ensure that the method exists and performs type checking on the arguments and return value, but it doesn\u2019t know the exact code to execute. To perform late binding, Java uses a special bit of code in lieu of the absolute call. This code calculates the address of the method body, using information stored in the object (this process is covered in great detail in the Polymorphism chapter). Thus, each object can behave differently according to the contents of that special bit of code. When you send a message to an object, the object actually does figure out what to do with that message. In some languages you must explicitly state that you want a method to have the flexibility of latebinding properties (C++ uses the virtual keyword to do this). In these languages, by default, methods are not dynamically bound. In Java, dynamic binding is the default behavior and you don\u2019t need to remember to add any extra keywords in order to get polymorphism. Consider the shape example. The family of classes (all based on the same uniform interface) was diagrammed earlier in this chapter. To demonstrate polymorphism, we want to write a single piece of code that ignores the specific details of type and talks only to the base class. That code is decoupled from type-specific information and thus is simpler to write and easier to understand. And, if a new type\u2014a Hexagon, for example\u2014is added through inheritance, the code you write will work just as well for the new type of Shape as it did on the existing types. Thus, the program is extensible. If you write a method in Java (as you will soon learn how to do): void doSomething ( Shape shape ) { shape . erase (); // ... shape . draw (); } This method speaks to any Shape, so it is independent of the specific type of object that it\u2019s drawing and erasing. If some other part of the program uses the doSomething( ) method: Circle circle = new Circle (); Triangle triangle = new Triangle (); Line line = new Line (); doSomething ( circle ); doSomething ( triangle ); doSomething ( line ); The calls to doSomething( ) automatically work correctly, regardless of the exact type of the object. This is a rather amazing trick. Consider the line: doSomething ( circle ); What\u2019s happening here is that a Circle is being passed into a method that\u2019s expecting a Shape. Since a Circle is a Shape it can be treated as one by doSomething( ) . That is, any message that doSomething( ) can send to a Shape, a Circle can accept. So it is a completely safe and logical thing to do. We call this process of treating a derived type as though it were its base type upcasting. The name cast is used in the sense of casting into a mold and the up comes from the way the inheritance diagram is typically arranged, with the base type at the top and the derived classes fanning out downward. Thus, casting to a base type is moving up the inheritance diagram: \u201cupcasting.\u201d An object-oriented program contains some upcasting somewhere, because that\u2019s how you decouple yourself from knowing about the exact type you\u2019re working with. Look at the code in doSomething( ) : shape . erase (); // ... shape . draw (); Notice that it doesn\u2019t say, \u201cIf you\u2019re a Circle, do this, if you\u2019re a Square, do that, etc.\u201d If you write that kind of code, which checks for all the possible types that a Shape can actually be, it\u2019s messy and you need to change it every time you add a new kind of Shape. Here, you just say, \u201cYou\u2019re a shape, I know you can erase() and draw( ) yourself, do it, and take care of the details correctly.\u201d What\u2019s impressive about the code in doSomething( ) is that, somehow, the right thing happens. Calling draw( ) for Circle causes different code to be executed than when calling draw( ) for a Square or a Line, but when the draw( ) message is sent to an anonymous Shape, the correct behavior occurs based on the actual type of the Shape. This is amazing because, as mentioned earlier, when the Java compiler is compiling the code for doSomething( ) , it cannot know exactly what types it is dealing with. So ordinarily, you\u2019d expect it to end up calling the version of erase( ) and draw( ) for the base class Shape, and not for the specific Circle, Square, or Line. And yet the right thing happens because of polymorphism. The compiler and runtime system handle the details; all you need to know right now is that it does happen, and more importantly, how to design with it. When you send a message to an object, the object will do the right thing, even when upcasting is involved. The singly rooted hierarchy One of the issues in OOP that has become especially prominent since the introduction of C++ is whether all classes should ultimately be inherited from a single base class. In Java (as with virtually all other OOP languages except for C++) the answer is yes, and the name of this ultimate base class is simply Object. It turns out that the benefits of the singly rooted hierarchy are many. All objects in a singly rooted hierarchy have an interface in common, so they are all ultimately the same fundamental type. The alternative (provided by C++) is that you don\u2019t know that everything is the same basic type. From a backward-compatibility standpoint this fits the model of C better and can be thought of as less restrictive, but when you want to do full-on objectoriented programming you must then build your own hierarchy to provide the same convenience that\u2019s built into other OOP languages. And in any new class library you acquire, some other incompatible interface will be used. It requires effort (and possibly multiple inheritance) to work the new interface into your design. Is the extra \u201cflexibility\u201d of C++ worth it? If you need it\u2014if you have a large investment in C\u2014it\u2019s quite valuable. If you\u2019re starting from scratch, other alternatives such as Java can often be more productive. All objects in a singly rooted hierarchy can be guaranteed to have certain functionality. You know you can perform certain basic operations on every object in your system. All objects can easily be created on the heap, and argument passing is greatly simplified. A singly rooted hierarchy makes it much easier to implement a garbage collector, which is one of the fundamental improvements of Java over C++. And since information about the type of an object is guaranteed to be in all objects, you\u2019ll never end up with an object whose type you cannot determine. This is especially important with system-level operations, such as exception handling, and to allow greater flexibility in programming. Containers In general, you don\u2019t know how many objects you\u2019re going to need to solve a particular problem, or how long they will last. You also don\u2019t know how to store those objects. How can you know how much space to create if that information isn\u2019t known until run time? The solution to most problems in object-oriented design seems flippant: You create another type of object. The new type of object that solves this particular problem holds references to other objects. Of course, you can do the same thing with an array, which is available in most languages. But this new object, generally called a container (also called a collection, but the Java library uses that term in a different sense so this book will use \u201ccontainer\u201d), will expand itself whenever necessary to accommodate everything you place inside it. So you don\u2019t need to know how many objects you\u2019re going to hold in a container. Just create a container object and let it take care of the details. Fortunately, a good OOP language comes with a set of containers as part of the package. In C++, it\u2019s part of the Standard C++ Library and is often called the Standard Template Library (STL). Smalltalk has a very complete set of containers. Java also has numerous containers in its standard library. In some libraries, one or two generic containers is considered good enough for all needs, and in others (Java, for example) the library has different types of containers for different needs: several different kinds of List classes (to hold sequences), Maps (also known as associative arrays, to associate objects with other objects), Sets (to hold one of each type of object), and more components such as queues, trees, stacks, etc. From a design standpoint, all you really want is a container that can be manipulated to solve your problem. If a single type of container satisfied all of your needs, there\u2019d be no reason to have different kinds. There are two reasons that you need a choice of containers. First, containers provide different types of interfaces and external behavior. A stack has a different interface and behavior than a queue, which is different from a set or a list. One of these might provide a more flexible solution to your problem than the other. Second, different containers have different efficiencies for certain operations. For example, there are two basic types of List: ArrayList and LinkedList. Both are simple sequences that can have identical interfaces and external behaviors. But certain operations can have significantly different costs. Randomly accessing elements in an ArrayList is a constant-time operation; it takes the same amount of time regardless of the element you select. However, in a LinkedList it is expensive to move through the list to randomly select an element, and it takes longer to find an element that is farther down the list. On the other hand, if you want to insert an element in the middle of a sequence, it\u2019s cheaper in a LinkedList than in an ArrayList. These and other operations have different efficiencies depending on the underlying structure of the sequence. You might start building your program with a LinkedList and, when tuning for performance, change to an ArrayList. Because of the abstraction via the interface List, you can change from one to the other with minimal impact on your code. Parameterized types (generics) Before Java SE5, containers held the one universal type in Java: Object. The singly rooted hierarchy means that everything is an Object, so a container that holds Objects can hold anything. 6 This made containers easy to reuse. To use such a container, you simply add object references to it and later ask for them back. But, since the container held only Objects, when you added an object reference into the container it was upcast to Object, thus losing its character. When fetching it back, you got an Object reference, and not a reference to the type that you put in. So how do you turn it back into something that has the specific type of the object that you put into the container? Here, the cast is used again, but this time you\u2019re not casting up the inheritance hierarchy to a more general type. Instead, you cast down the hierarchy to a more specific type. This manner of casting is called downcasting. With upcasting, you know, for example, that a Circle is a type of Shape so it\u2019s safe to upcast, but you don\u2019t know that an Object is necessarily a Circle or a Shape so it\u2019s hardly safe to downcast unless you know exactly what you\u2019re dealing with. It\u2019s not completely dangerous, however, because if you downcast to the wrong thing you\u2019ll get a runtime error called an exception, which will be described shortly. When you fetch object references from a container, though, you must have some way to remember exactly what they are so you can perform a proper downcast. Downcasting and the runtime checks require extra time for the running program and extra effort from the programmer. Wouldn\u2019t it make sense to somehow create the container so that it knows the types that it holds, eliminating the need for the downcast and a possible mistake? The solution is called a parameterized type mechanism. A parameterized type is a class that the compiler can automatically customize to work with particular types. For example, with a parameterized container, the compiler could customize that container so that it would accept only Shapes and fetch only Shapes. One of the big changes in Java SE5 is the addition of parameterized types, called generics in Java. You\u2019ll recognize the use of generics by the angle brackets with types inside; for example, an ArrayList that holds Shape can be created like this: ArrayList < Shape > shapes = new ArrayList < Shape >(); There have also been changes to many of the standard library components in order to take advantage of generics. As you will see, generics have an impact on much of the code in this book. Object creation & lifetime One critical issue when working with objects is the way they are created and destroyed. Each object requires resources, most notably memory, in order to exist. When an object is no longer needed it must be cleaned up so that these resources are released for reuse. In simple programming situations the question of how an object is cleaned up doesn\u2019t seem too challenging: You create the object, use it for as long as it\u2019s needed, and then it should be destroyed. However, it\u2019s not hard to encounter situations that are more complex. Suppose, for example, you are designing a system to manage air traffic for an airport. (The same model might also work for managing crates in a warehouse, or a video rental system, or a kennel for boarding pets.) At first it seems simple: Make a container to hold airplanes, then create a new airplane and place it in the container for each airplane that enters the air-traffic-control zone. For cleanup, simply clean up the appropriate airplane object when a plane leaves the zone. But perhaps you have some other system to record data about the planes; perhaps data that doesn\u2019t require such immediate attention as the main controller function. Maybe it\u2019s a record of the flight plans of all the small planes that leave the airport. So you have a second container of small planes, and whenever you create a plane object you also put it in this second container if it\u2019s a small plane. Then some background process performs operations on the objects in this container during idle moments. Now the problem is more difficult: How can you possibly know when to destroy the objects? When you\u2019re done with the object, some other part of the system might not be. This same problem can arise in a number of other situations, and in programming systems (such as C++) in which you must explicitly delete an object when you\u2019re done with it this can become quite complex. Where is the data for an object and how is the lifetime of the object controlled? C++ takes the approach that control of efficiency is the most important issue, so it gives the programmer a choice. For maximum runtime speed, the storage and lifetime can be determined while the program is being written, by placing the objects on the stack (these are sometimes called automatic or scoped variables) or in the static storage area. This places a priority on the speed of storage allocation and release, and this control can be very valuable in some situations. However, you sacrifice flexibility because you must know the exact quantity, lifetime, and type of objects while you\u2019re writing the program. If you are trying to solve a more general problem such as computer-aided design, warehouse management, or air-traffic control, this is too restrictive. The second approach is to create objects dynamically in a pool of memory called the heap. In this approach, you don\u2019t know until run time how many objects you need, what their lifetime is, or what their exact type is. Those are determined at the spur of the moment while the program is running. If you need a new object, you simply make it on the heap at the point that you need it. Because the storage is managed dynamically, at run time, the amount of time required to allocate storage on the heap can be noticeably longer than the time to create storage on the stack. Creating storage on the stack is often a single assembly instruction to move the stack pointer down and another to move it back up. The time to create heap storage depends on the design of the storage mechanism. The dynamic approach makes the generally logical assumption that objects tend to be complicated, so the extra overhead of finding storage and releasing that storage will not have an important impact on the creation of an object. In addition, the greater flexibility is essential to solve the general programming problem. Java uses dynamic memory allocation, exclusively. 7 Every time you want to create an object, you use the new operator to build a dynamic instance of that object. There\u2019s another issue, however, and that\u2019s the lifetime of an object. With languages that allow objects to be created on the stack, the compiler determines how long the object lasts and can automatically destroy it. However, if you create it on the heap the compiler has no knowledge of its lifetime. In a language like C++, you must determine programmatically when to destroy the object, which can lead to memory leaks if you don\u2019t do it correctly (and this is a common problem in C++ programs). Java provides a feature called a garbage collector that automatically discovers when an object is no longer in use and destroys it. A garbage collector is much more convenient because it reduces the number of issues that you must track and the code you must write. More importantly, the garbage collector provides a much higher level of insurance against the insidious problem of memory leaks, which has brought many a C++ project to its knees. With Java, the garbage collector is designed to take care of the problem of releasing the memory (although this doesn\u2019t include other aspects of cleaning up an object). The garbage collector \u201cknows\u201d when an object is no longer in use, and it then automatically releases the memory for that object. This, combined with the fact that all objects are inherited from the single root class Object and that you can create objects only one way\u2014on the heap\u2014makes the process of programming in Java much simpler than programming in C++. You have far fewer decisions to make and hurdles to overcome. Exception handling: dealing with errors Ever since the beginning of programming languages, error handling has been a particularly difficult issue. Because it\u2019s so hard to design a good error-handling scheme, many languages simply ignore the issue, passing the problem on to library designers who come up with halfway measures that work in many situations but that can easily be circumvented, generally by just ignoring them. A major problem with most error-handling schemes is that they rely on programmer vigilance in following an agreed-upon convention that is not enforced by the language. If the programmer is not vigilant\u2014often the case if they are in a hurry\u2014these schemes can easily be forgotten. Exception handling wires error handling directly into the programming language and sometimes even the operating system. An exception is an object that is \u201cthrown\u201d from the site of the error and can be \u201ccaught\u201d by an appropriate exception handler designed to handle that particular type of error. It\u2019s as if exception handling is a different, parallel path of execution that can be taken when things go wrong. And because it uses a separate execution path, it doesn\u2019t need to interfere with your normally executing code. This tends to make that code simpler to write because you aren\u2019t constantly forced to check for errors. In addition, a thrown exception is unlike an error value that\u2019s returned from a method or a flag that\u2019s set by a method in order to indicate an error condition\u2014these can be ignored. An exception cannot be ignored, so it\u2019s guaranteed to be dealt with at some point. Finally, exceptions provide a way to reliably recover from a bad situation. Instead of just exiting the program, you are often able to set things right and restore execution, which produces much more robust programs. Java\u2019s exception handling stands out among programming languages, because in Java, exception handling was wired in from the beginning and you\u2019re forced to use it. It is the single acceptable way to report errors. If you don\u2019t write your code to properly handle exceptions, you\u2019ll get a compile-time error message. This guaranteed consistency can sometimes make error handling much easier. It\u2019s worth noting that exception handling isn\u2019t an object-oriented feature, although in object-oriented languages the exception is normally represented by an object. Exception handling existed before object-oriented languages. Concurrent programming A fundamental concept in computer programming is the idea of handling more than one task at a time. Many programming problems require that the program stop what it\u2019s doing, deal with some other problem, and then return to the main process. The solution has been approached in many ways. Initially, programmers with low-level knowledge of the machine wrote interrupt service routines, and the suspension of the main process was initiated through a hardware interrupt. Although this worked well, it was difficult and non-portable, so it made moving a program to a new type of machine slow and expensive.","title":"Introduction-to-Objects"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Introduction-to-Objects/#introduction-to-objects","text":"\u201cWe cut nature up, organize it into concepts , and ascribe significances as we do, largely because we are parties to an agreement that holds throughout our speech community and is codified in the patterns of our language \u2026 we cannot talk at all except by subscribing to the organization and classification of data which the agreement decrees.\u201d Benjamin Lee Whorf (1897-1941) NOTE: \u6211\u4eec\u4e4b\u6240\u4ee5\u5c06\u81ea\u7136\u5206\u89e3\uff0c\u7ec4\u7ec7\u6210\u5404\u79cd\u6982\u5ff5\uff0c\u5e76\u6309\u5176\u542b\u4e49\u5206\u7c7b\uff0c\u4e3b\u8981\u662f\u6211\u4eec\u662f\u6574\u4e2a\u53e3\u8bed\u4ea4\u6d41\u793e\u4f1a\u5171\u540c\u9075\u5b88\u7684\u534f\u5b9a\u7684\u53c2\u4e0e\u8005\uff0c\u8fd9\u4e2a\u534f\u5b9a\u4ee5\u8bed\u8a00\u7684\u5f62\u5f0f\u56fa\u5b9a\u4e0b\u6765...\u9664\u975e\u8d5e\u6210\u8fd9\u4e2a\u8fd9\u4e2a\u534f\u5b9a\u4e2d\u6709\u5173\u8bed\u8a00\u7684\u7ec4\u7ec7\u548c\u5206\u7c7b\uff0c\u5426\u5219\u6211\u4eec\u65e0\u6cd5\u4ea4\u8c08\u3002 The genesis\uff08\u8d77\u6e90\uff09 of the computer revolution was in a machine . The genesis of our programming languages thus tends to look like that machine. NOTE: \u201cThe genesis of our programming languages thus tends to look like that machine\u201d\u7684\u610f\u601d\u662f\uff1a\u8d77\u521d\u7684programming language\u662f\u975e\u5e38\u7c7b\u4f3c\u4e8emachine\u7684\u3002\u4f5c\u8005\u6b64\u5904\u6240\u8868\u8fbe\u7684\u610f\u601d\uff0c\u65e9\u671f\u7684programming language\u4e3b\u8981\u662f\u4e3a\u4e86\u201c\u63cf\u8ff0\u201dmachine\u3002\u5173\u4e8e\u201c\u63cf\u8ff0\u201d\u53c2\u89c1\u6587\u7ae0 Language \u3002 But computers are not so much machines as they are mind amplification\uff08\u653e\u5927\uff09 tools (\u201cbicycles for the mind,\u201d as Steve Jobs is fond of saying) and a different kind of expressive medium . As a result, the tools are beginning to look less like machines and more like parts of our minds , and also like other forms of expression such as writing, painting, sculpture, animation, and filmmaking. Object-oriented programming (OOP) is part of this movement toward using the computer as an expressive medium . NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8868\u8fbe\u7684\u610f\u601d\u662fprogramming language\u7684\u53d1\u5c55\u8d8b\u52bf\u662f\u201c\u63cf\u8ff0\u201d mind\u3002\u663e\u7136OOP\u5c31\u662f\u5728\u8fd9\u79cd\u6d6a\u6f6e\u4e0b\u8bde\u751f\u7684\u3002 \u5173\u4e8eprogramming language\uff0c\u53c2\u89c1\u6587\u7ae0 Abstraction \u7684 Abstraction in programming language \u7ae0\u8282\u3002 This chapter will introduce you to the basic concepts of OOP, including an overview of development methods. This chapter is background and supplementary material. Many people do not feel comfortable wading into object-oriented programming without understanding the big picture first. Thus, there are many concepts that are introduced here to give you a solid overview of OOP. However, other people may not get the big picture concepts until they\u2019ve seen some of the mechanics first; these people may become bogged down and lost without some code to get their hands on. If you\u2019re part of this latter group and are eager to get to the specifics of the language, feel free to jump past this chapter\u2014skipping it at this point will not prevent you from writing programs or learning the language. However, you will want to come back here eventually to fill in your knowledge so you can understand why objects are important and how to design with them.","title":"Introduction to Objects"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Introduction-to-Objects/#the-progress-of-abstraction","text":"NOTE: \u672c\u8282\u4e3b\u8981\u63cf\u8ff0OO\u601d\u60f3\u3002 All programming languages provide abstractions . It can be argued that the complexity of the problems you\u2019re able to solve is directly related to the kind and quality of abstraction. By \u201ckind\u201d I mean, \u201cWhat is it that you are abstracting?\u201d Assembly language is a small abstraction of the underlying machine. Many so-called \u201cimperative\u201d languages that followed (such as FORTRAN, BASIC, and C) were abstractions of assembly language . These languages are big improvements over assembly language, but their primary abstraction still requires you to think in terms of the structure of the computer rather than the structure of the problem you are trying to solve\uff08\u4e5f\u5c31\u662f\u8bf4\uff0c\u5b83\u4eec\u8fd8\u4e0d\u591f\u62bd\u8c61\uff0c\u8fd8\u662f\u592a\u5e95\u5c42\u4e86\uff09. The programmer must establish the association between the machine model (in the \u201c solution space ,\u201d which is the place where you\u2019re implementing that solution, such as a computer) and the model of the problem that is actually being solved (in the \u201c problem space ,\u201d which is the place where the problem exists, such as a business). The effort required to perform this mapping, and the fact that it is extrinsic\uff08\u975e\u56fa\u6709\u7684\uff09 to the programming language, produces programs that are difficult to write and expensive to maintain, and as a side effect created the entire \u201cprogramming methods\u201d industry. NOTE: \u201cprogramming methods\u201d\u7684\u610f\u601d\u662f\u201c\u7a0b\u5e8f\u8bbe\u8ba1\u65b9\u6cd5\u5b66\u201d The alternative to modeling the machine is to model the problem you\u2019re trying to solve. Early languages such as LISP and APL chose particular views of the world (\u201cAll problems are ultimately lists\u201d or \u201cAll problems are algorithmic,\u201d respectively). Prolog casts all problems into chains of decisions. Languages have been created for constraint-based programming and for programming exclusively by manipulating graphical symbols. (The latter proved to be too restrictive.) Each of these approaches may be a good solution to the particular class of problem they\u2019re designed to solve, but when you step outside of that domain they become awkward. The object-oriented approach goes a step further by providing tools for the programmer to represent elements in the problem space . This representation is general enough that the programmer is not constrained to any particular type of problem. We refer to the elements in the problem space and their representations in the solution space as \u201c objects .\u201d (You will also need other objects that don\u2019t have problem-space analogs.) The idea is that the program is allowed to adapt itself to the lingo\uff08\u672f\u8bed\uff09 of the problem by adding new types of objects , so when you read the code describing the solution , you\u2019re reading words that also express the problem . This is a more flexible and powerful language abstraction than what we\u2019ve had before. Thus, OOP allows you to describe the problem in terms of the problem, rather than in terms of the computer where the solution will run. There\u2019s still a connection back to the computer: Each object looks quite a bit like a little computer \u2014it has a state , and it has operations that you can ask it to perform. However, this doesn\u2019t seem like such a bad analogy to objects in the real world\u2014they all have characteristics and behaviors. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u63cf\u8ff0\u4e86OO\u7684\u601d\u60f3\uff0c\u4f18\u52bf\u3002\u6211\u89c9\u5f97OO\u7684\u6838\u5fc3\u601d\u60f3\u5c31\u662f\u4f7f\u7528class\u6765\u63cf\u8ff0problem space\u4e2d\u7684\u5404\u79cd\u62bd\u8c61\u6982\u5ff5\uff0c\u7136\u540e\u5bf9\u95ee\u9898\u8fdb\u884c\u5efa\u6a21\uff0c\u8fdb\u884c\u5b9e\u73b0\u3002OO\u7684\u4f18\u52bf\u5728\u4e8e\uff1a OO\u66f4\u52a0\u62bd\u8c61\uff0c\u66f4\u52a0expressive OO\u662fgeneral\u7684\uff0c\u800c\u4e0d\u662fspecific\u7684 \u5173\u4e8eabstraction\uff0c\u53c2\u89c1\u6587\u7ae0 Abstraction \uff0c\u5176\u4e2d Abstraction in programming language \u7ae0\u8282\uff0c\u8ba8\u8bba\u4e86programming language\u7684\u53d1\u5c55\u7b80\u53f2\u3002 \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\u7684\u201cEach object looks quite a bit like a little computer \u201d\u6240\u8868\u8fbe\u7684\u601d\u60f3\u548c\u4e0b\u9762\u201cAn object provides services\u201d\u5c0f\u8282\u4e2d\u8868\u8fbe\u7684\u601d\u60f3\u7c7b\u4f3c\u3002 Alan Kay summarized five basic characteristics of Smalltalk , the first successful object-oriented language and one of the languages upon which Java is based. These characteristics represent a pure approach to object-oriented programming : Everything is an object . Think of an object as a fancy variable ; it stores data, but you can \u201cmake requests\u201d to that object, asking it to perform operations on itself. In theory, you can take any conceptual component in the problem you\u2019re trying to solve (dogs, buildings, services, etc.) and represent it as an object in your program. A program is a bunch of objects telling each other what to do by sending messages. To make a request of an object, you \u201csend a message\u201d to that object . More concretely, you can think of a message as a request to call a method that belongs to a particular object. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u603b\u7ed3\u4eceOOP\u7684\u89d2\u5ea6\u6765\u63cf\u8ff0\u7a0b\u5e8f\u7684\u8fd0\u884c\u3002 \u7262\u8bb0\u201csend a message\u201d\u548c\"make a request\u201c\uff0c\u540e\u9762\u4f1a\u9891\u7e41\u51fa\u73b0\uff0c\u5728\u4e0b\u4e00\u8282\u4f1a\u63cf\u8ff0\u5982\u4f55\u6765\u5b9e\u73b0\u201csend a message\u201d\u3002 Each object has its own memory made up of other objects . Put another way, you create a new kind of object by making a package containing existing objects. Thus, you can build complexity into a program while hiding it behind the simplicity of objects. NOTE: \u8fd9\u5c31\u662f\u6211\u4eec\u5e38\u5e38\u6240\u8bf4\u7684 Object composition Every object has a type . Using the parlance, each object is an instance of a class , in which \u201cclass\u201d is synonymous with \u201ctype.\u201d The most important distinguishing characteristic of a class is \u201cWhat messages can you send to it?\u201d All objects of a particular type can receive the same messages . This is actually a loaded statement, as you will see later. Because an object of type \u201ccircle\u201d is also an object of type \u201cshape,\u201d a circle is guaranteed to accept shape messages. This means you can write code that talks to shapes and automatically handle anything that fits the description of a shape. This substitutability is one of the powerful concepts in OOP. NOTE: \u4e0a\u97625\u6761\u5bf9OOP\u7684\u603b\u7ed3\u975e\u5e38\u597d\u3002 Booch offers an even more succinct description of an object: An object has state, behavior and identity. This means that an object can have internal data (which gives it state), methods (to produce behavior), and each object can be uniquely distinguished from every other object\u2014to put this in a concrete sense, each object has a unique address in memory. ATTENTION: This is actually a bit restrictive, since objects can conceivably exist in different machines and address spaces, and they can also be stored on disk. In these cases, the identity of the object must be determined by something other than memory address.","title":"The progress of abstraction"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Introduction-to-Objects/#an-object-has-an-interface","text":"NOTE: \u672c\u8282\u4e3b\u8981\u5206\u6790\u7684\u662fobject\u548cclass\u4e4b\u95f4\u7684\u5173\u7cfb\u3001class\u548ctype\u4e4b\u95f4\u7684\u5173\u7cfb\u3001\u5982\u4f55\u6765\u5b9e\u73b0\u201csent a message\u201d\u3002 Aristotle\uff08\u4e9a\u91cc\u58eb\u591a\u5fb7\uff09 was probably the first to begin a careful study of the concept of type ; he spoke of \u201cthe class of fishes and the class of birds.\u201d The idea that all objects, while being unique, are also part of a class of objects that have characteristics and behaviors in common was used directly in the first object-oriented language, Simula-67 , with its fundamental keyword class that introduces a new type into a program. Simula, as its name implies, was created for developing simulations such as the classic \u201cbank teller problem.\u201d In this, you have numerous tellers, customers, accounts, transactions, and units of money\u2014a lot of \u201cobjects.\u201d Objects that are identical except for their state during a program\u2019s execution are grouped together into \u201cclasses of objects,\u201d and that\u2019s where the keyword class came from. Creating abstract data types (classes) is a fundamental concept in object-oriented programming . Abstract data types work almost exactly like built-in types: You can create variables of a type (called objects or instances in object-oriented parlance) and manipulate those variables (called sending messages or requests ; you send a message and the object figures out what to do with it). The members (elements) of each class share some commonality: Every account has a balance, every teller can accept a deposit, etc. At the same time, each member has its own state: Each account has a different balance, each teller has a name. Thus, the tellers, customers, accounts, transactions, etc., can each be represented with a unique entity in the computer program. This entity is the object, and each object belongs to a particular class that defines its characteristics and behaviors. So, although what we really do in object-oriented programming is create new data types , virtually all object-oriented programming languages use the \u201cclass\u201d keyword. When you see the word \u201c type \u201d think \u201c class \u201d and vice versa. ATTENTION: Some people make a distinction, stating that type determines the interface while class is a particular implementation of that interface. Since a class describes a set of objects that have identical characteristics (data elements) and behaviors (functionality), a class is really a data type because a floating point number, for example, also has a set of characteristics and behaviors. The difference is that a programmer defines a class to fit a problem rather than being forced to use an existing data type that was designed to represent a unit of storage in a machine. You extend the programming language by adding new data types specific to your needs. The programming system welcomes the new classes and gives them all the care and type checking that it gives to built-in types. The object-oriented approach is not limited to building simulations. Whether or not you agree that any program is a simulation of the system you\u2019re designing, the use of OOP techniques can easily reduce a large set of problems to a simple solution. Once a class is established, you can make as many objects of that class as you like, and then manipulate those objects as if they are the elements that exist in the problem you are trying to solve. Indeed, one of the challenges of object-oriented programming is to create a one-to-one mapping between the elements in the problem space and objects in the solution space . NOTE: OOP\u7684challenge\u3002 But how do you get an object to do useful work for you? There needs to be a way to make a request of the object so that it will do something, such as complete a transaction, draw something on the screen, or turn on a switch. And each object can satisfy only certain requests. The requests you can make of an object are defined by its interface , and the type is what determines the interface. A simple example might be a representation of a light bulb: The interface determines the requests that you can make for a particular object. However, there must be code somewhere to satisfy that request. This, along with the hidden data , comprises the implementation . From a procedural programming standpoint, it\u2019s not that complicated. A type has a method associated with each possible request, and when you make a particular request to an object, that method is called. This process is usually summarized by saying that you \u201c send a message \u201d ( make a request ) to an object, and the object figures out what to do with that message (it executes code). The preceding diagram follows the format of the Unified Modeling Language (UML). Each class is represented by a box, with the type name in the top portion of the box, any data members that you care to describe in the middle portion of the box, and the methods (the functions that belong to this object, which receive any messages you send to that object) in the bottom portion of the box. Often, only the name of the class and the public methods are shown in UML design diagrams, so the middle portion is not shown, as in this case. If you\u2019re interested only in the class name, then the bottom portion doesn\u2019t need to be shown, either.","title":"An object has an interface"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Introduction-to-Objects/#an-object-provides-services","text":"NOTE: \u672c\u8282\u4e3b\u8981\u8bb2\u8ff0\u4e86\u5982\u4f55\u6765\u66f4\u597d\u5730\u4f7f\u7528OO\u6765\u89e3\u51b3\u95ee\u9898\uff0c\u79c9\u6301\uff1a\u5c06object\u7406\u89e3\u4e3a\u201cservice provider\u201d\u7684\u601d\u60f3\u3002 While you\u2019re trying to develop or understand a program design, one of the best ways to think about objects is as \u201c service providers .\u201d Your program itself will provide services to the user, and it will accomplish this by using the services offered by other objects. Your goal is to produce (or even better, locate in existing code libraries) a set of objects that provide the ideal services to solve your problem. Thinking of an object as a service provider has an additional benefit: It helps to improve the cohesiveness of the object. High cohesion is a fundamental quality of software design: It means that the various aspects of a software component (such as an object, although this could also apply to a method or a library of objects) \u201cfit together\u201d well. One problem people have when designing objects is cramming\uff08\u585e\u8fdb\uff09 too much functionality into one object. For example, in your check printing module, you may decide you need an object that knows all about formatting and printing. You\u2019ll probably discover that this is too much for one object, and that what you need is three or more objects. One object might be a catalog of all the possible check layouts, which can be queried for information about how to print a check. One object or set of objects can be a generic printing interface that knows all about different kinds of printers (but nothing about bookkeeping\u2014this one is a candidate for buying rather than writing yourself). And a third object could use the services of the other two to accomplish the task. Thus, each object has a cohesive set of services it offers. In a good object-oriented design, each object does one thing well, but doesn\u2019t try to do too much. This not only allows the discovery of objects that might be purchased (the printer interface object), but it also produces new objects that might be reused somewhere else (the catalog of check layouts). Treating objects as service providers is a great simplifying tool. This is useful not only during the design process, but also when someone else is trying to understand your code or reuse an object. If they can see the value of the object based on what service it provides, it makes it much easier to fit it into the design.","title":"An object provides services"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Introduction-to-Objects/#the-hidden-implementation","text":"It is helpful to break up the playing field into class creators (those who create new data types) and client programmers (the class consumers who use the data types in their applications). The goal of the client programmer is to collect a toolbox full of classes to use for rapid application development. The goal of the class creator is to build a class that exposes only what\u2019s necessary to the client programmer and keeps everything else hidden . Why? Because if it\u2019s hidden, the client programmer can\u2019t access it, which means that the class creator can change the hidden portion at will without worrying about the impact on anyone else. The hidden portion usually represents the tender insides of an object that could easily be corrupted by a careless or uninformed client programmer, so hiding the implementation reduces program bugs. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u6240\u63cf\u8ff0\u7684\u662f\u4f7f\u7528OOP\u5e26\u6765\u7684\u4e00\u4e2a\u597d\u5904\uff1ahidden\u3002 In any relationship it\u2019s important to have boundaries that are respected by all parties involved. When you create a library, you establish a relationship with the client programmer, who is also a programmer, but one who is putting together an application by using your library, possibly to build a bigger library. If all the members of a class are available to everyone, then the client programmer can do anything with that class and there\u2019s no way to enforce rules. Even though you might really prefer that the client programmer not directly manipulate some of the members of your class, without access control there\u2019s no way to prevent it. Everything\u2019s naked to the world. So the first reason for access control is to keep client programmers\u2019 hands off portions they shouldn\u2019t touch\u2014parts that are necessary for the internal operation of the data type but not part of the interface that users need in order to solve their particular problems. This is actually a service to client programmers because they can easily see what\u2019s important to them and what they can ignore. The second reason for access control is to allow the library designer to change the internal workings of the class without worrying about how it will affect the client programmer. For example, you might implement a particular class in a simple fashion to ease development, and then later discover that you need to rewrite it in order to make it run faster. If the interface and implementation are clearly separated and protected, you can accomplish this easily. Java uses three explicit keywords to set the boundaries in a class: public, private, and protected. These access specifiers determine who can use the definitions that follow. public means the following element is available to everyone. The private keyword, on the other hand, means that no one can access that element except you, the creator of the type, inside methods of that type. private is a brick wall between you and the client programmer. Someone who tries to access a private member will get a compile-time error. The protected keyword acts like private, with the exception that an inheriting class has access to protected members, but not private members. Inheritance will be introduced shortly. Java also has a \u201cdefault\u201d access, which comes into play if you don\u2019t use one of the aforementioned specifiers. This is usually called package access because classes can access the members of other classes in the same package (library component), but outside of the package those same members appear to be private.","title":"The hidden implementation"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Introduction-to-Objects/#reusing-the-implementation","text":"Once a class has been created and tested, it should (ideally) represent a useful unit of code. It turns out that this reusability is not nearly so easy to achieve as many would hope; it takes experience and insight to produce a reusable object design. But once you have such a design, it begs to be reused. Code reuse is one of the greatest advantages that object-oriented programming languages provide. The simplest way to reuse a class is to just use an object of that class directly, but you can also place an object of that class inside a new class. We call this \u201ccreating a member object.\u201d Your new class can be made up of any number and type of other objects, in any combination that you need to achieve the functionality desired in your new class. Because you are composing a new class from existing classes, this concept is called composition (if the composition happens dynamically, it\u2019s usually called aggregation). Composition is often referred to as a \u201chas-a\u201d relationship, as in \u201cA car has an engine.\u201d (This UML diagram indicates composition with the filled diamond, which states there is one car. I will typically use a simpler form: just a line, without the diamond, to indicate an association. 5 ) Composition comes with a great deal of flexibility. The member objects of your new class are typically private, making them inaccessible to the client programmers who are using the class. This allows you to change those members without disturbing existing client code. You can also change the member objects at run time, to dynamically change the behavior of your program. Inheritance, which is described next, does not have this flexibility since the compiler must place compile-time restrictions on classes created with inheritance. Because inheritance is so important in object-oriented programming, it is often highly emphasized, and the new programmer can get the idea that inheritance should be used everywhere. This can result in awkward and overly complicated designs. Instead, you should first look to composition when creating new classes, since it is simpler and more flexible. If you take this approach, your designs will be cleaner. Once you\u2019ve had some experience, it will be reasonably obvious when you need inheritance.","title":"Reusing the implementation"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Introduction-to-Objects/#inheritance","text":"By itself, the idea of an object is a convenient tool. It allows you to package data and functionality together by concept, so you can represent an appropriate problem-space idea rather than being forced to use the idioms of the underlying machine. These concepts are expressed as fundamental units in the programming language by using the class keyword. It seems a pity, however, to go to all the trouble to create a class and then be forced to create a brand new one that might have similar functionality. It\u2019s nicer if we can take the existing class, clone it, and then make additions and modifications to the clone. This is effectively what you get with inheritance, with the exception that if the original class (called the base class or superclass or parent class) is changed, the modified \u201cclone\u201d (called the derived class or inherited class or subclass or child class) also reflects those changes. (The arrow in this UML diagram points from the derived class to the base class. As you will see, there is commonly more than one derived class.) A type does more than describe the constraints on a set of objects; it also has a relationship with other types. Two types can have characteristics and behaviors in common, but one type may contain more characteristics than another and may also handle more messages (or handle them differently). Inheritance expresses this similarity between types by using the concept of base types and derived types. A base type contains all of the characteristics and behaviors that are shared among the types derived from it. You create a base type to represent the core of your ideas about some objects in your system. From the base type, you derive other types to express the different ways that this core can be realized. For example, a trash-recycling machine sorts pieces of trash. The base type is \u201ctrash\u201d, and each piece of trash has a weight, a value, and so on, and can be shredded, melted, or decomposed. From this, more specific types of trash are derived that may have additional characteristics (a bottle has a color) or behaviors (an aluminum can may be crushed, a steel can is magnetic). In addition, some behaviors may be different (the value of paper depends on its type and condition). Using inheritance, you can build a type hierarchy that expresses the problem you\u2019re trying to solve in terms of its types. A second example is the classic \u201cshape\u201d example, perhaps used in a computer-aided design system or game simulation. The base type is \u201cshape,\u201d and each shape has a size, a color, a position, and so on. Each shape can be drawn, erased, moved, colored, etc. From this, specific types of shapes are derived (inherited)\u2014circle, square, triangle, and so on\u2014each of which may have additional characteristics and behaviors. Certain shapes can be flipped, for example. Some behaviors may be different, such as when you want to calculate the area of a shape. The type hierarchy embodies both the similarities and differences between the shapes. Casting the solution in the same terms as the problem is very useful because you don\u2019t need a lot of intermediate models to get from a description of the problem to a description of the solution. With objects, the type hierarchy is the primary model, so you go directly from the description of the system in the real world to the description of the system in code. Indeed, one of the difficulties people have with object-oriented design is that it\u2019s too simple to get from the beginning to the end. A mind trained to look for complex solutions can initially be stumped by this simplicity. When you inherit from an existing type, you create a new type. This new type contains not only all the members of the existing type (although the private ones are hidden away and inaccessible), but more importantly it duplicates the interface of the base class. That is, all the messages you can send to objects of the base class you can also send to objects of the derived class. Since we know the type of a class by the messages we can send to it, this means that the derived class is the same type as the base class. In the previous example, \u201cA circle is a shape.\u201d This type equivalence via inheritance is one of the fundamental gateways in understanding the meaning of object-oriented programming. Since both the base class and derived class have the same fundamental interface, there must be some implementation to go along with that interface. That is, there must be some code to execute when an object receives a particular message. If you simply inherit a class and don\u2019t do anything else, the methods from the base-class interface come right along into the derived class. That means objects of the derived class have not only the same type, they also have the same behavior, which isn\u2019t particularly interesting. You have two ways to differentiate your new derived class from the original base class. The first is quite straightforward: You simply add brand new methods to the derived class. These new methods are not part of the base-class interface. This means that the base class simply didn\u2019t do as much as you wanted it to, so you added more methods. This simple and primitive use for inheritance is, at times, the perfect solution to your problem. However, you should look closely for the possibility that your base class might also need these additional methods. This process of discovery and iteration of your design happens regularly in object-oriented programming. Although inheritance may sometimes imply (especially in Java, where the keyword for inheritance is extends) that you are going to add new methods to the interface, that\u2019s not necessarily true. The second and more important way to differentiate your new class is to change the behavior of an existing base-class method. This is referred to as overriding that method. To override a method, you simply create a new definition for the method in the derived class. You\u2019re saying, \u201cI\u2019m using the same interface method here, but I want it to do something different for my new type.\u201d","title":"Inheritance"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Introduction-to-Objects/#is-a-vs-is-like-a-relationships","text":"There\u2019s a certain debate that can occur about inheritance: Should inheritance override only baseclass methods (and not add new methods that aren\u2019t in the base class)? This would mean that the derived class is exactly the same type as the base class since it has exactly the same interface. As a result, you can exactly substitute an object of the derived class for an object of the base class. This can be thought of as pure substitution, and it\u2019s often referred to as the substitution principle. In a sense, this is the ideal way to treat inheritance. We often refer to the relationship between the base class and derived classes in this case as an is-a relationship, because you can say, \u201cA circle is a shape.\u201d A test for inheritance is to determine whether you can state the is-a relationship about the classes and have it make sense. There are times when you must add new interface elements to a derived type, thus extending the interface. The new type can still be substituted for the base type, but the substitution isn\u2019t perfect because your new methods are not accessible from the base type. This can be described as an islike-a relationship (my term). The new type has the interface of the old type but it also contains other methods, so you can\u2019t really say it\u2019s exactly the same. For example, consider an air conditioner. Suppose your house is wired with all the controls for cooling; that is, it has an interface that allows you to control cooling. Imagine that the air conditioner breaks down and you replace it with a heat pump, which can both heat and cool. The heat pump is-like-an air conditioner, but it can do more. Because the control system of your house is designed only to control cooling, it is restricted to communication with the cooling part of the new object. The interface of the new object has been extended, and the existing system doesn\u2019t know about anything except the original interface. Of course, once you see this design it becomes clear that the base class \u201ccooling system\u201d is not general enough, and should be renamed to \u201ctemperature control system\u201d so that it can also include heating\u2014at which point the substitution principle will work. However, this diagram is an example of what can happen with design in the real world. When you see the substitution principle it\u2019s easy to feel like this approach (pure substitution) is the only way to do things, and in fact it is nice if your design works out that way. But you\u2019ll find that there are times when it\u2019s equally clear that you must add new methods to the interface of a derived class. With inspection both cases should be reasonably obvious.","title":"Is-a vs. is-like-a relationships"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Introduction-to-Objects/#interchangeable-objects-with-polymorphism","text":"When dealing with type hierarchies, you often want to treat an object not as the specific type that it is, but instead as its base type. This allows you to write code that doesn\u2019t depend on specific types. In the shape example, methods manipulate generic shapes, unconcerned about whether they\u2019re circles, squares, triangles, or some shape that hasn\u2019t even been defined yet. All shapes can be drawn, erased, and moved, so these methods simply send a message to a shape object; they don\u2019t worry about how the object copes with the message. Such code is unaffected by the addition of new types, and adding new types is the most common way to extend an object-oriented program to handle new situations. For example, you can derive a new subtype of shape called pentagon without modifying the methods that deal only with generic shapes. This ability to easily extend a design by deriving new subtypes is one of the essential ways to encapsulate change. This greatly improves designs while reducing the cost of software maintenance. There\u2019s a problem, however, with attempting to treat derived-type objects as their generic base types (circles as shapes, bicycles as vehicles, cormorants as birds, etc.). If a method is going to tell a generic shape to draw itself, or a generic vehicle to steer, or a generic bird to move, the compiler cannot know at compile time precisely what piece of code will be executed. That\u2019s the whole point\u2014when the message is sent, the programmer doesn\u2019t want to know what piece of code will be executed; the draw method can be applied equally to a circle, a square, or a triangle, and the object will execute the proper code depending on its specific type. If you don\u2019t have to know what piece of code will be executed, then when you add a new subtype, the code it executes can be different without requiring changes to the method that calls it. Therefore, the compiler cannot know precisely what piece of code is executed, so what does it do? For example, in the following diagram the BirdController object just works with generic Bird objects and does not know what exact type they are. This is convenient from BirdController\u2019s perspective because it doesn\u2019t have to write special code to determine the exact type of Bird it\u2019s working with or that Bird\u2019s behavior. So how does it happen that, when move( ) is called while ignoring the specific type of Bird, the right behavior will occur (a Goose walks, flies, or swims, and a Penguin walks or swims)? The answer is the primary twist in object-oriented programming: The compiler cannot make a function call in the traditional sense. The function call generated by a non-OOP compiler causes what is called early binding, a term you may not have heard before because you\u2019ve never thought about it any other way. It means the compiler generates a call to a specific function name, and the runtime system resolves this call to the absolute address of the code to be executed. In OOP, the program cannot determine the address of the code until run time, so some other scheme is necessary when a message is sent to a generic object. To solve the problem, object-oriented languages use the concept of late binding. When you send a message to an object, the code being called isn\u2019t determined until run time. The compiler does ensure that the method exists and performs type checking on the arguments and return value, but it doesn\u2019t know the exact code to execute. To perform late binding, Java uses a special bit of code in lieu of the absolute call. This code calculates the address of the method body, using information stored in the object (this process is covered in great detail in the Polymorphism chapter). Thus, each object can behave differently according to the contents of that special bit of code. When you send a message to an object, the object actually does figure out what to do with that message. In some languages you must explicitly state that you want a method to have the flexibility of latebinding properties (C++ uses the virtual keyword to do this). In these languages, by default, methods are not dynamically bound. In Java, dynamic binding is the default behavior and you don\u2019t need to remember to add any extra keywords in order to get polymorphism. Consider the shape example. The family of classes (all based on the same uniform interface) was diagrammed earlier in this chapter. To demonstrate polymorphism, we want to write a single piece of code that ignores the specific details of type and talks only to the base class. That code is decoupled from type-specific information and thus is simpler to write and easier to understand. And, if a new type\u2014a Hexagon, for example\u2014is added through inheritance, the code you write will work just as well for the new type of Shape as it did on the existing types. Thus, the program is extensible. If you write a method in Java (as you will soon learn how to do): void doSomething ( Shape shape ) { shape . erase (); // ... shape . draw (); } This method speaks to any Shape, so it is independent of the specific type of object that it\u2019s drawing and erasing. If some other part of the program uses the doSomething( ) method: Circle circle = new Circle (); Triangle triangle = new Triangle (); Line line = new Line (); doSomething ( circle ); doSomething ( triangle ); doSomething ( line ); The calls to doSomething( ) automatically work correctly, regardless of the exact type of the object. This is a rather amazing trick. Consider the line: doSomething ( circle ); What\u2019s happening here is that a Circle is being passed into a method that\u2019s expecting a Shape. Since a Circle is a Shape it can be treated as one by doSomething( ) . That is, any message that doSomething( ) can send to a Shape, a Circle can accept. So it is a completely safe and logical thing to do. We call this process of treating a derived type as though it were its base type upcasting. The name cast is used in the sense of casting into a mold and the up comes from the way the inheritance diagram is typically arranged, with the base type at the top and the derived classes fanning out downward. Thus, casting to a base type is moving up the inheritance diagram: \u201cupcasting.\u201d An object-oriented program contains some upcasting somewhere, because that\u2019s how you decouple yourself from knowing about the exact type you\u2019re working with. Look at the code in doSomething( ) : shape . erase (); // ... shape . draw (); Notice that it doesn\u2019t say, \u201cIf you\u2019re a Circle, do this, if you\u2019re a Square, do that, etc.\u201d If you write that kind of code, which checks for all the possible types that a Shape can actually be, it\u2019s messy and you need to change it every time you add a new kind of Shape. Here, you just say, \u201cYou\u2019re a shape, I know you can erase() and draw( ) yourself, do it, and take care of the details correctly.\u201d What\u2019s impressive about the code in doSomething( ) is that, somehow, the right thing happens. Calling draw( ) for Circle causes different code to be executed than when calling draw( ) for a Square or a Line, but when the draw( ) message is sent to an anonymous Shape, the correct behavior occurs based on the actual type of the Shape. This is amazing because, as mentioned earlier, when the Java compiler is compiling the code for doSomething( ) , it cannot know exactly what types it is dealing with. So ordinarily, you\u2019d expect it to end up calling the version of erase( ) and draw( ) for the base class Shape, and not for the specific Circle, Square, or Line. And yet the right thing happens because of polymorphism. The compiler and runtime system handle the details; all you need to know right now is that it does happen, and more importantly, how to design with it. When you send a message to an object, the object will do the right thing, even when upcasting is involved.","title":"Interchangeable objects with polymorphism"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Introduction-to-Objects/#the-singly-rooted-hierarchy","text":"One of the issues in OOP that has become especially prominent since the introduction of C++ is whether all classes should ultimately be inherited from a single base class. In Java (as with virtually all other OOP languages except for C++) the answer is yes, and the name of this ultimate base class is simply Object. It turns out that the benefits of the singly rooted hierarchy are many. All objects in a singly rooted hierarchy have an interface in common, so they are all ultimately the same fundamental type. The alternative (provided by C++) is that you don\u2019t know that everything is the same basic type. From a backward-compatibility standpoint this fits the model of C better and can be thought of as less restrictive, but when you want to do full-on objectoriented programming you must then build your own hierarchy to provide the same convenience that\u2019s built into other OOP languages. And in any new class library you acquire, some other incompatible interface will be used. It requires effort (and possibly multiple inheritance) to work the new interface into your design. Is the extra \u201cflexibility\u201d of C++ worth it? If you need it\u2014if you have a large investment in C\u2014it\u2019s quite valuable. If you\u2019re starting from scratch, other alternatives such as Java can often be more productive. All objects in a singly rooted hierarchy can be guaranteed to have certain functionality. You know you can perform certain basic operations on every object in your system. All objects can easily be created on the heap, and argument passing is greatly simplified. A singly rooted hierarchy makes it much easier to implement a garbage collector, which is one of the fundamental improvements of Java over C++. And since information about the type of an object is guaranteed to be in all objects, you\u2019ll never end up with an object whose type you cannot determine. This is especially important with system-level operations, such as exception handling, and to allow greater flexibility in programming.","title":"The singly rooted hierarchy"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Introduction-to-Objects/#containers","text":"In general, you don\u2019t know how many objects you\u2019re going to need to solve a particular problem, or how long they will last. You also don\u2019t know how to store those objects. How can you know how much space to create if that information isn\u2019t known until run time? The solution to most problems in object-oriented design seems flippant: You create another type of object. The new type of object that solves this particular problem holds references to other objects. Of course, you can do the same thing with an array, which is available in most languages. But this new object, generally called a container (also called a collection, but the Java library uses that term in a different sense so this book will use \u201ccontainer\u201d), will expand itself whenever necessary to accommodate everything you place inside it. So you don\u2019t need to know how many objects you\u2019re going to hold in a container. Just create a container object and let it take care of the details. Fortunately, a good OOP language comes with a set of containers as part of the package. In C++, it\u2019s part of the Standard C++ Library and is often called the Standard Template Library (STL). Smalltalk has a very complete set of containers. Java also has numerous containers in its standard library. In some libraries, one or two generic containers is considered good enough for all needs, and in others (Java, for example) the library has different types of containers for different needs: several different kinds of List classes (to hold sequences), Maps (also known as associative arrays, to associate objects with other objects), Sets (to hold one of each type of object), and more components such as queues, trees, stacks, etc. From a design standpoint, all you really want is a container that can be manipulated to solve your problem. If a single type of container satisfied all of your needs, there\u2019d be no reason to have different kinds. There are two reasons that you need a choice of containers. First, containers provide different types of interfaces and external behavior. A stack has a different interface and behavior than a queue, which is different from a set or a list. One of these might provide a more flexible solution to your problem than the other. Second, different containers have different efficiencies for certain operations. For example, there are two basic types of List: ArrayList and LinkedList. Both are simple sequences that can have identical interfaces and external behaviors. But certain operations can have significantly different costs. Randomly accessing elements in an ArrayList is a constant-time operation; it takes the same amount of time regardless of the element you select. However, in a LinkedList it is expensive to move through the list to randomly select an element, and it takes longer to find an element that is farther down the list. On the other hand, if you want to insert an element in the middle of a sequence, it\u2019s cheaper in a LinkedList than in an ArrayList. These and other operations have different efficiencies depending on the underlying structure of the sequence. You might start building your program with a LinkedList and, when tuning for performance, change to an ArrayList. Because of the abstraction via the interface List, you can change from one to the other with minimal impact on your code.","title":"Containers"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Introduction-to-Objects/#parameterized-types-generics","text":"Before Java SE5, containers held the one universal type in Java: Object. The singly rooted hierarchy means that everything is an Object, so a container that holds Objects can hold anything. 6 This made containers easy to reuse. To use such a container, you simply add object references to it and later ask for them back. But, since the container held only Objects, when you added an object reference into the container it was upcast to Object, thus losing its character. When fetching it back, you got an Object reference, and not a reference to the type that you put in. So how do you turn it back into something that has the specific type of the object that you put into the container? Here, the cast is used again, but this time you\u2019re not casting up the inheritance hierarchy to a more general type. Instead, you cast down the hierarchy to a more specific type. This manner of casting is called downcasting. With upcasting, you know, for example, that a Circle is a type of Shape so it\u2019s safe to upcast, but you don\u2019t know that an Object is necessarily a Circle or a Shape so it\u2019s hardly safe to downcast unless you know exactly what you\u2019re dealing with. It\u2019s not completely dangerous, however, because if you downcast to the wrong thing you\u2019ll get a runtime error called an exception, which will be described shortly. When you fetch object references from a container, though, you must have some way to remember exactly what they are so you can perform a proper downcast. Downcasting and the runtime checks require extra time for the running program and extra effort from the programmer. Wouldn\u2019t it make sense to somehow create the container so that it knows the types that it holds, eliminating the need for the downcast and a possible mistake? The solution is called a parameterized type mechanism. A parameterized type is a class that the compiler can automatically customize to work with particular types. For example, with a parameterized container, the compiler could customize that container so that it would accept only Shapes and fetch only Shapes. One of the big changes in Java SE5 is the addition of parameterized types, called generics in Java. You\u2019ll recognize the use of generics by the angle brackets with types inside; for example, an ArrayList that holds Shape can be created like this: ArrayList < Shape > shapes = new ArrayList < Shape >(); There have also been changes to many of the standard library components in order to take advantage of generics. As you will see, generics have an impact on much of the code in this book.","title":"Parameterized types (generics)"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Introduction-to-Objects/#object-creation-lifetime","text":"One critical issue when working with objects is the way they are created and destroyed. Each object requires resources, most notably memory, in order to exist. When an object is no longer needed it must be cleaned up so that these resources are released for reuse. In simple programming situations the question of how an object is cleaned up doesn\u2019t seem too challenging: You create the object, use it for as long as it\u2019s needed, and then it should be destroyed. However, it\u2019s not hard to encounter situations that are more complex. Suppose, for example, you are designing a system to manage air traffic for an airport. (The same model might also work for managing crates in a warehouse, or a video rental system, or a kennel for boarding pets.) At first it seems simple: Make a container to hold airplanes, then create a new airplane and place it in the container for each airplane that enters the air-traffic-control zone. For cleanup, simply clean up the appropriate airplane object when a plane leaves the zone. But perhaps you have some other system to record data about the planes; perhaps data that doesn\u2019t require such immediate attention as the main controller function. Maybe it\u2019s a record of the flight plans of all the small planes that leave the airport. So you have a second container of small planes, and whenever you create a plane object you also put it in this second container if it\u2019s a small plane. Then some background process performs operations on the objects in this container during idle moments. Now the problem is more difficult: How can you possibly know when to destroy the objects? When you\u2019re done with the object, some other part of the system might not be. This same problem can arise in a number of other situations, and in programming systems (such as C++) in which you must explicitly delete an object when you\u2019re done with it this can become quite complex. Where is the data for an object and how is the lifetime of the object controlled? C++ takes the approach that control of efficiency is the most important issue, so it gives the programmer a choice. For maximum runtime speed, the storage and lifetime can be determined while the program is being written, by placing the objects on the stack (these are sometimes called automatic or scoped variables) or in the static storage area. This places a priority on the speed of storage allocation and release, and this control can be very valuable in some situations. However, you sacrifice flexibility because you must know the exact quantity, lifetime, and type of objects while you\u2019re writing the program. If you are trying to solve a more general problem such as computer-aided design, warehouse management, or air-traffic control, this is too restrictive. The second approach is to create objects dynamically in a pool of memory called the heap. In this approach, you don\u2019t know until run time how many objects you need, what their lifetime is, or what their exact type is. Those are determined at the spur of the moment while the program is running. If you need a new object, you simply make it on the heap at the point that you need it. Because the storage is managed dynamically, at run time, the amount of time required to allocate storage on the heap can be noticeably longer than the time to create storage on the stack. Creating storage on the stack is often a single assembly instruction to move the stack pointer down and another to move it back up. The time to create heap storage depends on the design of the storage mechanism. The dynamic approach makes the generally logical assumption that objects tend to be complicated, so the extra overhead of finding storage and releasing that storage will not have an important impact on the creation of an object. In addition, the greater flexibility is essential to solve the general programming problem. Java uses dynamic memory allocation, exclusively. 7 Every time you want to create an object, you use the new operator to build a dynamic instance of that object. There\u2019s another issue, however, and that\u2019s the lifetime of an object. With languages that allow objects to be created on the stack, the compiler determines how long the object lasts and can automatically destroy it. However, if you create it on the heap the compiler has no knowledge of its lifetime. In a language like C++, you must determine programmatically when to destroy the object, which can lead to memory leaks if you don\u2019t do it correctly (and this is a common problem in C++ programs). Java provides a feature called a garbage collector that automatically discovers when an object is no longer in use and destroys it. A garbage collector is much more convenient because it reduces the number of issues that you must track and the code you must write. More importantly, the garbage collector provides a much higher level of insurance against the insidious problem of memory leaks, which has brought many a C++ project to its knees. With Java, the garbage collector is designed to take care of the problem of releasing the memory (although this doesn\u2019t include other aspects of cleaning up an object). The garbage collector \u201cknows\u201d when an object is no longer in use, and it then automatically releases the memory for that object. This, combined with the fact that all objects are inherited from the single root class Object and that you can create objects only one way\u2014on the heap\u2014makes the process of programming in Java much simpler than programming in C++. You have far fewer decisions to make and hurdles to overcome.","title":"Object creation &amp; lifetime"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Introduction-to-Objects/#exception-handling-dealing-with-errors","text":"Ever since the beginning of programming languages, error handling has been a particularly difficult issue. Because it\u2019s so hard to design a good error-handling scheme, many languages simply ignore the issue, passing the problem on to library designers who come up with halfway measures that work in many situations but that can easily be circumvented, generally by just ignoring them. A major problem with most error-handling schemes is that they rely on programmer vigilance in following an agreed-upon convention that is not enforced by the language. If the programmer is not vigilant\u2014often the case if they are in a hurry\u2014these schemes can easily be forgotten. Exception handling wires error handling directly into the programming language and sometimes even the operating system. An exception is an object that is \u201cthrown\u201d from the site of the error and can be \u201ccaught\u201d by an appropriate exception handler designed to handle that particular type of error. It\u2019s as if exception handling is a different, parallel path of execution that can be taken when things go wrong. And because it uses a separate execution path, it doesn\u2019t need to interfere with your normally executing code. This tends to make that code simpler to write because you aren\u2019t constantly forced to check for errors. In addition, a thrown exception is unlike an error value that\u2019s returned from a method or a flag that\u2019s set by a method in order to indicate an error condition\u2014these can be ignored. An exception cannot be ignored, so it\u2019s guaranteed to be dealt with at some point. Finally, exceptions provide a way to reliably recover from a bad situation. Instead of just exiting the program, you are often able to set things right and restore execution, which produces much more robust programs. Java\u2019s exception handling stands out among programming languages, because in Java, exception handling was wired in from the beginning and you\u2019re forced to use it. It is the single acceptable way to report errors. If you don\u2019t write your code to properly handle exceptions, you\u2019ll get a compile-time error message. This guaranteed consistency can sometimes make error handling much easier. It\u2019s worth noting that exception handling isn\u2019t an object-oriented feature, although in object-oriented languages the exception is normally represented by an object. Exception handling existed before object-oriented languages.","title":"Exception handling: dealing with errors"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Introduction-to-Objects/#concurrent-programming","text":"A fundamental concept in computer programming is the idea of handling more than one task at a time. Many programming problems require that the program stop what it\u2019s doing, deal with some other problem, and then return to the main process. The solution has been approached in many ways. Initially, programmers with low-level knowledge of the machine wrote interrupt service routines, and the suspension of the main process was initiated through a hardware interrupt. Although this worked well, it was difficult and non-portable, so it made moving a program to a new type of machine slow and expensive.","title":"Concurrent programming"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Introduction/","text":"Introduction \u201cHe gave man speech, and speech created thought, Which is the measure of the Universe\u201d\u2014Prometheus Unbound, Shelley \u4e0a\u5e1d\u8d4b\u4e88\u4e86\u4eba\u7c7b\u8bf4\u8bdd\u7684\u80fd\u529b\uff0c\u800c\u8bed\u8a00\u6709\u521b\u9020\u4e86\u601d\u60f3\uff0c\u601d\u60f3\u662f\u4eba\u7c7b\u5bf9\u5b87\u5b99\u7684\u5ea6\u91cf\u3002 Human beings ... are very much at the mercy of the particular language which has become the medium of expression for their society. It is quite an illusion to imagine that one adjusts to reality essentially without the use of language and that language is merely an incidental means of solving specific problems of communication and reflection. The fact of the matter is that the \u201creal world\u201d is to a large extent unconsciously built up on the language habits of the group. The Status of Linguistics as a Science, 1929, Edward Sapir \u4eba\u7c7b\u6781\u5176\u5bb9\u6613\u53d7\u90a3\u4e9b\u5df2\u7ecf\u6210\u4e3a\u793e\u4f1a\u8868\u8fbe\u5de5\u5177\u7684\u7279\u5b9a\u8bed\u8a00\u7684\u652f\u914d\u3002 Like any human language , Java provides a way to express concepts . If successful, this medium of expression will be significantly easier and more flexible than the alternatives as problems grow larger and more complex. NOTE: \u201chuman language\u201d\u4e5f\u5c31\u662f\u6211\u4eec\u5e73\u5e38\u6240\u8bf4\u7684 natural language \u3002\u5173\u4e8e\u201cconcept\u201c\uff0c\u53c2\u89c1\u6587\u7ae0 Abstraction \u3002 \u6b63\u5982\u5728\u6587\u7ae0 Language \u4e2d\uff0c\u6240\u603b\u7ed3\u7684\u201c\u4e0d\u540c\u8bed\u8a00\u6709\u7740\u5404\u81ea\u7684\u4f18\u52bf\u201d\uff0c\u663e\u7136\uff0cJava\u6709\u7740\u5b83\u7684\u4f18\u52bf\u3002 You can\u2019t look at Java as just a collection of features\u2014some of the features make no sense in isolation. You can use the sum of the parts only if you are thinking about design , not simply coding. And to understand Java in this way, you must understand the problems with the language and with programming in general. This book discusses programming problems, why they are problems, and the approach Java has taken to solve them. Thus, the set of features that I explain in each chapter are based on the way I see a particular type of problem being solved with the language. In this way I hope to move you, a little at a time, to the point where the Java mindset becomes your native tongue. Throughout, I\u2019ll be taking the attitude that you want to build a model in your head that allows you to develop a deep understanding of the language; if you encounter a puzzle, you\u2019ll feed it to your model and deduce the answer.","title":"Introduction"},{"location":"Theory/Programming-paradigm/Object-oriented-programming/Thinking-in-java/Introduction/#introduction","text":"\u201cHe gave man speech, and speech created thought, Which is the measure of the Universe\u201d\u2014Prometheus Unbound, Shelley \u4e0a\u5e1d\u8d4b\u4e88\u4e86\u4eba\u7c7b\u8bf4\u8bdd\u7684\u80fd\u529b\uff0c\u800c\u8bed\u8a00\u6709\u521b\u9020\u4e86\u601d\u60f3\uff0c\u601d\u60f3\u662f\u4eba\u7c7b\u5bf9\u5b87\u5b99\u7684\u5ea6\u91cf\u3002 Human beings ... are very much at the mercy of the particular language which has become the medium of expression for their society. It is quite an illusion to imagine that one adjusts to reality essentially without the use of language and that language is merely an incidental means of solving specific problems of communication and reflection. The fact of the matter is that the \u201creal world\u201d is to a large extent unconsciously built up on the language habits of the group. The Status of Linguistics as a Science, 1929, Edward Sapir \u4eba\u7c7b\u6781\u5176\u5bb9\u6613\u53d7\u90a3\u4e9b\u5df2\u7ecf\u6210\u4e3a\u793e\u4f1a\u8868\u8fbe\u5de5\u5177\u7684\u7279\u5b9a\u8bed\u8a00\u7684\u652f\u914d\u3002 Like any human language , Java provides a way to express concepts . If successful, this medium of expression will be significantly easier and more flexible than the alternatives as problems grow larger and more complex. NOTE: \u201chuman language\u201d\u4e5f\u5c31\u662f\u6211\u4eec\u5e73\u5e38\u6240\u8bf4\u7684 natural language \u3002\u5173\u4e8e\u201cconcept\u201c\uff0c\u53c2\u89c1\u6587\u7ae0 Abstraction \u3002 \u6b63\u5982\u5728\u6587\u7ae0 Language \u4e2d\uff0c\u6240\u603b\u7ed3\u7684\u201c\u4e0d\u540c\u8bed\u8a00\u6709\u7740\u5404\u81ea\u7684\u4f18\u52bf\u201d\uff0c\u663e\u7136\uff0cJava\u6709\u7740\u5b83\u7684\u4f18\u52bf\u3002 You can\u2019t look at Java as just a collection of features\u2014some of the features make no sense in isolation. You can use the sum of the parts only if you are thinking about design , not simply coding. And to understand Java in this way, you must understand the problems with the language and with programming in general. This book discusses programming problems, why they are problems, and the approach Java has taken to solve them. Thus, the set of features that I explain in each chapter are based on the way I see a particular type of problem being solved with the language. In this way I hope to move you, a little at a time, to the point where the Java mindset becomes your native tongue. Throughout, I\u2019ll be taking the attitude that you want to build a model in your head that allows you to develop a deep understanding of the language; if you encounter a puzzle, you\u2019ll feed it to your model and deduce the answer.","title":"Introduction"},{"location":"Theory/Reflection/Reflection/","text":"Reflection In computer science , reflection is the ability of a computer program to examine, introspect , and modify its own structure and behavior at runtime .[ 1] SUMMARY : \u5173\u4e8ereflection\u548c introspect \u4e4b\u95f4\u7684\u5dee\u5f02\u53c2\u89c1 introspect Historical background The earliest computers were programmed in their native assembly language , which were inherently reflective, as these original architectures could be programmed by defining instructions as data and using self-modifying code . As programming moved to compiled higher-level languages such as Algol , Cobol , and Fortran (but also Pascal and C and many other languages), this reflective ability largely disappeared until programming languages with reflection built into their type systems appeared.[ citation needed ] Brian Cantwell Smith 's 1982 doctoral dissertation[ 2] [ 3] introduced the notion of computational reflection in procedural programming languages and the notion of the meta-circular interpreter as a component of 3-Lisp . Uses Reflection helps programmers make generic software libraries to display data, process different formats of data, perform serialization or deserialization of data for communication, or do bundling and unbundling of data for containers or bursts of communication. TRANSLATION : \u53cd\u5c04\u5e2e\u52a9\u7a0b\u5e8f\u5458\u5236\u4f5c\u901a\u7528\u8f6f\u4ef6\u5e93\u4ee5\u663e\u793a\u6570\u636e\uff0c\u5904\u7406\u4e0d\u540c\u683c\u5f0f\u7684\u6570\u636e\uff0c\u6267\u884c\u6570\u636e\u7684\u5e8f\u5217\u5316\u6216\u53cd\u5e8f\u5217\u5316\u4ee5\u8fdb\u884c\u901a\u4fe1\uff0c\u6216\u8005\u4e3a\u5bb9\u5668\u6216\u7a81\u53d1\u901a\u4fe1\u8fdb\u884c\u6570\u636e\u7684\u6346\u7ed1\u548c\u5206\u62c6\u3002 Effective use of reflection almost always requires a plan: A design framework, encoding description, object library, a map of a database or entity relations. Reflection makes a language more suited to network-oriented code. For example, it assists languages such as Java to operate well in networks by enabling libraries for serialization, bundling and varying data formats. Languages without reflection (e.g. C ) have to use auxiliary compilers, e.g. for Abstract Syntax Notation , to produce code for serialization and bundling. Reflection can be used for observing and modifying program execution at runtime. A reflection-oriented program component can monitor the execution of an enclosure of code and can modify itself according to a desired goal related to that enclosure. This is typically accomplished by dynamically assigning program code at runtime. In object-oriented programming languages such as Java , reflection allows inspection of classes, interfaces, fields and methods at runtime without knowing the names of the interfaces, fields, methods at compile time. It also allows instantiation of new objects and invocation of methods. Reflection is often used as part of software testing , such as for the runtime creation/instantiation of mock objects . Reflection is also a key strategy for metaprogramming . In some object-oriented programming languages, such as C# and Java , reflection can be used to override member accessibility rules. For example, reflection makes it possible to change the value of a field marked \"private\" in a third-party library's class. Implementation A language supporting reflection provides a number of features available at runtime that would otherwise be difficult to accomplish in a lower-level language. Some of these features are the abilities to: Discover and modify source-code constructions (such as code blocks , classes , methods , protocols, etc.) as first-class objects at runtime. Convert a string matching the symbolic name of a class or function into a reference to or invocation of that class or function. Evaluate a string as if it were a source-code statement at runtime. SUMMARY : \u770b\u5230\u6b64\u5904\uff0c\u60f3\u5230\u4e86python\u7684 eval() \u00b6 Create a new interpreter for the language's bytecode to give a new meaning or purpose for a programming construct. These features can be implemented in different ways. In MOO , reflection forms a natural part of everyday programming idiom. When verbs (methods) are called, various variables such as verb (the name of the verb being called) and this (the object on which the verb is called) are populated to give the context of the call. Security is typically managed by accessing the caller stack programmatically: Since callers () is a list of the methods by which the current verb was eventually called, performing tests on callers ()[1] (the command invoked by the original user) allows the verb to protect itself against unauthorised use. Compiled languages rely on their runtime system to provide information about the source code. A compiled Objective-C executable, for example, records the names of all methods in a block of the executable, providing a table to correspond these with the underlying methods (or selectors for these methods) compiled into the program. In a compiled language that supports runtime creation of functions, such as Common Lisp , the runtime environment must include a compiler or an interpreter. Reflection can be implemented for languages not having built-in reflection facilities by using a program transformation system to define automated source-code changes. Examples The following code snippets create an instance foo of class Foo and invoke its method PrintHello . For each programming language , normal and reflection-based call sequences are shown. Python The following is an example in Python : # without reflection obj = Foo () obj . hello () # with reflection class_name = \"Foo\" method = \"hello\" obj = globals ()[ class_name ]() getattr ( obj , method )() # with eval eval ( \"Foo().hello()\" )","title":"Reflection"},{"location":"Theory/Reflection/Reflection/#reflection","text":"In computer science , reflection is the ability of a computer program to examine, introspect , and modify its own structure and behavior at runtime .[ 1] SUMMARY : \u5173\u4e8ereflection\u548c introspect \u4e4b\u95f4\u7684\u5dee\u5f02\u53c2\u89c1 introspect","title":"Reflection"},{"location":"Theory/Reflection/Reflection/#historical-background","text":"The earliest computers were programmed in their native assembly language , which were inherently reflective, as these original architectures could be programmed by defining instructions as data and using self-modifying code . As programming moved to compiled higher-level languages such as Algol , Cobol , and Fortran (but also Pascal and C and many other languages), this reflective ability largely disappeared until programming languages with reflection built into their type systems appeared.[ citation needed ] Brian Cantwell Smith 's 1982 doctoral dissertation[ 2] [ 3] introduced the notion of computational reflection in procedural programming languages and the notion of the meta-circular interpreter as a component of 3-Lisp .","title":"Historical background"},{"location":"Theory/Reflection/Reflection/#uses","text":"Reflection helps programmers make generic software libraries to display data, process different formats of data, perform serialization or deserialization of data for communication, or do bundling and unbundling of data for containers or bursts of communication. TRANSLATION : \u53cd\u5c04\u5e2e\u52a9\u7a0b\u5e8f\u5458\u5236\u4f5c\u901a\u7528\u8f6f\u4ef6\u5e93\u4ee5\u663e\u793a\u6570\u636e\uff0c\u5904\u7406\u4e0d\u540c\u683c\u5f0f\u7684\u6570\u636e\uff0c\u6267\u884c\u6570\u636e\u7684\u5e8f\u5217\u5316\u6216\u53cd\u5e8f\u5217\u5316\u4ee5\u8fdb\u884c\u901a\u4fe1\uff0c\u6216\u8005\u4e3a\u5bb9\u5668\u6216\u7a81\u53d1\u901a\u4fe1\u8fdb\u884c\u6570\u636e\u7684\u6346\u7ed1\u548c\u5206\u62c6\u3002 Effective use of reflection almost always requires a plan: A design framework, encoding description, object library, a map of a database or entity relations. Reflection makes a language more suited to network-oriented code. For example, it assists languages such as Java to operate well in networks by enabling libraries for serialization, bundling and varying data formats. Languages without reflection (e.g. C ) have to use auxiliary compilers, e.g. for Abstract Syntax Notation , to produce code for serialization and bundling. Reflection can be used for observing and modifying program execution at runtime. A reflection-oriented program component can monitor the execution of an enclosure of code and can modify itself according to a desired goal related to that enclosure. This is typically accomplished by dynamically assigning program code at runtime. In object-oriented programming languages such as Java , reflection allows inspection of classes, interfaces, fields and methods at runtime without knowing the names of the interfaces, fields, methods at compile time. It also allows instantiation of new objects and invocation of methods. Reflection is often used as part of software testing , such as for the runtime creation/instantiation of mock objects . Reflection is also a key strategy for metaprogramming . In some object-oriented programming languages, such as C# and Java , reflection can be used to override member accessibility rules. For example, reflection makes it possible to change the value of a field marked \"private\" in a third-party library's class.","title":"Uses"},{"location":"Theory/Reflection/Reflection/#implementation","text":"A language supporting reflection provides a number of features available at runtime that would otherwise be difficult to accomplish in a lower-level language. Some of these features are the abilities to: Discover and modify source-code constructions (such as code blocks , classes , methods , protocols, etc.) as first-class objects at runtime. Convert a string matching the symbolic name of a class or function into a reference to or invocation of that class or function. Evaluate a string as if it were a source-code statement at runtime. SUMMARY : \u770b\u5230\u6b64\u5904\uff0c\u60f3\u5230\u4e86python\u7684 eval() \u00b6 Create a new interpreter for the language's bytecode to give a new meaning or purpose for a programming construct. These features can be implemented in different ways. In MOO , reflection forms a natural part of everyday programming idiom. When verbs (methods) are called, various variables such as verb (the name of the verb being called) and this (the object on which the verb is called) are populated to give the context of the call. Security is typically managed by accessing the caller stack programmatically: Since callers () is a list of the methods by which the current verb was eventually called, performing tests on callers ()[1] (the command invoked by the original user) allows the verb to protect itself against unauthorised use. Compiled languages rely on their runtime system to provide information about the source code. A compiled Objective-C executable, for example, records the names of all methods in a block of the executable, providing a table to correspond these with the underlying methods (or selectors for these methods) compiled into the program. In a compiled language that supports runtime creation of functions, such as Common Lisp , the runtime environment must include a compiler or an interpreter. Reflection can be implemented for languages not having built-in reflection facilities by using a program transformation system to define automated source-code changes.","title":"Implementation"},{"location":"Theory/Reflection/Reflection/#examples","text":"The following code snippets create an instance foo of class Foo and invoke its method PrintHello . For each programming language , normal and reflection-based call sequences are shown.","title":"Examples"},{"location":"Theory/Reflection/Reflection/#python","text":"The following is an example in Python : # without reflection obj = Foo () obj . hello () # with reflection class_name = \"Foo\" method = \"hello\" obj = globals ()[ class_name ]() getattr ( obj , method )() # with eval eval ( \"Foo().hello()\" )","title":"Python"},{"location":"Theory/Reflection/Summary/","text":"Summary What is the difference between introspection and reflection?","title":"Summary"},{"location":"Theory/Reflection/Summary/#summary","text":"","title":"Summary"},{"location":"Theory/Reflection/Summary/#what-is-the-difference-between-introspection-and-reflection","text":"","title":"What is the difference between introspection and reflection?"},{"location":"Theory/Reflection/Type-introspection/","text":"Type introspection In computing , type introspection (\u7c7b\u578b\u53cd\u7701) is the ability of a program to examine the type or properties of an object at runtime . Some programming languages possess this capability. Introspection should not be confused with reflection , which goes a step further and is the ability for a program to manipulate the values, meta-data, properties and/or functions of an object at runtime. Some programming languages - e.g. Java, Python and Go - also possess that capability. Examples Python The most common method of introspection in Python is using the dir function to detail the attributes of an object. For example: class Foo ( object ): def __init__ ( self , val ): self . x = val def bar ( self ): return self . x ... >>> dir ( Foo ( 5 )) [ '__class__' , '__delattr__' , '__dict__' , '__doc__' , '__getattribute__' , '__hash__' , '__init__' , '__module__' , '__new__' , '__reduce__' , '__reduce_ex__' , '__repr__' , '__setattr__' , '__str__' , '__weakref__' , 'bar' , 'x' ] Also, the built-in functions type and isinstance can be used to determine what an object is while hasattr can determine what an object does . For example: >>> a = Foo ( 10 ) >>> b = Bar ( 11 ) >>> type ( a ) < type 'Foo' > >>> isinstance ( a , Foo ) True >>> isinstance ( a , type ( a )) True >>> isinstance ( a , type ( b )) False >>> hasattr ( a , 'bar' ) True In Python 2 but not Python 3, declaring class Foo instead of class Foo(object) will result in type returning the generic instance type instead of the class.[ 5] SUMMARY : \u53c2\u89c1 youdao/programming-language-python/python2to3 \uff0c\u5176\u4e2d\u603b\u7ed3\u4e86python2\u548cpython3\u4e4b\u95f4\u7684\u5dee\u5f02","title":"Type-introspection"},{"location":"Theory/Reflection/Type-introspection/#type-introspection","text":"In computing , type introspection (\u7c7b\u578b\u53cd\u7701) is the ability of a program to examine the type or properties of an object at runtime . Some programming languages possess this capability. Introspection should not be confused with reflection , which goes a step further and is the ability for a program to manipulate the values, meta-data, properties and/or functions of an object at runtime. Some programming languages - e.g. Java, Python and Go - also possess that capability.","title":"Type introspection"},{"location":"Theory/Reflection/Type-introspection/#examples","text":"","title":"Examples"},{"location":"Theory/Reflection/Type-introspection/#python","text":"The most common method of introspection in Python is using the dir function to detail the attributes of an object. For example: class Foo ( object ): def __init__ ( self , val ): self . x = val def bar ( self ): return self . x ... >>> dir ( Foo ( 5 )) [ '__class__' , '__delattr__' , '__dict__' , '__doc__' , '__getattribute__' , '__hash__' , '__init__' , '__module__' , '__new__' , '__reduce__' , '__reduce_ex__' , '__repr__' , '__setattr__' , '__str__' , '__weakref__' , 'bar' , 'x' ] Also, the built-in functions type and isinstance can be used to determine what an object is while hasattr can determine what an object does . For example: >>> a = Foo ( 10 ) >>> b = Bar ( 11 ) >>> type ( a ) < type 'Foo' > >>> isinstance ( a , Foo ) True >>> isinstance ( a , type ( a )) True >>> isinstance ( a , type ( b )) False >>> hasattr ( a , 'bar' ) True In Python 2 but not Python 3, declaring class Foo instead of class Foo(object) will result in type returning the generic instance type instead of the class.[ 5] SUMMARY : \u53c2\u89c1 youdao/programming-language-python/python2to3 \uff0c\u5176\u4e2d\u603b\u7ed3\u4e86python2\u548cpython3\u4e4b\u95f4\u7684\u5dee\u5f02","title":"Python"},{"location":"Theory/Resource-management/Resource-management/","text":"Resource management process\u5728\u5176\u751f\u547d\u5468\u671f\u5185\u4f1a\u5360\u7528\u4e00\u5b9a\u7684system resource\uff0c\u6240\u4ee5\u5b83\u5c31\u6d89\u53caresource management\u5373\u5982\u4f55\u6765\u7ba1\u7406\u5b83\u6240\u5360\u6709\u7684system resource\u3002 Resource management (computing) Implementation of resource management \u4e0d\u540c\u7684programming language\u7684resource management\u7b56\u7565\u662f\u4e0d\u540c\u7684\u3002 \u4e0d\u540c\u7684resource\u7684management\u7684\u7b56\u7565\u4e5f\u662f\u4e0d\u540c\u7684\uff0c\u6b63\u5982\u5728\u7ef4\u57fa\u767e\u79d1 Garbage collection (computer science) \u4e2d \u6240\u603b\u7ed3\u7684\uff1a Resources other than memory, such as network sockets , database handles , user interaction windows , file and device descriptors, are not typically handled by garbage collection.","title":"Resource-management"},{"location":"Theory/Resource-management/Resource-management/#resource-management","text":"process\u5728\u5176\u751f\u547d\u5468\u671f\u5185\u4f1a\u5360\u7528\u4e00\u5b9a\u7684system resource\uff0c\u6240\u4ee5\u5b83\u5c31\u6d89\u53caresource management\u5373\u5982\u4f55\u6765\u7ba1\u7406\u5b83\u6240\u5360\u6709\u7684system resource\u3002","title":"Resource management"},{"location":"Theory/Resource-management/Resource-management/#resource-management-computing","text":"","title":"Resource management (computing)"},{"location":"Theory/Resource-management/Resource-management/#implementation-of-resource-management","text":"\u4e0d\u540c\u7684programming language\u7684resource management\u7b56\u7565\u662f\u4e0d\u540c\u7684\u3002 \u4e0d\u540c\u7684resource\u7684management\u7684\u7b56\u7565\u4e5f\u662f\u4e0d\u540c\u7684\uff0c\u6b63\u5982\u5728\u7ef4\u57fa\u767e\u79d1 Garbage collection (computer science) \u4e2d \u6240\u603b\u7ed3\u7684\uff1a Resources other than memory, such as network sockets , database handles , user interaction windows , file and device descriptors, are not typically handled by garbage collection.","title":"Implementation of resource management"},{"location":"Theory/Resource-management/Memory-management/Memory-management/","text":"Memory management \u672c\u6587\u6240\u63cf\u8ff0\u7684memory management\u662f\u6307process\u7ea7\u522b\u7684memory management\uff0c\u800c\u4e0d\u662fOS kernel\u7ea7\u522b\u7684memory management\uff0c\u5173\u4e8eOS kernel\u7684memory management\uff0c\u53c2\u89c1\u5de5\u7a0b Linux-OS \u3002process\u7ea7\u522b\u7684memory management\u4e3b\u8981\u7531programming language\u7684\u5b9e\u73b0\u51b3\u5b9a\uff0c\u76ee\u524d\u6709\u5982\u4e0b\u4e24\u79cd\u65b9\u5f0f\uff1a Automatic memory management Manual memory management \u7ef4\u57fa\u767e\u79d1 Memory management Memory management is a form of resource management applied to computer memory . The essential requirement of memory management is to provide ways to dynamically allocate portions of memory to programs at their request, and free it for reuse when no longer needed. This is critical to any advanced computer system where more than a single process might be underway\uff08\u8fd0\u884c\u4e2d\uff09 at any time. Several methods have been devised that increase the effectiveness of memory management. Virtual memory systems separate the memory addresses used by a process from actual physical addresses, allowing separation of processes and increasing the size of the virtual address space beyond the available amount of RAM using paging or swapping to secondary storage . The quality of the virtual memory manager can have an extensive effect on overall system performance. Details Memory management within an address space is generally categorized as either automatic memory management, usually involving garbage collection , or manual memory management . NOTE: automatic memory management\u548c manual memory management \u662f\u5f53\u524dprogramming language implementation\u6240\u91c7\u7528\u7684\u4e24\u79cd\u4e3b\u6d41\u65b9\u5f0f\uff0c\u540e\u9762\u4f1a\u5bf9\u6b64\u8fdb\u884c\u5c55\u5f00\u3002 Dynamic memory allocation See also: C dynamic memory allocation Implementations Fixed-size blocks allocation Main article: Memory pool Buddy blocks Further information: Buddy memory allocation Slab allocation Main article: Slab allocation Stack allocation Main article: Stack-based memory allocation Automatic variables Main article: Automatic variable In many programming language implementations, all variables declared within a procedure (subroutine, or function) are local to that function; the runtime environment for the program automatically allocates memory for these variables on program execution entry to the procedure, and automatically releases that memory when the procedure is exited. Special declarations may allow local variables to retain values between invocations of the procedure, or may allow local variables to be accessed by other procedures. The automatic allocation of local variables makes recursion possible, to a depth limited by available memory. Garbage collection Main article: Garbage collection (computer science)","title":"Memory-management"},{"location":"Theory/Resource-management/Memory-management/Memory-management/#memory-management","text":"\u672c\u6587\u6240\u63cf\u8ff0\u7684memory management\u662f\u6307process\u7ea7\u522b\u7684memory management\uff0c\u800c\u4e0d\u662fOS kernel\u7ea7\u522b\u7684memory management\uff0c\u5173\u4e8eOS kernel\u7684memory management\uff0c\u53c2\u89c1\u5de5\u7a0b Linux-OS \u3002process\u7ea7\u522b\u7684memory management\u4e3b\u8981\u7531programming language\u7684\u5b9e\u73b0\u51b3\u5b9a\uff0c\u76ee\u524d\u6709\u5982\u4e0b\u4e24\u79cd\u65b9\u5f0f\uff1a Automatic memory management Manual memory management","title":"Memory management"},{"location":"Theory/Resource-management/Memory-management/Memory-management/#memory-management_1","text":"Memory management is a form of resource management applied to computer memory . The essential requirement of memory management is to provide ways to dynamically allocate portions of memory to programs at their request, and free it for reuse when no longer needed. This is critical to any advanced computer system where more than a single process might be underway\uff08\u8fd0\u884c\u4e2d\uff09 at any time. Several methods have been devised that increase the effectiveness of memory management. Virtual memory systems separate the memory addresses used by a process from actual physical addresses, allowing separation of processes and increasing the size of the virtual address space beyond the available amount of RAM using paging or swapping to secondary storage . The quality of the virtual memory manager can have an extensive effect on overall system performance.","title":"\u7ef4\u57fa\u767e\u79d1Memory management"},{"location":"Theory/Resource-management/Memory-management/Memory-management/#details","text":"Memory management within an address space is generally categorized as either automatic memory management, usually involving garbage collection , or manual memory management . NOTE: automatic memory management\u548c manual memory management \u662f\u5f53\u524dprogramming language implementation\u6240\u91c7\u7528\u7684\u4e24\u79cd\u4e3b\u6d41\u65b9\u5f0f\uff0c\u540e\u9762\u4f1a\u5bf9\u6b64\u8fdb\u884c\u5c55\u5f00\u3002","title":"Details"},{"location":"Theory/Resource-management/Memory-management/Memory-management/#dynamic-memory-allocation","text":"See also: C dynamic memory allocation","title":"Dynamic memory allocation"},{"location":"Theory/Resource-management/Memory-management/Memory-management/#implementations","text":"","title":"Implementations"},{"location":"Theory/Resource-management/Memory-management/Memory-management/#fixed-size-blocks-allocation","text":"Main article: Memory pool","title":"Fixed-size blocks allocation"},{"location":"Theory/Resource-management/Memory-management/Memory-management/#buddy-blocks","text":"Further information: Buddy memory allocation","title":"Buddy blocks"},{"location":"Theory/Resource-management/Memory-management/Memory-management/#slab-allocation","text":"Main article: Slab allocation","title":"Slab allocation"},{"location":"Theory/Resource-management/Memory-management/Memory-management/#stack-allocation","text":"Main article: Stack-based memory allocation","title":"Stack allocation"},{"location":"Theory/Resource-management/Memory-management/Memory-management/#automatic-variables","text":"Main article: Automatic variable In many programming language implementations, all variables declared within a procedure (subroutine, or function) are local to that function; the runtime environment for the program automatically allocates memory for these variables on program execution entry to the procedure, and automatically releases that memory when the procedure is exited. Special declarations may allow local variables to retain values between invocations of the procedure, or may allow local variables to be accessed by other procedures. The automatic allocation of local variables makes recursion possible, to a depth limited by available memory.","title":"Automatic variables"},{"location":"Theory/Resource-management/Memory-management/Memory-management/#garbage-collection","text":"Main article: Garbage collection (computer science)","title":"Garbage collection"},{"location":"Theory/Resource-management/Memory-management/Automatic-memory-management/Automatic-memory-management/","text":"Automatic memory management \u201cautomatic memory management\u201d\u5373\u201c\u81ea\u52a8\u5185\u5b58\u7ba1\u7406\u201d\uff0c\u76ee\u524d\u7684\u5b9e\u73b0\u65b9\u5f0f\u662fgarbage collection\u3002 \u7ef4\u57fa\u767e\u79d1 Garbage collection (computer science)","title":"Automatic-memory-management"},{"location":"Theory/Resource-management/Memory-management/Automatic-memory-management/Automatic-memory-management/#automatic-memory-management","text":"\u201cautomatic memory management\u201d\u5373\u201c\u81ea\u52a8\u5185\u5b58\u7ba1\u7406\u201d\uff0c\u76ee\u524d\u7684\u5b9e\u73b0\u65b9\u5f0f\u662fgarbage collection\u3002","title":"Automatic memory management"},{"location":"Theory/Resource-management/Memory-management/Automatic-memory-management/Automatic-memory-management/#garbage-collection-computer-science","text":"","title":"\u7ef4\u57fa\u767e\u79d1Garbage collection (computer science)"},{"location":"Theory/Resource-management/Memory-management/Manual-memory-management/C-dynamic-memory-allocation/","text":"C dynamic memory allocation C dynamic memory allocation","title":"C-dynamic-memory-allocation"},{"location":"Theory/Resource-management/Memory-management/Manual-memory-management/C-dynamic-memory-allocation/#c-dynamic-memory-allocation","text":"","title":"C dynamic memory allocation"},{"location":"Theory/Resource-management/Memory-management/Manual-memory-management/Manual-memory-management/","text":"Manual memory management \u201cmanual memory management\u201d\u5373\u201c\u624b\u5de5\u5185\u5b58\u7ba1\u7406\u201d \u7ef4\u57fa\u767e\u79d1 Manual memory management Implementation of manual memory management manual memory management\u7684\u6240\u6709\u5de5\u4f5c\u7531programmer\u6765\u5b8c\u6210\uff0c\u6240\u4ee5\u5bf9programmer\u7684\u8981\u6c42\u8f83\u9ad8\uff0c\u9700\u8981programmer\u5bf9process\u7684memory model\uff08\u53c2\u89c1\u5de5\u7a0b Linux-OS \uff09\u6709\u4e00\u5b9a\u4e86\u89e3\u3002\u5728\u8fdb\u884cprogramming\u7684\u65f6\u5019\uff0cmemory resource\u7528\u201cvariable\u201d\u6765\u8868\u793a\uff0c\u53ef\u4ee5\u901a\u8fc7variable\u6982\u5ff5\u6765\u5206\u6790manual memory management\u3002 Variable (computer science) Static variable Automatic variable Object lifetime Memory management of c++ \u53c2\u89c1\u7ef4\u57fa\u767e\u79d1 C++ \u7684 Object storage \u6bb5\u3002","title":"Manual-memory-management"},{"location":"Theory/Resource-management/Memory-management/Manual-memory-management/Manual-memory-management/#manual-memory-management","text":"\u201cmanual memory management\u201d\u5373\u201c\u624b\u5de5\u5185\u5b58\u7ba1\u7406\u201d","title":"Manual memory management"},{"location":"Theory/Resource-management/Memory-management/Manual-memory-management/Manual-memory-management/#manual-memory-management_1","text":"","title":"\u7ef4\u57fa\u767e\u79d1Manual memory management"},{"location":"Theory/Resource-management/Memory-management/Manual-memory-management/Manual-memory-management/#implementation-of-manual-memory-management","text":"manual memory management\u7684\u6240\u6709\u5de5\u4f5c\u7531programmer\u6765\u5b8c\u6210\uff0c\u6240\u4ee5\u5bf9programmer\u7684\u8981\u6c42\u8f83\u9ad8\uff0c\u9700\u8981programmer\u5bf9process\u7684memory model\uff08\u53c2\u89c1\u5de5\u7a0b Linux-OS \uff09\u6709\u4e00\u5b9a\u4e86\u89e3\u3002\u5728\u8fdb\u884cprogramming\u7684\u65f6\u5019\uff0cmemory resource\u7528\u201cvariable\u201d\u6765\u8868\u793a\uff0c\u53ef\u4ee5\u901a\u8fc7variable\u6982\u5ff5\u6765\u5206\u6790manual memory management\u3002 Variable (computer science) Static variable Automatic variable Object lifetime","title":"Implementation of manual memory management"},{"location":"Theory/Resource-management/Memory-management/Manual-memory-management/Manual-memory-management/#memory-management-of-c","text":"\u53c2\u89c1\u7ef4\u57fa\u767e\u79d1 C++ \u7684 Object storage \u6bb5\u3002","title":"Memory management of c++"},{"location":"Theory/Resource-management/Memory-management/Manual-memory-management/Non-local-variable/","text":"Non-local variable","title":"Non-local-variable"},{"location":"Theory/Resource-management/Memory-management/Manual-memory-management/Non-local-variable/#non-local-variable","text":"","title":"Non-local variable"},{"location":"Theory/Resource-management/Memory-management/Manual-memory-management/Static-variable/","text":"Static variable In computer programming , a static variable is a variable that has been allocated \"statically\", meaning that its lifetime (or \"extent\") is the entire run of the program. This is in contrast to shorter-lived automatic variables , whose storage is stack allocated and deallocated on the call stack ; and in contrast to objects , whose storage is dynamically allocated and deallocated in heap memory . Variable lifetime is contrasted with scope (where a variable can be used): \"global\" and \"local\" refer to scope, not lifetime, but scope often implies lifetime. In many languages, global variables are always static, but in some languages they are dynamic, while local variables are generally automatic, but may be static. In general, static memory allocation is the allocation of memory at compile time , before the associated program is executed, unlike dynamic memory allocation or automatic memory allocation where memory is allocated as required at run time .[ 1] Addressing The absolute address addressing mode can only be used with static variables, because those are the only kinds of variables whose location is known by the compiler at compile time. When the program (executable or library) is loaded into memory, static variables are stored in the data segment of the program's address space (if initialized), or the BSS segment (if uninitialized), and are stored in corresponding sections of object files prior to loading. Scope See also: Variable (computer science) \u00a7 Scope and extent In terms of scope and extent , static variables have extent the entire run of the program, but may have more limited scope . A basic distinction is between a static global variable , which has global scope and thus is in context throughout the program, and a static local variable, which has local scope. A static local variable is different from a local variable as a static local variable is initialized only once no matter how many times the function in which it resides is called and its value is retained and accessible through many calls to the function in which it is declared, e.g. to be used as a count variable. A static variable may also have module scope or some variant, such as internal linkage in C , which is a form of file scope or module scope. Example An example of static local variable in C: #include <stdio.h> void func () { static int x = 0 ; /* x is initialized only once across five calls of func() and the variable will get incremented five times after these calls. The final value of x will be 5. */ x ++ ; printf ( \"%d \\n \" , x ); // outputs the value of x } int main () { //int argc, char *argv[] inside the main is optional in the particular program func (); // prints 1 func (); // prints 2 func (); // prints 3 func (); // prints 4 func (); // prints 5 return 0 ; } Object-oriented programming In object-oriented programming , there is also the concept of a static member variable , which is a \" class variable \" of a statically defined class, i.e., a member variable of a given class which is shared across all instances (objects), and is accessible as a member variable of these objects. A class variable of a dynamically defined class, in languages where classes can be defined at run time, is allocated when the class is defined and is not static. Object constants known at compile-time, such as string literals , are usually allocated statically. In object-oriented programming, the virtual method tables of classes are usually allocated statically. A statically defined value can also be global in its scope ensuring the same immutable value is used throughout a run for consistency.","title":"Static-variable"},{"location":"Theory/Resource-management/Memory-management/Manual-memory-management/Static-variable/#static-variable","text":"In computer programming , a static variable is a variable that has been allocated \"statically\", meaning that its lifetime (or \"extent\") is the entire run of the program. This is in contrast to shorter-lived automatic variables , whose storage is stack allocated and deallocated on the call stack ; and in contrast to objects , whose storage is dynamically allocated and deallocated in heap memory . Variable lifetime is contrasted with scope (where a variable can be used): \"global\" and \"local\" refer to scope, not lifetime, but scope often implies lifetime. In many languages, global variables are always static, but in some languages they are dynamic, while local variables are generally automatic, but may be static. In general, static memory allocation is the allocation of memory at compile time , before the associated program is executed, unlike dynamic memory allocation or automatic memory allocation where memory is allocated as required at run time .[ 1]","title":"Static variable"},{"location":"Theory/Resource-management/Memory-management/Manual-memory-management/Static-variable/#addressing","text":"The absolute address addressing mode can only be used with static variables, because those are the only kinds of variables whose location is known by the compiler at compile time. When the program (executable or library) is loaded into memory, static variables are stored in the data segment of the program's address space (if initialized), or the BSS segment (if uninitialized), and are stored in corresponding sections of object files prior to loading.","title":"Addressing"},{"location":"Theory/Resource-management/Memory-management/Manual-memory-management/Static-variable/#scope","text":"See also: Variable (computer science) \u00a7 Scope and extent In terms of scope and extent , static variables have extent the entire run of the program, but may have more limited scope . A basic distinction is between a static global variable , which has global scope and thus is in context throughout the program, and a static local variable, which has local scope. A static local variable is different from a local variable as a static local variable is initialized only once no matter how many times the function in which it resides is called and its value is retained and accessible through many calls to the function in which it is declared, e.g. to be used as a count variable. A static variable may also have module scope or some variant, such as internal linkage in C , which is a form of file scope or module scope.","title":"Scope"},{"location":"Theory/Resource-management/Memory-management/Manual-memory-management/Static-variable/#example","text":"An example of static local variable in C: #include <stdio.h> void func () { static int x = 0 ; /* x is initialized only once across five calls of func() and the variable will get incremented five times after these calls. The final value of x will be 5. */ x ++ ; printf ( \"%d \\n \" , x ); // outputs the value of x } int main () { //int argc, char *argv[] inside the main is optional in the particular program func (); // prints 1 func (); // prints 2 func (); // prints 3 func (); // prints 4 func (); // prints 5 return 0 ; }","title":"Example"},{"location":"Theory/Resource-management/Memory-management/Manual-memory-management/Static-variable/#object-oriented-programming","text":"In object-oriented programming , there is also the concept of a static member variable , which is a \" class variable \" of a statically defined class, i.e., a member variable of a given class which is shared across all instances (objects), and is accessible as a member variable of these objects. A class variable of a dynamically defined class, in languages where classes can be defined at run time, is allocated when the class is defined and is not static. Object constants known at compile-time, such as string literals , are usually allocated statically. In object-oriented programming, the virtual method tables of classes are usually allocated statically. A statically defined value can also be global in its scope ensuring the same immutable value is used throughout a run for consistency.","title":"Object-oriented programming"},{"location":"Theory/Serialization/Library/","text":"Library Protocol buffer https://github.com/protocolbuffers/protobuf https://developers.google.com/protocol-buffers/","title":"Library"},{"location":"Theory/Serialization/Library/#library","text":"","title":"Library"},{"location":"Theory/Serialization/Library/#protocol-buffer","text":"https://github.com/protocolbuffers/protobuf https://developers.google.com/protocol-buffers/","title":"Protocol buffer"},{"location":"Theory/Serialization/Serialization/","text":"Serialization \u4e3a\u4e86\u4f7f\u7528\u54ea\u79cdprogramming language\uff0c\u90fd\u53ef\u80fd\u4f1a\u6d89\u53ca\u5230serialization\u95ee\u9898\uff0c\u672c\u6587\u5bf9\u6b64\u8fdb\u884c\u603b\u7ed3\u3002 \u7ef4\u57fa\u767e\u79d1 Serialization In computer science , in the context of data storage, serialization (or serialisation) is the process of translating data structures or object state into a format that can be stored (for example, in a file or memory buffer ) or transmitted (for example, across a network connection link) and reconstructed later (possibly in a different computer environment). When the resulting series of bits is reread according to the serialization format , it can be used to create a semantically identical clone of the original object. For many complex objects, such as those that make extensive use of references , this process is not straightforward. Serialization of object-oriented objects does not include any of their associated methods with which they were previously linked. This process of serializing an object is also called marshalling an object. The opposite operation, extracting a data structure from a series of bytes, is deserialization (also called unmarshalling ). Uses A method of transferring data through the wires ( messaging ). A method of storing data (in databases , on hard disk drives ). A method of remote procedure calls , e.g., as in SOAP . A method for distributing objects, especially in component-based software engineering such as COM , CORBA , etc. A method for detecting changes in time-varying data. For some of these features to be useful, architecture independence must be maintained. For example, for maximal use of distribution, a computer running on a different hardware architecture should be able to reliably reconstruct a serialized data stream , regardless of endianness . This means that the simpler and faster procedure of directly copying the memory layout of the data structure cannot work reliably for all architectures. Serializing the data structure in an architecture-independent format means preventing the problems of byte ordering , memory layout, or simply different ways of representing data structures in different programming languages . Inherent to any serialization scheme is that, because the encoding of the data is by definition serial, extracting one part of the serialized data structure requires that the entire object be read from start to end, and reconstructed. In many applications, this linearity(\u7ebf\u6027) is an asset(\u4f18\u70b9), because it enables simple, common I/O interfaces to be utilized to hold and pass on the state of an object. In applications where higher performance is an issue, it can make sense to expend more effort to deal with a more complex, non-linear storage organization. Even on a single machine, primitive pointer objects are too fragile to save because the objects to which they point may be reloaded to a different location in memory. To deal with this, the serialization process includes a step called unswizzling or pointer unswizzling , where direct pointer references are converted to references based on name or position. The deserialization process includes an inverse step called pointer swizzling . Since both serializing and deserializing can be driven from common code (for example, the Serialize function in Microsoft Foundation Classes ), it is possible for the common code to do both at the same time, and thus, 1) detect differences between the objects being serialized and their prior copies, and 2) provide the input for the next such detection. It is not necessary to actually build the prior copy because differences can be detected on the fly. The technique is called differential execution . This is useful in the programming of user interfaces whose contents are time-varying \u2014 graphical objects can be created, removed, altered, or made to handle input events without necessarily having to write separate code to do those things. Implementation \u6bd4\u5982 pickle \u2014 Python object serialization \u00b6 \u3002 binary serialization vs protoc-buff \u5728ust\u9879\u76ee\u4e2d\uff0c\u76f4\u63a5\u4f7f\u7528\u7684binary serialization\uff0c\u4e3a\u6bcf\u79cd\u8bf7\u6c42\u90fd\u6d89\u53ca\u4e00\u4e2a struct \uff0c\u7136\u540eclient\u548cserver\u4e4b\u95f4\u5c31\u4f7f\u7528 struct \u6765\u4f5c\u4e3aprotocol\u3002\u663e\u7136\u8fd9\u79cd\u5b9e\u73b0\u65b9\u5f0f\u662f\u6700\u6700\u9ad8\u6548\u7684\uff0c\u4f46\u662f\u8fd9\u79cd\u5b9e\u73b0\u65b9\u5f0f\u6240\u5e26\u6765\u7684\u4e00\u4e2a\u95ee\u9898\u662f\uff1a\u6bcf\u6b21\u65b0\u589e\u4e00\u4e2a\u8bf7\u6c42\uff0c\u5c31\u6d89\u53ca\u5230client\u548cserver\u7684\u5168\u90e8\u7684\u4fee\u6539\u3002\u800c\u4e0d\u662f\u50cf\u666e\u901a\u7684\u534f\u8bae\u90a3\u6837\u3002\u4e0e\u6b64\u76f8\u5173\u7684\u662fredis\u7684\u534f\u8bae\u3001http\u534f\u8bae\u3002 https://stackoverflow.com/questions/2966500/protobuf-net-not-faster-than-binary-serialization https://theburningmonk.com/2011/08/performance-test-binaryformatter-vs-protobuf-net/","title":"Serialization"},{"location":"Theory/Serialization/Serialization/#serialization","text":"\u4e3a\u4e86\u4f7f\u7528\u54ea\u79cdprogramming language\uff0c\u90fd\u53ef\u80fd\u4f1a\u6d89\u53ca\u5230serialization\u95ee\u9898\uff0c\u672c\u6587\u5bf9\u6b64\u8fdb\u884c\u603b\u7ed3\u3002","title":"Serialization"},{"location":"Theory/Serialization/Serialization/#serialization_1","text":"In computer science , in the context of data storage, serialization (or serialisation) is the process of translating data structures or object state into a format that can be stored (for example, in a file or memory buffer ) or transmitted (for example, across a network connection link) and reconstructed later (possibly in a different computer environment). When the resulting series of bits is reread according to the serialization format , it can be used to create a semantically identical clone of the original object. For many complex objects, such as those that make extensive use of references , this process is not straightforward. Serialization of object-oriented objects does not include any of their associated methods with which they were previously linked. This process of serializing an object is also called marshalling an object. The opposite operation, extracting a data structure from a series of bytes, is deserialization (also called unmarshalling ).","title":"\u7ef4\u57fa\u767e\u79d1Serialization"},{"location":"Theory/Serialization/Serialization/#uses","text":"A method of transferring data through the wires ( messaging ). A method of storing data (in databases , on hard disk drives ). A method of remote procedure calls , e.g., as in SOAP . A method for distributing objects, especially in component-based software engineering such as COM , CORBA , etc. A method for detecting changes in time-varying data. For some of these features to be useful, architecture independence must be maintained. For example, for maximal use of distribution, a computer running on a different hardware architecture should be able to reliably reconstruct a serialized data stream , regardless of endianness . This means that the simpler and faster procedure of directly copying the memory layout of the data structure cannot work reliably for all architectures. Serializing the data structure in an architecture-independent format means preventing the problems of byte ordering , memory layout, or simply different ways of representing data structures in different programming languages . Inherent to any serialization scheme is that, because the encoding of the data is by definition serial, extracting one part of the serialized data structure requires that the entire object be read from start to end, and reconstructed. In many applications, this linearity(\u7ebf\u6027) is an asset(\u4f18\u70b9), because it enables simple, common I/O interfaces to be utilized to hold and pass on the state of an object. In applications where higher performance is an issue, it can make sense to expend more effort to deal with a more complex, non-linear storage organization. Even on a single machine, primitive pointer objects are too fragile to save because the objects to which they point may be reloaded to a different location in memory. To deal with this, the serialization process includes a step called unswizzling or pointer unswizzling , where direct pointer references are converted to references based on name or position. The deserialization process includes an inverse step called pointer swizzling . Since both serializing and deserializing can be driven from common code (for example, the Serialize function in Microsoft Foundation Classes ), it is possible for the common code to do both at the same time, and thus, 1) detect differences between the objects being serialized and their prior copies, and 2) provide the input for the next such detection. It is not necessary to actually build the prior copy because differences can be detected on the fly. The technique is called differential execution . This is useful in the programming of user interfaces whose contents are time-varying \u2014 graphical objects can be created, removed, altered, or made to handle input events without necessarily having to write separate code to do those things.","title":"Uses"},{"location":"Theory/Serialization/Serialization/#implementation","text":"\u6bd4\u5982 pickle \u2014 Python object serialization \u00b6 \u3002","title":"Implementation"},{"location":"Theory/Serialization/Serialization/#binary-serialization-vs-protoc-buff","text":"\u5728ust\u9879\u76ee\u4e2d\uff0c\u76f4\u63a5\u4f7f\u7528\u7684binary serialization\uff0c\u4e3a\u6bcf\u79cd\u8bf7\u6c42\u90fd\u6d89\u53ca\u4e00\u4e2a struct \uff0c\u7136\u540eclient\u548cserver\u4e4b\u95f4\u5c31\u4f7f\u7528 struct \u6765\u4f5c\u4e3aprotocol\u3002\u663e\u7136\u8fd9\u79cd\u5b9e\u73b0\u65b9\u5f0f\u662f\u6700\u6700\u9ad8\u6548\u7684\uff0c\u4f46\u662f\u8fd9\u79cd\u5b9e\u73b0\u65b9\u5f0f\u6240\u5e26\u6765\u7684\u4e00\u4e2a\u95ee\u9898\u662f\uff1a\u6bcf\u6b21\u65b0\u589e\u4e00\u4e2a\u8bf7\u6c42\uff0c\u5c31\u6d89\u53ca\u5230client\u548cserver\u7684\u5168\u90e8\u7684\u4fee\u6539\u3002\u800c\u4e0d\u662f\u50cf\u666e\u901a\u7684\u534f\u8bae\u90a3\u6837\u3002\u4e0e\u6b64\u76f8\u5173\u7684\u662fredis\u7684\u534f\u8bae\u3001http\u534f\u8bae\u3002 https://stackoverflow.com/questions/2966500/protobuf-net-not-faster-than-binary-serialization https://theburningmonk.com/2011/08/performance-test-binaryformatter-vs-protobuf-net/","title":"binary serialization vs protoc-buff"},{"location":"Theory/Subroutine/","text":"\u5173\u4e8e\u672c\u7ae0 \u57fa\u672c\u4e0a\u6240\u6709\u4e3b\u6d41\u7684programming language\u90fd\u652f\u6301\u201c\u51fd\u6570\u201d\u7684\u6982\u5ff5\uff0c\u4f5c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u5e08\uff0c\u6211\u4eec\u5e73\u65f6\u6240\u8bf4\u7684\u201c\u5b9a\u4e49\u4e00\u4e2a\u51fd\u6570\u201d\u3001\u201c\u8c03\u7528\u51fd\u6570\u201d\uff0c\u5176\u5b9e\u4e25\u683c\u610f\u4e49\u4e0a\u6765\u8bf4\u662f\u201cSubroutine\u201d\u3002\u4e00\u63d0\u53ca\u51fd\u6570\uff0c\u53ef\u4ee5\u5f15\u51fa\u4e00\u4e9b\u5217\u7684\u76f8\u5173\u7684\u5185\u5bb9\uff0c\u53ef\u4ee5\u8bf4\u6db5\u76d6\u4e86\u6211\u4eec\u5e73\u65f6\u7f16\u7a0b\u4e2d\u7684\u65b9\u65b9\u9762\u9762\uff1a \u7ef4\u57fa\u767e\u79d1 Subroutine \u7ef4\u57fa\u767e\u79d1 Functional programming \u7ef4\u57fa\u767e\u79d1 Higher-order function \u7ef4\u57fa\u767e\u79d1 Function object \u7ef4\u57fa\u767e\u79d1 Function pointer \u7ef4\u57fa\u767e\u79d1 Method (computer programming) \u7ef4\u57fa\u767e\u79d1 Lambda \u7ef4\u57fa\u767e\u79d1 Closure \u7ef4\u57fa\u767e\u79d1 Callback \u7ef4\u57fa\u767e\u79d1 First-class function ...... \u5728\u7ef4\u57fa\u767e\u79d1\u7684 Category:Subroutines \u4e2d\u603b\u7ed3\u4e86\u4e0esubroutine\u76f8\u5173\u7684\u5185\u5bb9\u3002 Subroutine VS function VS method subroutine\u548cfunction\u57fa\u672c\u4e0a\u662f\u540c\u4e49\u8bcd\uff0c\u9700\u8981\u533a\u5206\u7684\u662ffunction\u548c mathematical function \uff0cprogramming language\u662f\u53ef\u4ee5\u63cf\u8ff0 mathematical function \u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4f7f\u7528programming language\u5b9a\u4e49\u7684function\u6765\u5b9e\u73b0 mathematical function \uff0c\u8f6f\u4ef6\u5de5\u7a0b\u4e2dfunction\u548c\u6570\u5b66\u4e2d\u7684function\u662f\u4e0d\u540c\u7684\uff0c\u8fd9\u4e00\u70b9\u5728 Functional programming \u4e2d\u6709\u9610\u8ff0\u3002 Object-oriented programming Method What is the difference between a function and a subroutine? Functions and Subroutines event driven programming and call back Javascript function as a parameter to another function?","title":"Introduction"},{"location":"Theory/Subroutine/#_1","text":"\u57fa\u672c\u4e0a\u6240\u6709\u4e3b\u6d41\u7684programming language\u90fd\u652f\u6301\u201c\u51fd\u6570\u201d\u7684\u6982\u5ff5\uff0c\u4f5c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u5e08\uff0c\u6211\u4eec\u5e73\u65f6\u6240\u8bf4\u7684\u201c\u5b9a\u4e49\u4e00\u4e2a\u51fd\u6570\u201d\u3001\u201c\u8c03\u7528\u51fd\u6570\u201d\uff0c\u5176\u5b9e\u4e25\u683c\u610f\u4e49\u4e0a\u6765\u8bf4\u662f\u201cSubroutine\u201d\u3002\u4e00\u63d0\u53ca\u51fd\u6570\uff0c\u53ef\u4ee5\u5f15\u51fa\u4e00\u4e9b\u5217\u7684\u76f8\u5173\u7684\u5185\u5bb9\uff0c\u53ef\u4ee5\u8bf4\u6db5\u76d6\u4e86\u6211\u4eec\u5e73\u65f6\u7f16\u7a0b\u4e2d\u7684\u65b9\u65b9\u9762\u9762\uff1a \u7ef4\u57fa\u767e\u79d1 Subroutine \u7ef4\u57fa\u767e\u79d1 Functional programming \u7ef4\u57fa\u767e\u79d1 Higher-order function \u7ef4\u57fa\u767e\u79d1 Function object \u7ef4\u57fa\u767e\u79d1 Function pointer \u7ef4\u57fa\u767e\u79d1 Method (computer programming) \u7ef4\u57fa\u767e\u79d1 Lambda \u7ef4\u57fa\u767e\u79d1 Closure \u7ef4\u57fa\u767e\u79d1 Callback \u7ef4\u57fa\u767e\u79d1 First-class function ...... \u5728\u7ef4\u57fa\u767e\u79d1\u7684 Category:Subroutines \u4e2d\u603b\u7ed3\u4e86\u4e0esubroutine\u76f8\u5173\u7684\u5185\u5bb9\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Theory/Subroutine/#subroutine-vs-function-vs-method","text":"subroutine\u548cfunction\u57fa\u672c\u4e0a\u662f\u540c\u4e49\u8bcd\uff0c\u9700\u8981\u533a\u5206\u7684\u662ffunction\u548c mathematical function \uff0cprogramming language\u662f\u53ef\u4ee5\u63cf\u8ff0 mathematical function \u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4f7f\u7528programming language\u5b9a\u4e49\u7684function\u6765\u5b9e\u73b0 mathematical function \uff0c\u8f6f\u4ef6\u5de5\u7a0b\u4e2dfunction\u548c\u6570\u5b66\u4e2d\u7684function\u662f\u4e0d\u540c\u7684\uff0c\u8fd9\u4e00\u70b9\u5728 Functional programming \u4e2d\u6709\u9610\u8ff0\u3002 Object-oriented programming Method What is the difference between a function and a subroutine? Functions and Subroutines","title":"Subroutine VS function VS method"},{"location":"Theory/Subroutine/#event-driven-programming-and-call-back","text":"Javascript function as a parameter to another function?","title":"event driven programming and call back"},{"location":"Theory/Subroutine/First-class-function/","text":"First class function \u7ef4\u57fa\u767e\u79d1 First-class function NOTE: \u6211\u662f\u5148\u770b\u5230closure\uff0c\u5728\u6765\u770b\u8fd9\u7bc7\u6587\u7ae0\u7684\uff0c \u73b0\u5728\u770b\u6765\uff0c\u4e24\u8005\u4e4b\u95f4\u7684\u5173\u7cfb\u662f\uff1a\u4e3a\u4e86\u652f\u6301first-class function\uff0c\u624d\u5f15\u5165\u4e86closure\u3002 In computer science , a programming language is said to have first-class functions if it treats functions as first-class citizens . This means the language supports: passing functions as arguments to other functions returning functions as the values from other functions, assigning function to variables or storing them in data structures.[ 1] Some programming language theorists require support for anonymous functions (function literals) as well. In languages with first-class functions , the names of functions do not have any special status; they are treated like ordinary variables with a function type . The term was coined by Christopher Strachey in the context of \"functions as first-class citizens\" in the mid-1960s. NOTE\uff1a\u5bf9\u4e8epython\u8fd9\u79cd\u7c7b\u578b\u7684\u8bed\u8a00\u6765\u8bf4\uff0c\u4e00\u5207\u7686\u5bf9\u8c61\uff0c\u6240\u4ee5\u5728python\u4e2d\uff0c\u51fd\u6570\u4e5f\u662f\u5bf9\u8c61\uff0c\u6240\u4ee5\u5b83\u5bf9first-class function\u652f\u6301\u7684\u5b9e\u73b0\u5e94\u8be5\u662f\u76f8\u5bf9\u5bb9\u6613\u7684\u3002\u5bf9\u6bd4\u6765\u770b\uff0c\u5728c++\u4e2d\uff0c\u5e76\u6ca1\u6709function type\uff0c\u90a3\u4e48c++\u662f\u5982\u4f55\u5b9e\u73b0\u7684\u5462\uff1f First-class functions are a necessity for the functional programming style, in which the use of higher-order functions is a standard practice. A simple example of a higher-ordered function is the map function, which takes, as its arguments, a function and a list , and returns the list formed by applying the function to each member of the list. For a language to support map , it must support passing a function as an argument. NOTE\uff1amap\u662f\u4e00\u4e2a higher-ordered function \uff0c\u5b83\u672c\u8eab\u662f\u4e00\u4e2a\u51fd\u6570\uff0c\u5b83\u4ee5\u53e6\u5916\u4e00\u4e2a\u51fd\u6570\u4f5c\u4e3a\u53c2\u6570\u3002 There are certain implementation difficulties in passing functions as arguments or returning them as results, especially in the presence of non-local variables introduced in nested and anonymous functions . Historically, these were termed the funarg problems , the name coming from \"function argument\".[ 5] In early imperative languages (\u547d\u4ee4\u5f0f\u8bed\u8a00) these problems were avoided by either not supporting functions as result types (e.g. ALGOL 60 , Pascal ) or omitting(\u7701\u7565) nested functions and thus non-local variables (e.g. C ). The early functional language Lisp took the approach of dynamic scoping , where non-local variables refer to the closest definition of that variable at the point where the function is executed, instead of where it was defined. Proper support for lexically scoped first-class functions was introduced in Scheme and requires handling references to functions as closures instead of bare function pointers ,[ 4] which in turn makes garbage collection a necessity. NOTE: \u8fd9\u6bb5\u8bdd\u4e2d\u63d0\u53ca\u5230\u4e86 dynamic scoping \u548c lexically scoped \uff0c\u7ed3\u5408\u4e0b\u9762\u7684\u5185\u5bb9\u53ef\u77e5\uff0c lexically scoped \u5bf9\u5b9e\u73b0first-class function\u66f4\u6709\u4ef7\u503c\uff0c\u5b83\u7684\u5b9e\u73b0\u9700\u8981\u4f9d\u8d56 closures \u3002 Concepts In this section we compare how particular programming idioms are handled in a functional language with first-class functions ( Haskell ) compared to an imperative language (\u547d\u4ee4\u5f0f\u8bed\u8a00) where functions are second-class citizens ( C ). NOTE: \u672c\u7ae0\u7684\u5185\u5bb9\u662f\u5bf9\u6bd4\u652f\u6301**first-class functions**\u7684\u4e00\u4e9bprogramming idioms\u4e2d\uff0c\u51fd\u6570\u5f0f\u7f16\u7a0b\u8bed\u8a00\u548c**imperative language**(\u547d\u4ee4\u5f0f\u8bed\u8a00) \u7684\u5b9e\u73b0\u7ec6\u8282\u3002 Higher-order functions: passing functions as arguments Further information: Higher-order function In languages where functions are first-class citizens , functions can be passed as arguments to other functions in the same way as other values (a function taking another function as argument is called a higher-order function ). In the language Haskell : map :: ( a -> b ) -> [ a ] -> [ b ] map f [] = [] map f ( x : xs ) = f x : map f xs Languages where functions are not first-class often still allow one to write higher-order functions through the use of features such as function pointers or delegates . In the language C : void map ( int ( * f )( int ), int x [], size_t n ) { for ( int i = 0 ; i < n ; i ++ ) x [ i ] = f ( x [ i ]); } When comparing the two samples, one should note that there are a number of differences between the two approaches that are not directly related to the support of first-class functions . The Haskell sample operates on lists , while the C sample operates on arrays . Both are the most natural compound data structures in the respective languages and making the C sample operate on linked lists would have made it unnecessarily complex. This also accounts for the fact that the C function needs an additional parameter (giving the size of the array.) The C function updates the array in-place , returning no value, whereas in Haskell data structures are persistent (a new list is returned while the old is left intact(\u5b8c\u6574).) The Haskell sample uses recursion to traverse the list, while the C sample uses iteration . Again, this is the most natural way to express this function in both languages, but the Haskell sample could easily have been expressed in terms of a fold and the C sample in terms of recursion. Finally, the Haskell function has a polymorphic type, as this is not supported by C we have fixed all type variables to the type constant int . Anonymous and nested functions Further information: Anonymous function and Nested function In languages supporting anonymous functions , we can pass such a function as an argument to a higher-order function: main = map ( \\ x -> 3 * x + 1 ) [ 1 , 2 , 3 , 4 , 5 ] In a language which does not support anonymous functions, we have to bind it to a name instead: int f ( int x ) { return 3 * x + 1 ; } int main () { int list [] = { 1 , 2 , 3 , 4 , 5 }; map ( f , list , 5 ); } Non-local variables and closures Further information: Non-local variable and Closure (computer science) Once we have anonymous or nested functions , it becomes natural for them to refer to variables outside of their body (called non-local variables ): main = let a = 3 b = 1 in map ( \\ x -> a * x + b ) [ 1 , 2 , 3 , 4 , 5 ] If functions are represented with bare(\u88f8) function pointers(\u88f8\u6307\u9488\uff0c\u8bf4\u660e\u6ca1\u6709\u643a\u5e26\u5916\u5c42\u51fd\u6570\u7684\u4e00\u4e9b\u4fe1\u606f), we can not know anymore how the value that is outside of the function's body should be passed to it, and because of that a closure needs to be built manually(\u624b\u52a8\u5730\u6765\u6784\u9020closure). Therefore we can not speak of \"first-class\" functions here. typedef struct { int ( * f )( int , int , int ); int * a ; int * b ; } closure_t ; void map ( closure_t * closure , int x [], size_t n ) { for ( int i = 0 ; i < n ; ++ i ) x [ i ] = ( * closure -> f )( * closure -> a , * closure -> b , x [ i ]); } int f ( int a , int b , int x ) { return a * x + b ; } void main () { int l [] = { 1 , 2 , 3 , 4 , 5 }; int a = 3 ; int b = 1 ; closure_t closure = { f , & a , & b }; map ( & closure , l , 5 ); } Also note that the map is now specialized to functions referring to two int s outside of their environment. This can be set up more generally, but requires more boilerplate code . If f would have been a nested function we would still have run into the same problem and this is the reason they are not supported in C. Higher-order functions: returning functions as results When returning a function, we are in fact returning its closure (\u8fd4\u56de\u4e00\u4e2a\u51fd\u6570\uff0c\u5347\u7ea7\u4e0a\u662f\u8fd4\u56de\u8be5\u51fd\u6570\u7684closure). In the C example any local variables captured by the closure will go out of scope once we return from the function that builds the closure (\u5f53\u4ece\u6784\u9020closure\u7684\u51fd\u6570\u4e2d\u8fd4\u56de\u65f6\uff0c\u4efb\u4f55\u7531closure\u6355\u83b7\u7684**local variables**\u5c06\u79bb\u5f00\u4ed6\u4eec\u539f\u672c\u6240\u5c5e\u7684scope\uff0c\u5373\u8d85\u51fascope). Forcing the closure at a later point will result in undefined behaviour, possibly corrupting the stack. This is known as the upwards funarg problem . \u603b\u7ed3\uff1aHigher-order functions\u4e0d\u4ec5\u4ec5\u6307\u90a3\u4e9b\u4ee5\u51fd\u6570\u4f5c\u4e3a\u53c2\u6570\u7684\u51fd\u6570\uff0c\u8fd8\u6307\u90a3\u4e9b\u8fd4\u56de\u51fd\u6570\u7684\u51fd\u6570\u3002\u53c2\u89c1 Higher-order function \u3002 Assigning functions to variables Assigning functions to variables and storing them inside (global) datastructures potentially suffers from the same difficulties as returning functions. f :: [[ Integer ] -> [ Integer ]] f = let a = 3 b = 1 in [ map ( \\ x -> a * x + b ), map ( \\ x -> b * x + a )] Equality of functions Further information: Function equality As one can test most literals and values for equality, it is natural to ask whether a programming language can support testing functions for equality. On further inspection, this question appears more difficult and one has to distinguish between several types of function equality:[ 7] Extensional equality Two functions f and g are considered extensionally equal if they agree on their outputs for all inputs (\u2200 x . f ( x ) = g ( x )). Under this definition of equality, for example, any two implementations of a stable sorting algorithm , such as insertion sort and merge sort , would be considered equal. Deciding on extensional equality is undecidable in general and even for functions with finite domains often intractable. For this reason no programming language implements function equality as extensional equality. Intensional equality Under intensional equality, two functions f and g are considered equal if they have the same \"internal structure\". This kind of equality could be implemented in interpreted languages by comparing the source code of the function bodies (such as in Interpreted Lisp 1.5) or the object code in compiled languages . Intensional equality implies extensional equality (under the assumption that the functions do not depend on the value of the program counter .) Reference equality Given the impracticality of implementing extensional and intensional equality, most languages supporting testing functions for equality use reference equality. All functions or closures are assigned a unique identifier (usually the address of the function body or the closure) and equality is decided based on equality of the identifier. Two separately defined, but otherwise identical function definitions will be considered unequal. Referential equality implies intensional and extensional equality. Referential equality breaks referential transparency and is therefore not supported in pure languages, such as Haskell. Type theory Main article: Function type In type theory , the type of functions accepting values of type A and returning values of type B may be written as A \u2192 B or B**A . In the Curry-Howard correspondence , function types are related to logical implication ; lambda abstraction corresponds to discharging hypothetical assumptions and function application corresponds to the modus ponens inference rule. Besides the usual case of programming functions, type theory also uses first-class functions to model associative arrays and similar data structures . In category-theoretical accounts of programming, the availability of first-class functions corresponds to the closed category assumption. For instance, the simply typed lambda calculus corresponds to the internal language of cartesian closed categories . Language support Functional programming languages, such as Scheme , ML , Haskell , F# , and Scala , all have first-class functions . When Lisp , one of the earliest functional languages, was designed, not all aspects of first-class functions were then properly understood, resulting in functions being dynamically scoped . The later Scheme and Common Lisp dialects do have lexically scoped first-class functions. \u603b\u7ed3\uff1a\u5bf9\u4e8e\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u7406\u89e3\u4f9d\u8d56\u4e8e\u7406\u89e3**dynamically scoped**\u548c**lexically scoped**\u3002 Many scripting languages, including Perl , Python , PHP , Lua , Tcl /Tk, JavaScript and Io , have first-class functions . For imperative languages, a distinction has to be made between Algol and its descendants such as Pascal, the traditional C family , and the modern garbage-collected variants. The Algol family has allowed nested functions and higher-order taking function as arguments, but not higher-order functions that return functions as results (except Algol 68, which allows this). The reason for this was that it was not known how to deal with non-local variables if a nested-function was returned as a result (and Algol 68 produces runtime errors in such cases). The C family allowed both passing functions as arguments and returning them as results, but avoided any problems by not supporting nested functions (\u663e\u7136\u4e0d\u652f\u6301**nested functions**\u5c31\u907f\u514d\u4e86**non-local variables**\u95ee\u9898). (The gcc compiler allows them as an extension.) As the usefulness of returning functions primarily lies in the ability to return nested functions that have captured non-local variables , instead of top-level functions, these languages are generally not considered to have first-class functions. Modern imperative languages often support garbage-collection making the implementation of first-class functions feasible. First-class functions have often only been supported in later revisions of the language, including C# 2.0 and Apple's Blocks extension to C, C++ and Objective-C. C++11 has added support for anonymous functions and closures to the language, but because of the non-garbage collected nature of the language, special care has to be taken for non-local variables in functions to be returned as results (see below). C++ C++11 closures can capture non-local variables by reference (without extending their lifetime) by copy construction by move construction (the variable lives as long as the closure does). The former potentially avoids an expensive copy and allows to modify the original variable but is unsafe in case the closure is returned (see dangling references ). The second is safe if the closure is returned but requires a copy and cannot be used to modify the original variable (which might not exist any more at the time the closure is called). The latter is safe if the closure is returned and does not require a copy but cannot be used to modify the original variable either. Python Explicit partial application with functools.partial since version 2.5, and operator.methodcaller since version 2.6.","title":"First-class-function"},{"location":"Theory/Subroutine/First-class-function/#first-class-function","text":"","title":"First class function"},{"location":"Theory/Subroutine/First-class-function/#first-class-function_1","text":"NOTE: \u6211\u662f\u5148\u770b\u5230closure\uff0c\u5728\u6765\u770b\u8fd9\u7bc7\u6587\u7ae0\u7684\uff0c \u73b0\u5728\u770b\u6765\uff0c\u4e24\u8005\u4e4b\u95f4\u7684\u5173\u7cfb\u662f\uff1a\u4e3a\u4e86\u652f\u6301first-class function\uff0c\u624d\u5f15\u5165\u4e86closure\u3002 In computer science , a programming language is said to have first-class functions if it treats functions as first-class citizens . This means the language supports: passing functions as arguments to other functions returning functions as the values from other functions, assigning function to variables or storing them in data structures.[ 1] Some programming language theorists require support for anonymous functions (function literals) as well. In languages with first-class functions , the names of functions do not have any special status; they are treated like ordinary variables with a function type . The term was coined by Christopher Strachey in the context of \"functions as first-class citizens\" in the mid-1960s. NOTE\uff1a\u5bf9\u4e8epython\u8fd9\u79cd\u7c7b\u578b\u7684\u8bed\u8a00\u6765\u8bf4\uff0c\u4e00\u5207\u7686\u5bf9\u8c61\uff0c\u6240\u4ee5\u5728python\u4e2d\uff0c\u51fd\u6570\u4e5f\u662f\u5bf9\u8c61\uff0c\u6240\u4ee5\u5b83\u5bf9first-class function\u652f\u6301\u7684\u5b9e\u73b0\u5e94\u8be5\u662f\u76f8\u5bf9\u5bb9\u6613\u7684\u3002\u5bf9\u6bd4\u6765\u770b\uff0c\u5728c++\u4e2d\uff0c\u5e76\u6ca1\u6709function type\uff0c\u90a3\u4e48c++\u662f\u5982\u4f55\u5b9e\u73b0\u7684\u5462\uff1f First-class functions are a necessity for the functional programming style, in which the use of higher-order functions is a standard practice. A simple example of a higher-ordered function is the map function, which takes, as its arguments, a function and a list , and returns the list formed by applying the function to each member of the list. For a language to support map , it must support passing a function as an argument. NOTE\uff1amap\u662f\u4e00\u4e2a higher-ordered function \uff0c\u5b83\u672c\u8eab\u662f\u4e00\u4e2a\u51fd\u6570\uff0c\u5b83\u4ee5\u53e6\u5916\u4e00\u4e2a\u51fd\u6570\u4f5c\u4e3a\u53c2\u6570\u3002 There are certain implementation difficulties in passing functions as arguments or returning them as results, especially in the presence of non-local variables introduced in nested and anonymous functions . Historically, these were termed the funarg problems , the name coming from \"function argument\".[ 5] In early imperative languages (\u547d\u4ee4\u5f0f\u8bed\u8a00) these problems were avoided by either not supporting functions as result types (e.g. ALGOL 60 , Pascal ) or omitting(\u7701\u7565) nested functions and thus non-local variables (e.g. C ). The early functional language Lisp took the approach of dynamic scoping , where non-local variables refer to the closest definition of that variable at the point where the function is executed, instead of where it was defined. Proper support for lexically scoped first-class functions was introduced in Scheme and requires handling references to functions as closures instead of bare function pointers ,[ 4] which in turn makes garbage collection a necessity. NOTE: \u8fd9\u6bb5\u8bdd\u4e2d\u63d0\u53ca\u5230\u4e86 dynamic scoping \u548c lexically scoped \uff0c\u7ed3\u5408\u4e0b\u9762\u7684\u5185\u5bb9\u53ef\u77e5\uff0c lexically scoped \u5bf9\u5b9e\u73b0first-class function\u66f4\u6709\u4ef7\u503c\uff0c\u5b83\u7684\u5b9e\u73b0\u9700\u8981\u4f9d\u8d56 closures \u3002","title":"\u7ef4\u57fa\u767e\u79d1First-class function"},{"location":"Theory/Subroutine/First-class-function/#concepts","text":"In this section we compare how particular programming idioms are handled in a functional language with first-class functions ( Haskell ) compared to an imperative language (\u547d\u4ee4\u5f0f\u8bed\u8a00) where functions are second-class citizens ( C ). NOTE: \u672c\u7ae0\u7684\u5185\u5bb9\u662f\u5bf9\u6bd4\u652f\u6301**first-class functions**\u7684\u4e00\u4e9bprogramming idioms\u4e2d\uff0c\u51fd\u6570\u5f0f\u7f16\u7a0b\u8bed\u8a00\u548c**imperative language**(\u547d\u4ee4\u5f0f\u8bed\u8a00) \u7684\u5b9e\u73b0\u7ec6\u8282\u3002","title":"Concepts"},{"location":"Theory/Subroutine/First-class-function/#higher-order-functions-passing-functions-as-arguments","text":"Further information: Higher-order function In languages where functions are first-class citizens , functions can be passed as arguments to other functions in the same way as other values (a function taking another function as argument is called a higher-order function ). In the language Haskell : map :: ( a -> b ) -> [ a ] -> [ b ] map f [] = [] map f ( x : xs ) = f x : map f xs Languages where functions are not first-class often still allow one to write higher-order functions through the use of features such as function pointers or delegates . In the language C : void map ( int ( * f )( int ), int x [], size_t n ) { for ( int i = 0 ; i < n ; i ++ ) x [ i ] = f ( x [ i ]); } When comparing the two samples, one should note that there are a number of differences between the two approaches that are not directly related to the support of first-class functions . The Haskell sample operates on lists , while the C sample operates on arrays . Both are the most natural compound data structures in the respective languages and making the C sample operate on linked lists would have made it unnecessarily complex. This also accounts for the fact that the C function needs an additional parameter (giving the size of the array.) The C function updates the array in-place , returning no value, whereas in Haskell data structures are persistent (a new list is returned while the old is left intact(\u5b8c\u6574).) The Haskell sample uses recursion to traverse the list, while the C sample uses iteration . Again, this is the most natural way to express this function in both languages, but the Haskell sample could easily have been expressed in terms of a fold and the C sample in terms of recursion. Finally, the Haskell function has a polymorphic type, as this is not supported by C we have fixed all type variables to the type constant int .","title":"Higher-order functions: passing functions as arguments"},{"location":"Theory/Subroutine/First-class-function/#anonymous-and-nested-functions","text":"Further information: Anonymous function and Nested function In languages supporting anonymous functions , we can pass such a function as an argument to a higher-order function: main = map ( \\ x -> 3 * x + 1 ) [ 1 , 2 , 3 , 4 , 5 ] In a language which does not support anonymous functions, we have to bind it to a name instead: int f ( int x ) { return 3 * x + 1 ; } int main () { int list [] = { 1 , 2 , 3 , 4 , 5 }; map ( f , list , 5 ); }","title":"Anonymous and nested functions"},{"location":"Theory/Subroutine/First-class-function/#non-local-variables-and-closures","text":"Further information: Non-local variable and Closure (computer science) Once we have anonymous or nested functions , it becomes natural for them to refer to variables outside of their body (called non-local variables ): main = let a = 3 b = 1 in map ( \\ x -> a * x + b ) [ 1 , 2 , 3 , 4 , 5 ] If functions are represented with bare(\u88f8) function pointers(\u88f8\u6307\u9488\uff0c\u8bf4\u660e\u6ca1\u6709\u643a\u5e26\u5916\u5c42\u51fd\u6570\u7684\u4e00\u4e9b\u4fe1\u606f), we can not know anymore how the value that is outside of the function's body should be passed to it, and because of that a closure needs to be built manually(\u624b\u52a8\u5730\u6765\u6784\u9020closure). Therefore we can not speak of \"first-class\" functions here. typedef struct { int ( * f )( int , int , int ); int * a ; int * b ; } closure_t ; void map ( closure_t * closure , int x [], size_t n ) { for ( int i = 0 ; i < n ; ++ i ) x [ i ] = ( * closure -> f )( * closure -> a , * closure -> b , x [ i ]); } int f ( int a , int b , int x ) { return a * x + b ; } void main () { int l [] = { 1 , 2 , 3 , 4 , 5 }; int a = 3 ; int b = 1 ; closure_t closure = { f , & a , & b }; map ( & closure , l , 5 ); } Also note that the map is now specialized to functions referring to two int s outside of their environment. This can be set up more generally, but requires more boilerplate code . If f would have been a nested function we would still have run into the same problem and this is the reason they are not supported in C.","title":"Non-local variables and closures"},{"location":"Theory/Subroutine/First-class-function/#higher-order-functions-returning-functions-as-results","text":"When returning a function, we are in fact returning its closure (\u8fd4\u56de\u4e00\u4e2a\u51fd\u6570\uff0c\u5347\u7ea7\u4e0a\u662f\u8fd4\u56de\u8be5\u51fd\u6570\u7684closure). In the C example any local variables captured by the closure will go out of scope once we return from the function that builds the closure (\u5f53\u4ece\u6784\u9020closure\u7684\u51fd\u6570\u4e2d\u8fd4\u56de\u65f6\uff0c\u4efb\u4f55\u7531closure\u6355\u83b7\u7684**local variables**\u5c06\u79bb\u5f00\u4ed6\u4eec\u539f\u672c\u6240\u5c5e\u7684scope\uff0c\u5373\u8d85\u51fascope). Forcing the closure at a later point will result in undefined behaviour, possibly corrupting the stack. This is known as the upwards funarg problem . \u603b\u7ed3\uff1aHigher-order functions\u4e0d\u4ec5\u4ec5\u6307\u90a3\u4e9b\u4ee5\u51fd\u6570\u4f5c\u4e3a\u53c2\u6570\u7684\u51fd\u6570\uff0c\u8fd8\u6307\u90a3\u4e9b\u8fd4\u56de\u51fd\u6570\u7684\u51fd\u6570\u3002\u53c2\u89c1 Higher-order function \u3002","title":"Higher-order functions: returning functions as results"},{"location":"Theory/Subroutine/First-class-function/#assigning-functions-to-variables","text":"Assigning functions to variables and storing them inside (global) datastructures potentially suffers from the same difficulties as returning functions. f :: [[ Integer ] -> [ Integer ]] f = let a = 3 b = 1 in [ map ( \\ x -> a * x + b ), map ( \\ x -> b * x + a )]","title":"Assigning functions to variables"},{"location":"Theory/Subroutine/First-class-function/#equality-of-functions","text":"Further information: Function equality As one can test most literals and values for equality, it is natural to ask whether a programming language can support testing functions for equality. On further inspection, this question appears more difficult and one has to distinguish between several types of function equality:[ 7] Extensional equality Two functions f and g are considered extensionally equal if they agree on their outputs for all inputs (\u2200 x . f ( x ) = g ( x )). Under this definition of equality, for example, any two implementations of a stable sorting algorithm , such as insertion sort and merge sort , would be considered equal. Deciding on extensional equality is undecidable in general and even for functions with finite domains often intractable. For this reason no programming language implements function equality as extensional equality. Intensional equality Under intensional equality, two functions f and g are considered equal if they have the same \"internal structure\". This kind of equality could be implemented in interpreted languages by comparing the source code of the function bodies (such as in Interpreted Lisp 1.5) or the object code in compiled languages . Intensional equality implies extensional equality (under the assumption that the functions do not depend on the value of the program counter .) Reference equality Given the impracticality of implementing extensional and intensional equality, most languages supporting testing functions for equality use reference equality. All functions or closures are assigned a unique identifier (usually the address of the function body or the closure) and equality is decided based on equality of the identifier. Two separately defined, but otherwise identical function definitions will be considered unequal. Referential equality implies intensional and extensional equality. Referential equality breaks referential transparency and is therefore not supported in pure languages, such as Haskell.","title":"Equality of functions"},{"location":"Theory/Subroutine/First-class-function/#type-theory","text":"Main article: Function type In type theory , the type of functions accepting values of type A and returning values of type B may be written as A \u2192 B or B**A . In the Curry-Howard correspondence , function types are related to logical implication ; lambda abstraction corresponds to discharging hypothetical assumptions and function application corresponds to the modus ponens inference rule. Besides the usual case of programming functions, type theory also uses first-class functions to model associative arrays and similar data structures . In category-theoretical accounts of programming, the availability of first-class functions corresponds to the closed category assumption. For instance, the simply typed lambda calculus corresponds to the internal language of cartesian closed categories .","title":"Type theory"},{"location":"Theory/Subroutine/First-class-function/#language-support","text":"Functional programming languages, such as Scheme , ML , Haskell , F# , and Scala , all have first-class functions . When Lisp , one of the earliest functional languages, was designed, not all aspects of first-class functions were then properly understood, resulting in functions being dynamically scoped . The later Scheme and Common Lisp dialects do have lexically scoped first-class functions. \u603b\u7ed3\uff1a\u5bf9\u4e8e\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u7406\u89e3\u4f9d\u8d56\u4e8e\u7406\u89e3**dynamically scoped**\u548c**lexically scoped**\u3002 Many scripting languages, including Perl , Python , PHP , Lua , Tcl /Tk, JavaScript and Io , have first-class functions . For imperative languages, a distinction has to be made between Algol and its descendants such as Pascal, the traditional C family , and the modern garbage-collected variants. The Algol family has allowed nested functions and higher-order taking function as arguments, but not higher-order functions that return functions as results (except Algol 68, which allows this). The reason for this was that it was not known how to deal with non-local variables if a nested-function was returned as a result (and Algol 68 produces runtime errors in such cases). The C family allowed both passing functions as arguments and returning them as results, but avoided any problems by not supporting nested functions (\u663e\u7136\u4e0d\u652f\u6301**nested functions**\u5c31\u907f\u514d\u4e86**non-local variables**\u95ee\u9898). (The gcc compiler allows them as an extension.) As the usefulness of returning functions primarily lies in the ability to return nested functions that have captured non-local variables , instead of top-level functions, these languages are generally not considered to have first-class functions. Modern imperative languages often support garbage-collection making the implementation of first-class functions feasible. First-class functions have often only been supported in later revisions of the language, including C# 2.0 and Apple's Blocks extension to C, C++ and Objective-C. C++11 has added support for anonymous functions and closures to the language, but because of the non-garbage collected nature of the language, special care has to be taken for non-local variables in functions to be returned as results (see below).","title":"Language support"},{"location":"Theory/Subroutine/First-class-function/#c","text":"C++11 closures can capture non-local variables by reference (without extending their lifetime) by copy construction by move construction (the variable lives as long as the closure does). The former potentially avoids an expensive copy and allows to modify the original variable but is unsafe in case the closure is returned (see dangling references ). The second is safe if the closure is returned but requires a copy and cannot be used to modify the original variable (which might not exist any more at the time the closure is called). The latter is safe if the closure is returned and does not require a copy but cannot be used to modify the original variable either.","title":"C++"},{"location":"Theory/Subroutine/First-class-function/#python","text":"Explicit partial application with functools.partial since version 2.5, and operator.methodcaller since version 2.6.","title":"Python"},{"location":"Theory/Subroutine/Function-object/","text":"Function object \u7ef4\u57fa\u767e\u79d1 Function object","title":"Function-object"},{"location":"Theory/Subroutine/Function-object/#function-object","text":"","title":"Function object"},{"location":"Theory/Subroutine/Function-object/#function-object_1","text":"","title":"\u7ef4\u57fa\u767e\u79d1Function object"},{"location":"Theory/Subroutine/Variadic-function/","text":"Variadic function \"variadic function\"\u5373\u53d8\u53c2\u51fd\u6570\uff0c\u8fd9\u662f\u73b0\u4ee3programming language\u666e\u904d\u652f\u6301\u7684\u4e00\u79cdfeature\uff0c\u672c\u6587\u5bf9\u5b83\u8fdb\u884c\u63cf\u8ff0\u3002 \u7ef4\u57fa\u767e\u79d1 Variadic function","title":"Variadic-function"},{"location":"Theory/Subroutine/Variadic-function/#variadic-function","text":"\"variadic function\"\u5373\u53d8\u53c2\u51fd\u6570\uff0c\u8fd9\u662f\u73b0\u4ee3programming language\u666e\u904d\u652f\u6301\u7684\u4e00\u79cdfeature\uff0c\u672c\u6587\u5bf9\u5b83\u8fdb\u884c\u63cf\u8ff0\u3002","title":"Variadic function"},{"location":"Theory/Subroutine/Variadic-function/#variadic-function_1","text":"","title":"\u7ef4\u57fa\u767e\u79d1Variadic function"},{"location":"Theory/Syntax/","text":"\u5173\u4e8e\u672c\u7ae0 \u5173\u4e8esyntax\u7684\u5185\u5bb9\uff0c\u53c2\u89c1\u5de5\u7a0b compiler-principle \u3002","title":"Introduction"},{"location":"Theory/Syntax/#_1","text":"\u5173\u4e8esyntax\u7684\u5185\u5bb9\uff0c\u53c2\u89c1\u5de5\u7a0b compiler-principle \u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Theory/Type-system/Class-and-type/","text":"Class and type OOP\u7684unit\u662fobject\uff0c\u800c\u4e0d\u662fclass\u3002OOP\u6709\u4e24\u4e2a\u6d41\u6d3e\uff0cclass-based\u548cprototype-based\u3002 class\u76f8\u5f53\u4e8e\u4e00\u79cd\u7c7b\u578b\uff0ctype system\u4e2d\u7684\u6982\u5ff5\u57fa\u672c\u4e0a\u90fd\u80fd\u591f\u5e94\u7528\u4e8eclass\u3002","title":"Class-and-type"},{"location":"Theory/Type-system/Class-and-type/#class-and-type","text":"OOP\u7684unit\u662fobject\uff0c\u800c\u4e0d\u662fclass\u3002OOP\u6709\u4e24\u4e2a\u6d41\u6d3e\uff0cclass-based\u548cprototype-based\u3002 class\u76f8\u5f53\u4e8e\u4e00\u79cd\u7c7b\u578b\uff0ctype system\u4e2d\u7684\u6982\u5ff5\u57fa\u672c\u4e0a\u90fd\u80fd\u591f\u5e94\u7528\u4e8eclass\u3002","title":"Class and type"},{"location":"Theory/Type-system/Static-vs-dynamic-typing/","text":"Static vs. dynamic typing of programming languages Updated 2010-10-20 \u2014 added a bit more information about Boo\u2019s type inferencing. Updated 2012-04-08 \u2014 This post is an appendix to a post comparing Java and Python. Some comments on this post are actually comments on that other post. There is widespread confusion or disagreement about the meanings of the words static, dynamic, strong and weak when used to describe the type systems of programming languages. Here is a description of the way (or at least one of the ways) these terms are most commonly used. | | | | ------------------------------------------------------------ | ------------------------------------------------------------ | | In a statically typed language , every variable name is bound both to a type (at compile time , by means of a data declaration ) to an object .The binding to an object is optional \u2014 if a name is not bound to an object, the name is said to be null.*Once a variable name has been bound to a type (that is, declared) it can be bound (via an assignment statement) only to objects of that type; it cannot ever be bound to an object of a different type. An attempt to bind the name to an object of the wrong type will raise a type exception. | In a **dynamically typed language* , every variable name is (unless it is null) bound only to an object.Names are bound to objects at execution time by means of assignment statements, and it is possible to bind a name to objects of different types during the execution of the program. | | | | Here is an example. In a statically-typed language, the following sequence of statements (which binds an integer object, then a string object, to the name employeeName ) is illegal. If employeeName had been declared to be an int , then the second statement would be illegal; if it had been declared to be a String , then the first statement would be illegal. But in a dynamically-typed language this sequence of statements is perfectly fine. `employeeName = 9 employeeName = \"Steve Ferg\"` Python is a dynamically-typed language . Java is a statically-typed language . [Is it possible to have a dynamically typed language without duck typing? closed] static vs dynamic vs strong vs weak vs duck typing THINKING : string type\u548cduck type\u662f\u5426\u51b2\u7a81\uff1f https://devopedia.org/duck-typing","title":"Static-vs-dynamic-typing"},{"location":"Theory/Type-system/Static-vs-dynamic-typing/#static-vs-dynamic-typing-of-programming-languages","text":"Updated 2010-10-20 \u2014 added a bit more information about Boo\u2019s type inferencing. Updated 2012-04-08 \u2014 This post is an appendix to a post comparing Java and Python. Some comments on this post are actually comments on that other post. There is widespread confusion or disagreement about the meanings of the words static, dynamic, strong and weak when used to describe the type systems of programming languages. Here is a description of the way (or at least one of the ways) these terms are most commonly used. | | | | ------------------------------------------------------------ | ------------------------------------------------------------ | | In a statically typed language , every variable name is bound both to a type (at compile time , by means of a data declaration ) to an object .The binding to an object is optional \u2014 if a name is not bound to an object, the name is said to be null.*Once a variable name has been bound to a type (that is, declared) it can be bound (via an assignment statement) only to objects of that type; it cannot ever be bound to an object of a different type. An attempt to bind the name to an object of the wrong type will raise a type exception. | In a **dynamically typed language* , every variable name is (unless it is null) bound only to an object.Names are bound to objects at execution time by means of assignment statements, and it is possible to bind a name to objects of different types during the execution of the program. | | | | Here is an example. In a statically-typed language, the following sequence of statements (which binds an integer object, then a string object, to the name employeeName ) is illegal. If employeeName had been declared to be an int , then the second statement would be illegal; if it had been declared to be a String , then the first statement would be illegal. But in a dynamically-typed language this sequence of statements is perfectly fine. `employeeName = 9 employeeName = \"Steve Ferg\"` Python is a dynamically-typed language . Java is a statically-typed language .","title":"Static vs. dynamic typing of programming languages"},{"location":"Theory/Type-system/Static-vs-dynamic-typing/#is-it-possible-to-have-a-dynamically-typed-language-without-duck-typing-closed93","text":"","title":"[Is it possible to have a dynamically typed language without duck typing? closed]"},{"location":"Theory/Type-system/Static-vs-dynamic-typing/#static-vs-dynamic-vs-strong-vs-weak-vs-duck-typing","text":"THINKING : string type\u548cduck type\u662f\u5426\u51b2\u7a81\uff1f https://devopedia.org/duck-typing","title":"static vs dynamic vs strong vs weak vs duck typing"},{"location":"Theory/Type-system/Subtyping/","text":"","title":"Subtyping"},{"location":"Theory/Type-system/Type-safety/","text":"Type safety Type safety In computer science , type safety is the extent to which a programming language discourages or prevents type errors . A type error is erroneous or undesirable program behaviour caused by a discrepancy\uff08\u4e0d\u76f8\u7b26\uff09 between differing data types for the program's constants, variables, and methods (functions), e.g., treating an integer ( int ) as a floating-point number ( float ). Type safety is sometimes alternatively considered to be a property of a computer program rather than the language in which that program is written; that is, some languages have type-safe facilities that can be circumvented\uff08\u7ed5\u5f00\uff09by programmers who adopt practices that exhibit poor type safety. The formal type-theoretic definition of type safety is considerably stronger than what is understood by most programmers. Type enforcement can be static, catching potential errors at compile time , or dynamic, associating type information with values at run-time and consulting them as needed to detect imminent\uff08\u5373\u5c06\u5230\u6765\u7684\uff09 errors, or a combination of both. The behaviors classified as type errors by a given programming language are usually those that result from attempts to perform operations on values that are not of the appropriate data type . This classification is partly based on opinion; it may imply that any operation not leading to program crashes, security flaws or other obvious failures is legitimate and need not be considered an error, or it may imply that any contravention of the programmer's explicit intent (as communicated via typing annotations) to be erroneous and not \"type-safe\". In the context of static (compile-time) type systems , type safety usually involves (among other things) a guarantee that the eventual value of any expression will be a legitimate member of that expression's static type . The precise requirement is more subtle than this \u2014 see, for example, subtype and polymorphism for complications. SUMMARY : type of expression\uff1b Type safety is closely linked to memory safety , a restriction on the ability to copy arbitrary bit patterns from one memory location to another. For instance, in an implementation of a language that has some type {\\displaystyle t} , such that some sequence of bits (of the appropriate length) does not represent a legitimate member of {\\displaystyle t} , if that language allows data to be copied into a variable of type {\\displaystyle t} , then it is not type-safe because such an operation might assign a non-{\\displaystyle t} value to that variable. Conversely, if the language is type-unsafe to the extent of allowing an arbitrary integer to be used as a pointer , then it is not memory-safe. SUMMARY : type safe\u662fmemory safe\u7684\u4e00\u4e2a\u5145\u5206\u6761\u4ef6\uff1b Most statically typed languages provide a degree of type safety that is strictly stronger than memory safety , because their type systems enforce the proper use of abstract data types defined by programmers even when this is not strictly necessary for memory safety or for the prevention of any kind of catastrophic failure.","title":"Type-safety"},{"location":"Theory/Type-system/Type-safety/#type-safety","text":"In computer science , type safety is the extent to which a programming language discourages or prevents type errors . A type error is erroneous or undesirable program behaviour caused by a discrepancy\uff08\u4e0d\u76f8\u7b26\uff09 between differing data types for the program's constants, variables, and methods (functions), e.g., treating an integer ( int ) as a floating-point number ( float ). Type safety is sometimes alternatively considered to be a property of a computer program rather than the language in which that program is written; that is, some languages have type-safe facilities that can be circumvented\uff08\u7ed5\u5f00\uff09by programmers who adopt practices that exhibit poor type safety. The formal type-theoretic definition of type safety is considerably stronger than what is understood by most programmers. Type enforcement can be static, catching potential errors at compile time , or dynamic, associating type information with values at run-time and consulting them as needed to detect imminent\uff08\u5373\u5c06\u5230\u6765\u7684\uff09 errors, or a combination of both. The behaviors classified as type errors by a given programming language are usually those that result from attempts to perform operations on values that are not of the appropriate data type . This classification is partly based on opinion; it may imply that any operation not leading to program crashes, security flaws or other obvious failures is legitimate and need not be considered an error, or it may imply that any contravention of the programmer's explicit intent (as communicated via typing annotations) to be erroneous and not \"type-safe\". In the context of static (compile-time) type systems , type safety usually involves (among other things) a guarantee that the eventual value of any expression will be a legitimate member of that expression's static type . The precise requirement is more subtle than this \u2014 see, for example, subtype and polymorphism for complications. SUMMARY : type of expression\uff1b Type safety is closely linked to memory safety , a restriction on the ability to copy arbitrary bit patterns from one memory location to another. For instance, in an implementation of a language that has some type {\\displaystyle t} , such that some sequence of bits (of the appropriate length) does not represent a legitimate member of {\\displaystyle t} , if that language allows data to be copied into a variable of type {\\displaystyle t} , then it is not type-safe because such an operation might assign a non-{\\displaystyle t} value to that variable. Conversely, if the language is type-unsafe to the extent of allowing an arbitrary integer to be used as a pointer , then it is not memory-safe. SUMMARY : type safe\u662fmemory safe\u7684\u4e00\u4e2a\u5145\u5206\u6761\u4ef6\uff1b Most statically typed languages provide a degree of type safety that is strictly stronger than memory safety , because their type systems enforce the proper use of abstract data types defined by programmers even when this is not strictly necessary for memory safety or for the prevention of any kind of catastrophic failure.","title":"Type safety"},{"location":"Theory/Type-system/Type-system/","text":"Type system \u5728\u7f16\u7a0b\u8fc7\u7a0b\u4e2d\uff0c\u5c11\u4e0d\u4e86\u8ddf**\u7c7b\u578b**\u6253\u4ea4\u9053\uff1a\u6211\u4eec\u4f1a\u521b\u5efa\u4e00\u4e2a\u7c7b\u578b\uff08\u5982\u5b9a\u4e49\u4e00\u4e2a\u7c7b\uff09\uff0c\u6211\u4eec\u4f1a\u5bf9\u4e0d\u540c\u7c7b\u578b\u7684\u6570\u636e\u8fdb\u884c\u8fd0\u7b97\uff0c\u7b49\u7b49\u3002\u5982\u679c\u5bf9\u6570\u636e\u7684\u7c7b\u578b\u8ba4\u8bc6\u4e0d\u591f\uff0c\u5219\u4f1a\u5bfc\u81f4 \u7c7b\u578b\u9519\u8bef \u8fd9\u79cd\u5e38\u89c1\u7684\u7f16\u7a0b\u9519\u8bef\u3002\u6240\u4ee5\u5bf9**\u7f16\u7a0b\u8bed\u8a00**\u7684**\u7c7b\u578b\u7cfb\u7edf**\u6709\u4e00\u4e2a\u5b8c\u6574\u6df1\u523b\u7684\u8ba4\u77e5\u975e\u5e38\u91cd\u8981\u3002\u6211\u5728\u7f16\u7a0b\u8fc7\u7a0b\u4e2d\u4e5f\u66fe\u9677\u5165\u6df7\u6dc6\u3001\u8bef\u7528\u7c7b\u578b\u7684\u6df1\u6e0a\uff0c\u4e3a\u6b64\u641c\u5bfb\u5bf9**\u7f16\u7a0b\u8bed\u8a00**\u7684**\u7c7b\u578b\u7cfb\u7edf**\u6709\u5b8c\u6574\u4ecb\u7ecd\u7684\u6587\u7ae0\uff0c\u4e0b\u9762\u8fd9\u7bc7\u6587\u7ae0\u6211\u89c9\u5f97\u975e\u5e38\u597d\uff0c\u6e90\u81ea\u7ef4\u57fa\u767e\u79d1\uff0c\u539f\u6587\u662f\u5168\u82f1\u7684\uff0c\u6211\u81ea\u5df1\u5728\u9605\u8bfb\u8fc7\u7a0b\u4e2d\u6dfb\u52a0\u4e86\u4e00\u4e9b\u6ce8\u91ca\u548c\u7ffb\u8bd1\u3002 \u7ef4\u57fa\u767e\u79d1 Type system This article is about type systems from the point-of-view of computer programming. For a theoretical formulation(\u9610\u8ff0), see type theory . In programming languages , a type system is a set of rules that assigns a property called type to the various constructs(\u7ec4\u6210\u90e8\u5206) of a computer program , such as variables , expressions , functions or modules (\u5c06\u7c7b\u578b\u4f5c\u4e3a\u4e00\u4e2a\u5c5e\u6027).[ 1] These types formalize and enforce the otherwise implicit categories the programmer uses for data structures and components (e.g. \"string\", \"array of float\", \"function returning boolean\")(\u8fd9\u6bb5\u8bdd\u4e2d\u201cthe programmer uses for data structures and components \u201d\u662f\u5b9a\u8bed\uff0c\u4fee\u9970categories\uff0c\u5b57\u9762\u610f\u601d\u662f\uff1a\u7c7b\u578b\u5f62\u5f0f\u5316\u5e76\u5f3a\u5236\u6267\u884c\u7a0b\u5e8f\u5458\u7528\u4e8e\u6570\u636e\u7ed3\u6784\u548c\u7ec4\u4ef6\u7684\u9690\u5f0f\u7c7b\u522b\u3002\u5404\u79cd\u7f16\u7a0b\u8bed\u8a00\u4e2d\u90fd\u4f1a\u63d0\u4f9b\u57fa\u672c\u7c7b\u578b\uff0c\u5982int\uff0cfloat\u7b49\uff0c\u4e5f\u4f1a\u63d0\u4f9b\u4e00\u4e9b\u590d\u5408\u7c7b\u578b\uff0c\u5982\u5bb9\u5668string\u7b49\u3002\u663e\u7136\u8fd9\u4e9b\u590d\u5408\u7c7b\u578b\u7684\u5b9a\u4e49\u662f\u79bb\u4e0d\u5f00\u57fa\u672c\u7c7b\u578b\u7684\u3002). The main purpose of a type system is to reduce possibilities for bugs in computer programs[ 2] by defining interfaces between different parts of a computer program, and then checking that the parts have been connected in a consistent way. This checking can happen statically (at compile time ), dynamically (at run time ), or as a combination of static and dynamic checking. Type systems have other purposes as well, such as expressing business rules(\u8868\u8fbe\u4e1a\u52a1\u89c4\u5219), enabling certain compiler optimizations, allowing for multiple dispatch (\u5141\u8bb8\u591a\u7ea7\u8c03\u7528), providing a form of documentation, etc. A type system associates a type with each computed value and, by examining the flow of these values, attempts to ensure or prove that no type errors can occur. The given type system in question determines exactly what constitutes(\u6784\u6210) a type error, but in general the aim is to prevent operations expecting a certain kind of value from being used with values for which that operation does not make sense ( logic errors ). Type systems are often specified as part of programming languages , and built into the interpreters and compilers for them; although the type system of a language can be extended by optional tools that perform added kinds of checks using the language's original type syntax and grammar. \u603b\u7ed3\uff1a\u524d\u9762\u8fd9\u6bb5\u6587\u5b57\u4e3b\u8981\u9610\u8ff0\u4e86\u8fd9\u4e9b\u5185\u5bb9\uff1a \u4ec0\u4e48\u662f\u7c7b\u578b \u7f16\u7a0b\u8bed\u8a00\u4e2d\u4e3a\u4ec0\u4e48\u8981\u4f7f\u7528\u7c7b\u578b\u5373\u4f7f\u7528\u7c7b\u578b\u80fd\u591f\u4e3a\u7f16\u7a0b\u8bed\u8a00\u5e26\u6765\u4ec0\u4e48\u597d\u5904 \u7c7b\u578b\u7cfb\u7edf\u7684\u7ec4\u6210 Q&A : \u8fd0\u884c\u65f6\u7c7b\u578b\u68c0\u67e5\u662f\u4ec0\u4e48\uff1f\u662f\u548c\u591a\u6001\u6709\u5173\u7684\u5417\uff1f Usage overview An example of a simple type system is that of the C language . The portions(\u7ec4\u6210\u90e8\u5206) of a C program are the function definitions. One function is invoked by another function. The interface of a function states the name of the function and a list of values that are passed to the function's code. The code of an invoking function states the name of the invoked, along with the names of variables that hold values to pass to it. During execution, the values are placed into temporary storage , then execution jumps to the code of the invoked function. The invoked function's code accesses the values and makes use of them. If the instructions inside the function are written with the assumption of receiving an integer value, but the calling code passed a floating-point value, then the wrong result will be computed by the invoked function. The C compiler checks the type declared for each variable sent, against the type declared for each variable in the interface of the invoked function(C\u7f16\u8bd1\u5668\u4f1a\u68c0\u67e5\u51fd\u6570\u5f62\u53c2\u7684\u7c7b\u578b\uff0c\u4ee5\u53ca\u8c03\u7528\u51fd\u6570\u65f6\u5019\u4f20\u5165\u7684\u5b9e\u53c2\u7684\u7c7b\u578b). If the types do not match, the compiler throws a compile-time error(\u5982\u679c\u7c7b\u578b\u4e0d\u5339\u914d\uff0c\u5219\u7f16\u8bd1\u5668\u5728\u7f16\u8bd1\u9636\u6bb5\u5c31\u4f1a\u629b\u51fa\u4e00\u4e2a\u7f16\u8bd1\u9519\u8bef). \u603b\u7ed3\uff1a\u8fd9\u6bb5\u8bdd\u4ee5C\u7f16\u8bd1\u5668\u7684**\u9759\u6001\u7c7b\u578b\u68c0\u67e5**\u4e3a\u4f8b\u6765\u8bf4\u660e\u7c7b\u578b\u7684\u4e00\u4e2a\u4f5c\u7528 A compiler may also use the static type of a value to optimize the storage it needs and the choice of algorithms for operations on the value. In many C compilers the float data type , for example, is represented in 32 bits , in accord with(\u4e0e\u4ec0\u4e48\u4e00\u81f4) the IEEE specification for single-precision floating point numbers . They will thus use floating-point-specific microprocessor operations on those values (floating-point addition, multiplication, etc.)(\u5b83\u4eec\u5c06\u5bf9\u8fd9\u4e9b\u503c\u4f7f\u7528\u6d6e\u70b9\u7279\u5b9a\u7684\u5fae\u5904\u7406\u5668\u64cd\u4f5c\uff08\u6d6e\u70b9\u52a0\u6cd5\uff0c\u4e58\u6cd5\u7b49\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u4f18\u5316). \u603b\u7ed3\uff1a\u8fd9\u6bb5\u80e1\u4ee5float\u7c7b\u578b\u7684\u6570\u636e\u4e3a\u4f8b\u6765\u8bf4\u660e\uff1a\u7f16\u8bd1\u5668\u5728\u6c47\u7f16\u9636\u6bb5\u53ef\u4ee5\u6839\u636evalue\u7684static type\u6765\u4f18\u5316\u5bf9\u8be5value\u7684\u5b58\u50a8\u4ee5\u53ca\u9009\u62e9\u5904\u7406\u8be5value\u7684\u6307\u4ee4\u3002 The depth of type constraints(\u7c7b\u578b\u9650\u5236) and the manner of their evaluation(\u7c7b\u578b\u63a8\u65ad) affect the typing of the language. A programming language may further associate an operation with various resolutions for each type, in the case of type polymorphism (\u5728\u7c7b\u578b\u591a\u6001\u6027\u7684\u60c5\u51b5\u4e0b\uff0c\u7f16\u7a0b\u8bed\u8a00\u53ef\u4ee5\u8fdb\u4e00\u6b65\u5c06\u64cd\u4f5c\u4e0e\u6bcf\u79cd\u7c7b\u578b\u7684\u5404\u79cd\u5206\u8fa8\u7387\u76f8\u5173\u8054\u3002\u6b64\u5904\u5c06resolutions\u7ffb\u8bd1\u4e3a\u5206\u8fa8\u7387\uff0c\u611f\u89c9\u662f\u4e0d\u5bf9\u7684). Type theory is the study of type systems. The concrete types of some programming languages, such as integers and strings, depend on practical issues of computer architecture, compiler implementation, and language design. Fundamentals Formally, type theory studies type systems. A programming language must have occurrence to type check using the type system whether at compile time or runtime, manually annotated or automatically inferred. \u603b\u7ed3\uff1a\u65e0\u8bba\u662f\u5728\u7f16\u8bd1\u65f6\u8fd8\u662f\u5728\u8fd0\u884c\u65f6\uff0c\u624b\u52a8\u6ce8\u91ca\u6216\u81ea\u52a8\u63a8\u65ad\uff0c\u7f16\u7a0b\u8bed\u8a00\u90fd\u5fc5\u987b\u4f7f\u7528\u7c7b\u578b\u7cfb\u7edf\u8fdb\u884c\u7c7b\u578b\u68c0\u67e5\u3002 As Mark Manasse concisely put it:[ 3] The fundamental problem addressed by a type theory is to ensure that programs have meaning. The fundamental problem caused by a type theory is that meaningful programs may not have meanings ascribed to\uff08\u5f52\u5c5e\u4e8e\uff09 them. The quest for richer type systems results from this tension. \u603b\u7ed3\uff1aMark Manasse\u7684\u89c2\u70b9\u662f**\u7c7b\u578b**\u4f7f\u7a0b\u5e8f\u5177\u6709**\u610f\u4e49**\uff0c\u4e0b\u9762\u7684\u8bdd\u5bf9\u8fd9\u4e2a\u89c2\u70b9\u8fdb\u884c\u4e86\u9610\u8ff0\uff1a Assigning a data type, termed typing , gives meaning to a sequence of bits such as a value in memory or some object such as a variable . The hardware of a general purpose computer is unable to discriminate(\u533a\u5206) between for example a memory address and an instruction code (\u6307\u4ee4\u4ee3\u7801), or between a character , an integer , or a floating-point number , because it makes no intrinsic distinction(\u533a\u5206) between any of the possible values that a sequence of bits might mean (\u8fd9\u6bb5\u8bdd\u7684\u610f\u601d\u662f\u5f53\u6211\u4eec\u5c06\u9ad8\u7ea7\u8bed\u8a00\u6240\u7f16\u5199\u7684\u7a0b\u5e8f\u7ffb\u8bd1\u6210\u4e8c\u8fdb\u5236\u7a0b\u5e8f\u540e\uff0c\u786c\u4ef6\u5c42\uff0c\u6bd4\u5982CPU\uff0c\u5728\u6267\u884c\u8fd9\u4e9b\u4e8c\u8fdb\u5236\u7a0b\u5e8f\u7684\u65f6\u5019\uff0c\u5e76\u4e0d\u4f1a\u5173\u5fc3\u8fd9\u4e9b\u4e8c\u8fdb\u5236\u6570\u636e\u6240\u4ee3\u8868\u7684\u542b\u4e49\uff08\u8fd9\u4e9b\u6570\u636e\u8868\u793a\u7684\u662f\u5185\u5b58\u5730\u5740\uff0c\u8fd8\u662f\u6307\u4ee4\u7801\uff0c\u7b49\u7b49\uff09\uff0c\u4e5f\u5c31\u662f\u786c\u4ef6\u5c42\u538b\u6839\u5c31\u6ca1\u6709\u7c7b\u578b\u7684\u6982\u5ff5\uff0c\u5bf9\u5b83\u4eec\u800c\u8a00\uff0c\u6240\u6709\u7684\u4e00\u5207\u90fd\u662f\u4e8c\u8fdb\u5236\u6570).[ note 1] Associating a sequence of bits with a type conveys that meaning to the programmable hardware to form a symbolic system composed of that hardware and some program(\u5c06\u4e8c\u8fdb\u5236\u4e32\u548c\u7c7b\u578b\u76f8\u5173\u8054\u80fd\u591f\u5c06\u7c7b\u578b\u7684\u610f\u4e49\u4f20\u9012\u5230\u53ef\u7f16\u7a0b\u786c\u4ef6\uff0c\u8fd9\u6837\u53ef\u4ee5\u5b9e\u73b0\u7531\u786c\u4ef6\u548c\u7a0b\u5e8f\u7ec4\u6210\u7684symbolic system). A program associates each value with at least one specific type, but it also can occur that one value is associated with many subtypes . Other entities, such as objects , modules , communication channels, and dependencies can become associated with a type. Even a type can become associated with a type. An implementation of a type system could in theory associate identifications called data type (a type of a value), class (a type of an object), and kind (a type of a type , or metatype ). These are the abstractions that typing can go through, on a hierarchy of levels contained in a system. \u603b\u7ed3\uff1a\u7a0b\u5e8f\u4e3a\u6bcf\u4e2avalue\u5173\u8054\u4e00\u4e2a\u7c7b\u578b\uff0c\u6709\u53ef\u80fd\u51fa\u73b0\u7684\u4e00\u79cd\u60c5\u51b5\u662f\u4e00\u4e2avalue\u53ef\u4ee5\u5173\u8054\u591a\u4e2a\u5b50\u7c7b\u578b\u3002\u5176\u4ed6\u7a0b\u5e8f\u7ec4\u6210\u90e8\u5206\uff0c\u6bd4\u5982object\uff0cmodule\uff0c\u7b49\u7b49\uff0c\u4e5f\u90fd\u53ef\u4ee5\u548c\u4e00\u4e2a\u7c7b\u578b\u76f8\u5173\u8054\u3002\u663e\u7136\u7c7b\u578b\u7cfb\u7edf\u4e2d\u53ef\u4ee5\u5305\u542b\u7684\u7c7b\u578b\u662f\u975e\u5e38\u6bd4\u8f83\u591a\uff0c\u6bd4\u8f83\u590d\u6742\u7684\u3002\u7c7b\u578b\u7cfb\u7edf\u4e00\u79cd\u7406\u8bba\u4e0a\u7684\u5b9e\u73b0\u65b9\u5f0f\u662f\u4ee5hierarchy\u5373\u5c42\u7684\u65b9\u5f0f\u6765\u5bf9\u5404\u79cd\u7c7b\u578b\u8fdb\u884c\u5b9a\u4e49\u3002 When a programming language evolves a more elaborate(\u590d\u6742) type system, it gains a more finely grained(\u7ec6\u5316) rule set than basic type checking, but this comes at a price when the type inferences (and other properties) become undecidable (\u4e0d\u53ef\u5224\u5b9a), and when more attention must be paid by the programmer to annotate(\u6ce8\u91ca) code or to consider computer-related operations and functioning. It is challenging to find a sufficiently expressive type system that satisfies all programming practices in a type safe manner. \u603b\u7ed3\uff1a\u968f\u7740\u7f16\u7a0b\u8bed\u8a00\u7684\u8fdb\u5316\uff0c\u7c7b\u578b\u7cfb\u7edf\u4e5f\u4f1a\u53d8\u5f97\u66f4\u52a0\u590d\u6742\uff0c\u9664\u4e86\u6700\u57fa\u672c\u7684type checking\uff0c\u7c7b\u578b\u7cfb\u7edf\u5c06\u4f1a\u5305\u542b\u66f4\u52a0\u7ec6\u5316\u7684\u89c4\u5219\u96c6\uff0c\u4f46\u662f\u66f4\u52a0\u7ec6\u5316\u7684\u89c4\u5219\u96c6\u4e5f\u610f\u5473\u7740\u7c7b\u578b\u63a8\u5bfc\u53ef\u80fd\u53d8\u5f97\u4e0d\u786e\u5b9a\uff0c\u4e5f\u610f\u5473\u7740\u7a0b\u5e8f\u5458\u9700\u8981\u82b1\u8d39\u66f4\u591a\u7684\u7cbe\u529b\u5728\u5bf9\u4ee3\u7801\u8fdb\u884c\u6ce8\u91ca\uff0c\u601d\u8003\u4e0e\u8ba1\u7b97\u673a\u76f8\u5173\u7684\u64cd\u4f5c\uff0c\u529f\u80fd\u7b49\u3002\u6240\u4ee5\u5bfb\u627e\u5230\u4e00\u4e2a\u65e2\u7c7b\u578b\u5b89\u5168\uff0c\u6709\u6ee1\u8db3\u6240\u6709\u7f16\u7a0b\u6700\u4f73\u5b9e\u8df5\u7684\uff0c\u5e76\u4e14\u5177\u6709\u8db3\u591f\u8868\u8fbe\u529b\u7684\u7c7b\u578b\u7cfb\u7edf\u662f\u5177\u6709\u6311\u6218\u6027\u7684\u3002 The more type restrictions that are imposed by the compiler, the more strongly typed a programming language is. Strongly typed languages (\u5f3a\u7c7b\u578b\u8bed\u8a00) often require the programmer to make explicit conversions(\u663e\u793a\u7c7b\u578b\u8f6c\u6362) in contexts where an implicit conversion would cause no harm(\u5f3a\u7c7b\u578b\u8bed\u8a00\u901a\u5e38\u9700\u8981\u7a0b\u5e8f\u5458\u5728\u9690\u5f0f\u8f6c\u6362\u4e0d\u4f1a\u9020\u6210\u4f24\u5bb3\u7684\u4e0a\u4e0b\u6587\u4e2d\u8fdb\u884c\u663e\u5f0f\u8f6c\u6362). Pascal's type system has been described as \"too strong\" because, for example, the size of an array or string is part of its type, making some programming tasks difficult.[ 4] [ 5] Haskell is also strongly typed but its types are automatically inferred(\u7c7b\u578b\u662f\u81ea\u52a8\u63a8\u5bfc\u7684) so that explicit conversions are often (but not always) unnecessary. \u603b\u7ed3\uff1a\u5982\u679c\u4ece\u7c7b\u578b\u9650\u5236\u7684\u5f3a\u5f31\u6765\u5224\u5b9a\u7f16\u7a0b\u8bed\u8a00\u7684\u8bdd\uff0c\u90a3\u4e9b\u7c7b\u578b\u9650\u5236\u8f83\u5f3a\u7684\u8bed\u8a00\u5c31\u53ef\u4ee5\u79f0\u4e4b\u4e3a\u201c\u5f3a\u7c7b\u578b\u8bed\u8a00\u201d\u3002\u4ece\u4f5c\u8005\u6240\u5217\u4e3e\u7684**Pascal**\u548c**Haskell**\u7684\u4f8b\u5b50\u6765\u770b\uff0c\u7f16\u7a0b\u8bed\u8a00\u5982\u4f55\u4e3a\u7a0b\u5e8f\u5458\u51cf\u4f4e\u7f16\u7a0b\u7684\u5de5\u4f5c\u91cf\u662f\u975e\u5e38\u91cd\u8981\u7684\uff0c\u4e24\u8005\u540c\u4e3a\u5f3a\u7c7b\u578b\u8bed\u8a00\uff0c\u4f46\u662fHaskell\u7684\u81ea\u52a8\u7c7b\u578b\u63a8\u5bfc\u673a\u5236\u663e\u7136\u51cf\u4f4e\u4e86\u5176\u7f16\u7a0b\u7684\u5de5\u4f5c\u91cf\u3002 A programming language compiler can also implement a dependent type or an effect system , which enables even more program specifications to be verified by a type checker. Beyond simple value-type pairs, a virtual \"region\" of code is associated with an \"effect\" component describing what is being done with what , and enabling for example to \"throw\" an error report. Thus the symbolic system may be a type and effect system , which endows it with more safety checking than type checking alone. \u603b\u7ed3\uff1a\u7f16\u7a0b\u8bed\u8a00\u7f16\u8bd1\u5668\u4e5f\u53ef\u4ee5\u5b9e\u73b0dependent type\u6216effect system\uff0c\u8fd9\u4f7ftype checker\u53ef\u4ee5\u9a8c\u8bc1\u66f4\u591a\u7684\u7a0b\u5e8f\u89c4\u8303\u3002 \u9664\u7b80\u5355\u7684value-type\u5bf9\u4e4b\u5916\uff0c\u4ee3\u7801\u7684\u865a\u62df\u201cregion\u201d\u53ef\u4ee5\u548c\u4e00\u4e2a\"effect\"**\u7ec4\u4ef6**\u76f8\u5173\u8054\uff0c\u8fd9\u4e2a**\u7ec4\u4ef6**\u80fd\u591f\u63cf\u8ff0\u6b63\u5728\u505a\u4ec0\u4e48\u3001\u201c\u629b\u51fa\u201d\u9519\u8bef\u62a5\u544a\u3002 \u56e0\u6b64\uff0csymbolic system \u53ef\u80fd\u662f\u4e00\u4e2a*type and effect system*\uff0c\u5373\u9664\u4e86type\uff0c\u5b83\u8fd8\u6d89\u53caeffect\uff0c\u5b83\u6bd4\u5355\u7eaf\u7684\u7c7b\u578b\u68c0\u67e5\u8d4b\u4e88\u5b83\u66f4\u591a\u7684\u5b89\u5168\u68c0\u67e5\u3002 Whether automated by the compiler or specified by a programmer , a type system makes program behavior illegal if outside the type-system rules(\u7c7b\u578b\u7cfb\u7edf\u65e0\u8bba\u662f\u7531\u7f16\u8bd1\u5668\u81ea\u52a8\u6267\u884c\u8fd8\u662f\u7531\u7a0b\u5e8f\u5458\u6307\u5b9a\uff0c\u5982\u679c\u7a0b\u5e8f\u4e0d\u7b26\u5408\u7c7b\u578b\u7cfb\u7edf\u7684\u89c4\u5219\uff0c\u5219\u7a0b\u5e8f\u884c\u4e3a\u5c31\u6709\u53ef\u80fd\u53d8\u5f97\u975e\u6cd5). Advantages provided by programmer-specified type systems include: Abstraction (or modularity ) \u2013 Types enable programmers to think at a higher level than the bit or byte, not bothering with low-level implementation. For example, programmers can begin to think of a string as a set of character values instead of as a mere array of bytes. Higher still, types enable programmers to think about and express interfaces between two of any -sized subsystems. This enables more levels of localization so that the definitions required for interoperability of the subsystems remain consistent when those two subsystems communicate. Documentation \u2013 In more expressive type systems, types can serve as a form of documentation clarifying the intent of the programmer. For example, if a programmer declares a function as returning a timestamp type, this documents the function when the timestamp type can be explicitly declared deeper in the code to be an integer type. Advantages provided by compiler-specified type systems include: Optimization \u2013 Static type-checking may provide useful compile-time information. For example, if a type requires that a value must align in memory at a multiple of four bytes, the compiler may be able to use more efficient machine instructions. Safety \u2013 A type system enables the compiler to detect meaningless or probably invalid code. For example, we can identify an expression 3 / \"Hello, World\" as invalid, when the rules do not specify how to divide an integer by a string . Strong typing offers more safety, but cannot guarantee complete type safety . \u603b\u7ed3\uff1a\u7c7b\u578b\u7cfb\u7edf\u53ef\u4ee5\u7531\u7f16\u8bd1\u5668\u6765\u5b9e\u73b0\uff08\u8fd9\u662f\u4e3b\u6d410\uff09\uff0c\u5f53\u7136\u4e5f\u53ef\u4ee5\u7531\u7a0b\u5e8f\u5458\u6765\u8fdb\u884c\u6307\u5b9a\uff0c\u65e0\u8bba\u662f\u6709\u8c01\uff0c\u5982\u679c\u67e5\u8be2\u4e0d\u7b26\u5408\u7c7b\u578b\u89c4\u5219\uff0c\u5219\u7a0b\u5e8f\u7684\u884c\u4e3a\u90fd\u53ef\u80fd\u662f\u975e\u6cd5\u7684\u3002\u5e76\u4e14\u4e0a\u9762\u7684\u5185\u5bb9\u8fd8\u8ba8\u8bba\u4e86programmer-specified type systems\u548ccompiler-specified type systems\u5404\u81ea\u7684\u4f18\u52bf\u3002 Type errors A type error is an unintended condition which might manifest(\u51fa\u73b0) in multiple stages of a program's development. Thus a facility for detection of the error is needed in the type system . In some languages, such as Haskell, for which type inference is automated, lint might be available to its compiler to aid in the detection of error. Type safety contributes to program correctness , but can only guarantee correctness at the cost of making the type checking itself an undecidable problem .In a type system with automated type checking a program may prove to run incorrectly yet be safely typed, and produce no compiler errors. Division by zero is an unsafe and incorrect operation, but a type checker running at compile time only doesn't scan for division by zero in most languages, and then it is left as a runtime error . To prove the absence of these more-general-than-types defects, other kinds of formal methods , collectively known as program analyses , are in common use. Alternatively, a sufficiently expressive type system, such as in dependently typed languages, can prevent these kinds of errors (for example, expressing the type of non-zero numbers ). In addition software testing is an empirical method for finding errors that the type checker cannot detect. Type checking The process of verifying and enforcing the constraints of types\u2014 type checking \u2014may occur either at compile-time (a static check) or at run-time . If a language specification(\u8bed\u8a00\u89c4\u8303) requires its typing rules strongly (i.e., more or less allowing only those automatic type conversions that do not lose information(\u5373\u6216\u591a\u6216\u5c11\u53ea\u5141\u8bb8\u90a3\u4e9b\u4e0d\u4f1a\u4e22\u5931\u4fe1\u606f\u7684\u81ea\u52a8\u7c7b\u578b\u8f6c\u6362)), one can refer to the process as strongly typed , if not, as weakly typed . The terms are not usually used in a strict sense. Q&A : \u54ea\u4e9b\u7c7b\u578b\u4e4b\u95f4\u662f\u80fd\u591f\u8fdb\u884c\u81ea\u52a8\u7c7b\u578b\u8f6c\u6362\u7684\u5462\uff1f Static type checking Static type checking is the process of verifying the type safety of a program based on analysis of a program's text (source code). If a program passes a static type checker, then the program is guaranteed to satisfy some set of type safety properties for all possible inputs. Static type checking can be considered a limited form of program verification (see type safety ), and in a type-safe language, can be considered also an optimization. If a compiler can prove that a program is well-typed, then it does not need to emit dynamic safety checks , allowing the resulting compiled binary to run faster and to be smaller. Static type checking for Turing-complete languages is inherently(\u672c\u8d28\u4e0a) conservative. That is, if a type system is both sound (meaning that it rejects all incorrect programs) and decidable (meaning that it is possible to write an algorithm that determines whether a program is well-typed), then it must be incomplete (meaning there are correct programs, which are also rejected, even though they do not encounter runtime errors).[ 6] \u603b\u7ed3\uff1a\u4e0a\u9762\u4e09\u6bb5\u8bdd\u5bf9\u9759\u6001\u7c7b\u578b\u68c0\u67e5\u8fdb\u884c\u4e86\u4ecb\u7ecd\uff0c\u5176\u4e2d\u7b2c\u4e00\u6bb5\u8bdd\u548c\u7b2c\u4e8c\u6bb5\u8bdd\u662f\u6bd4\u8f83\u597d\u7406\u89e3\u7684\uff0c\u6bd4\u8f83\u96be\u7406\u89e3\u7684\u662f\u7b2c\u4e09\u6bb5\u8bdd\u3002\u5176\u5b9e\u5982\u679c\u7ed3\u5408\u4e0b\u9762 \u8fd9\u4e2a\u4f8b\u5b50\u7684\u8bdd\uff0c\u7b2c\u4e09\u6bb5\u8bdd\u7684\u542b\u4e49\u4e5f\u662f\u53ef\u4ee5\u5012\u63a8\u51fa\u6765\u7684\u3002\u7b2c\u4e09\u6bb5\u8bdd\u7684\u610f\u601d\u662f\uff1a\u5bf9\u4e8e**Turing-complete languages** \u800c\u8a00\uff0c\u9759\u6001\u7c7b\u578b\u68c0\u67e5\u662f\u4fdd\u5b88\u7684\u3002\u5982\u679c\u4e00\u4e2a\u7c7b\u578b\u7cfb\u7edf\u662fsound\u548cdecidable\u7684\uff0c\u90a3\u4e48\u5b83\u4e00\u5b9a\u662fincomplete\u7684\uff08\u610f\u5473\u7740\u4e00\u4e2a\u6b63\u786e\u7684\u7a0b\u5e8f\uff0c\u5373\u4f7f\u5b83\u4e0d\u4f1a\u4ea7\u751f\u8fd0\u884c\u65f6\u9519\u8bef\uff0c\u4f46\u662f\u9759\u6001\u7c7b\u578b\u68c0\u67e5\u8fd8\u662f\u4f1a\u8ba4\u4e3a\u5b83\u662f\u9519\u8bef\u7684\u800c\u62d2\u7edd\u5b83\uff09\u3002\u6bd4\u5982\u4e0b\u9762\u7684\u8fd9\u4e2a\u4f8b\u5b50\uff0c\u5982\u679c complex text \u6c38\u8fdc\u662f true \uff0c\u5219 else \u5206\u652f\u5c06\u6c38\u8fdc\u90fd\u4e0d\u4f1a\u88ab\u6267\u884c\u5230\uff0c\u90a3\u4e48 else \u5206\u652f\u4e2d\u7684\u4ee3\u7801\u5c31\u4e0d\u4f1a\u4ea7\u751f\u8fd0\u884c\u65f6\u9519\u8bef\uff0c\u4f46\u662f\u5927\u591a\u6570type checker\u662f\u4f1a\u62d2\u7edd\u8fd9\u4e2a\u4ee3\u7801\u7684\u3002 For example, consider a program containing the code: if <complex test> then <do something> else <generate type error> Even if the expression <complex test> always evaluates to true at run-time, most type checkers will reject the program as ill-typed, because it is difficult (if not impossible) for a static analyzer to determine that the else branch will not be taken.[ 7] Conversely, a static type checker will quickly detect type errors in rarely used code paths. Without static type checking , even code coverage tests with 100% coverage may be unable to find such type errors. The tests(\u6307\u524d\u9762\u63d0\u5230\u7684code coverage tests ) may fail to detect such type errors, because the combination of all places where values are created and all places where a certain value is used must be taken into account. \u603b\u7ed3\uff1a\u8fd9\u6bb5\u8bdd\u662f\u7ed3\u5408\u4e0a\u9762\u7684\u90a3\u4e2a\u5c0f\u7a0b\u5e8f\u5bf9type checker\u8fdb\u884c\u4e86\u4e00\u4e2a\u8fa9\u8bc1\u5730\u5206\u6790\u3002 A number of useful and common programming language features cannot be checked statically, such as downcasting . Thus, many languages will have both static and dynamic type checking; the static type checker verifies what it can, and dynamic checks verify the rest. Many languages with static type checking provide a way to bypass(\u7ed5\u8fc7) the type checker . Some languages allow programmers to choose between static and dynamic type safety. For example, C# distinguishes between statically-typed and dynamically-typed variables. Uses of the former are checked statically, whereas uses of the latter are checked dynamically. Other languages allow writing code that is not type-safe. For example, in C , programmers can freely cast a value between any two types that have the same size. \u603b\u7ed3\uff1a\u4e00\u4e9b\u975e\u5e38\u6709\u7528\u7684\u8bed\u8a00\u7279\u6027\u662f\u65e0\u6cd5\u8fdb\u884c\u9759\u6001\u68c0\u67e5\u7684\uff0c\u6240\u4ee5\u5f88\u591a\u7f16\u7a0b\u8bed\u8a00\u65e2\u6709\u9759\u6001\u7c7b\u578b\u68c0\u67e5\u53c8\u6709\u52a8\u6001\u7c7b\u578b\u68c0\u67e5\u3002\u5e76\u4e14\u7ed3\u5408\u524d\u9762\u7684\u90a3\u4e2a\u5bf9\u9759\u6001\u7c7b\u578b\u68c0\u67e5\u8fdb\u884c\u5206\u6790\u7684\u4f8b\u5b50\uff0c\u53ef\u4ee5\u770b\u51fa\u6709\u65f6\u5019\u662f\u4e0d\u9700\u8981\u8fdb\u884c\u9759\u6001\u7c7b\u578b\u68c0\u67e5\u7684\uff0c\u6240\u4ee5\u6709\u7684\u7f16\u7a0b\u8bed\u8a00\u5c31\u5141\u8bb8\u7531\u7a0b\u5e8f\u5458\u6765\u6307\u5b9a\u662f\u5426\u8fdb\u884c\u9759\u6001\u7c7b\u578b\u68c0\u67e5\u548c\u52a8\u6001\u7c7b\u578b\u68c0\u67e5\uff0c\u6bd4\u5982 C# \uff0c\u6765\u51b3\u5b9a\u7a0b\u5e8f\u662f\u5426\u6ee1\u8db3**\u9759\u6001\u7c7b\u578b\u5b89\u5168\u6027**\u548c**\u52a8\u6001\u7c7b\u578b\u5b89\u5168\u6027**\uff1b\u751a\u81f3\u6709\u7684\u8bed\u8a00\u5e76\u4e0d\u8981\u6c42\u7c7b\u578b\u5b89\u5168\uff0c\u6bd4\u5982 C \u8bed\u8a00\uff0c\u5b83\u5141\u8bb8\u5bf9\u76f8\u540c\u5927\u5c0f\u7684\u7c7b\u578b\u8fdb\u884c\u8f6c\u6362\u3002\u8bf7\u53c2\u7167\u4e0b\u9762\u8fd9\u4e2a\u94fe\u63a5\u6765\u770b\u54ea\u4e9b\u8bed\u8a00\u662f\u4f1a\u8fdb\u884c\u9759\u6001\u7c7b\u578b\u68c0\u67e5\u7684\u3002 For a list of languages with static type checking, see the category for statically typed languages . Dynamic type checking and runtime type information Dynamic type checking is the process of verifying the type safety of a program at runtime. Implementations of dynamically type-checked languages generally associate each runtime object with a type tag (i.e., a reference to a type) containing its type information . This runtime type information ( RTTI ) can also be used to implement dynamic dispatch , late binding , downcasting , reflection , and similar features. \u603b\u7ed3\uff1a\u8fd9\u6bb5\u8bdd\u7ed9\u51fa\u4e86**Dynamic type checking** \u5373\u52a8\u6001\u7c7b\u578b\u68c0\u67e5\u7684\u542b\u4e49\u7684\u89e3\u91ca\uff0c\u4ee5\u53ca\u5176\u5b9e\u73b0\u65b9\u5f0f\uff1aRTTI\uff0c\u5e76\u4e14\u8fd9\u91cc\u8fd8\u63d0\u5230\u4e86RTTI\u5904\u7406\u53ef\u4ee5\u7528\u4e8e**Dynamic type checking** \u5916\uff0c\u8fd8\u53ef\u4ee5\u7528\u4e8e\u5b9e\u73b0 dynamic dispatch , late binding , downcasting , reflection , and similar features. Most type-safe languages include some form of dynamic type checking , even if they also have a static type checker. The reason for this is that many useful features or properties are difficult or impossible to verify statically. For example, suppose that a program defines two types, A and B, where B is a subtype of A. If the program tries to convert a value of type A to type B, which is known as downcasting , then the operation is legal only if the value being converted is actually a value of type B(\u5982\u679c\u7528python\u6765\u89e3\u91ca\u7684\u8bdd\u5c31\u662ftype()==B). Thus, a dynamic check is needed to verify that the operation is safe. This requirement is one of the criticisms(\u6279\u8bc4) of downcasting . \u603b\u7ed3\uff1a\u8fd9\u6bb5\u8bdd\u4ee5**downcasting**\u4e3a\u4f8b\u8bf4\u660e\u4e86\u4e3a\u4ec0\u4e48\u7f16\u7a0b\u8bed\u8a00\u9700\u8981**dynamic type checking**\u3002 By definition, dynamic type checking may cause a program to fail at runtime. In some programming languages, it is possible to anticipate and recover from these failures. In others, type-checking errors are considered fatal. Programming languages that include dynamic type checking but not static type checking are often called \" dynamically typed programming languages \". For a list of such languages, see the category for dynamically typed programming languages . \u603b\u7ed3\uff1a\u8fd9\u91cc\u7ed9\u51fa\u4e86**dynamically typed programming languages**\u7684\u6b63\u786e\u7684\u5b9a\u4e49\u3002python\u5c31\u662f\u4e00\u95e8**dynamically typed programming language** Combining static and dynamic type checking[ edit ] Some languages allow both static and dynamic typing (type checking), sometimes called soft typing. For example, Java and some other ostensibly statically typed languages support downcasting types to their subtypes , querying an object to discover its dynamic type, and other type operations that depend on runtime type information . More generally, most programming languages include mechanisms for dispatching over different 'kinds' of data, such as disjoint unions , subtype polymorphism , and variant types . Even when not interacting with type annotations or type checking, such mechanisms are materially similar to dynamic typing implementations. See programming language for more discussion of the interactions between static and dynamic typing. Objects in object-oriented languages are usually accessed by a reference whose static target type (or manifest type (\u8868\u9762\u7c7b\u578b)) is equal to either the object's run-time type (its latent type (\u6f5c\u85cf\u7c7b\u578b)) or a supertype thereof. This is conformant with the Liskov substitution principle , which states that all operations performed on an instance of a given type can also be performed on an instance of a subtype . This concept is also known as subsumption . In some languages subtypes may also possess covariant or contravariant return types and argument types respectively. Certain languages, for example Clojure , Common Lisp , or Cython are dynamically type-checked by default, but allow programs to opt into static type checking by providing optional annotations . One reason to use such hints would be to optimize the performance of critical sections of a program. This is formalized by gradual typing . The programming environment DrRacket , a pedagogic environment based on Lisp, and a precursor of the language Racket was also soft-typed. Conversely, as of version 4.0, the C# language provides a way to indicate that a variable should not be statically type-checked. A variable whose type is dynamic will not be subject to static type checking. Instead, the program relies on runtime type information to determine how the variable may be used.[ 8] Static and dynamic type checking in practice The choice between static and dynamic typing requires certain trade-offs . Static typing can find type errors reliably at compile time, which should increase the reliability of the delivered program. However, programmers disagree over how commonly type errors occur, resulting in further disagreements over the proportion of those bugs that are coded that would be caught by appropriately representing the designed types in code.[ 9] [ 10] Static typing advocates[ who? ] believe programs are more reliable when they have been well type-checked, whereas dynamic-typing advocates[ who? ] point to distributed code that has proven reliable and to small bug databases.[ citation needed ] The value of static typing, then, presumably[ vague ]increases as the strength of the type system is increased. Advocates of dependent typing ,[ who? ] implemented in languages such as Dependent ML and Epigram , have suggested that almost all bugs can be considered type errors, if the types used in a program are properly declared by the programmer or correctly inferred by the compiler.[ 11] Static typing usually results in compiled code that executes faster. When the compiler knows the exact data types that are in use (which is necessary for static verification, either through declaration or inference) it can produce optimized machine code. Some dynamically typed languages such as Common Lisp allow optional type declarations for optimization for this reason. By contrast, dynamic typing may allow compilers to run faster and interpreters to dynamically load new code, because changes to source code in dynamically typed languages may result in less checking to perform and less code to revisit.[ clarification needed ] This too may reduce the edit-compile-test-debug cycle. Statically typed languages that lack type inference (such as C and Java ) require that programmers declare the types that a method or function must use. This can serve as added program documentation, that is active and dynamic, instead of static. This allows a compiler to prevent it from drifting out of synchrony, and from being ignored by programmers. However, a language can be statically typed without requiring type declarations (examples include Haskell , Scala , OCaml , F# , and to a lesser extent C# and C++ ), so explicit type declaration is not a necessary requirement for static typing in all languages. Dynamic typing allows constructs that some static type checking would reject as illegal. For example, eval functions, which execute arbitrary data as code, become possible. An eval function is possible with static typing, but requires advanced uses of algebraic data types . Further, dynamic typing better accommodates transitional code and prototyping, such as allowing a placeholder data structure ( mock object ) to be transparently used in place of a full data structure (usually for the purposes of experimentation and testing). Dynamic typing typically allows duck typing (which enables easier code reuse ). Many[ specify ] languages with static typing also feature duck typing or other mechanisms like generic programming that also enable easier code reuse. Dynamic typing typically makes metaprogramming easier to use. For example, C++ templates are typically more cumbersome to write than the equivalent Ruby or Python code since C++ has stronger rules regarding type definitions (for both functions and variables). This forces a developer to write more boilerplate code for a template than a Python developer would need to. More advanced run-time constructs such as metaclasses and introspection are often harder to use in statically typed languages. In some languages, such features may also be used e.g. to generate new types and behaviors on the fly, based on run-time data. Such advanced constructs are often provided by dynamic programming languages ; many of these are dynamically typed, although dynamic typing need not be related to dynamic programming languages . Strong and weak type systems[ edit ] Main article: Strong and weak typing Languages are often colloquially referred to as strongly typed or weakly typed . In fact, there is no universally accepted definition of what these terms mean. In general, there are more precise terms to represent the differences between type systems that lead people to call them \"strong\" or \"weak\". Type safety and memory safety[ edit ] Main article: Type safety A third way of categorizing the type system of a programming language uses the safety of typed operations and conversions . Computer scientists consider a language \"type-safe\" if it does not allow operations or conversions that violate the rules of the type system. Some observers use the term memory-safe language (or just safe language ) to describe languages that do not allow programs to access memory that has not been assigned for their use. For example, a memory-safe language will check array bounds , or else statically guarantee (i.e., at compile time before execution) that array accesses out of the array boundaries will cause compile-time and perhaps runtime errors. Consider the following program of a language that is both type-safe and memory-safe :[ 12] 1 var x := 5; 2 var y := \"37\"; 3 var z := x + y; In this example, the variable z will have the value 42. Although this may not be what the programmer anticipated, it is a well-defined result. If y were a different string, one that could not be converted to a number (e.g. \"Hello World\"), the result would be well-defined as well. Note that a program can be type-safe or memory-safe and still crash on an invalid operation; in fact, if a program encounters an operation that is not type-safe, terminating the program is often the only option. Now consider a similar example in C: 1 int x = 5 ; 2 char y [] = \"37\" ; 3 char * z = x + y ; In this example z will point to a memory address five characters beyond y , equivalent to three characters after the terminating zero character of the string pointed to by y . This is memory that the program is not expected to access. It may contain garbage data, and it certainly doesn't contain anything useful. As this example shows, C is neither a memory-safe nor a type-safe language. In general, type-safety and memory-safety go hand in hand. For example, a language that supports pointer arithmetic and number-to-pointer conversions (like C) is neither memory-safe nor type-safe , because it allows arbitrary memory to be accessed as if it were valid memory of any type. For more information, see memory safety . Variable levels of type checking[ edit ] Some languages allow different levels of checking to apply to different regions of code. Examples include: The use strict directive in JavaScript [ 13] [ 14] [ 15] and Perl applies stronger checking. The declare(strict_types=1) in PHP [ 16] on a per-file basis allows only a variable of exact type of the type declaration will be accepted, or a TypeError will be thrown. The Option Strict On in VB.NET allows the compiler to require a conversion between objects. Additional tools such as lint and IBM Rational Purify can also be used to achieve a higher level of strictness. Optional type systems[ edit ] It has been proposed, chiefly by Gilad Bracha , that the choice of type system be made independent of choice of language; that a type system should be a module that can be plugged into a language as needed. He believes this is advantageous, because what he calls mandatory type systems make languages less expressive and code more fragile.[ 17] The requirement that types do not affect the semantics of the language is difficult to fulfill. Optional typing is related to gradual typing , but still distinct from it.[ 18] [ better source needed ] Polymorphism and types[ edit ] Main article: Polymorphism (computer science) The term polymorphism refers to the ability of code (especially, functions or classes) to act on values of multiple types, or to the ability of different instances of the same data structure to contain elements of different types. Type systems that allow polymorphism generally do so in order to improve the potential for code re-use: in a language with polymorphism, programmers need only implement a data structure such as a list or an associative array once, rather than once for each type of element with which they plan to use it. For this reason computer scientists sometimes call the use of certain forms of polymorphism generic programming . The type-theoretic foundations of polymorphism are closely related to those of abstraction , modularity and (in some cases) subtyping . Duck typing[ edit ] Main article: Duck typing In duck typing ,[ 19] a statement calling a method m on an object does not rely on the declared type of the object; only that the object, of whatever type, must supply an implementation of the method called, when called, at run-time. Duck typing differs from structural typing in that, if the part (of the whole module structure) needed for a given local computation is present at runtime , the duck type system is satisfied in its type identity analysis. On the other hand, a structural type system would require the analysis of the whole module structure at compile time to determine type identity or type dependence. Duck typing differs from a nominative type system in a number of aspects. The most prominent ones are that for duck typing, type information is determined at runtime (as contrasted to compile time), and the name of the type is irrelevant to determine type identity or type dependence; only partial structure information is required for that for a given point in the program execution. Duck typing uses the premise that (referring to a value) \"if it walks like a duck, and quacks like a duck, then it is a duck\" (this is a reference to the duck test that is attributed to James Whitcomb Riley ). The term may have been coined[ citation needed ] by Alex Martelli in a 2000 message[ 20] to the comp.lang.python newsgroup (see Python ). While one controlled experiment showed an increase in developer productivity for duck typing in single developer projects,[ 21] other controlled experiments on API usability show the opposite.[ 22] [ 23] Specialized type systems[ edit ] Many type systems have been created that are specialized for use in certain environments with certain types of data, or for out-of-band static program analysis . Frequently, these are based on ideas from formal type theory and are only available as part of prototype research systems. Dependent types[ edit ] Main article: Dependent type Dependent types are based on the idea of using scalars or values to more precisely describe the type of some other value. For example, {\\displaystyle \\mathrm {matrix} (3,3)} might be the type of a {\\displaystyle 3\\times 3} matrix. We can then define typing rules such as the following rule for matrix multiplication: {\\displaystyle \\mathrm {matrix} _{\\mathrm {multiply} }:\\mathrm {matrix} (k,m)\\times \\mathrm {matrix} (m,n)\\to \\mathrm {matrix} (k,n)} where {\\displaystyle k} , {\\displaystyle m} , {\\displaystyle n} are arbitrary positive integer values. A variant of ML called Dependent ML has been created based on this type system, but because type checking for conventional dependent types is undecidable , not all programs using them can be type-checked without some kind of limits. Dependent ML limits the sort of equality it can decide to Presburger arithmetic . Other languages such as Epigram make the value of all expressions in the language decidable so that type checking can be decidable. However, in general proof of decidability is undecidable , so many programs require hand-written annotations that may be very non-trivial. As this impedes the development process, many language implementations provide an easy way out in the form of an option to disable this condition. This, however, comes at the cost of making the type-checker run in an infinite loop when fed programs that do not type-check, causing the compilation to fail. Linear types[ edit ] Main article: Linear type Linear types , based on the theory of linear logic , and closely related to uniqueness types , are types assigned to values having the property that they have one and only one reference to them at all times. These are valuable for describing large immutable values such as files, strings, and so on, because any operation that simultaneously destroys a linear object and creates a similar object (such as ' str= str + \"a\" ') can be optimized \"under the hood\" into an in-place mutation. Normally this is not possible, as such mutations could cause side effects on parts of the program holding other references to the object, violating referential transparency . They are also used in the prototype operating system Singularity for interprocess communication, statically ensuring that processes cannot share objects in shared memory in order to prevent race conditions. The Clean language (a Haskell -like language) uses this type system in order to gain a lot of speed (compared to performing a deep copy) while remaining safe. Intersection types[ edit ] Main article: Intersection type Intersection types are types describing values that belong to both of two other given types with overlapping value sets. For example, in most implementations of C the signed char has range -128 to 127 and the unsigned char has range 0 to 255, so the intersection type of these two types would have range 0 to 127. Such an intersection type could be safely passed into functions expecting either signed or unsigned chars, because it is compatible with both types. Intersection types are useful for describing overloaded function types: For example, if \" int \u2192 int \" is the type of functions taking an integer argument and returning an integer, and \" float \u2192 float \" is the type of functions taking a float argument and returning a float, then the intersection of these two types can be used to describe functions that do one or the other, based on what type of input they are given. Such a function could be passed into another function expecting an \" int \u2192 int \" function safely; it simply would not use the \" float \u2192 float \" functionality. In a subclassing hierarchy, the intersection of a type and an ancestor type (such as its parent) is the most derived type. The intersection of sibling types is empty. The Forsythe language includes a general implementation of intersection types. A restricted form is refinement types . Union types[ edit ] Main article: Union type Union types are types describing values that belong to either of two types. For example, in C, the signed char has a -128 to 127 range, and the unsigned char has a 0 to 255 range, so the union of these two types would have an overall \"virtual\" range of -128 to 255 that may be used partially depending on which union member is accessed. Any function handling this union type would have to deal with integers in this complete range. More generally, the only valid operations on a union type are operations that are valid on both types being unioned. C's \"union\" concept is similar to union types, but is not typesafe, as it permits operations that are valid on either*type, rather than *both . Union types are important in program analysis, where they are used to represent symbolic values whose exact nature (e.g., value or type) is not known. In a subclassing hierarchy, the union of a type and an ancestor type (such as its parent) is the ancestor type. The union of sibling types is a subtype of their common ancestor (that is, all operations permitted on their common ancestor are permitted on the union type, but they may also have other valid operations in common). Existential types[ edit ] Main article: Existential quantifier Existential types are frequently used in connection with record types to represent modules and abstract data types , due to their ability to separate implementation from interface. For example, the type \"T = \u2203X { a: X; f: (X \u2192 int); }\" describes a module interface that has a data member named a of type X and a function named f that takes a parameter of the same type X and returns an integer. This could be implemented in different ways; for example: intT = { a: int; f: (int \u2192 int); } floatT = { a: float; f: (float \u2192 int); } These types are both subtypes of the more general existential type T and correspond to concrete implementation types, so any value of one of these types is a value of type T. Given a value \"t\" of type \"T\", we know that \"t.f(t.a)\" is well-typed, regardless of what the abstract type X is. This gives flexibility for choosing types suited to a particular implementation while clients that use only values of the interface type\u2014the existential type\u2014are isolated from these choices. In general it's impossible for the typechecker to infer which existential type a given module belongs to. In the above example intT { a: int; f: (int \u2192 int); } could also have the type \u2203X { a: X; f: (int \u2192 int); }. The simplest solution is to annotate every module with its intended type, e.g.: intT = { a: int; f: (int \u2192 int); } as \u2203X { a: X; f: (X \u2192 int); } Although abstract data types and modules had been implemented in programming languages for quite some time, it wasn't until 1988 that John C. Mitchell and Gordon Plotkin established the formal theory under the slogan: \"Abstract [data] types have existential type\".[ 24] The theory is a second-order typed lambda calculus similar to System F , but with existential instead of universal quantification. Gradual typing[ edit ] Main article: Gradual typing Gradual typing is a type system in which variables may be typed either at compile-time (which is static typing) or at run-time (which is dynamic typing), allowing software developers to choose either type paradigm as appropriate, from within a single language.[ 25] In particular, gradual typing uses a special type named dynamic*to represent statically-unknown types, and gradual typing replaces the notion of type equality with a new relation called *consistency that relates the dynamic type to every other type. The consistency relation is symmetric but not transitive.[ 26] Explicit or implicit declaration and inference Further information: Type inference Many static type systems, such as those of C and Java, require type declarations : The programmer must explicitly associate each variable with a specific type. Others, such as Haskell's, perform type inference : The compiler draws conclusions about the types of variables based on how programmers use those variables. For example, given a function f(x, y) that adds x and y together, the compiler can infer that x and y must be numbers \u2013 since addition is only defined for numbers. Thus, any call to f elsewhere in the program that specifies a non-numeric type (such as a string or list) as an argument would signal an error. Numerical and string constants and expressions in code can and often do imply type in a particular context. For example, an expression 3.14 might imply a type of floating-point , while [1, 2, 3] might imply a list of integers \u2013 typically an array . Type inference is in general possible, if it is decidable in the type theory in question. Moreover, even if inference is undecidable in general for a given type theory, inference is often possible for a large subset of real-world programs. Haskell's type system, a version of Hindley\u2013Milner , is a restriction of System F\u03c9 to so-called rank-1 polymorphic types, in which type inference is decidable. Most Haskell compilers allow arbitrary-rank polymorphism as an extension, but this makes type inference undecidable. (Type checking is decidable, however, and rank-1 programs still have type inference; higher rank polymorphic programs are rejected unless given explicit type annotations.) Unified type system[ edit ] Some languages like Perl 6 or C# have a unified type system.[ 27] This means that all C# types including primitive types inherit from a single root object. Every type in C# inherits from the Object class. Java has several primitive types that are not objects. Java provides wrapper object types that exist together with the primitive types so developers can use either the wrapper object types or the simpler non-object primitive types. Compatibility: equivalence and subtyping[ edit ] A type-checker for a statically typed language must verify that the type of any expression is consistent with the type expected by the context in which that expression appears. For example, in an assignment statement of the form x := *e* , the inferred type of the expression e must be consistent with the declared or inferred type of the variable x . This notion of consistency, called compatibility , is specific to each programming language. If the type of e and the type of x are the same, and assignment is allowed for that type, then this is a valid expression. Thus, in the simplest type systems, the question of whether two types are compatible reduces to that of whether they are equal (or equivalent ). Different languages, however, have different criteria for when two type expressions are understood to denote the same type. These different equational theories of types vary widely, two extreme cases being structural type systems , in which any two types that describe values with the same structure are equivalent, and nominative type systems , in which no two syntactically distinct type expressions denote the same type ( i.e. , types must have the same \"name\" in order to be equal). In languages with subtyping , the compatibility relation is more complex. In particular, if A is a subtype of B , then a value of type A can be used in a context where one of type B is expected, even if the reverse is not true. Like equivalence, the subtype relation is defined differently for each programming language, with many variations possible. The presence of parametric or ad hoc polymorphism in a language may also have implications for type compatibility. Notes[ edit ] Jump up^ The Burroughs ALGOL computer line determined a memory location's contents by its flag bits. Flag bits specify the contents of a memory location. Instruction, data type, and functions are specified by a 3 bit code in addition to its 48 bit contents. Only the MCP (Master Control Program) could write to the flag code bits. See also[ edit ] Computer programming portal Comparison of type systems Covariance and contravariance (computer science) Polymorphism in object-oriented programming Type rules Type signature Type theory References[ edit ] Jump up^ Pierce 2002 , p. 1: \"A type system is a tractable syntactic method for proving the absence of certain program behaviors by classifying phrases according to the kinds of values they compute.\" Jump up^ Cardelli 2004 , p. 1: \"The fundamental purpose of a type system is to prevent the occurrence of execution errors during the running of a program.\" Jump up^ Pierce 2002 , p. 208. Jump up^ Infoworld 25 April 1983 Jump up^ Brian Kernighan : Why Pascal is not my favorite language Jump up^ \"... any sound, decidable type system must be incomplete\" \u2014D. Remy (2017). p. 29, Remy, Didier. \"Type systems for programming languages\" (PDF). Retrieved 26 May2013. Jump up^ Pierce 2002 . Jump up^ \"dynamic (C# Reference)\" . MSDN Library . Microsoft. Retrieved 14 January 2014. Jump up^ Meijer, Erik; Drayton, Peter. \"Static Typing Where Possible, Dynamic Typing When Needed: The End of the Cold War Between Programming Languages\" (PDF). Microsoft Corporation. Jump up^ Laucher, Amanda; Snively, Paul. \"Types vs Tests\" . InfoQ. Jump up^ Xi, Hongwei; Scott, Dana (1998). \"Dependent Types in Practical Programming\". Proceedings of ACM SIGPLAN Symposium on Principles of Programming Languages . ACM Press: 214\u2013227. CiteSeerX 10.1.1.41.548 \u202f . Jump up^ Visual Basic is an example of a language that is both type-safe and memory-safe. Jump up^ Standard ECMA-262 . Ecma-international.org. Retrieved on 2013-07-17. Jump up^ Strict mode - JavaScript | MDN . Developer.mozilla.org (2013-07-03). Retrieved on 2013-07-17. Jump up^ Strict Mode (JavaScript) . Msdn.microsoft.com. Retrieved on 2013-07-17. Jump up^ Strict typing Jump up^ Bracha, G.: Pluggable Types Jump up^ https://stackoverflow.com/a/13414347/975097 Jump up^ Rozsnyai, S.; Schiefer, J.; Schatten, A. (2007). \"Concepts and models for typing events for event-based systems\". Proceedings of the 2007 inaugural international conference on Distributed event-based systems \u2013 DEBS '07 . p. 62. doi : 10.1145/1266894.1266904 . ISBN 9781595936653 . Jump up^ Martelli, Alex (26 July 2000). \"Re: polymorphism (was Re: Type checking in python?)\" . Usenet: 8lmvn6017l@news1.newsguy.com . Jump up^ Stefan Hanenberg. \u201dAn experiment about static and dynamic type systems: doubts about the positive impact of static type systems on development time\u201c. OOPSLA 2010. Jump up^ Kleinschmager, Hanenberg, Robbes, Tanter, Stefik: Do static type systems improve the maintainability of software systems? An empirical study. ICPC 2012 Jump up^ Hanenberg, Kleinschmager, S.Robbes, R.Tanter, Stefik: An empirical study on the impact of static typing on software maintainability, ESE 2014 Jump up^ Mitchell, John C.; Plotkin, Gordon D.; Abstract Types Have Existential Type , ACM Transactions on Programming Languages and Systems, Vol. 10, No. 3, July 1988, pp. 470\u2013502 Jump up^ Siek, Jeremy. \"What is gradual typing?\" . Jump up^ Siek, Jeremy; Taha, Walid (September 2006). Gradual Typing for Functional Languages (PDF). Scheme and Functional Programming 2006 . University of Chicago . pp. 81\u201392. Jump up^ Standard ECMA-334 , 8.2.4 Type system unification. Further reading","title":"Type-system"},{"location":"Theory/Type-system/Type-system/#type-system","text":"\u5728\u7f16\u7a0b\u8fc7\u7a0b\u4e2d\uff0c\u5c11\u4e0d\u4e86\u8ddf**\u7c7b\u578b**\u6253\u4ea4\u9053\uff1a\u6211\u4eec\u4f1a\u521b\u5efa\u4e00\u4e2a\u7c7b\u578b\uff08\u5982\u5b9a\u4e49\u4e00\u4e2a\u7c7b\uff09\uff0c\u6211\u4eec\u4f1a\u5bf9\u4e0d\u540c\u7c7b\u578b\u7684\u6570\u636e\u8fdb\u884c\u8fd0\u7b97\uff0c\u7b49\u7b49\u3002\u5982\u679c\u5bf9\u6570\u636e\u7684\u7c7b\u578b\u8ba4\u8bc6\u4e0d\u591f\uff0c\u5219\u4f1a\u5bfc\u81f4 \u7c7b\u578b\u9519\u8bef \u8fd9\u79cd\u5e38\u89c1\u7684\u7f16\u7a0b\u9519\u8bef\u3002\u6240\u4ee5\u5bf9**\u7f16\u7a0b\u8bed\u8a00**\u7684**\u7c7b\u578b\u7cfb\u7edf**\u6709\u4e00\u4e2a\u5b8c\u6574\u6df1\u523b\u7684\u8ba4\u77e5\u975e\u5e38\u91cd\u8981\u3002\u6211\u5728\u7f16\u7a0b\u8fc7\u7a0b\u4e2d\u4e5f\u66fe\u9677\u5165\u6df7\u6dc6\u3001\u8bef\u7528\u7c7b\u578b\u7684\u6df1\u6e0a\uff0c\u4e3a\u6b64\u641c\u5bfb\u5bf9**\u7f16\u7a0b\u8bed\u8a00**\u7684**\u7c7b\u578b\u7cfb\u7edf**\u6709\u5b8c\u6574\u4ecb\u7ecd\u7684\u6587\u7ae0\uff0c\u4e0b\u9762\u8fd9\u7bc7\u6587\u7ae0\u6211\u89c9\u5f97\u975e\u5e38\u597d\uff0c\u6e90\u81ea\u7ef4\u57fa\u767e\u79d1\uff0c\u539f\u6587\u662f\u5168\u82f1\u7684\uff0c\u6211\u81ea\u5df1\u5728\u9605\u8bfb\u8fc7\u7a0b\u4e2d\u6dfb\u52a0\u4e86\u4e00\u4e9b\u6ce8\u91ca\u548c\u7ffb\u8bd1\u3002","title":"Type system"},{"location":"Theory/Type-system/Type-system/#type-system_1","text":"This article is about type systems from the point-of-view of computer programming. For a theoretical formulation(\u9610\u8ff0), see type theory . In programming languages , a type system is a set of rules that assigns a property called type to the various constructs(\u7ec4\u6210\u90e8\u5206) of a computer program , such as variables , expressions , functions or modules (\u5c06\u7c7b\u578b\u4f5c\u4e3a\u4e00\u4e2a\u5c5e\u6027).[ 1] These types formalize and enforce the otherwise implicit categories the programmer uses for data structures and components (e.g. \"string\", \"array of float\", \"function returning boolean\")(\u8fd9\u6bb5\u8bdd\u4e2d\u201cthe programmer uses for data structures and components \u201d\u662f\u5b9a\u8bed\uff0c\u4fee\u9970categories\uff0c\u5b57\u9762\u610f\u601d\u662f\uff1a\u7c7b\u578b\u5f62\u5f0f\u5316\u5e76\u5f3a\u5236\u6267\u884c\u7a0b\u5e8f\u5458\u7528\u4e8e\u6570\u636e\u7ed3\u6784\u548c\u7ec4\u4ef6\u7684\u9690\u5f0f\u7c7b\u522b\u3002\u5404\u79cd\u7f16\u7a0b\u8bed\u8a00\u4e2d\u90fd\u4f1a\u63d0\u4f9b\u57fa\u672c\u7c7b\u578b\uff0c\u5982int\uff0cfloat\u7b49\uff0c\u4e5f\u4f1a\u63d0\u4f9b\u4e00\u4e9b\u590d\u5408\u7c7b\u578b\uff0c\u5982\u5bb9\u5668string\u7b49\u3002\u663e\u7136\u8fd9\u4e9b\u590d\u5408\u7c7b\u578b\u7684\u5b9a\u4e49\u662f\u79bb\u4e0d\u5f00\u57fa\u672c\u7c7b\u578b\u7684\u3002). The main purpose of a type system is to reduce possibilities for bugs in computer programs[ 2] by defining interfaces between different parts of a computer program, and then checking that the parts have been connected in a consistent way. This checking can happen statically (at compile time ), dynamically (at run time ), or as a combination of static and dynamic checking. Type systems have other purposes as well, such as expressing business rules(\u8868\u8fbe\u4e1a\u52a1\u89c4\u5219), enabling certain compiler optimizations, allowing for multiple dispatch (\u5141\u8bb8\u591a\u7ea7\u8c03\u7528), providing a form of documentation, etc. A type system associates a type with each computed value and, by examining the flow of these values, attempts to ensure or prove that no type errors can occur. The given type system in question determines exactly what constitutes(\u6784\u6210) a type error, but in general the aim is to prevent operations expecting a certain kind of value from being used with values for which that operation does not make sense ( logic errors ). Type systems are often specified as part of programming languages , and built into the interpreters and compilers for them; although the type system of a language can be extended by optional tools that perform added kinds of checks using the language's original type syntax and grammar. \u603b\u7ed3\uff1a\u524d\u9762\u8fd9\u6bb5\u6587\u5b57\u4e3b\u8981\u9610\u8ff0\u4e86\u8fd9\u4e9b\u5185\u5bb9\uff1a \u4ec0\u4e48\u662f\u7c7b\u578b \u7f16\u7a0b\u8bed\u8a00\u4e2d\u4e3a\u4ec0\u4e48\u8981\u4f7f\u7528\u7c7b\u578b\u5373\u4f7f\u7528\u7c7b\u578b\u80fd\u591f\u4e3a\u7f16\u7a0b\u8bed\u8a00\u5e26\u6765\u4ec0\u4e48\u597d\u5904 \u7c7b\u578b\u7cfb\u7edf\u7684\u7ec4\u6210 Q&A : \u8fd0\u884c\u65f6\u7c7b\u578b\u68c0\u67e5\u662f\u4ec0\u4e48\uff1f\u662f\u548c\u591a\u6001\u6709\u5173\u7684\u5417\uff1f","title":"\u7ef4\u57fa\u767e\u79d1Type system"},{"location":"Theory/Type-system/Type-system/#usage-overview","text":"An example of a simple type system is that of the C language . The portions(\u7ec4\u6210\u90e8\u5206) of a C program are the function definitions. One function is invoked by another function. The interface of a function states the name of the function and a list of values that are passed to the function's code. The code of an invoking function states the name of the invoked, along with the names of variables that hold values to pass to it. During execution, the values are placed into temporary storage , then execution jumps to the code of the invoked function. The invoked function's code accesses the values and makes use of them. If the instructions inside the function are written with the assumption of receiving an integer value, but the calling code passed a floating-point value, then the wrong result will be computed by the invoked function. The C compiler checks the type declared for each variable sent, against the type declared for each variable in the interface of the invoked function(C\u7f16\u8bd1\u5668\u4f1a\u68c0\u67e5\u51fd\u6570\u5f62\u53c2\u7684\u7c7b\u578b\uff0c\u4ee5\u53ca\u8c03\u7528\u51fd\u6570\u65f6\u5019\u4f20\u5165\u7684\u5b9e\u53c2\u7684\u7c7b\u578b). If the types do not match, the compiler throws a compile-time error(\u5982\u679c\u7c7b\u578b\u4e0d\u5339\u914d\uff0c\u5219\u7f16\u8bd1\u5668\u5728\u7f16\u8bd1\u9636\u6bb5\u5c31\u4f1a\u629b\u51fa\u4e00\u4e2a\u7f16\u8bd1\u9519\u8bef). \u603b\u7ed3\uff1a\u8fd9\u6bb5\u8bdd\u4ee5C\u7f16\u8bd1\u5668\u7684**\u9759\u6001\u7c7b\u578b\u68c0\u67e5**\u4e3a\u4f8b\u6765\u8bf4\u660e\u7c7b\u578b\u7684\u4e00\u4e2a\u4f5c\u7528 A compiler may also use the static type of a value to optimize the storage it needs and the choice of algorithms for operations on the value. In many C compilers the float data type , for example, is represented in 32 bits , in accord with(\u4e0e\u4ec0\u4e48\u4e00\u81f4) the IEEE specification for single-precision floating point numbers . They will thus use floating-point-specific microprocessor operations on those values (floating-point addition, multiplication, etc.)(\u5b83\u4eec\u5c06\u5bf9\u8fd9\u4e9b\u503c\u4f7f\u7528\u6d6e\u70b9\u7279\u5b9a\u7684\u5fae\u5904\u7406\u5668\u64cd\u4f5c\uff08\u6d6e\u70b9\u52a0\u6cd5\uff0c\u4e58\u6cd5\u7b49\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u4f18\u5316). \u603b\u7ed3\uff1a\u8fd9\u6bb5\u80e1\u4ee5float\u7c7b\u578b\u7684\u6570\u636e\u4e3a\u4f8b\u6765\u8bf4\u660e\uff1a\u7f16\u8bd1\u5668\u5728\u6c47\u7f16\u9636\u6bb5\u53ef\u4ee5\u6839\u636evalue\u7684static type\u6765\u4f18\u5316\u5bf9\u8be5value\u7684\u5b58\u50a8\u4ee5\u53ca\u9009\u62e9\u5904\u7406\u8be5value\u7684\u6307\u4ee4\u3002 The depth of type constraints(\u7c7b\u578b\u9650\u5236) and the manner of their evaluation(\u7c7b\u578b\u63a8\u65ad) affect the typing of the language. A programming language may further associate an operation with various resolutions for each type, in the case of type polymorphism (\u5728\u7c7b\u578b\u591a\u6001\u6027\u7684\u60c5\u51b5\u4e0b\uff0c\u7f16\u7a0b\u8bed\u8a00\u53ef\u4ee5\u8fdb\u4e00\u6b65\u5c06\u64cd\u4f5c\u4e0e\u6bcf\u79cd\u7c7b\u578b\u7684\u5404\u79cd\u5206\u8fa8\u7387\u76f8\u5173\u8054\u3002\u6b64\u5904\u5c06resolutions\u7ffb\u8bd1\u4e3a\u5206\u8fa8\u7387\uff0c\u611f\u89c9\u662f\u4e0d\u5bf9\u7684). Type theory is the study of type systems. The concrete types of some programming languages, such as integers and strings, depend on practical issues of computer architecture, compiler implementation, and language design.","title":"Usage overview"},{"location":"Theory/Type-system/Type-system/#fundamentals","text":"Formally, type theory studies type systems. A programming language must have occurrence to type check using the type system whether at compile time or runtime, manually annotated or automatically inferred. \u603b\u7ed3\uff1a\u65e0\u8bba\u662f\u5728\u7f16\u8bd1\u65f6\u8fd8\u662f\u5728\u8fd0\u884c\u65f6\uff0c\u624b\u52a8\u6ce8\u91ca\u6216\u81ea\u52a8\u63a8\u65ad\uff0c\u7f16\u7a0b\u8bed\u8a00\u90fd\u5fc5\u987b\u4f7f\u7528\u7c7b\u578b\u7cfb\u7edf\u8fdb\u884c\u7c7b\u578b\u68c0\u67e5\u3002 As Mark Manasse concisely put it:[ 3] The fundamental problem addressed by a type theory is to ensure that programs have meaning. The fundamental problem caused by a type theory is that meaningful programs may not have meanings ascribed to\uff08\u5f52\u5c5e\u4e8e\uff09 them. The quest for richer type systems results from this tension. \u603b\u7ed3\uff1aMark Manasse\u7684\u89c2\u70b9\u662f**\u7c7b\u578b**\u4f7f\u7a0b\u5e8f\u5177\u6709**\u610f\u4e49**\uff0c\u4e0b\u9762\u7684\u8bdd\u5bf9\u8fd9\u4e2a\u89c2\u70b9\u8fdb\u884c\u4e86\u9610\u8ff0\uff1a Assigning a data type, termed typing , gives meaning to a sequence of bits such as a value in memory or some object such as a variable . The hardware of a general purpose computer is unable to discriminate(\u533a\u5206) between for example a memory address and an instruction code (\u6307\u4ee4\u4ee3\u7801), or between a character , an integer , or a floating-point number , because it makes no intrinsic distinction(\u533a\u5206) between any of the possible values that a sequence of bits might mean (\u8fd9\u6bb5\u8bdd\u7684\u610f\u601d\u662f\u5f53\u6211\u4eec\u5c06\u9ad8\u7ea7\u8bed\u8a00\u6240\u7f16\u5199\u7684\u7a0b\u5e8f\u7ffb\u8bd1\u6210\u4e8c\u8fdb\u5236\u7a0b\u5e8f\u540e\uff0c\u786c\u4ef6\u5c42\uff0c\u6bd4\u5982CPU\uff0c\u5728\u6267\u884c\u8fd9\u4e9b\u4e8c\u8fdb\u5236\u7a0b\u5e8f\u7684\u65f6\u5019\uff0c\u5e76\u4e0d\u4f1a\u5173\u5fc3\u8fd9\u4e9b\u4e8c\u8fdb\u5236\u6570\u636e\u6240\u4ee3\u8868\u7684\u542b\u4e49\uff08\u8fd9\u4e9b\u6570\u636e\u8868\u793a\u7684\u662f\u5185\u5b58\u5730\u5740\uff0c\u8fd8\u662f\u6307\u4ee4\u7801\uff0c\u7b49\u7b49\uff09\uff0c\u4e5f\u5c31\u662f\u786c\u4ef6\u5c42\u538b\u6839\u5c31\u6ca1\u6709\u7c7b\u578b\u7684\u6982\u5ff5\uff0c\u5bf9\u5b83\u4eec\u800c\u8a00\uff0c\u6240\u6709\u7684\u4e00\u5207\u90fd\u662f\u4e8c\u8fdb\u5236\u6570).[ note 1] Associating a sequence of bits with a type conveys that meaning to the programmable hardware to form a symbolic system composed of that hardware and some program(\u5c06\u4e8c\u8fdb\u5236\u4e32\u548c\u7c7b\u578b\u76f8\u5173\u8054\u80fd\u591f\u5c06\u7c7b\u578b\u7684\u610f\u4e49\u4f20\u9012\u5230\u53ef\u7f16\u7a0b\u786c\u4ef6\uff0c\u8fd9\u6837\u53ef\u4ee5\u5b9e\u73b0\u7531\u786c\u4ef6\u548c\u7a0b\u5e8f\u7ec4\u6210\u7684symbolic system). A program associates each value with at least one specific type, but it also can occur that one value is associated with many subtypes . Other entities, such as objects , modules , communication channels, and dependencies can become associated with a type. Even a type can become associated with a type. An implementation of a type system could in theory associate identifications called data type (a type of a value), class (a type of an object), and kind (a type of a type , or metatype ). These are the abstractions that typing can go through, on a hierarchy of levels contained in a system. \u603b\u7ed3\uff1a\u7a0b\u5e8f\u4e3a\u6bcf\u4e2avalue\u5173\u8054\u4e00\u4e2a\u7c7b\u578b\uff0c\u6709\u53ef\u80fd\u51fa\u73b0\u7684\u4e00\u79cd\u60c5\u51b5\u662f\u4e00\u4e2avalue\u53ef\u4ee5\u5173\u8054\u591a\u4e2a\u5b50\u7c7b\u578b\u3002\u5176\u4ed6\u7a0b\u5e8f\u7ec4\u6210\u90e8\u5206\uff0c\u6bd4\u5982object\uff0cmodule\uff0c\u7b49\u7b49\uff0c\u4e5f\u90fd\u53ef\u4ee5\u548c\u4e00\u4e2a\u7c7b\u578b\u76f8\u5173\u8054\u3002\u663e\u7136\u7c7b\u578b\u7cfb\u7edf\u4e2d\u53ef\u4ee5\u5305\u542b\u7684\u7c7b\u578b\u662f\u975e\u5e38\u6bd4\u8f83\u591a\uff0c\u6bd4\u8f83\u590d\u6742\u7684\u3002\u7c7b\u578b\u7cfb\u7edf\u4e00\u79cd\u7406\u8bba\u4e0a\u7684\u5b9e\u73b0\u65b9\u5f0f\u662f\u4ee5hierarchy\u5373\u5c42\u7684\u65b9\u5f0f\u6765\u5bf9\u5404\u79cd\u7c7b\u578b\u8fdb\u884c\u5b9a\u4e49\u3002 When a programming language evolves a more elaborate(\u590d\u6742) type system, it gains a more finely grained(\u7ec6\u5316) rule set than basic type checking, but this comes at a price when the type inferences (and other properties) become undecidable (\u4e0d\u53ef\u5224\u5b9a), and when more attention must be paid by the programmer to annotate(\u6ce8\u91ca) code or to consider computer-related operations and functioning. It is challenging to find a sufficiently expressive type system that satisfies all programming practices in a type safe manner. \u603b\u7ed3\uff1a\u968f\u7740\u7f16\u7a0b\u8bed\u8a00\u7684\u8fdb\u5316\uff0c\u7c7b\u578b\u7cfb\u7edf\u4e5f\u4f1a\u53d8\u5f97\u66f4\u52a0\u590d\u6742\uff0c\u9664\u4e86\u6700\u57fa\u672c\u7684type checking\uff0c\u7c7b\u578b\u7cfb\u7edf\u5c06\u4f1a\u5305\u542b\u66f4\u52a0\u7ec6\u5316\u7684\u89c4\u5219\u96c6\uff0c\u4f46\u662f\u66f4\u52a0\u7ec6\u5316\u7684\u89c4\u5219\u96c6\u4e5f\u610f\u5473\u7740\u7c7b\u578b\u63a8\u5bfc\u53ef\u80fd\u53d8\u5f97\u4e0d\u786e\u5b9a\uff0c\u4e5f\u610f\u5473\u7740\u7a0b\u5e8f\u5458\u9700\u8981\u82b1\u8d39\u66f4\u591a\u7684\u7cbe\u529b\u5728\u5bf9\u4ee3\u7801\u8fdb\u884c\u6ce8\u91ca\uff0c\u601d\u8003\u4e0e\u8ba1\u7b97\u673a\u76f8\u5173\u7684\u64cd\u4f5c\uff0c\u529f\u80fd\u7b49\u3002\u6240\u4ee5\u5bfb\u627e\u5230\u4e00\u4e2a\u65e2\u7c7b\u578b\u5b89\u5168\uff0c\u6709\u6ee1\u8db3\u6240\u6709\u7f16\u7a0b\u6700\u4f73\u5b9e\u8df5\u7684\uff0c\u5e76\u4e14\u5177\u6709\u8db3\u591f\u8868\u8fbe\u529b\u7684\u7c7b\u578b\u7cfb\u7edf\u662f\u5177\u6709\u6311\u6218\u6027\u7684\u3002 The more type restrictions that are imposed by the compiler, the more strongly typed a programming language is. Strongly typed languages (\u5f3a\u7c7b\u578b\u8bed\u8a00) often require the programmer to make explicit conversions(\u663e\u793a\u7c7b\u578b\u8f6c\u6362) in contexts where an implicit conversion would cause no harm(\u5f3a\u7c7b\u578b\u8bed\u8a00\u901a\u5e38\u9700\u8981\u7a0b\u5e8f\u5458\u5728\u9690\u5f0f\u8f6c\u6362\u4e0d\u4f1a\u9020\u6210\u4f24\u5bb3\u7684\u4e0a\u4e0b\u6587\u4e2d\u8fdb\u884c\u663e\u5f0f\u8f6c\u6362). Pascal's type system has been described as \"too strong\" because, for example, the size of an array or string is part of its type, making some programming tasks difficult.[ 4] [ 5] Haskell is also strongly typed but its types are automatically inferred(\u7c7b\u578b\u662f\u81ea\u52a8\u63a8\u5bfc\u7684) so that explicit conversions are often (but not always) unnecessary. \u603b\u7ed3\uff1a\u5982\u679c\u4ece\u7c7b\u578b\u9650\u5236\u7684\u5f3a\u5f31\u6765\u5224\u5b9a\u7f16\u7a0b\u8bed\u8a00\u7684\u8bdd\uff0c\u90a3\u4e9b\u7c7b\u578b\u9650\u5236\u8f83\u5f3a\u7684\u8bed\u8a00\u5c31\u53ef\u4ee5\u79f0\u4e4b\u4e3a\u201c\u5f3a\u7c7b\u578b\u8bed\u8a00\u201d\u3002\u4ece\u4f5c\u8005\u6240\u5217\u4e3e\u7684**Pascal**\u548c**Haskell**\u7684\u4f8b\u5b50\u6765\u770b\uff0c\u7f16\u7a0b\u8bed\u8a00\u5982\u4f55\u4e3a\u7a0b\u5e8f\u5458\u51cf\u4f4e\u7f16\u7a0b\u7684\u5de5\u4f5c\u91cf\u662f\u975e\u5e38\u91cd\u8981\u7684\uff0c\u4e24\u8005\u540c\u4e3a\u5f3a\u7c7b\u578b\u8bed\u8a00\uff0c\u4f46\u662fHaskell\u7684\u81ea\u52a8\u7c7b\u578b\u63a8\u5bfc\u673a\u5236\u663e\u7136\u51cf\u4f4e\u4e86\u5176\u7f16\u7a0b\u7684\u5de5\u4f5c\u91cf\u3002 A programming language compiler can also implement a dependent type or an effect system , which enables even more program specifications to be verified by a type checker. Beyond simple value-type pairs, a virtual \"region\" of code is associated with an \"effect\" component describing what is being done with what , and enabling for example to \"throw\" an error report. Thus the symbolic system may be a type and effect system , which endows it with more safety checking than type checking alone. \u603b\u7ed3\uff1a\u7f16\u7a0b\u8bed\u8a00\u7f16\u8bd1\u5668\u4e5f\u53ef\u4ee5\u5b9e\u73b0dependent type\u6216effect system\uff0c\u8fd9\u4f7ftype checker\u53ef\u4ee5\u9a8c\u8bc1\u66f4\u591a\u7684\u7a0b\u5e8f\u89c4\u8303\u3002 \u9664\u7b80\u5355\u7684value-type\u5bf9\u4e4b\u5916\uff0c\u4ee3\u7801\u7684\u865a\u62df\u201cregion\u201d\u53ef\u4ee5\u548c\u4e00\u4e2a\"effect\"**\u7ec4\u4ef6**\u76f8\u5173\u8054\uff0c\u8fd9\u4e2a**\u7ec4\u4ef6**\u80fd\u591f\u63cf\u8ff0\u6b63\u5728\u505a\u4ec0\u4e48\u3001\u201c\u629b\u51fa\u201d\u9519\u8bef\u62a5\u544a\u3002 \u56e0\u6b64\uff0csymbolic system \u53ef\u80fd\u662f\u4e00\u4e2a*type and effect system*\uff0c\u5373\u9664\u4e86type\uff0c\u5b83\u8fd8\u6d89\u53caeffect\uff0c\u5b83\u6bd4\u5355\u7eaf\u7684\u7c7b\u578b\u68c0\u67e5\u8d4b\u4e88\u5b83\u66f4\u591a\u7684\u5b89\u5168\u68c0\u67e5\u3002 Whether automated by the compiler or specified by a programmer , a type system makes program behavior illegal if outside the type-system rules(\u7c7b\u578b\u7cfb\u7edf\u65e0\u8bba\u662f\u7531\u7f16\u8bd1\u5668\u81ea\u52a8\u6267\u884c\u8fd8\u662f\u7531\u7a0b\u5e8f\u5458\u6307\u5b9a\uff0c\u5982\u679c\u7a0b\u5e8f\u4e0d\u7b26\u5408\u7c7b\u578b\u7cfb\u7edf\u7684\u89c4\u5219\uff0c\u5219\u7a0b\u5e8f\u884c\u4e3a\u5c31\u6709\u53ef\u80fd\u53d8\u5f97\u975e\u6cd5). Advantages provided by programmer-specified type systems include: Abstraction (or modularity ) \u2013 Types enable programmers to think at a higher level than the bit or byte, not bothering with low-level implementation. For example, programmers can begin to think of a string as a set of character values instead of as a mere array of bytes. Higher still, types enable programmers to think about and express interfaces between two of any -sized subsystems. This enables more levels of localization so that the definitions required for interoperability of the subsystems remain consistent when those two subsystems communicate. Documentation \u2013 In more expressive type systems, types can serve as a form of documentation clarifying the intent of the programmer. For example, if a programmer declares a function as returning a timestamp type, this documents the function when the timestamp type can be explicitly declared deeper in the code to be an integer type. Advantages provided by compiler-specified type systems include: Optimization \u2013 Static type-checking may provide useful compile-time information. For example, if a type requires that a value must align in memory at a multiple of four bytes, the compiler may be able to use more efficient machine instructions. Safety \u2013 A type system enables the compiler to detect meaningless or probably invalid code. For example, we can identify an expression 3 / \"Hello, World\" as invalid, when the rules do not specify how to divide an integer by a string . Strong typing offers more safety, but cannot guarantee complete type safety . \u603b\u7ed3\uff1a\u7c7b\u578b\u7cfb\u7edf\u53ef\u4ee5\u7531\u7f16\u8bd1\u5668\u6765\u5b9e\u73b0\uff08\u8fd9\u662f\u4e3b\u6d410\uff09\uff0c\u5f53\u7136\u4e5f\u53ef\u4ee5\u7531\u7a0b\u5e8f\u5458\u6765\u8fdb\u884c\u6307\u5b9a\uff0c\u65e0\u8bba\u662f\u6709\u8c01\uff0c\u5982\u679c\u67e5\u8be2\u4e0d\u7b26\u5408\u7c7b\u578b\u89c4\u5219\uff0c\u5219\u7a0b\u5e8f\u7684\u884c\u4e3a\u90fd\u53ef\u80fd\u662f\u975e\u6cd5\u7684\u3002\u5e76\u4e14\u4e0a\u9762\u7684\u5185\u5bb9\u8fd8\u8ba8\u8bba\u4e86programmer-specified type systems\u548ccompiler-specified type systems\u5404\u81ea\u7684\u4f18\u52bf\u3002","title":"Fundamentals"},{"location":"Theory/Type-system/Type-system/#type-errors","text":"A type error is an unintended condition which might manifest(\u51fa\u73b0) in multiple stages of a program's development. Thus a facility for detection of the error is needed in the type system . In some languages, such as Haskell, for which type inference is automated, lint might be available to its compiler to aid in the detection of error. Type safety contributes to program correctness , but can only guarantee correctness at the cost of making the type checking itself an undecidable problem .In a type system with automated type checking a program may prove to run incorrectly yet be safely typed, and produce no compiler errors. Division by zero is an unsafe and incorrect operation, but a type checker running at compile time only doesn't scan for division by zero in most languages, and then it is left as a runtime error . To prove the absence of these more-general-than-types defects, other kinds of formal methods , collectively known as program analyses , are in common use. Alternatively, a sufficiently expressive type system, such as in dependently typed languages, can prevent these kinds of errors (for example, expressing the type of non-zero numbers ). In addition software testing is an empirical method for finding errors that the type checker cannot detect.","title":"Type errors"},{"location":"Theory/Type-system/Type-system/#type-checking","text":"The process of verifying and enforcing the constraints of types\u2014 type checking \u2014may occur either at compile-time (a static check) or at run-time . If a language specification(\u8bed\u8a00\u89c4\u8303) requires its typing rules strongly (i.e., more or less allowing only those automatic type conversions that do not lose information(\u5373\u6216\u591a\u6216\u5c11\u53ea\u5141\u8bb8\u90a3\u4e9b\u4e0d\u4f1a\u4e22\u5931\u4fe1\u606f\u7684\u81ea\u52a8\u7c7b\u578b\u8f6c\u6362)), one can refer to the process as strongly typed , if not, as weakly typed . The terms are not usually used in a strict sense. Q&A : \u54ea\u4e9b\u7c7b\u578b\u4e4b\u95f4\u662f\u80fd\u591f\u8fdb\u884c\u81ea\u52a8\u7c7b\u578b\u8f6c\u6362\u7684\u5462\uff1f","title":"Type checking"},{"location":"Theory/Type-system/Type-system/#static-type-checking","text":"Static type checking is the process of verifying the type safety of a program based on analysis of a program's text (source code). If a program passes a static type checker, then the program is guaranteed to satisfy some set of type safety properties for all possible inputs. Static type checking can be considered a limited form of program verification (see type safety ), and in a type-safe language, can be considered also an optimization. If a compiler can prove that a program is well-typed, then it does not need to emit dynamic safety checks , allowing the resulting compiled binary to run faster and to be smaller. Static type checking for Turing-complete languages is inherently(\u672c\u8d28\u4e0a) conservative. That is, if a type system is both sound (meaning that it rejects all incorrect programs) and decidable (meaning that it is possible to write an algorithm that determines whether a program is well-typed), then it must be incomplete (meaning there are correct programs, which are also rejected, even though they do not encounter runtime errors).[ 6] \u603b\u7ed3\uff1a\u4e0a\u9762\u4e09\u6bb5\u8bdd\u5bf9\u9759\u6001\u7c7b\u578b\u68c0\u67e5\u8fdb\u884c\u4e86\u4ecb\u7ecd\uff0c\u5176\u4e2d\u7b2c\u4e00\u6bb5\u8bdd\u548c\u7b2c\u4e8c\u6bb5\u8bdd\u662f\u6bd4\u8f83\u597d\u7406\u89e3\u7684\uff0c\u6bd4\u8f83\u96be\u7406\u89e3\u7684\u662f\u7b2c\u4e09\u6bb5\u8bdd\u3002\u5176\u5b9e\u5982\u679c\u7ed3\u5408\u4e0b\u9762 \u8fd9\u4e2a\u4f8b\u5b50\u7684\u8bdd\uff0c\u7b2c\u4e09\u6bb5\u8bdd\u7684\u542b\u4e49\u4e5f\u662f\u53ef\u4ee5\u5012\u63a8\u51fa\u6765\u7684\u3002\u7b2c\u4e09\u6bb5\u8bdd\u7684\u610f\u601d\u662f\uff1a\u5bf9\u4e8e**Turing-complete languages** \u800c\u8a00\uff0c\u9759\u6001\u7c7b\u578b\u68c0\u67e5\u662f\u4fdd\u5b88\u7684\u3002\u5982\u679c\u4e00\u4e2a\u7c7b\u578b\u7cfb\u7edf\u662fsound\u548cdecidable\u7684\uff0c\u90a3\u4e48\u5b83\u4e00\u5b9a\u662fincomplete\u7684\uff08\u610f\u5473\u7740\u4e00\u4e2a\u6b63\u786e\u7684\u7a0b\u5e8f\uff0c\u5373\u4f7f\u5b83\u4e0d\u4f1a\u4ea7\u751f\u8fd0\u884c\u65f6\u9519\u8bef\uff0c\u4f46\u662f\u9759\u6001\u7c7b\u578b\u68c0\u67e5\u8fd8\u662f\u4f1a\u8ba4\u4e3a\u5b83\u662f\u9519\u8bef\u7684\u800c\u62d2\u7edd\u5b83\uff09\u3002\u6bd4\u5982\u4e0b\u9762\u7684\u8fd9\u4e2a\u4f8b\u5b50\uff0c\u5982\u679c complex text \u6c38\u8fdc\u662f true \uff0c\u5219 else \u5206\u652f\u5c06\u6c38\u8fdc\u90fd\u4e0d\u4f1a\u88ab\u6267\u884c\u5230\uff0c\u90a3\u4e48 else \u5206\u652f\u4e2d\u7684\u4ee3\u7801\u5c31\u4e0d\u4f1a\u4ea7\u751f\u8fd0\u884c\u65f6\u9519\u8bef\uff0c\u4f46\u662f\u5927\u591a\u6570type checker\u662f\u4f1a\u62d2\u7edd\u8fd9\u4e2a\u4ee3\u7801\u7684\u3002 For example, consider a program containing the code: if <complex test> then <do something> else <generate type error> Even if the expression <complex test> always evaluates to true at run-time, most type checkers will reject the program as ill-typed, because it is difficult (if not impossible) for a static analyzer to determine that the else branch will not be taken.[ 7] Conversely, a static type checker will quickly detect type errors in rarely used code paths. Without static type checking , even code coverage tests with 100% coverage may be unable to find such type errors. The tests(\u6307\u524d\u9762\u63d0\u5230\u7684code coverage tests ) may fail to detect such type errors, because the combination of all places where values are created and all places where a certain value is used must be taken into account. \u603b\u7ed3\uff1a\u8fd9\u6bb5\u8bdd\u662f\u7ed3\u5408\u4e0a\u9762\u7684\u90a3\u4e2a\u5c0f\u7a0b\u5e8f\u5bf9type checker\u8fdb\u884c\u4e86\u4e00\u4e2a\u8fa9\u8bc1\u5730\u5206\u6790\u3002 A number of useful and common programming language features cannot be checked statically, such as downcasting . Thus, many languages will have both static and dynamic type checking; the static type checker verifies what it can, and dynamic checks verify the rest. Many languages with static type checking provide a way to bypass(\u7ed5\u8fc7) the type checker . Some languages allow programmers to choose between static and dynamic type safety. For example, C# distinguishes between statically-typed and dynamically-typed variables. Uses of the former are checked statically, whereas uses of the latter are checked dynamically. Other languages allow writing code that is not type-safe. For example, in C , programmers can freely cast a value between any two types that have the same size. \u603b\u7ed3\uff1a\u4e00\u4e9b\u975e\u5e38\u6709\u7528\u7684\u8bed\u8a00\u7279\u6027\u662f\u65e0\u6cd5\u8fdb\u884c\u9759\u6001\u68c0\u67e5\u7684\uff0c\u6240\u4ee5\u5f88\u591a\u7f16\u7a0b\u8bed\u8a00\u65e2\u6709\u9759\u6001\u7c7b\u578b\u68c0\u67e5\u53c8\u6709\u52a8\u6001\u7c7b\u578b\u68c0\u67e5\u3002\u5e76\u4e14\u7ed3\u5408\u524d\u9762\u7684\u90a3\u4e2a\u5bf9\u9759\u6001\u7c7b\u578b\u68c0\u67e5\u8fdb\u884c\u5206\u6790\u7684\u4f8b\u5b50\uff0c\u53ef\u4ee5\u770b\u51fa\u6709\u65f6\u5019\u662f\u4e0d\u9700\u8981\u8fdb\u884c\u9759\u6001\u7c7b\u578b\u68c0\u67e5\u7684\uff0c\u6240\u4ee5\u6709\u7684\u7f16\u7a0b\u8bed\u8a00\u5c31\u5141\u8bb8\u7531\u7a0b\u5e8f\u5458\u6765\u6307\u5b9a\u662f\u5426\u8fdb\u884c\u9759\u6001\u7c7b\u578b\u68c0\u67e5\u548c\u52a8\u6001\u7c7b\u578b\u68c0\u67e5\uff0c\u6bd4\u5982 C# \uff0c\u6765\u51b3\u5b9a\u7a0b\u5e8f\u662f\u5426\u6ee1\u8db3**\u9759\u6001\u7c7b\u578b\u5b89\u5168\u6027**\u548c**\u52a8\u6001\u7c7b\u578b\u5b89\u5168\u6027**\uff1b\u751a\u81f3\u6709\u7684\u8bed\u8a00\u5e76\u4e0d\u8981\u6c42\u7c7b\u578b\u5b89\u5168\uff0c\u6bd4\u5982 C \u8bed\u8a00\uff0c\u5b83\u5141\u8bb8\u5bf9\u76f8\u540c\u5927\u5c0f\u7684\u7c7b\u578b\u8fdb\u884c\u8f6c\u6362\u3002\u8bf7\u53c2\u7167\u4e0b\u9762\u8fd9\u4e2a\u94fe\u63a5\u6765\u770b\u54ea\u4e9b\u8bed\u8a00\u662f\u4f1a\u8fdb\u884c\u9759\u6001\u7c7b\u578b\u68c0\u67e5\u7684\u3002 For a list of languages with static type checking, see the category for statically typed languages .","title":"Static type checking"},{"location":"Theory/Type-system/Type-system/#dynamic-type-checking-and-runtime-type-information","text":"Dynamic type checking is the process of verifying the type safety of a program at runtime. Implementations of dynamically type-checked languages generally associate each runtime object with a type tag (i.e., a reference to a type) containing its type information . This runtime type information ( RTTI ) can also be used to implement dynamic dispatch , late binding , downcasting , reflection , and similar features. \u603b\u7ed3\uff1a\u8fd9\u6bb5\u8bdd\u7ed9\u51fa\u4e86**Dynamic type checking** \u5373\u52a8\u6001\u7c7b\u578b\u68c0\u67e5\u7684\u542b\u4e49\u7684\u89e3\u91ca\uff0c\u4ee5\u53ca\u5176\u5b9e\u73b0\u65b9\u5f0f\uff1aRTTI\uff0c\u5e76\u4e14\u8fd9\u91cc\u8fd8\u63d0\u5230\u4e86RTTI\u5904\u7406\u53ef\u4ee5\u7528\u4e8e**Dynamic type checking** \u5916\uff0c\u8fd8\u53ef\u4ee5\u7528\u4e8e\u5b9e\u73b0 dynamic dispatch , late binding , downcasting , reflection , and similar features. Most type-safe languages include some form of dynamic type checking , even if they also have a static type checker. The reason for this is that many useful features or properties are difficult or impossible to verify statically. For example, suppose that a program defines two types, A and B, where B is a subtype of A. If the program tries to convert a value of type A to type B, which is known as downcasting , then the operation is legal only if the value being converted is actually a value of type B(\u5982\u679c\u7528python\u6765\u89e3\u91ca\u7684\u8bdd\u5c31\u662ftype()==B). Thus, a dynamic check is needed to verify that the operation is safe. This requirement is one of the criticisms(\u6279\u8bc4) of downcasting . \u603b\u7ed3\uff1a\u8fd9\u6bb5\u8bdd\u4ee5**downcasting**\u4e3a\u4f8b\u8bf4\u660e\u4e86\u4e3a\u4ec0\u4e48\u7f16\u7a0b\u8bed\u8a00\u9700\u8981**dynamic type checking**\u3002 By definition, dynamic type checking may cause a program to fail at runtime. In some programming languages, it is possible to anticipate and recover from these failures. In others, type-checking errors are considered fatal. Programming languages that include dynamic type checking but not static type checking are often called \" dynamically typed programming languages \". For a list of such languages, see the category for dynamically typed programming languages . \u603b\u7ed3\uff1a\u8fd9\u91cc\u7ed9\u51fa\u4e86**dynamically typed programming languages**\u7684\u6b63\u786e\u7684\u5b9a\u4e49\u3002python\u5c31\u662f\u4e00\u95e8**dynamically typed programming language**","title":"Dynamic type checking and runtime type information"},{"location":"Theory/Type-system/Type-system/#combining-static-and-dynamic-type-checkingedit","text":"Some languages allow both static and dynamic typing (type checking), sometimes called soft typing. For example, Java and some other ostensibly statically typed languages support downcasting types to their subtypes , querying an object to discover its dynamic type, and other type operations that depend on runtime type information . More generally, most programming languages include mechanisms for dispatching over different 'kinds' of data, such as disjoint unions , subtype polymorphism , and variant types . Even when not interacting with type annotations or type checking, such mechanisms are materially similar to dynamic typing implementations. See programming language for more discussion of the interactions between static and dynamic typing. Objects in object-oriented languages are usually accessed by a reference whose static target type (or manifest type (\u8868\u9762\u7c7b\u578b)) is equal to either the object's run-time type (its latent type (\u6f5c\u85cf\u7c7b\u578b)) or a supertype thereof. This is conformant with the Liskov substitution principle , which states that all operations performed on an instance of a given type can also be performed on an instance of a subtype . This concept is also known as subsumption . In some languages subtypes may also possess covariant or contravariant return types and argument types respectively. Certain languages, for example Clojure , Common Lisp , or Cython are dynamically type-checked by default, but allow programs to opt into static type checking by providing optional annotations . One reason to use such hints would be to optimize the performance of critical sections of a program. This is formalized by gradual typing . The programming environment DrRacket , a pedagogic environment based on Lisp, and a precursor of the language Racket was also soft-typed. Conversely, as of version 4.0, the C# language provides a way to indicate that a variable should not be statically type-checked. A variable whose type is dynamic will not be subject to static type checking. Instead, the program relies on runtime type information to determine how the variable may be used.[ 8]","title":"Combining static and dynamic type checking[edit]"},{"location":"Theory/Type-system/Type-system/#static-and-dynamic-type-checking-in-practice","text":"The choice between static and dynamic typing requires certain trade-offs . Static typing can find type errors reliably at compile time, which should increase the reliability of the delivered program. However, programmers disagree over how commonly type errors occur, resulting in further disagreements over the proportion of those bugs that are coded that would be caught by appropriately representing the designed types in code.[ 9] [ 10] Static typing advocates[ who? ] believe programs are more reliable when they have been well type-checked, whereas dynamic-typing advocates[ who? ] point to distributed code that has proven reliable and to small bug databases.[ citation needed ] The value of static typing, then, presumably[ vague ]increases as the strength of the type system is increased. Advocates of dependent typing ,[ who? ] implemented in languages such as Dependent ML and Epigram , have suggested that almost all bugs can be considered type errors, if the types used in a program are properly declared by the programmer or correctly inferred by the compiler.[ 11] Static typing usually results in compiled code that executes faster. When the compiler knows the exact data types that are in use (which is necessary for static verification, either through declaration or inference) it can produce optimized machine code. Some dynamically typed languages such as Common Lisp allow optional type declarations for optimization for this reason. By contrast, dynamic typing may allow compilers to run faster and interpreters to dynamically load new code, because changes to source code in dynamically typed languages may result in less checking to perform and less code to revisit.[ clarification needed ] This too may reduce the edit-compile-test-debug cycle. Statically typed languages that lack type inference (such as C and Java ) require that programmers declare the types that a method or function must use. This can serve as added program documentation, that is active and dynamic, instead of static. This allows a compiler to prevent it from drifting out of synchrony, and from being ignored by programmers. However, a language can be statically typed without requiring type declarations (examples include Haskell , Scala , OCaml , F# , and to a lesser extent C# and C++ ), so explicit type declaration is not a necessary requirement for static typing in all languages. Dynamic typing allows constructs that some static type checking would reject as illegal. For example, eval functions, which execute arbitrary data as code, become possible. An eval function is possible with static typing, but requires advanced uses of algebraic data types . Further, dynamic typing better accommodates transitional code and prototyping, such as allowing a placeholder data structure ( mock object ) to be transparently used in place of a full data structure (usually for the purposes of experimentation and testing). Dynamic typing typically allows duck typing (which enables easier code reuse ). Many[ specify ] languages with static typing also feature duck typing or other mechanisms like generic programming that also enable easier code reuse. Dynamic typing typically makes metaprogramming easier to use. For example, C++ templates are typically more cumbersome to write than the equivalent Ruby or Python code since C++ has stronger rules regarding type definitions (for both functions and variables). This forces a developer to write more boilerplate code for a template than a Python developer would need to. More advanced run-time constructs such as metaclasses and introspection are often harder to use in statically typed languages. In some languages, such features may also be used e.g. to generate new types and behaviors on the fly, based on run-time data. Such advanced constructs are often provided by dynamic programming languages ; many of these are dynamically typed, although dynamic typing need not be related to dynamic programming languages .","title":"Static and dynamic type checking in practice"},{"location":"Theory/Type-system/Type-system/#strong-and-weak-type-systemsedit","text":"Main article: Strong and weak typing Languages are often colloquially referred to as strongly typed or weakly typed . In fact, there is no universally accepted definition of what these terms mean. In general, there are more precise terms to represent the differences between type systems that lead people to call them \"strong\" or \"weak\".","title":"Strong and weak type systems[edit]"},{"location":"Theory/Type-system/Type-system/#type-safety-and-memory-safetyedit","text":"Main article: Type safety A third way of categorizing the type system of a programming language uses the safety of typed operations and conversions . Computer scientists consider a language \"type-safe\" if it does not allow operations or conversions that violate the rules of the type system. Some observers use the term memory-safe language (or just safe language ) to describe languages that do not allow programs to access memory that has not been assigned for their use. For example, a memory-safe language will check array bounds , or else statically guarantee (i.e., at compile time before execution) that array accesses out of the array boundaries will cause compile-time and perhaps runtime errors. Consider the following program of a language that is both type-safe and memory-safe :[ 12] 1 var x := 5; 2 var y := \"37\"; 3 var z := x + y; In this example, the variable z will have the value 42. Although this may not be what the programmer anticipated, it is a well-defined result. If y were a different string, one that could not be converted to a number (e.g. \"Hello World\"), the result would be well-defined as well. Note that a program can be type-safe or memory-safe and still crash on an invalid operation; in fact, if a program encounters an operation that is not type-safe, terminating the program is often the only option. Now consider a similar example in C: 1 int x = 5 ; 2 char y [] = \"37\" ; 3 char * z = x + y ; In this example z will point to a memory address five characters beyond y , equivalent to three characters after the terminating zero character of the string pointed to by y . This is memory that the program is not expected to access. It may contain garbage data, and it certainly doesn't contain anything useful. As this example shows, C is neither a memory-safe nor a type-safe language. In general, type-safety and memory-safety go hand in hand. For example, a language that supports pointer arithmetic and number-to-pointer conversions (like C) is neither memory-safe nor type-safe , because it allows arbitrary memory to be accessed as if it were valid memory of any type. For more information, see memory safety .","title":"Type safety and memory safety[edit]"},{"location":"Theory/Type-system/Type-system/#variable-levels-of-type-checkingedit","text":"Some languages allow different levels of checking to apply to different regions of code. Examples include: The use strict directive in JavaScript [ 13] [ 14] [ 15] and Perl applies stronger checking. The declare(strict_types=1) in PHP [ 16] on a per-file basis allows only a variable of exact type of the type declaration will be accepted, or a TypeError will be thrown. The Option Strict On in VB.NET allows the compiler to require a conversion between objects. Additional tools such as lint and IBM Rational Purify can also be used to achieve a higher level of strictness.","title":"Variable levels of type checking[edit]"},{"location":"Theory/Type-system/Type-system/#optional-type-systemsedit","text":"It has been proposed, chiefly by Gilad Bracha , that the choice of type system be made independent of choice of language; that a type system should be a module that can be plugged into a language as needed. He believes this is advantageous, because what he calls mandatory type systems make languages less expressive and code more fragile.[ 17] The requirement that types do not affect the semantics of the language is difficult to fulfill. Optional typing is related to gradual typing , but still distinct from it.[ 18] [ better source needed ]","title":"Optional type systems[edit]"},{"location":"Theory/Type-system/Type-system/#polymorphism-and-typesedit","text":"Main article: Polymorphism (computer science) The term polymorphism refers to the ability of code (especially, functions or classes) to act on values of multiple types, or to the ability of different instances of the same data structure to contain elements of different types. Type systems that allow polymorphism generally do so in order to improve the potential for code re-use: in a language with polymorphism, programmers need only implement a data structure such as a list or an associative array once, rather than once for each type of element with which they plan to use it. For this reason computer scientists sometimes call the use of certain forms of polymorphism generic programming . The type-theoretic foundations of polymorphism are closely related to those of abstraction , modularity and (in some cases) subtyping .","title":"Polymorphism and types[edit]"},{"location":"Theory/Type-system/Type-system/#duck-typingedit","text":"Main article: Duck typing In duck typing ,[ 19] a statement calling a method m on an object does not rely on the declared type of the object; only that the object, of whatever type, must supply an implementation of the method called, when called, at run-time. Duck typing differs from structural typing in that, if the part (of the whole module structure) needed for a given local computation is present at runtime , the duck type system is satisfied in its type identity analysis. On the other hand, a structural type system would require the analysis of the whole module structure at compile time to determine type identity or type dependence. Duck typing differs from a nominative type system in a number of aspects. The most prominent ones are that for duck typing, type information is determined at runtime (as contrasted to compile time), and the name of the type is irrelevant to determine type identity or type dependence; only partial structure information is required for that for a given point in the program execution. Duck typing uses the premise that (referring to a value) \"if it walks like a duck, and quacks like a duck, then it is a duck\" (this is a reference to the duck test that is attributed to James Whitcomb Riley ). The term may have been coined[ citation needed ] by Alex Martelli in a 2000 message[ 20] to the comp.lang.python newsgroup (see Python ). While one controlled experiment showed an increase in developer productivity for duck typing in single developer projects,[ 21] other controlled experiments on API usability show the opposite.[ 22] [ 23]","title":"Duck typing[edit]"},{"location":"Theory/Type-system/Type-system/#specialized-type-systemsedit","text":"Many type systems have been created that are specialized for use in certain environments with certain types of data, or for out-of-band static program analysis . Frequently, these are based on ideas from formal type theory and are only available as part of prototype research systems.","title":"Specialized type systems[edit]"},{"location":"Theory/Type-system/Type-system/#dependent-typesedit","text":"Main article: Dependent type Dependent types are based on the idea of using scalars or values to more precisely describe the type of some other value. For example, {\\displaystyle \\mathrm {matrix} (3,3)} might be the type of a {\\displaystyle 3\\times 3} matrix. We can then define typing rules such as the following rule for matrix multiplication: {\\displaystyle \\mathrm {matrix} _{\\mathrm {multiply} }:\\mathrm {matrix} (k,m)\\times \\mathrm {matrix} (m,n)\\to \\mathrm {matrix} (k,n)} where {\\displaystyle k} , {\\displaystyle m} , {\\displaystyle n} are arbitrary positive integer values. A variant of ML called Dependent ML has been created based on this type system, but because type checking for conventional dependent types is undecidable , not all programs using them can be type-checked without some kind of limits. Dependent ML limits the sort of equality it can decide to Presburger arithmetic . Other languages such as Epigram make the value of all expressions in the language decidable so that type checking can be decidable. However, in general proof of decidability is undecidable , so many programs require hand-written annotations that may be very non-trivial. As this impedes the development process, many language implementations provide an easy way out in the form of an option to disable this condition. This, however, comes at the cost of making the type-checker run in an infinite loop when fed programs that do not type-check, causing the compilation to fail.","title":"Dependent types[edit]"},{"location":"Theory/Type-system/Type-system/#linear-typesedit","text":"Main article: Linear type Linear types , based on the theory of linear logic , and closely related to uniqueness types , are types assigned to values having the property that they have one and only one reference to them at all times. These are valuable for describing large immutable values such as files, strings, and so on, because any operation that simultaneously destroys a linear object and creates a similar object (such as ' str= str + \"a\" ') can be optimized \"under the hood\" into an in-place mutation. Normally this is not possible, as such mutations could cause side effects on parts of the program holding other references to the object, violating referential transparency . They are also used in the prototype operating system Singularity for interprocess communication, statically ensuring that processes cannot share objects in shared memory in order to prevent race conditions. The Clean language (a Haskell -like language) uses this type system in order to gain a lot of speed (compared to performing a deep copy) while remaining safe.","title":"Linear types[edit]"},{"location":"Theory/Type-system/Type-system/#intersection-typesedit","text":"Main article: Intersection type Intersection types are types describing values that belong to both of two other given types with overlapping value sets. For example, in most implementations of C the signed char has range -128 to 127 and the unsigned char has range 0 to 255, so the intersection type of these two types would have range 0 to 127. Such an intersection type could be safely passed into functions expecting either signed or unsigned chars, because it is compatible with both types. Intersection types are useful for describing overloaded function types: For example, if \" int \u2192 int \" is the type of functions taking an integer argument and returning an integer, and \" float \u2192 float \" is the type of functions taking a float argument and returning a float, then the intersection of these two types can be used to describe functions that do one or the other, based on what type of input they are given. Such a function could be passed into another function expecting an \" int \u2192 int \" function safely; it simply would not use the \" float \u2192 float \" functionality. In a subclassing hierarchy, the intersection of a type and an ancestor type (such as its parent) is the most derived type. The intersection of sibling types is empty. The Forsythe language includes a general implementation of intersection types. A restricted form is refinement types .","title":"Intersection types[edit]"},{"location":"Theory/Type-system/Type-system/#union-typesedit","text":"Main article: Union type Union types are types describing values that belong to either of two types. For example, in C, the signed char has a -128 to 127 range, and the unsigned char has a 0 to 255 range, so the union of these two types would have an overall \"virtual\" range of -128 to 255 that may be used partially depending on which union member is accessed. Any function handling this union type would have to deal with integers in this complete range. More generally, the only valid operations on a union type are operations that are valid on both types being unioned. C's \"union\" concept is similar to union types, but is not typesafe, as it permits operations that are valid on either*type, rather than *both . Union types are important in program analysis, where they are used to represent symbolic values whose exact nature (e.g., value or type) is not known. In a subclassing hierarchy, the union of a type and an ancestor type (such as its parent) is the ancestor type. The union of sibling types is a subtype of their common ancestor (that is, all operations permitted on their common ancestor are permitted on the union type, but they may also have other valid operations in common).","title":"Union types[edit]"},{"location":"Theory/Type-system/Type-system/#existential-typesedit","text":"Main article: Existential quantifier Existential types are frequently used in connection with record types to represent modules and abstract data types , due to their ability to separate implementation from interface. For example, the type \"T = \u2203X { a: X; f: (X \u2192 int); }\" describes a module interface that has a data member named a of type X and a function named f that takes a parameter of the same type X and returns an integer. This could be implemented in different ways; for example: intT = { a: int; f: (int \u2192 int); } floatT = { a: float; f: (float \u2192 int); } These types are both subtypes of the more general existential type T and correspond to concrete implementation types, so any value of one of these types is a value of type T. Given a value \"t\" of type \"T\", we know that \"t.f(t.a)\" is well-typed, regardless of what the abstract type X is. This gives flexibility for choosing types suited to a particular implementation while clients that use only values of the interface type\u2014the existential type\u2014are isolated from these choices. In general it's impossible for the typechecker to infer which existential type a given module belongs to. In the above example intT { a: int; f: (int \u2192 int); } could also have the type \u2203X { a: X; f: (int \u2192 int); }. The simplest solution is to annotate every module with its intended type, e.g.: intT = { a: int; f: (int \u2192 int); } as \u2203X { a: X; f: (X \u2192 int); } Although abstract data types and modules had been implemented in programming languages for quite some time, it wasn't until 1988 that John C. Mitchell and Gordon Plotkin established the formal theory under the slogan: \"Abstract [data] types have existential type\".[ 24] The theory is a second-order typed lambda calculus similar to System F , but with existential instead of universal quantification.","title":"Existential types[edit]"},{"location":"Theory/Type-system/Type-system/#gradual-typingedit","text":"Main article: Gradual typing Gradual typing is a type system in which variables may be typed either at compile-time (which is static typing) or at run-time (which is dynamic typing), allowing software developers to choose either type paradigm as appropriate, from within a single language.[ 25] In particular, gradual typing uses a special type named dynamic*to represent statically-unknown types, and gradual typing replaces the notion of type equality with a new relation called *consistency that relates the dynamic type to every other type. The consistency relation is symmetric but not transitive.[ 26]","title":"Gradual typing[edit]"},{"location":"Theory/Type-system/Type-system/#explicit-or-implicit-declaration-and-inference","text":"Further information: Type inference Many static type systems, such as those of C and Java, require type declarations : The programmer must explicitly associate each variable with a specific type. Others, such as Haskell's, perform type inference : The compiler draws conclusions about the types of variables based on how programmers use those variables. For example, given a function f(x, y) that adds x and y together, the compiler can infer that x and y must be numbers \u2013 since addition is only defined for numbers. Thus, any call to f elsewhere in the program that specifies a non-numeric type (such as a string or list) as an argument would signal an error. Numerical and string constants and expressions in code can and often do imply type in a particular context. For example, an expression 3.14 might imply a type of floating-point , while [1, 2, 3] might imply a list of integers \u2013 typically an array . Type inference is in general possible, if it is decidable in the type theory in question. Moreover, even if inference is undecidable in general for a given type theory, inference is often possible for a large subset of real-world programs. Haskell's type system, a version of Hindley\u2013Milner , is a restriction of System F\u03c9 to so-called rank-1 polymorphic types, in which type inference is decidable. Most Haskell compilers allow arbitrary-rank polymorphism as an extension, but this makes type inference undecidable. (Type checking is decidable, however, and rank-1 programs still have type inference; higher rank polymorphic programs are rejected unless given explicit type annotations.)","title":"Explicit or implicit declaration and inference"},{"location":"Theory/Type-system/Type-system/#unified-type-systemedit","text":"Some languages like Perl 6 or C# have a unified type system.[ 27] This means that all C# types including primitive types inherit from a single root object. Every type in C# inherits from the Object class. Java has several primitive types that are not objects. Java provides wrapper object types that exist together with the primitive types so developers can use either the wrapper object types or the simpler non-object primitive types.","title":"Unified type system[edit]"},{"location":"Theory/Type-system/Type-system/#compatibility-equivalence-and-subtypingedit","text":"A type-checker for a statically typed language must verify that the type of any expression is consistent with the type expected by the context in which that expression appears. For example, in an assignment statement of the form x := *e* , the inferred type of the expression e must be consistent with the declared or inferred type of the variable x . This notion of consistency, called compatibility , is specific to each programming language. If the type of e and the type of x are the same, and assignment is allowed for that type, then this is a valid expression. Thus, in the simplest type systems, the question of whether two types are compatible reduces to that of whether they are equal (or equivalent ). Different languages, however, have different criteria for when two type expressions are understood to denote the same type. These different equational theories of types vary widely, two extreme cases being structural type systems , in which any two types that describe values with the same structure are equivalent, and nominative type systems , in which no two syntactically distinct type expressions denote the same type ( i.e. , types must have the same \"name\" in order to be equal). In languages with subtyping , the compatibility relation is more complex. In particular, if A is a subtype of B , then a value of type A can be used in a context where one of type B is expected, even if the reverse is not true. Like equivalence, the subtype relation is defined differently for each programming language, with many variations possible. The presence of parametric or ad hoc polymorphism in a language may also have implications for type compatibility.","title":"Compatibility: equivalence and subtyping[edit]"},{"location":"Theory/Type-system/Type-system/#notesedit","text":"Jump up^ The Burroughs ALGOL computer line determined a memory location's contents by its flag bits. Flag bits specify the contents of a memory location. Instruction, data type, and functions are specified by a 3 bit code in addition to its 48 bit contents. Only the MCP (Master Control Program) could write to the flag code bits.","title":"Notes[edit]"},{"location":"Theory/Type-system/Type-system/#see-alsoedit","text":"Computer programming portal Comparison of type systems Covariance and contravariance (computer science) Polymorphism in object-oriented programming Type rules Type signature Type theory","title":"See also[edit]"},{"location":"Theory/Type-system/Type-system/#referencesedit","text":"Jump up^ Pierce 2002 , p. 1: \"A type system is a tractable syntactic method for proving the absence of certain program behaviors by classifying phrases according to the kinds of values they compute.\" Jump up^ Cardelli 2004 , p. 1: \"The fundamental purpose of a type system is to prevent the occurrence of execution errors during the running of a program.\" Jump up^ Pierce 2002 , p. 208. Jump up^ Infoworld 25 April 1983 Jump up^ Brian Kernighan : Why Pascal is not my favorite language Jump up^ \"... any sound, decidable type system must be incomplete\" \u2014D. Remy (2017). p. 29, Remy, Didier. \"Type systems for programming languages\" (PDF). Retrieved 26 May2013. Jump up^ Pierce 2002 . Jump up^ \"dynamic (C# Reference)\" . MSDN Library . Microsoft. Retrieved 14 January 2014. Jump up^ Meijer, Erik; Drayton, Peter. \"Static Typing Where Possible, Dynamic Typing When Needed: The End of the Cold War Between Programming Languages\" (PDF). Microsoft Corporation. Jump up^ Laucher, Amanda; Snively, Paul. \"Types vs Tests\" . InfoQ. Jump up^ Xi, Hongwei; Scott, Dana (1998). \"Dependent Types in Practical Programming\". Proceedings of ACM SIGPLAN Symposium on Principles of Programming Languages . ACM Press: 214\u2013227. CiteSeerX 10.1.1.41.548 \u202f . Jump up^ Visual Basic is an example of a language that is both type-safe and memory-safe. Jump up^ Standard ECMA-262 . Ecma-international.org. Retrieved on 2013-07-17. Jump up^ Strict mode - JavaScript | MDN . Developer.mozilla.org (2013-07-03). Retrieved on 2013-07-17. Jump up^ Strict Mode (JavaScript) . Msdn.microsoft.com. Retrieved on 2013-07-17. Jump up^ Strict typing Jump up^ Bracha, G.: Pluggable Types Jump up^ https://stackoverflow.com/a/13414347/975097 Jump up^ Rozsnyai, S.; Schiefer, J.; Schatten, A. (2007). \"Concepts and models for typing events for event-based systems\". Proceedings of the 2007 inaugural international conference on Distributed event-based systems \u2013 DEBS '07 . p. 62. doi : 10.1145/1266894.1266904 . ISBN 9781595936653 . Jump up^ Martelli, Alex (26 July 2000). \"Re: polymorphism (was Re: Type checking in python?)\" . Usenet: 8lmvn6017l@news1.newsguy.com . Jump up^ Stefan Hanenberg. \u201dAn experiment about static and dynamic type systems: doubts about the positive impact of static type systems on development time\u201c. OOPSLA 2010. Jump up^ Kleinschmager, Hanenberg, Robbes, Tanter, Stefik: Do static type systems improve the maintainability of software systems? An empirical study. ICPC 2012 Jump up^ Hanenberg, Kleinschmager, S.Robbes, R.Tanter, Stefik: An empirical study on the impact of static typing on software maintainability, ESE 2014 Jump up^ Mitchell, John C.; Plotkin, Gordon D.; Abstract Types Have Existential Type , ACM Transactions on Programming Languages and Systems, Vol. 10, No. 3, July 1988, pp. 470\u2013502 Jump up^ Siek, Jeremy. \"What is gradual typing?\" . Jump up^ Siek, Jeremy; Taha, Walid (September 2006). Gradual Typing for Functional Languages (PDF). Scheme and Functional Programming 2006 . University of Chicago . pp. 81\u201392. Jump up^ Standard ECMA-334 , 8.2.4 Type system unification.","title":"References[edit]"},{"location":"Theory/Type-system/Type-system/#further-reading","text":"","title":"Further reading"},{"location":"Theory/Type-system/Type/","text":"Type \u63d0\u8d77type\uff0c\u6709\u975e\u5e38\u591a\u4e0e\u4e4b\u76f8\u5173\u7684\u6982\u5ff5\u3002\u5728\u7ef4\u57fa\u767e\u79d1 Type system \u4e2d\uff0c\u603b\u7ed3\u4e86\u4e0etype system\u76f8\u5173\u7684\u6982\u5ff5\u3002 Subtyping Downcasting Type conversion static type and runtime type \u5728\u6587\u7ae0 A polyglot's guide to multiple dispatch \u4e2d\uff0c\u63d0\u51fa\u4e86static type\u548cdynamic type\u7684\u6982\u5ff5\u3002","title":"Type"},{"location":"Theory/Type-system/Type/#type","text":"\u63d0\u8d77type\uff0c\u6709\u975e\u5e38\u591a\u4e0e\u4e4b\u76f8\u5173\u7684\u6982\u5ff5\u3002\u5728\u7ef4\u57fa\u767e\u79d1 Type system \u4e2d\uff0c\u603b\u7ed3\u4e86\u4e0etype system\u76f8\u5173\u7684\u6982\u5ff5\u3002","title":"Type"},{"location":"Theory/Type-system/Type/#subtyping","text":"","title":"Subtyping"},{"location":"Theory/Type-system/Type/#downcasting","text":"","title":"Downcasting"},{"location":"Theory/Type-system/Type/#type-conversion","text":"","title":"Type conversion"},{"location":"Theory/Type-system/Type/#static-type-and-runtime-type","text":"\u5728\u6587\u7ae0 A polyglot's guide to multiple dispatch \u4e2d\uff0c\u63d0\u51fa\u4e86static type\u548cdynamic type\u7684\u6982\u5ff5\u3002","title":"static type and runtime type"}]}